{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5491b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947d0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
    "sys.path.append(pose_sample_rpi_path)\n",
    "\n",
    "# Load MoveNet Thunder model\n",
    "import utils\n",
    "from data import BodyPart\n",
    "from ml import Movenet\n",
    "movenet = Movenet('movenet_thunder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e4b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/shellygoel2324/data_merged.csv'\n",
    "#labels_path = '/home/shellygoel2324/processedLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9d37956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pose_landmarks(csv_path):\n",
    "    \"\"\"Loads a CSV created by MoveNetPreprocessor.\n",
    "    Returns:\n",
    "        X: Detected landmark coordinates and scores of shape (N, 17 * 3)\n",
    "        y: Ground truth labels of shape (N, label_count)\n",
    "        classes: The list of all class names found in the dataset\n",
    "        dataframe: The CSV loaded as a Pandas dataframe features (X) and ground\n",
    "        truth labels (y) to use later to train a pose classification model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    \n",
    "    dataframe[\"label\"] = dataframe[\"label\"] - 1\n",
    "  \n",
    "    print(dataframe[\"label\"].unique())\n",
    "    \n",
    "    \n",
    "    curr_num = dataframe.loc[dataframe['label'] == 0]\n",
    "    \n",
    "    dataFinal = curr_num.sample(n=5000)\n",
    "    #print(f\"{i}:{curr_num_sub.shape}\")\n",
    "    #dataFinal.append(curr_num_sub)\n",
    "    \n",
    "    print(f\"{0}:{dataFinal.shape}\")\n",
    "    \n",
    "    '''\n",
    "    0: 5000\n",
    "    1:2500*2\n",
    "        2: 1000*5\n",
    "            3:250*20\n",
    "                4: 250*20\n",
    "                    5: 50*100\n",
    "                \n",
    "    '''\n",
    "        \n",
    "    for i in range(1, 6):\n",
    "        \n",
    "        curr_num = dataframe.loc[dataframe['label'] == i]\n",
    "        \n",
    "        '''\n",
    "        num_s = 0\n",
    "        if i == 1:\n",
    "            num_s = 2\n",
    "        if i == 2:\n",
    "            num_s = 5\n",
    "        if i == 3:\n",
    "            num_s = 20\n",
    "        if i == 4:\n",
    "            num_s = 20     \n",
    "        if i == 5:\n",
    "            num_s = 100\n",
    "            '''\n",
    "            \n",
    "        curr_num_sub = curr_num.sample(n=5000, replace = True)\n",
    "        print(f\"{i}:{curr_num_sub.shape}\")\n",
    "        dataFinal = dataFinal.append(curr_num_sub, ignore_index=True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(dataFinal.shape)\n",
    "    \n",
    "    dataframe = dataFinal\n",
    "    labels = dataframe[\"label\"]#pd.read_csv(labels_path, header=None)\n",
    "    \n",
    "    print(labels.unique())\n",
    "    df_to_process = dataframe.copy()\n",
    "\n",
    "    # Drop the file_name columns as you don't need it during training.\n",
    "    df_to_process.drop(columns=['file_name'], inplace=True)\n",
    "\n",
    "    # Extract the list of class names\n",
    "    df_to_process.pop('class_name')\n",
    "    df_to_process.pop('class_no')\n",
    "    df_to_process.pop('label')\n",
    "\n",
    "    # Extract the labels\n",
    "    y = labels\n",
    "    classes = range(6)\n",
    "\n",
    "    # Convert the input features and labels into the correct format for training.\n",
    "    X = df_to_process.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "\n",
    "    return X, y, classes, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d93bd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 1. 2. 4. 5.]\n",
      "0:(5000, 55)\n",
      "1:(5000, 55)\n",
      "2:(5000, 55)\n",
      "3:(5000, 55)\n",
      "4:(5000, 55)\n",
      "5:(5000, 55)\n",
      "(30000, 55)\n",
      "[0. 1. 2. 3. 4. 5.]\n",
      "(30000, 51) (30000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the train data\n",
    "X, y, class_names, _ = load_pose_landmarks(data_path)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Split training data (X, y) into (X_train, y_train) and (X_val, y_val)\n",
    "\n",
    "# 80/10/10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "#print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "#60/20/20\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ead317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DISTRIBUTION\n",
      "0: 0.16495833333333335\n",
      "0: 3959\n",
      "1: 0.16629166666666667\n",
      "1: 3991\n",
      "2: 0.1675\n",
      "2: 4020\n",
      "3: 0.16695833333333332\n",
      "3: 4007\n",
      "4: 0.167125\n",
      "4: 4011\n",
      "5: 0.16716666666666666\n",
      "5: 4012\n",
      "\n",
      "TEST DISTRIBUTION\n",
      "0: 0.17333333333333334\n",
      "1: 0.168\n",
      "2: 0.165\n",
      "3: 0.159\n",
      "4: 0.16533333333333333\n",
      "5: 0.16933333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DISTRIBUTION\")\n",
    "\n",
    "sample_dist = []\n",
    "for i in range(0,6):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_train:\n",
    "            if tf.argmax(sample) == i:\n",
    "                num_i+=1\n",
    "    dist = num_i/len(y_train)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    print(f\"{i}: {num_i}\")\n",
    "    sample_dist.append(dist)\n",
    "\n",
    "\n",
    "print(\"\\nTEST DISTRIBUTION\")\n",
    "for i in range(0,6):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_test:\n",
    "            if tf.argmax(sample) == i:\n",
    "                num_i+=1\n",
    "\n",
    "    dist = num_i/len(y_test)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    #sample_dist.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb51e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "134c92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40405853 0.40732448 0.41028424 0.40895745 0.40936569 0.40946775]\n",
      "[2.474888942451101, 2.455045182451493, 2.43733465750346, 2.445242157016199, 2.4428036208336845, 2.442194746551323]\n"
     ]
    }
   ],
   "source": [
    "sample_dist = sample_dist/np.linalg.norm(sample_dist)\n",
    "weight_balanced= [1/s for s in sample_dist]\n",
    "\n",
    "print(sample_dist)\n",
    "print(weight_balanced)\n",
    "#weight_balanced = weight_balanced/np.linalg.norm(weight_balanced)\n",
    "#print(weight_balanced)\n",
    "#print(np.sum(weight_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f5e271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "for i in range(6):\n",
    "    class_weights[i] = weight_balanced[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "348958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    \n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center\n",
    "\n",
    "\n",
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "\n",
    "        It is the maximum of two values:\n",
    "        * Torso size multiplied by `torso_size_multiplier`\n",
    "        * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "    return pose_size\n",
    "\n",
    "\n",
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "        scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "    # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def no_normalization(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    landmarks = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Flatten the landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks[:, :, :2])\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cea2f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c23041",
   "metadata": {},
   "source": [
    "## Normalize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28566ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 51)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 17, 3)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 17, 2)       0           ['reshape[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpLambd  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " a)                                                              ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_1 (TFOpLam  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " bda)                                                            ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2)            0           ['tf.compat.v1.gather[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_1[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['tf.math.multiply[0][0]',       \n",
      " da)                                                              'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size (TFOpLambda)  ()                  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 2)         0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div (TFOpLa  ()                  0           ['tf.compat.v1.size[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.broadcast_to (TFOpLambda)   (None, 17, 2)        0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.compat.v1.floor_div[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 17, 2)        0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.broadcast_to[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_6 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_7 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_6[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_7[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 2)           0           ['tf.math.multiply_6[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_1 (TFOpLambd  ()                  0           ['tf.math.subtract[0][0]']       \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_4 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_5 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_2 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_3 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_1 (TFOp  ()                  0           ['tf.compat.v1.size_1[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_5[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_3[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.broadcast_to_1 (TFOpLambda)  (None, 17, 2)       0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 2)           0           ['tf.math.multiply_4[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 2)           0           ['tf.math.multiply_2[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 17, 2)       0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.broadcast_to_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_2[0][0]', \n",
      " )                                                                'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_8 (TFOpLam  (17, 2)             0           ['tf.math.subtract_2[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm (TFOpLambda)  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_1 (TFOpLambd  (2,)                0           ['tf.compat.v1.gather_8[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  ()                  0           ['tf.compat.v1.norm[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['tf.compat.v1.norm_1[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   ()                   0           ['tf.math.multiply_8[0][0]',     \n",
      "                                                                  'tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 17, 2)        0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.maximum[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 34)           0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          4480        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,126\n",
      "Trainable params: 13,126\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = landmarks_to_embedding(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ebdb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9df7224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1481/1500 [============================>.] - ETA: 0s - loss: 0.1870 - tp: 4824.0000 - fp: 720.0000 - tn: 117760.0000 - fn: 18872.0000 - accuracy: 0.8622 - precision: 0.8701 - recall: 0.2036 - auc: 0.8936 - prc: 0.6644\n",
      "Epoch 1: val_loss improved from inf to 0.12727, saving model to weights.best.onlyfocalloss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 04:35:43.563650: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.1866 - tp: 4930.0000 - fp: 733.0000 - tn: 119267.0000 - fn: 19070.0000 - accuracy: 0.8625 - precision: 0.8706 - recall: 0.2054 - auc: 0.8940 - prc: 0.6657 - val_loss: 0.1273 - val_tp: 1250.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 1750.0000 - val_accuracy: 0.8967 - val_precision: 0.9198 - val_recall: 0.4167 - val_auc: 0.9543 - val_prc: 0.8291\n",
      "Epoch 2/200\n",
      "1481/1500 [============================>.] - ETA: 0s - loss: 0.1378 - tp: 9118.0000 - fp: 1086.0000 - tn: 117394.0000 - fn: 14578.0000 - accuracy: 0.8898 - precision: 0.8936 - recall: 0.3848 - auc: 0.9450 - prc: 0.7965\n",
      "Epoch 2: val_loss improved from 0.12727 to 0.10641, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1378 - tp: 9247.0000 - fp: 1105.0000 - tn: 118895.0000 - fn: 14753.0000 - accuracy: 0.8899 - precision: 0.8933 - recall: 0.3853 - auc: 0.9450 - prc: 0.7964 - val_loss: 0.1064 - val_tp: 1582.0000 - val_fp: 123.0000 - val_tn: 14877.0000 - val_fn: 1418.0000 - val_accuracy: 0.9144 - val_precision: 0.9279 - val_recall: 0.5273 - val_auc: 0.9677 - val_prc: 0.8716\n",
      "Epoch 3/200\n",
      "1487/1500 [============================>.] - ETA: 0s - loss: 0.1239 - tp: 10880.0000 - fp: 1161.0000 - tn: 117799.0000 - fn: 12912.0000 - accuracy: 0.9014 - precision: 0.9036 - recall: 0.4573 - auc: 0.9559 - prc: 0.8316\n",
      "Epoch 3: val_loss improved from 0.10641 to 0.09934, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1238 - tp: 10982.0000 - fp: 1172.0000 - tn: 118828.0000 - fn: 13018.0000 - accuracy: 0.9015 - precision: 0.9036 - recall: 0.4576 - auc: 0.9560 - prc: 0.8320 - val_loss: 0.0993 - val_tp: 1720.0000 - val_fp: 151.0000 - val_tn: 14849.0000 - val_fn: 1280.0000 - val_accuracy: 0.9205 - val_precision: 0.9193 - val_recall: 0.5733 - val_auc: 0.9728 - val_prc: 0.8865\n",
      "Epoch 4/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.1159 - tp: 12093.0000 - fp: 1185.0000 - tn: 118655.0000 - fn: 11875.0000 - accuracy: 0.9092 - precision: 0.9108 - recall: 0.5045 - auc: 0.9618 - prc: 0.8519\n",
      "Epoch 4: val_loss improved from 0.09934 to 0.09330, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1159 - tp: 12109.0000 - fp: 1188.0000 - tn: 118812.0000 - fn: 11891.0000 - accuracy: 0.9092 - precision: 0.9107 - recall: 0.5045 - auc: 0.9618 - prc: 0.8517 - val_loss: 0.0933 - val_tp: 1809.0000 - val_fp: 135.0000 - val_tn: 14865.0000 - val_fn: 1191.0000 - val_accuracy: 0.9263 - val_precision: 0.9306 - val_recall: 0.6030 - val_auc: 0.9762 - val_prc: 0.9008\n",
      "Epoch 5/200\n",
      "1487/1500 [============================>.] - ETA: 0s - loss: 0.1104 - tp: 12767.0000 - fp: 1244.0000 - tn: 117716.0000 - fn: 11025.0000 - accuracy: 0.9141 - precision: 0.9112 - recall: 0.5366 - auc: 0.9655 - prc: 0.8640\n",
      "Epoch 5: val_loss improved from 0.09330 to 0.08998, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1105 - tp: 12864.0000 - fp: 1256.0000 - tn: 118744.0000 - fn: 11136.0000 - accuracy: 0.9139 - precision: 0.9110 - recall: 0.5360 - auc: 0.9654 - prc: 0.8639 - val_loss: 0.0900 - val_tp: 1824.0000 - val_fp: 124.0000 - val_tn: 14876.0000 - val_fn: 1176.0000 - val_accuracy: 0.9278 - val_precision: 0.9363 - val_recall: 0.6080 - val_auc: 0.9778 - val_prc: 0.9082\n",
      "Epoch 6/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.1076 - tp: 13430.0000 - fp: 1232.0000 - tn: 118528.0000 - fn: 10522.0000 - accuracy: 0.9182 - precision: 0.9160 - recall: 0.5607 - auc: 0.9673 - prc: 0.8720\n",
      "Epoch 6: val_loss improved from 0.08998 to 0.08782, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1076 - tp: 13455.0000 - fp: 1233.0000 - tn: 118767.0000 - fn: 10545.0000 - accuracy: 0.9182 - precision: 0.9161 - recall: 0.5606 - auc: 0.9673 - prc: 0.8721 - val_loss: 0.0878 - val_tp: 1919.0000 - val_fp: 141.0000 - val_tn: 14859.0000 - val_fn: 1081.0000 - val_accuracy: 0.9321 - val_precision: 0.9316 - val_recall: 0.6397 - val_auc: 0.9790 - val_prc: 0.9126\n",
      "Epoch 7/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.1048 - tp: 13726.0000 - fp: 1244.0000 - tn: 118196.0000 - fn: 10162.0000 - accuracy: 0.9204 - precision: 0.9169 - recall: 0.5746 - auc: 0.9693 - prc: 0.8777\n",
      "Epoch 7: val_loss improved from 0.08782 to 0.08716, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1048 - tp: 13786.0000 - fp: 1249.0000 - tn: 118751.0000 - fn: 10214.0000 - accuracy: 0.9204 - precision: 0.9169 - recall: 0.5744 - auc: 0.9693 - prc: 0.8777 - val_loss: 0.0872 - val_tp: 1895.0000 - val_fp: 134.0000 - val_tn: 14866.0000 - val_fn: 1105.0000 - val_accuracy: 0.9312 - val_precision: 0.9340 - val_recall: 0.6317 - val_auc: 0.9796 - val_prc: 0.9138\n",
      "Epoch 8/200\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.1026 - tp: 13892.0000 - fp: 1200.0000 - tn: 117360.0000 - fn: 9820.0000 - accuracy: 0.9225 - precision: 0.9205 - recall: 0.5859 - auc: 0.9704 - prc: 0.8831\n",
      "Epoch 8: val_loss improved from 0.08716 to 0.08528, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1028 - tp: 14052.0000 - fp: 1217.0000 - tn: 118783.0000 - fn: 9948.0000 - accuracy: 0.9225 - precision: 0.9203 - recall: 0.5855 - auc: 0.9702 - prc: 0.8828 - val_loss: 0.0853 - val_tp: 1876.0000 - val_fp: 133.0000 - val_tn: 14867.0000 - val_fn: 1124.0000 - val_accuracy: 0.9302 - val_precision: 0.9338 - val_recall: 0.6253 - val_auc: 0.9805 - val_prc: 0.9182\n",
      "Epoch 9/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.1010 - tp: 14173.0000 - fp: 1204.0000 - tn: 118476.0000 - fn: 9763.0000 - accuracy: 0.9236 - precision: 0.9217 - recall: 0.5921 - auc: 0.9716 - prc: 0.8867\n",
      "Epoch 9: val_loss improved from 0.08528 to 0.08221, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1011 - tp: 14210.0000 - fp: 1207.0000 - tn: 118793.0000 - fn: 9790.0000 - accuracy: 0.9236 - precision: 0.9217 - recall: 0.5921 - auc: 0.9715 - prc: 0.8867 - val_loss: 0.0822 - val_tp: 2010.0000 - val_fp: 145.0000 - val_tn: 14855.0000 - val_fn: 990.0000 - val_accuracy: 0.9369 - val_precision: 0.9327 - val_recall: 0.6700 - val_auc: 0.9819 - val_prc: 0.9226\n",
      "Epoch 10/200\n",
      "1487/1500 [============================>.] - ETA: 0s - loss: 0.1001 - tp: 14252.0000 - fp: 1227.0000 - tn: 117733.0000 - fn: 9540.0000 - accuracy: 0.9246 - precision: 0.9207 - recall: 0.5990 - auc: 0.9721 - prc: 0.8888\n",
      "Epoch 10: val_loss improved from 0.08221 to 0.08115, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1000 - tp: 14384.0000 - fp: 1237.0000 - tn: 118763.0000 - fn: 9616.0000 - accuracy: 0.9246 - precision: 0.9208 - recall: 0.5993 - auc: 0.9721 - prc: 0.8889 - val_loss: 0.0812 - val_tp: 2022.0000 - val_fp: 138.0000 - val_tn: 14862.0000 - val_fn: 978.0000 - val_accuracy: 0.9380 - val_precision: 0.9361 - val_recall: 0.6740 - val_auc: 0.9820 - val_prc: 0.9258\n",
      "Epoch 11/200\n",
      "1481/1500 [============================>.] - ETA: 0s - loss: 0.0980 - tp: 14499.0000 - fp: 1269.0000 - tn: 117211.0000 - fn: 9197.0000 - accuracy: 0.9264 - precision: 0.9195 - recall: 0.6119 - auc: 0.9732 - prc: 0.8932\n",
      "Epoch 11: val_loss improved from 0.08115 to 0.07884, saving model to weights.best.onlyfocalloss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0980 - tp: 14680.0000 - fp: 1289.0000 - tn: 118711.0000 - fn: 9320.0000 - accuracy: 0.9263 - precision: 0.9193 - recall: 0.6117 - auc: 0.9732 - prc: 0.8932 - val_loss: 0.0788 - val_tp: 2039.0000 - val_fp: 133.0000 - val_tn: 14867.0000 - val_fn: 961.0000 - val_accuracy: 0.9392 - val_precision: 0.9388 - val_recall: 0.6797 - val_auc: 0.9832 - val_prc: 0.9298\n",
      "Epoch 12/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0964 - tp: 14759.0000 - fp: 1281.0000 - tn: 118159.0000 - fn: 9129.0000 - accuracy: 0.9274 - precision: 0.9201 - recall: 0.6178 - auc: 0.9740 - prc: 0.8965\n",
      "Epoch 12: val_loss did not improve from 0.07884\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0964 - tp: 14831.0000 - fp: 1285.0000 - tn: 118715.0000 - fn: 9169.0000 - accuracy: 0.9274 - precision: 0.9203 - recall: 0.6180 - auc: 0.9740 - prc: 0.8965 - val_loss: 0.0804 - val_tp: 1967.0000 - val_fp: 112.0000 - val_tn: 14888.0000 - val_fn: 1033.0000 - val_accuracy: 0.9364 - val_precision: 0.9461 - val_recall: 0.6557 - val_auc: 0.9829 - val_prc: 0.9287\n",
      "Epoch 13/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0956 - tp: 14922.0000 - fp: 1203.0000 - tn: 118477.0000 - fn: 9014.0000 - accuracy: 0.9289 - precision: 0.9254 - recall: 0.6234 - auc: 0.9747 - prc: 0.8988\n",
      "Epoch 13: val_loss improved from 0.07884 to 0.07746, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0956 - tp: 14961.0000 - fp: 1205.0000 - tn: 118795.0000 - fn: 9039.0000 - accuracy: 0.9289 - precision: 0.9255 - recall: 0.6234 - auc: 0.9747 - prc: 0.8987 - val_loss: 0.0775 - val_tp: 2045.0000 - val_fp: 119.0000 - val_tn: 14881.0000 - val_fn: 955.0000 - val_accuracy: 0.9403 - val_precision: 0.9450 - val_recall: 0.6817 - val_auc: 0.9839 - val_prc: 0.9314\n",
      "Epoch 14/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0951 - tp: 14981.0000 - fp: 1274.0000 - tn: 117926.0000 - fn: 8859.0000 - accuracy: 0.9292 - precision: 0.9216 - recall: 0.6284 - auc: 0.9748 - prc: 0.8999\n",
      "Epoch 14: val_loss improved from 0.07746 to 0.07615, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0950 - tp: 15089.0000 - fp: 1281.0000 - tn: 118719.0000 - fn: 8911.0000 - accuracy: 0.9292 - precision: 0.9217 - recall: 0.6287 - auc: 0.9748 - prc: 0.8999 - val_loss: 0.0761 - val_tp: 2011.0000 - val_fp: 106.0000 - val_tn: 14894.0000 - val_fn: 989.0000 - val_accuracy: 0.9392 - val_precision: 0.9499 - val_recall: 0.6703 - val_auc: 0.9845 - val_prc: 0.9348\n",
      "Epoch 15/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0927 - tp: 15198.0000 - fp: 1247.0000 - tn: 118593.0000 - fn: 8770.0000 - accuracy: 0.9303 - precision: 0.9242 - recall: 0.6341 - auc: 0.9762 - prc: 0.9042\n",
      "Epoch 15: val_loss did not improve from 0.07615\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0927 - tp: 15216.0000 - fp: 1250.0000 - tn: 118750.0000 - fn: 8784.0000 - accuracy: 0.9303 - precision: 0.9241 - recall: 0.6340 - auc: 0.9762 - prc: 0.9042 - val_loss: 0.0773 - val_tp: 2066.0000 - val_fp: 134.0000 - val_tn: 14866.0000 - val_fn: 934.0000 - val_accuracy: 0.9407 - val_precision: 0.9391 - val_recall: 0.6887 - val_auc: 0.9839 - val_prc: 0.9317\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0924 - tp: 15305.0000 - fp: 1242.0000 - tn: 118758.0000 - fn: 8695.0000 - accuracy: 0.9310 - precision: 0.9249 - recall: 0.6377 - auc: 0.9763 - prc: 0.9057\n",
      "Epoch 16: val_loss improved from 0.07615 to 0.07472, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0924 - tp: 15305.0000 - fp: 1242.0000 - tn: 118758.0000 - fn: 8695.0000 - accuracy: 0.9310 - precision: 0.9249 - recall: 0.6377 - auc: 0.9763 - prc: 0.9057 - val_loss: 0.0747 - val_tp: 2076.0000 - val_fp: 128.0000 - val_tn: 14872.0000 - val_fn: 924.0000 - val_accuracy: 0.9416 - val_precision: 0.9419 - val_recall: 0.6920 - val_auc: 0.9850 - val_prc: 0.9361\n",
      "Epoch 17/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0909 - tp: 15449.0000 - fp: 1263.0000 - tn: 117937.0000 - fn: 8391.0000 - accuracy: 0.9325 - precision: 0.9244 - recall: 0.6480 - auc: 0.9771 - prc: 0.9082\n",
      "Epoch 17: val_loss improved from 0.07472 to 0.07151, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0909 - tp: 15550.0000 - fp: 1272.0000 - tn: 118728.0000 - fn: 8450.0000 - accuracy: 0.9325 - precision: 0.9244 - recall: 0.6479 - auc: 0.9771 - prc: 0.9081 - val_loss: 0.0715 - val_tp: 2102.0000 - val_fp: 114.0000 - val_tn: 14886.0000 - val_fn: 898.0000 - val_accuracy: 0.9438 - val_precision: 0.9486 - val_recall: 0.7007 - val_auc: 0.9862 - val_prc: 0.9425\n",
      "Epoch 18/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0911 - tp: 15500.0000 - fp: 1271.0000 - tn: 118569.0000 - fn: 8468.0000 - accuracy: 0.9323 - precision: 0.9242 - recall: 0.6467 - auc: 0.9770 - prc: 0.9080\n",
      "Epoch 18: val_loss did not improve from 0.07151\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0911 - tp: 15521.0000 - fp: 1273.0000 - tn: 118727.0000 - fn: 8479.0000 - accuracy: 0.9323 - precision: 0.9242 - recall: 0.6467 - auc: 0.9770 - prc: 0.9080 - val_loss: 0.0735 - val_tp: 2085.0000 - val_fp: 119.0000 - val_tn: 14881.0000 - val_fn: 915.0000 - val_accuracy: 0.9426 - val_precision: 0.9460 - val_recall: 0.6950 - val_auc: 0.9854 - val_prc: 0.9390\n",
      "Epoch 19/200\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.0911 - tp: 15318.0000 - fp: 1216.0000 - tn: 117344.0000 - fn: 8394.0000 - accuracy: 0.9325 - precision: 0.9265 - recall: 0.6460 - auc: 0.9770 - prc: 0.9074\n",
      "Epoch 19: val_loss did not improve from 0.07151\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0912 - tp: 15504.0000 - fp: 1233.0000 - tn: 118767.0000 - fn: 8496.0000 - accuracy: 0.9324 - precision: 0.9263 - recall: 0.6460 - auc: 0.9770 - prc: 0.9073 - val_loss: 0.0734 - val_tp: 2088.0000 - val_fp: 124.0000 - val_tn: 14876.0000 - val_fn: 912.0000 - val_accuracy: 0.9424 - val_precision: 0.9439 - val_recall: 0.6960 - val_auc: 0.9855 - val_prc: 0.9392\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0897 - tp: 15608.0000 - fp: 1210.0000 - tn: 118790.0000 - fn: 8392.0000 - accuracy: 0.9333 - precision: 0.9281 - recall: 0.6503 - auc: 0.9777 - prc: 0.9108\n",
      "Epoch 20: val_loss did not improve from 0.07151\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0897 - tp: 15608.0000 - fp: 1210.0000 - tn: 118790.0000 - fn: 8392.0000 - accuracy: 0.9333 - precision: 0.9281 - recall: 0.6503 - auc: 0.9777 - prc: 0.9108 - val_loss: 0.0717 - val_tp: 2077.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 923.0000 - val_accuracy: 0.9426 - val_precision: 0.9493 - val_recall: 0.6923 - val_auc: 0.9864 - val_prc: 0.9420\n",
      "Epoch 21/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0901 - tp: 15580.0000 - fp: 1236.0000 - tn: 118044.0000 - fn: 8276.0000 - accuracy: 0.9335 - precision: 0.9265 - recall: 0.6531 - auc: 0.9780 - prc: 0.9103\n",
      "Epoch 21: val_loss did not improve from 0.07151\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0901 - tp: 15673.0000 - fp: 1248.0000 - tn: 118752.0000 - fn: 8327.0000 - accuracy: 0.9335 - precision: 0.9262 - recall: 0.6530 - auc: 0.9780 - prc: 0.9103 - val_loss: 0.0731 - val_tp: 2102.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 898.0000 - val_accuracy: 0.9434 - val_precision: 0.9460 - val_recall: 0.7007 - val_auc: 0.9858 - val_prc: 0.9405\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1500 [============================>.] - ETA: 0s - loss: 0.0886 - tp: 15540.0000 - fp: 1209.0000 - tn: 117191.0000 - fn: 8140.0000 - accuracy: 0.9342 - precision: 0.9278 - recall: 0.6562 - auc: 0.9783 - prc: 0.9127\n",
      "Epoch 22: val_loss did not improve from 0.07151\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0885 - tp: 15764.0000 - fp: 1225.0000 - tn: 118775.0000 - fn: 8236.0000 - accuracy: 0.9343 - precision: 0.9279 - recall: 0.6568 - auc: 0.9784 - prc: 0.9128 - val_loss: 0.0718 - val_tp: 2103.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 897.0000 - val_accuracy: 0.9440 - val_precision: 0.9499 - val_recall: 0.7010 - val_auc: 0.9863 - val_prc: 0.9414\n",
      "Epoch 23/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0890 - tp: 15785.0000 - fp: 1215.0000 - tn: 118705.0000 - fn: 8199.0000 - accuracy: 0.9346 - precision: 0.9285 - recall: 0.6581 - auc: 0.9781 - prc: 0.9125\n",
      "Epoch 23: val_loss improved from 0.07151 to 0.06992, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0890 - tp: 15794.0000 - fp: 1215.0000 - tn: 118785.0000 - fn: 8206.0000 - accuracy: 0.9346 - precision: 0.9286 - recall: 0.6581 - auc: 0.9781 - prc: 0.9125 - val_loss: 0.0699 - val_tp: 2086.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 914.0000 - val_accuracy: 0.9437 - val_precision: 0.9543 - val_recall: 0.6953 - val_auc: 0.9872 - val_prc: 0.9458\n",
      "Epoch 24/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0882 - tp: 15836.0000 - fp: 1212.0000 - tn: 117988.0000 - fn: 8004.0000 - accuracy: 0.9356 - precision: 0.9289 - recall: 0.6643 - auc: 0.9786 - prc: 0.9142\n",
      "Epoch 24: val_loss did not improve from 0.06992\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0881 - tp: 15949.0000 - fp: 1215.0000 - tn: 118785.0000 - fn: 8051.0000 - accuracy: 0.9357 - precision: 0.9292 - recall: 0.6645 - auc: 0.9787 - prc: 0.9144 - val_loss: 0.0723 - val_tp: 2047.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 953.0000 - val_accuracy: 0.9418 - val_precision: 0.9561 - val_recall: 0.6823 - val_auc: 0.9862 - val_prc: 0.9429\n",
      "Epoch 25/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0870 - tp: 15890.0000 - fp: 1184.0000 - tn: 117856.0000 - fn: 7918.0000 - accuracy: 0.9363 - precision: 0.9307 - recall: 0.6674 - auc: 0.9792 - prc: 0.9159\n",
      "Epoch 25: val_loss did not improve from 0.06992\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0869 - tp: 16029.0000 - fp: 1194.0000 - tn: 118806.0000 - fn: 7971.0000 - accuracy: 0.9364 - precision: 0.9307 - recall: 0.6679 - auc: 0.9792 - prc: 0.9161 - val_loss: 0.0702 - val_tp: 2134.0000 - val_fp: 121.0000 - val_tn: 14879.0000 - val_fn: 866.0000 - val_accuracy: 0.9452 - val_precision: 0.9463 - val_recall: 0.7113 - val_auc: 0.9867 - val_prc: 0.9444\n",
      "Epoch 26/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0863 - tp: 15947.0000 - fp: 1224.0000 - tn: 118056.0000 - fn: 7909.0000 - accuracy: 0.9362 - precision: 0.9287 - recall: 0.6685 - auc: 0.9796 - prc: 0.9174\n",
      "Epoch 26: val_loss improved from 0.06992 to 0.06870, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0863 - tp: 16034.0000 - fp: 1236.0000 - tn: 118764.0000 - fn: 7966.0000 - accuracy: 0.9361 - precision: 0.9284 - recall: 0.6681 - auc: 0.9796 - prc: 0.9173 - val_loss: 0.0687 - val_tp: 2139.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 861.0000 - val_accuracy: 0.9460 - val_precision: 0.9507 - val_recall: 0.7130 - val_auc: 0.9874 - val_prc: 0.9466\n",
      "Epoch 27/200\n",
      "1484/1500 [============================>.] - ETA: 0s - loss: 0.0872 - tp: 15723.0000 - fp: 1193.0000 - tn: 117527.0000 - fn: 8021.0000 - accuracy: 0.9353 - precision: 0.9295 - recall: 0.6622 - auc: 0.9791 - prc: 0.9160\n",
      "Epoch 27: val_loss improved from 0.06870 to 0.06825, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0872 - tp: 15902.0000 - fp: 1205.0000 - tn: 118795.0000 - fn: 8098.0000 - accuracy: 0.9354 - precision: 0.9296 - recall: 0.6626 - auc: 0.9791 - prc: 0.9162 - val_loss: 0.0683 - val_tp: 2183.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 817.0000 - val_accuracy: 0.9479 - val_precision: 0.9479 - val_recall: 0.7277 - val_auc: 0.9875 - val_prc: 0.9480\n",
      "Epoch 28/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0855 - tp: 16079.0000 - fp: 1188.0000 - tn: 118012.0000 - fn: 7761.0000 - accuracy: 0.9374 - precision: 0.9312 - recall: 0.6745 - auc: 0.9799 - prc: 0.9190\n",
      "Epoch 28: val_loss improved from 0.06825 to 0.06767, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0856 - tp: 16182.0000 - fp: 1200.0000 - tn: 118800.0000 - fn: 7818.0000 - accuracy: 0.9374 - precision: 0.9310 - recall: 0.6743 - auc: 0.9799 - prc: 0.9188 - val_loss: 0.0677 - val_tp: 2151.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 849.0000 - val_accuracy: 0.9478 - val_precision: 0.9594 - val_recall: 0.7170 - val_auc: 0.9879 - val_prc: 0.9487\n",
      "Epoch 29/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0858 - tp: 16012.0000 - fp: 1192.0000 - tn: 118168.0000 - fn: 7860.0000 - accuracy: 0.9368 - precision: 0.9307 - recall: 0.6707 - auc: 0.9797 - prc: 0.9180\n",
      "Epoch 29: val_loss did not improve from 0.06767\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0858 - tp: 16095.0000 - fp: 1199.0000 - tn: 118801.0000 - fn: 7905.0000 - accuracy: 0.9368 - precision: 0.9307 - recall: 0.6706 - auc: 0.9797 - prc: 0.9180 - val_loss: 0.0680 - val_tp: 2197.0000 - val_fp: 105.0000 - val_tn: 14895.0000 - val_fn: 803.0000 - val_accuracy: 0.9496 - val_precision: 0.9544 - val_recall: 0.7323 - val_auc: 0.9879 - val_prc: 0.9482\n",
      "Epoch 30/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0850 - tp: 16255.0000 - fp: 1170.0000 - tn: 118590.0000 - fn: 7697.0000 - accuracy: 0.9383 - precision: 0.9329 - recall: 0.6786 - auc: 0.9802 - prc: 0.9207\n",
      "Epoch 30: val_loss did not improve from 0.06767\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0850 - tp: 16291.0000 - fp: 1172.0000 - tn: 118828.0000 - fn: 7709.0000 - accuracy: 0.9383 - precision: 0.9329 - recall: 0.6788 - auc: 0.9802 - prc: 0.9208 - val_loss: 0.0692 - val_tp: 2192.0000 - val_fp: 130.0000 - val_tn: 14870.0000 - val_fn: 808.0000 - val_accuracy: 0.9479 - val_precision: 0.9440 - val_recall: 0.7307 - val_auc: 0.9874 - val_prc: 0.9455\n",
      "Epoch 31/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0855 - tp: 16093.0000 - fp: 1210.0000 - tn: 118310.0000 - fn: 7811.0000 - accuracy: 0.9371 - precision: 0.9301 - recall: 0.6732 - auc: 0.9799 - prc: 0.9192\n",
      "Epoch 31: val_loss did not improve from 0.06767\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0854 - tp: 16160.0000 - fp: 1211.0000 - tn: 118789.0000 - fn: 7840.0000 - accuracy: 0.9371 - precision: 0.9303 - recall: 0.6733 - auc: 0.9799 - prc: 0.9193 - val_loss: 0.0683 - val_tp: 2172.0000 - val_fp: 114.0000 - val_tn: 14886.0000 - val_fn: 828.0000 - val_accuracy: 0.9477 - val_precision: 0.9501 - val_recall: 0.7240 - val_auc: 0.9876 - val_prc: 0.9476\n",
      "Epoch 32/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0841 - tp: 16357.0000 - fp: 1199.0000 - tn: 118721.0000 - fn: 7627.0000 - accuracy: 0.9387 - precision: 0.9317 - recall: 0.6820 - auc: 0.9806 - prc: 0.9222\n",
      "Epoch 32: val_loss did not improve from 0.06767\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0841 - tp: 16369.0000 - fp: 1202.0000 - tn: 118798.0000 - fn: 7631.0000 - accuracy: 0.9387 - precision: 0.9316 - recall: 0.6820 - auc: 0.9806 - prc: 0.9221 - val_loss: 0.0683 - val_tp: 2174.0000 - val_fp: 117.0000 - val_tn: 14883.0000 - val_fn: 826.0000 - val_accuracy: 0.9476 - val_precision: 0.9489 - val_recall: 0.7247 - val_auc: 0.9876 - val_prc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "1487/1500 [============================>.] - ETA: 0s - loss: 0.0840 - tp: 16135.0000 - fp: 1227.0000 - tn: 117733.0000 - fn: 7657.0000 - accuracy: 0.9378 - precision: 0.9293 - recall: 0.6782 - auc: 0.9806 - prc: 0.9221\n",
      "Epoch 33: val_loss improved from 0.06767 to 0.06512, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0842 - tp: 16278.0000 - fp: 1237.0000 - tn: 118763.0000 - fn: 7722.0000 - accuracy: 0.9378 - precision: 0.9294 - recall: 0.6783 - auc: 0.9805 - prc: 0.9219 - val_loss: 0.0651 - val_tp: 2183.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 817.0000 - val_accuracy: 0.9491 - val_precision: 0.9562 - val_recall: 0.7277 - val_auc: 0.9888 - val_prc: 0.9528\n",
      "Epoch 34/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0843 - tp: 16301.0000 - fp: 1184.0000 - tn: 118736.0000 - fn: 7683.0000 - accuracy: 0.9384 - precision: 0.9323 - recall: 0.6797 - auc: 0.9806 - prc: 0.9221\n",
      "Epoch 34: val_loss did not improve from 0.06512\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0843 - tp: 16311.0000 - fp: 1185.0000 - tn: 118815.0000 - fn: 7689.0000 - accuracy: 0.9384 - precision: 0.9323 - recall: 0.6796 - auc: 0.9806 - prc: 0.9221 - val_loss: 0.0668 - val_tp: 2105.0000 - val_fp: 86.0000 - val_tn: 14914.0000 - val_fn: 895.0000 - val_accuracy: 0.9455 - val_precision: 0.9607 - val_recall: 0.7017 - val_auc: 0.9882 - val_prc: 0.9506\n",
      "Epoch 35/200\n",
      "1480/1500 [============================>.] - ETA: 0s - loss: 0.0832 - tp: 16142.0000 - fp: 1145.0000 - tn: 117255.0000 - fn: 7538.0000 - accuracy: 0.9389 - precision: 0.9338 - recall: 0.6817 - auc: 0.9811 - prc: 0.9239\n",
      "Epoch 35: val_loss improved from 0.06512 to 0.06501, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0833 - tp: 16357.0000 - fp: 1164.0000 - tn: 118836.0000 - fn: 7643.0000 - accuracy: 0.9388 - precision: 0.9336 - recall: 0.6815 - auc: 0.9811 - prc: 0.9237 - val_loss: 0.0650 - val_tp: 2172.0000 - val_fp: 105.0000 - val_tn: 14895.0000 - val_fn: 828.0000 - val_accuracy: 0.9482 - val_precision: 0.9539 - val_recall: 0.7240 - val_auc: 0.9888 - val_prc: 0.9523\n",
      "Epoch 36/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0826 - tp: 16395.0000 - fp: 1148.0000 - tn: 118212.0000 - fn: 7477.0000 - accuracy: 0.9398 - precision: 0.9346 - recall: 0.6868 - auc: 0.9814 - prc: 0.9249\n",
      "Epoch 36: val_loss did not improve from 0.06501\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0825 - tp: 16486.0000 - fp: 1152.0000 - tn: 118848.0000 - fn: 7514.0000 - accuracy: 0.9398 - precision: 0.9347 - recall: 0.6869 - auc: 0.9814 - prc: 0.9250 - val_loss: 0.0661 - val_tp: 2229.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 771.0000 - val_accuracy: 0.9505 - val_precision: 0.9489 - val_recall: 0.7430 - val_auc: 0.9884 - val_prc: 0.9503\n",
      "Epoch 37/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0836 - tp: 16317.0000 - fp: 1152.0000 - tn: 118208.0000 - fn: 7555.0000 - accuracy: 0.9392 - precision: 0.9341 - recall: 0.6835 - auc: 0.9811 - prc: 0.9227\n",
      "Epoch 37: val_loss improved from 0.06501 to 0.06449, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0836 - tp: 16405.0000 - fp: 1156.0000 - tn: 118844.0000 - fn: 7595.0000 - accuracy: 0.9392 - precision: 0.9342 - recall: 0.6835 - auc: 0.9811 - prc: 0.9227 - val_loss: 0.0645 - val_tp: 2246.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 754.0000 - val_accuracy: 0.9514 - val_precision: 0.9493 - val_recall: 0.7487 - val_auc: 0.9889 - val_prc: 0.9532\n",
      "Epoch 38/200\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.0821 - tp: 16308.0000 - fp: 1143.0000 - tn: 117417.0000 - fn: 7404.0000 - accuracy: 0.9399 - precision: 0.9345 - recall: 0.6878 - auc: 0.9817 - prc: 0.9256\n",
      "Epoch 38: val_loss did not improve from 0.06449\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0822 - tp: 16511.0000 - fp: 1161.0000 - tn: 118839.0000 - fn: 7489.0000 - accuracy: 0.9399 - precision: 0.9343 - recall: 0.6880 - auc: 0.9817 - prc: 0.9256 - val_loss: 0.0648 - val_tp: 2232.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 768.0000 - val_accuracy: 0.9512 - val_precision: 0.9526 - val_recall: 0.7440 - val_auc: 0.9889 - val_prc: 0.9528\n",
      "Epoch 39/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0823 - tp: 16480.0000 - fp: 1147.0000 - tn: 117973.0000 - fn: 7344.0000 - accuracy: 0.9406 - precision: 0.9349 - recall: 0.6917 - auc: 0.9815 - prc: 0.9249\n",
      "Epoch 39: val_loss did not improve from 0.06449\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0822 - tp: 16606.0000 - fp: 1154.0000 - tn: 118846.0000 - fn: 7394.0000 - accuracy: 0.9406 - precision: 0.9350 - recall: 0.6919 - auc: 0.9816 - prc: 0.9252 - val_loss: 0.0646 - val_tp: 2200.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 800.0000 - val_accuracy: 0.9498 - val_precision: 0.9553 - val_recall: 0.7333 - val_auc: 0.9889 - val_prc: 0.9535\n",
      "Epoch 40/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0811 - tp: 16506.0000 - fp: 1161.0000 - tn: 118119.0000 - fn: 7350.0000 - accuracy: 0.9405 - precision: 0.9343 - recall: 0.6919 - auc: 0.9821 - prc: 0.9274\n",
      "Epoch 40: val_loss improved from 0.06449 to 0.06366, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0813 - tp: 16599.0000 - fp: 1173.0000 - tn: 118827.0000 - fn: 7401.0000 - accuracy: 0.9405 - precision: 0.9340 - recall: 0.6916 - auc: 0.9821 - prc: 0.9271 - val_loss: 0.0637 - val_tp: 2221.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 779.0000 - val_accuracy: 0.9507 - val_precision: 0.9536 - val_recall: 0.7403 - val_auc: 0.9893 - val_prc: 0.9546\n",
      "Epoch 41/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0832 - tp: 16451.0000 - fp: 1136.0000 - tn: 118544.0000 - fn: 7485.0000 - accuracy: 0.9400 - precision: 0.9354 - recall: 0.6873 - auc: 0.9813 - prc: 0.9243\n",
      "Epoch 41: val_loss improved from 0.06366 to 0.06261, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0833 - tp: 16493.0000 - fp: 1139.0000 - tn: 118861.0000 - fn: 7507.0000 - accuracy: 0.9400 - precision: 0.9354 - recall: 0.6872 - auc: 0.9813 - prc: 0.9243 - val_loss: 0.0626 - val_tp: 2271.0000 - val_fp: 113.0000 - val_tn: 14887.0000 - val_fn: 729.0000 - val_accuracy: 0.9532 - val_precision: 0.9526 - val_recall: 0.7570 - val_auc: 0.9895 - val_prc: 0.9554\n",
      "Epoch 42/200\n",
      "1481/1500 [============================>.] - ETA: 0s - loss: 0.0829 - tp: 16337.0000 - fp: 1138.0000 - tn: 117342.0000 - fn: 7359.0000 - accuracy: 0.9402 - precision: 0.9349 - recall: 0.6894 - auc: 0.9813 - prc: 0.9245\n",
      "Epoch 42: val_loss did not improve from 0.06261\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0827 - tp: 16556.0000 - fp: 1153.0000 - tn: 118847.0000 - fn: 7444.0000 - accuracy: 0.9403 - precision: 0.9349 - recall: 0.6898 - auc: 0.9814 - prc: 0.9247 - val_loss: 0.0634 - val_tp: 2256.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 744.0000 - val_accuracy: 0.9529 - val_precision: 0.9563 - val_recall: 0.7520 - val_auc: 0.9892 - val_prc: 0.9544\n",
      "Epoch 43/200\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.0815 - tp: 16347.0000 - fp: 1157.0000 - tn: 117403.0000 - fn: 7365.0000 - accuracy: 0.9401 - precision: 0.9339 - recall: 0.6894 - auc: 0.9819 - prc: 0.9267\n",
      "Epoch 43: val_loss did not improve from 0.06261\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0815 - tp: 16541.0000 - fp: 1169.0000 - tn: 118831.0000 - fn: 7459.0000 - accuracy: 0.9401 - precision: 0.9340 - recall: 0.6892 - auc: 0.9819 - prc: 0.9267 - val_loss: 0.0636 - val_tp: 2211.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 789.0000 - val_accuracy: 0.9506 - val_precision: 0.9567 - val_recall: 0.7370 - val_auc: 0.9892 - val_prc: 0.9542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0818 - tp: 16509.0000 - fp: 1141.0000 - tn: 118539.0000 - fn: 7427.0000 - accuracy: 0.9403 - precision: 0.9354 - recall: 0.6897 - auc: 0.9819 - prc: 0.9261\n",
      "Epoch 44: val_loss improved from 0.06261 to 0.06162, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0817 - tp: 16557.0000 - fp: 1144.0000 - tn: 118856.0000 - fn: 7443.0000 - accuracy: 0.9404 - precision: 0.9354 - recall: 0.6899 - auc: 0.9819 - prc: 0.9262 - val_loss: 0.0616 - val_tp: 2212.0000 - val_fp: 90.0000 - val_tn: 14910.0000 - val_fn: 788.0000 - val_accuracy: 0.9512 - val_precision: 0.9609 - val_recall: 0.7373 - val_auc: 0.9900 - val_prc: 0.9580\n",
      "Epoch 45/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0820 - tp: 16601.0000 - fp: 1160.0000 - tn: 118760.0000 - fn: 7383.0000 - accuracy: 0.9406 - precision: 0.9347 - recall: 0.6922 - auc: 0.9816 - prc: 0.9259\n",
      "Epoch 45: val_loss did not improve from 0.06162\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0820 - tp: 16612.0000 - fp: 1162.0000 - tn: 118838.0000 - fn: 7388.0000 - accuracy: 0.9406 - precision: 0.9346 - recall: 0.6922 - auc: 0.9816 - prc: 0.9259 - val_loss: 0.0625 - val_tp: 2241.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 759.0000 - val_accuracy: 0.9521 - val_precision: 0.9561 - val_recall: 0.7470 - val_auc: 0.9895 - val_prc: 0.9562\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0822 - tp: 16555.0000 - fp: 1142.0000 - tn: 118858.0000 - fn: 7445.0000 - accuracy: 0.9404 - precision: 0.9355 - recall: 0.6898 - auc: 0.9815 - prc: 0.9258\n",
      "Epoch 46: val_loss did not improve from 0.06162\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0822 - tp: 16555.0000 - fp: 1142.0000 - tn: 118858.0000 - fn: 7445.0000 - accuracy: 0.9404 - precision: 0.9355 - recall: 0.6898 - auc: 0.9815 - prc: 0.9258 - val_loss: 0.0618 - val_tp: 2242.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 758.0000 - val_accuracy: 0.9522 - val_precision: 0.9561 - val_recall: 0.7473 - val_auc: 0.9898 - val_prc: 0.9571\n",
      "Epoch 47/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0799 - tp: 16666.0000 - fp: 1140.0000 - tn: 118620.0000 - fn: 7286.0000 - accuracy: 0.9414 - precision: 0.9360 - recall: 0.6958 - auc: 0.9824 - prc: 0.9291\n",
      "Epoch 47: val_loss improved from 0.06162 to 0.06097, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0799 - tp: 16702.0000 - fp: 1141.0000 - tn: 118859.0000 - fn: 7298.0000 - accuracy: 0.9414 - precision: 0.9361 - recall: 0.6959 - auc: 0.9825 - prc: 0.9292 - val_loss: 0.0610 - val_tp: 2307.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 693.0000 - val_accuracy: 0.9548 - val_precision: 0.9506 - val_recall: 0.7690 - val_auc: 0.9901 - val_prc: 0.9577\n",
      "Epoch 48/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0809 - tp: 16648.0000 - fp: 1146.0000 - tn: 118054.0000 - fn: 7192.0000 - accuracy: 0.9417 - precision: 0.9356 - recall: 0.6983 - auc: 0.9822 - prc: 0.9281\n",
      "Epoch 48: val_loss did not improve from 0.06097\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0808 - tp: 16763.0000 - fp: 1150.0000 - tn: 118850.0000 - fn: 7237.0000 - accuracy: 0.9418 - precision: 0.9358 - recall: 0.6985 - auc: 0.9822 - prc: 0.9281 - val_loss: 0.0626 - val_tp: 2220.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 780.0000 - val_accuracy: 0.9514 - val_precision: 0.9594 - val_recall: 0.7400 - val_auc: 0.9897 - val_prc: 0.9558\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0803 - tp: 16736.0000 - fp: 1156.0000 - tn: 118844.0000 - fn: 7264.0000 - accuracy: 0.9415 - precision: 0.9354 - recall: 0.6973 - auc: 0.9825 - prc: 0.9290\n",
      "Epoch 49: val_loss did not improve from 0.06097\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0803 - tp: 16736.0000 - fp: 1156.0000 - tn: 118844.0000 - fn: 7264.0000 - accuracy: 0.9415 - precision: 0.9354 - recall: 0.6973 - auc: 0.9825 - prc: 0.9290 - val_loss: 0.0622 - val_tp: 2280.0000 - val_fp: 107.0000 - val_tn: 14893.0000 - val_fn: 720.0000 - val_accuracy: 0.9541 - val_precision: 0.9552 - val_recall: 0.7600 - val_auc: 0.9897 - val_prc: 0.9563\n",
      "Epoch 50/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0791 - tp: 16847.0000 - fp: 1110.0000 - tn: 118490.0000 - fn: 7073.0000 - accuracy: 0.9430 - precision: 0.9382 - recall: 0.7043 - auc: 0.9830 - prc: 0.9309\n",
      "Epoch 50: val_loss did not improve from 0.06097\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0792 - tp: 16896.0000 - fp: 1114.0000 - tn: 118886.0000 - fn: 7104.0000 - accuracy: 0.9429 - precision: 0.9381 - recall: 0.7040 - auc: 0.9829 - prc: 0.9308 - val_loss: 0.0613 - val_tp: 2222.0000 - val_fp: 89.0000 - val_tn: 14911.0000 - val_fn: 778.0000 - val_accuracy: 0.9518 - val_precision: 0.9615 - val_recall: 0.7407 - val_auc: 0.9899 - val_prc: 0.9575\n",
      "Epoch 51/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0794 - tp: 16767.0000 - fp: 1136.0000 - tn: 118464.0000 - fn: 7153.0000 - accuracy: 0.9422 - precision: 0.9365 - recall: 0.7010 - auc: 0.9828 - prc: 0.9304\n",
      "Epoch 51: val_loss did not improve from 0.06097\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0795 - tp: 16823.0000 - fp: 1141.0000 - tn: 118859.0000 - fn: 7177.0000 - accuracy: 0.9422 - precision: 0.9365 - recall: 0.7010 - auc: 0.9827 - prc: 0.9303 - val_loss: 0.0630 - val_tp: 2257.0000 - val_fp: 117.0000 - val_tn: 14883.0000 - val_fn: 743.0000 - val_accuracy: 0.9522 - val_precision: 0.9507 - val_recall: 0.7523 - val_auc: 0.9893 - val_prc: 0.9547\n",
      "Epoch 52/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0799 - tp: 16646.0000 - fp: 1145.0000 - tn: 118055.0000 - fn: 7194.0000 - accuracy: 0.9417 - precision: 0.9356 - recall: 0.6982 - auc: 0.9826 - prc: 0.9299\n",
      "Epoch 52: val_loss improved from 0.06097 to 0.06018, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0798 - tp: 16765.0000 - fp: 1150.0000 - tn: 118850.0000 - fn: 7235.0000 - accuracy: 0.9418 - precision: 0.9358 - recall: 0.6985 - auc: 0.9827 - prc: 0.9301 - val_loss: 0.0602 - val_tp: 2271.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 729.0000 - val_accuracy: 0.9544 - val_precision: 0.9615 - val_recall: 0.7570 - val_auc: 0.9905 - val_prc: 0.9599\n",
      "Epoch 53/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0794 - tp: 16736.0000 - fp: 1152.0000 - tn: 117888.0000 - fn: 7072.0000 - accuracy: 0.9424 - precision: 0.9356 - recall: 0.7030 - auc: 0.9828 - prc: 0.9309\n",
      "Epoch 53: val_loss did not improve from 0.06018\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0794 - tp: 16870.0000 - fp: 1158.0000 - tn: 118842.0000 - fn: 7130.0000 - accuracy: 0.9424 - precision: 0.9358 - recall: 0.7029 - auc: 0.9828 - prc: 0.9309 - val_loss: 0.0613 - val_tp: 2250.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 750.0000 - val_accuracy: 0.9529 - val_precision: 0.9583 - val_recall: 0.7500 - val_auc: 0.9899 - val_prc: 0.9580\n",
      "Epoch 54/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0792 - tp: 16739.0000 - fp: 1145.0000 - tn: 118135.0000 - fn: 7117.0000 - accuracy: 0.9423 - precision: 0.9360 - recall: 0.7017 - auc: 0.9827 - prc: 0.9307\n",
      "Epoch 54: val_loss improved from 0.06018 to 0.06008, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0792 - tp: 16835.0000 - fp: 1150.0000 - tn: 118850.0000 - fn: 7165.0000 - accuracy: 0.9423 - precision: 0.9361 - recall: 0.7015 - auc: 0.9828 - prc: 0.9308 - val_loss: 0.0601 - val_tp: 2267.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 733.0000 - val_accuracy: 0.9533 - val_precision: 0.9545 - val_recall: 0.7557 - val_auc: 0.9903 - val_prc: 0.9593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0795 - tp: 16816.0000 - fp: 1154.0000 - tn: 118366.0000 - fn: 7088.0000 - accuracy: 0.9425 - precision: 0.9358 - recall: 0.7035 - auc: 0.9829 - prc: 0.9307\n",
      "Epoch 55: val_loss improved from 0.06008 to 0.05959, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0795 - tp: 16879.0000 - fp: 1157.0000 - tn: 118843.0000 - fn: 7121.0000 - accuracy: 0.9425 - precision: 0.9359 - recall: 0.7033 - auc: 0.9829 - prc: 0.9307 - val_loss: 0.0596 - val_tp: 2262.0000 - val_fp: 78.0000 - val_tn: 14922.0000 - val_fn: 738.0000 - val_accuracy: 0.9547 - val_precision: 0.9667 - val_recall: 0.7540 - val_auc: 0.9906 - val_prc: 0.9607\n",
      "Epoch 56/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0786 - tp: 16953.0000 - fp: 1141.0000 - tn: 118619.0000 - fn: 6999.0000 - accuracy: 0.9434 - precision: 0.9369 - recall: 0.7078 - auc: 0.9834 - prc: 0.9323\n",
      "Epoch 56: val_loss improved from 0.05959 to 0.05887, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0786 - tp: 16985.0000 - fp: 1143.0000 - tn: 118857.0000 - fn: 7015.0000 - accuracy: 0.9433 - precision: 0.9369 - recall: 0.7077 - auc: 0.9834 - prc: 0.9322 - val_loss: 0.0589 - val_tp: 2268.0000 - val_fp: 79.0000 - val_tn: 14921.0000 - val_fn: 732.0000 - val_accuracy: 0.9549 - val_precision: 0.9663 - val_recall: 0.7560 - val_auc: 0.9908 - val_prc: 0.9618\n",
      "Epoch 57/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0779 - tp: 16796.0000 - fp: 1132.0000 - tn: 118308.0000 - fn: 7092.0000 - accuracy: 0.9426 - precision: 0.9369 - recall: 0.7031 - auc: 0.9835 - prc: 0.9331\n",
      "Epoch 57: val_loss improved from 0.05887 to 0.05829, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0778 - tp: 16881.0000 - fp: 1139.0000 - tn: 118861.0000 - fn: 7119.0000 - accuracy: 0.9427 - precision: 0.9368 - recall: 0.7034 - auc: 0.9835 - prc: 0.9332 - val_loss: 0.0583 - val_tp: 2349.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 651.0000 - val_accuracy: 0.9578 - val_precision: 0.9557 - val_recall: 0.7830 - val_auc: 0.9910 - val_prc: 0.9610\n",
      "Epoch 58/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0793 - tp: 17003.0000 - fp: 1156.0000 - tn: 118764.0000 - fn: 6981.0000 - accuracy: 0.9435 - precision: 0.9363 - recall: 0.7089 - auc: 0.9831 - prc: 0.9315\n",
      "Epoch 58: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0793 - tp: 17013.0000 - fp: 1156.0000 - tn: 118844.0000 - fn: 6987.0000 - accuracy: 0.9435 - precision: 0.9364 - recall: 0.7089 - auc: 0.9831 - prc: 0.9315 - val_loss: 0.0592 - val_tp: 2308.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 692.0000 - val_accuracy: 0.9562 - val_precision: 0.9601 - val_recall: 0.7693 - val_auc: 0.9906 - val_prc: 0.9609\n",
      "Epoch 59/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0785 - tp: 16954.0000 - fp: 1093.0000 - tn: 118507.0000 - fn: 6966.0000 - accuracy: 0.9438 - precision: 0.9394 - recall: 0.7088 - auc: 0.9832 - prc: 0.9325\n",
      "Epoch 59: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0784 - tp: 17010.0000 - fp: 1096.0000 - tn: 118904.0000 - fn: 6990.0000 - accuracy: 0.9438 - precision: 0.9395 - recall: 0.7088 - auc: 0.9833 - prc: 0.9326 - val_loss: 0.0593 - val_tp: 2290.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 710.0000 - val_accuracy: 0.9550 - val_precision: 0.9582 - val_recall: 0.7633 - val_auc: 0.9905 - val_prc: 0.9606\n",
      "Epoch 60/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0773 - tp: 16895.0000 - fp: 1127.0000 - tn: 117913.0000 - fn: 6913.0000 - accuracy: 0.9437 - precision: 0.9375 - recall: 0.7096 - auc: 0.9837 - prc: 0.9339\n",
      "Epoch 60: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0773 - tp: 17032.0000 - fp: 1133.0000 - tn: 118867.0000 - fn: 6968.0000 - accuracy: 0.9437 - precision: 0.9376 - recall: 0.7097 - auc: 0.9837 - prc: 0.9339 - val_loss: 0.0591 - val_tp: 2278.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 722.0000 - val_accuracy: 0.9544 - val_precision: 0.9588 - val_recall: 0.7593 - val_auc: 0.9907 - val_prc: 0.9608\n",
      "Epoch 61/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0790 - tp: 16933.0000 - fp: 1188.0000 - tn: 118652.0000 - fn: 7035.0000 - accuracy: 0.9428 - precision: 0.9344 - recall: 0.7065 - auc: 0.9832 - prc: 0.9315\n",
      "Epoch 61: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0790 - tp: 16953.0000 - fp: 1191.0000 - tn: 118809.0000 - fn: 7047.0000 - accuracy: 0.9428 - precision: 0.9344 - recall: 0.7064 - auc: 0.9832 - prc: 0.9314 - val_loss: 0.0610 - val_tp: 2250.0000 - val_fp: 80.0000 - val_tn: 14920.0000 - val_fn: 750.0000 - val_accuracy: 0.9539 - val_precision: 0.9657 - val_recall: 0.7500 - val_auc: 0.9901 - val_prc: 0.9584\n",
      "Epoch 62/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0772 - tp: 17001.0000 - fp: 1128.0000 - tn: 118552.0000 - fn: 6935.0000 - accuracy: 0.9439 - precision: 0.9378 - recall: 0.7103 - auc: 0.9838 - prc: 0.9339\n",
      "Epoch 62: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0771 - tp: 17049.0000 - fp: 1129.0000 - tn: 118871.0000 - fn: 6951.0000 - accuracy: 0.9439 - precision: 0.9379 - recall: 0.7104 - auc: 0.9838 - prc: 0.9340 - val_loss: 0.0591 - val_tp: 2337.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 663.0000 - val_accuracy: 0.9570 - val_precision: 0.9547 - val_recall: 0.7790 - val_auc: 0.9906 - val_prc: 0.9603\n",
      "Epoch 63/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0779 - tp: 17017.0000 - fp: 1141.0000 - tn: 118779.0000 - fn: 6967.0000 - accuracy: 0.9437 - precision: 0.9372 - recall: 0.7095 - auc: 0.9834 - prc: 0.9327\n",
      "Epoch 63: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0780 - tp: 17026.0000 - fp: 1144.0000 - tn: 118856.0000 - fn: 6974.0000 - accuracy: 0.9436 - precision: 0.9370 - recall: 0.7094 - auc: 0.9834 - prc: 0.9326 - val_loss: 0.0593 - val_tp: 2297.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 703.0000 - val_accuracy: 0.9556 - val_precision: 0.9599 - val_recall: 0.7657 - val_auc: 0.9906 - val_prc: 0.9604\n",
      "Epoch 64/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0789 - tp: 16951.0000 - fp: 1090.0000 - tn: 118510.0000 - fn: 6969.0000 - accuracy: 0.9438 - precision: 0.9396 - recall: 0.7087 - auc: 0.9832 - prc: 0.9321\n",
      "Epoch 64: val_loss did not improve from 0.05829\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0789 - tp: 17010.0000 - fp: 1095.0000 - tn: 118905.0000 - fn: 6990.0000 - accuracy: 0.9439 - precision: 0.9395 - recall: 0.7088 - auc: 0.9832 - prc: 0.9321 - val_loss: 0.0589 - val_tp: 2305.0000 - val_fp: 99.0000 - val_tn: 14901.0000 - val_fn: 695.0000 - val_accuracy: 0.9559 - val_precision: 0.9588 - val_recall: 0.7683 - val_auc: 0.9907 - val_prc: 0.9610\n",
      "Epoch 65/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0766 - tp: 17075.0000 - fp: 1117.0000 - tn: 118243.0000 - fn: 6797.0000 - accuracy: 0.9447 - precision: 0.9386 - recall: 0.7153 - auc: 0.9840 - prc: 0.9353\n",
      "Epoch 65: val_loss improved from 0.05829 to 0.05804, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0766 - tp: 17168.0000 - fp: 1121.0000 - tn: 118879.0000 - fn: 6832.0000 - accuracy: 0.9448 - precision: 0.9387 - recall: 0.7153 - auc: 0.9841 - prc: 0.9354 - val_loss: 0.0580 - val_tp: 2281.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 719.0000 - val_accuracy: 0.9548 - val_precision: 0.9604 - val_recall: 0.7603 - val_auc: 0.9912 - val_prc: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0787 - tp: 16897.0000 - fp: 1104.0000 - tn: 118656.0000 - fn: 7055.0000 - accuracy: 0.9432 - precision: 0.9387 - recall: 0.7055 - auc: 0.9833 - prc: 0.9322\n",
      "Epoch 66: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0787 - tp: 16926.0000 - fp: 1106.0000 - tn: 118894.0000 - fn: 7074.0000 - accuracy: 0.9432 - precision: 0.9387 - recall: 0.7053 - auc: 0.9833 - prc: 0.9321 - val_loss: 0.0586 - val_tp: 2311.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 689.0000 - val_accuracy: 0.9566 - val_precision: 0.9617 - val_recall: 0.7703 - val_auc: 0.9909 - val_prc: 0.9616\n",
      "Epoch 67/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0777 - tp: 17079.0000 - fp: 1136.0000 - tn: 118864.0000 - fn: 6921.0000 - accuracy: 0.9440 - precision: 0.9376 - recall: 0.7116 - auc: 0.9837 - prc: 0.9341\n",
      "Epoch 67: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0777 - tp: 17079.0000 - fp: 1136.0000 - tn: 118864.0000 - fn: 6921.0000 - accuracy: 0.9440 - precision: 0.9376 - recall: 0.7116 - auc: 0.9837 - prc: 0.9341 - val_loss: 0.0623 - val_tp: 2237.0000 - val_fp: 99.0000 - val_tn: 14901.0000 - val_fn: 763.0000 - val_accuracy: 0.9521 - val_precision: 0.9576 - val_recall: 0.7457 - val_auc: 0.9895 - val_prc: 0.9565\n",
      "Epoch 68/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0759 - tp: 17197.0000 - fp: 1141.0000 - tn: 118459.0000 - fn: 6723.0000 - accuracy: 0.9452 - precision: 0.9378 - recall: 0.7189 - auc: 0.9844 - prc: 0.9366\n",
      "Epoch 68: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0759 - tp: 17261.0000 - fp: 1144.0000 - tn: 118856.0000 - fn: 6739.0000 - accuracy: 0.9453 - precision: 0.9378 - recall: 0.7192 - auc: 0.9844 - prc: 0.9366 - val_loss: 0.0590 - val_tp: 2334.0000 - val_fp: 110.0000 - val_tn: 14890.0000 - val_fn: 666.0000 - val_accuracy: 0.9569 - val_precision: 0.9550 - val_recall: 0.7780 - val_auc: 0.9906 - val_prc: 0.9608\n",
      "Epoch 69/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0781 - tp: 17000.0000 - fp: 1179.0000 - tn: 118021.0000 - fn: 6840.0000 - accuracy: 0.9439 - precision: 0.9351 - recall: 0.7131 - auc: 0.9834 - prc: 0.9330\n",
      "Epoch 69: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0780 - tp: 17125.0000 - fp: 1183.0000 - tn: 118817.0000 - fn: 6875.0000 - accuracy: 0.9440 - precision: 0.9354 - recall: 0.7135 - auc: 0.9835 - prc: 0.9332 - val_loss: 0.0595 - val_tp: 2293.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 707.0000 - val_accuracy: 0.9552 - val_precision: 0.9582 - val_recall: 0.7643 - val_auc: 0.9906 - val_prc: 0.9606\n",
      "Epoch 70/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0759 - tp: 17178.0000 - fp: 1147.0000 - tn: 118133.0000 - fn: 6678.0000 - accuracy: 0.9453 - precision: 0.9374 - recall: 0.7201 - auc: 0.9843 - prc: 0.9365\n",
      "Epoch 70: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0761 - tp: 17276.0000 - fp: 1160.0000 - tn: 118840.0000 - fn: 6724.0000 - accuracy: 0.9453 - precision: 0.9371 - recall: 0.7198 - auc: 0.9842 - prc: 0.9362 - val_loss: 0.0584 - val_tp: 2300.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 700.0000 - val_accuracy: 0.9559 - val_precision: 0.9607 - val_recall: 0.7667 - val_auc: 0.9910 - val_prc: 0.9619\n",
      "Epoch 71/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0768 - tp: 17101.0000 - fp: 1090.0000 - tn: 118670.0000 - fn: 6851.0000 - accuracy: 0.9447 - precision: 0.9401 - recall: 0.7140 - auc: 0.9840 - prc: 0.9354\n",
      "Epoch 71: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0768 - tp: 17135.0000 - fp: 1094.0000 - tn: 118906.0000 - fn: 6865.0000 - accuracy: 0.9447 - precision: 0.9400 - recall: 0.7140 - auc: 0.9840 - prc: 0.9354 - val_loss: 0.0588 - val_tp: 2353.0000 - val_fp: 112.0000 - val_tn: 14888.0000 - val_fn: 647.0000 - val_accuracy: 0.9578 - val_precision: 0.9546 - val_recall: 0.7843 - val_auc: 0.9908 - val_prc: 0.9609\n",
      "Epoch 72/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0775 - tp: 17057.0000 - fp: 1145.0000 - tn: 117895.0000 - fn: 6751.0000 - accuracy: 0.9447 - precision: 0.9371 - recall: 0.7164 - auc: 0.9839 - prc: 0.9340\n",
      "Epoch 72: val_loss did not improve from 0.05804\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0774 - tp: 17197.0000 - fp: 1153.0000 - tn: 118847.0000 - fn: 6803.0000 - accuracy: 0.9447 - precision: 0.9372 - recall: 0.7165 - auc: 0.9839 - prc: 0.9341 - val_loss: 0.0589 - val_tp: 2304.0000 - val_fp: 95.0000 - val_tn: 14905.0000 - val_fn: 696.0000 - val_accuracy: 0.9561 - val_precision: 0.9604 - val_recall: 0.7680 - val_auc: 0.9907 - val_prc: 0.9610\n",
      "Epoch 73/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0761 - tp: 17231.0000 - fp: 1104.0000 - tn: 118176.0000 - fn: 6625.0000 - accuracy: 0.9460 - precision: 0.9398 - recall: 0.7223 - auc: 0.9842 - prc: 0.9363\n",
      "Epoch 73: val_loss improved from 0.05804 to 0.05747, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0761 - tp: 17328.0000 - fp: 1113.0000 - tn: 118887.0000 - fn: 6672.0000 - accuracy: 0.9459 - precision: 0.9396 - recall: 0.7220 - auc: 0.9842 - prc: 0.9362 - val_loss: 0.0575 - val_tp: 2317.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 683.0000 - val_accuracy: 0.9570 - val_precision: 0.9622 - val_recall: 0.7723 - val_auc: 0.9912 - val_prc: 0.9630\n",
      "Epoch 74/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 17254.0000 - fp: 1070.0000 - tn: 118610.0000 - fn: 6682.0000 - accuracy: 0.9460 - precision: 0.9416 - recall: 0.7208 - auc: 0.9844 - prc: 0.9373\n",
      "Epoch 74: val_loss did not improve from 0.05747\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0754 - tp: 17303.0000 - fp: 1073.0000 - tn: 118927.0000 - fn: 6697.0000 - accuracy: 0.9460 - precision: 0.9416 - recall: 0.7210 - auc: 0.9844 - prc: 0.9374 - val_loss: 0.0576 - val_tp: 2312.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 688.0000 - val_accuracy: 0.9566 - val_precision: 0.9609 - val_recall: 0.7707 - val_auc: 0.9911 - val_prc: 0.9628\n",
      "Epoch 75/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0772 - tp: 17144.0000 - fp: 1155.0000 - tn: 118765.0000 - fn: 6840.0000 - accuracy: 0.9444 - precision: 0.9369 - recall: 0.7148 - auc: 0.9839 - prc: 0.9346\n",
      "Epoch 75: val_loss did not improve from 0.05747\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0771 - tp: 17158.0000 - fp: 1155.0000 - tn: 118845.0000 - fn: 6842.0000 - accuracy: 0.9445 - precision: 0.9369 - recall: 0.7149 - auc: 0.9839 - prc: 0.9346 - val_loss: 0.0590 - val_tp: 2287.0000 - val_fp: 89.0000 - val_tn: 14911.0000 - val_fn: 713.0000 - val_accuracy: 0.9554 - val_precision: 0.9625 - val_recall: 0.7623 - val_auc: 0.9905 - val_prc: 0.9605\n",
      "Epoch 76/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0765 - tp: 17192.0000 - fp: 1087.0000 - tn: 118593.0000 - fn: 6744.0000 - accuracy: 0.9455 - precision: 0.9405 - recall: 0.7182 - auc: 0.9843 - prc: 0.9359\n",
      "Epoch 76: val_loss improved from 0.05747 to 0.05688, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0765 - tp: 17239.0000 - fp: 1090.0000 - tn: 118910.0000 - fn: 6761.0000 - accuracy: 0.9455 - precision: 0.9405 - recall: 0.7183 - auc: 0.9843 - prc: 0.9359 - val_loss: 0.0569 - val_tp: 2315.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 685.0000 - val_accuracy: 0.9568 - val_precision: 0.9618 - val_recall: 0.7717 - val_auc: 0.9914 - val_prc: 0.9638\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0747 - tp: 17423.0000 - fp: 1137.0000 - tn: 118863.0000 - fn: 6577.0000 - accuracy: 0.9464 - precision: 0.9387 - recall: 0.7260 - auc: 0.9850 - prc: 0.9384\n",
      "Epoch 77: val_loss did not improve from 0.05688\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0747 - tp: 17423.0000 - fp: 1137.0000 - tn: 118863.0000 - fn: 6577.0000 - accuracy: 0.9464 - precision: 0.9387 - recall: 0.7260 - auc: 0.9850 - prc: 0.9384 - val_loss: 0.0570 - val_tp: 2337.0000 - val_fp: 97.0000 - val_tn: 14903.0000 - val_fn: 663.0000 - val_accuracy: 0.9578 - val_precision: 0.9601 - val_recall: 0.7790 - val_auc: 0.9912 - val_prc: 0.9635\n",
      "Epoch 78/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0771 - tp: 17248.0000 - fp: 1110.0000 - tn: 118570.0000 - fn: 6688.0000 - accuracy: 0.9457 - precision: 0.9395 - recall: 0.7206 - auc: 0.9839 - prc: 0.9356\n",
      "Epoch 78: val_loss did not improve from 0.05688\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0770 - tp: 17302.0000 - fp: 1112.0000 - tn: 118888.0000 - fn: 6698.0000 - accuracy: 0.9458 - precision: 0.9396 - recall: 0.7209 - auc: 0.9840 - prc: 0.9357 - val_loss: 0.0570 - val_tp: 2310.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 690.0000 - val_accuracy: 0.9561 - val_precision: 0.9585 - val_recall: 0.7700 - val_auc: 0.9914 - val_prc: 0.9634\n",
      "Epoch 79/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0751 - tp: 17270.0000 - fp: 1087.0000 - tn: 118113.0000 - fn: 6570.0000 - accuracy: 0.9465 - precision: 0.9408 - recall: 0.7244 - auc: 0.9848 - prc: 0.9384\n",
      "Epoch 79: val_loss did not improve from 0.05688\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0751 - tp: 17390.0000 - fp: 1095.0000 - tn: 118905.0000 - fn: 6610.0000 - accuracy: 0.9465 - precision: 0.9408 - recall: 0.7246 - auc: 0.9848 - prc: 0.9384 - val_loss: 0.0581 - val_tp: 2344.0000 - val_fp: 115.0000 - val_tn: 14885.0000 - val_fn: 656.0000 - val_accuracy: 0.9572 - val_precision: 0.9532 - val_recall: 0.7813 - val_auc: 0.9909 - val_prc: 0.9616\n",
      "Epoch 80/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0757 - tp: 17366.0000 - fp: 1099.0000 - tn: 118821.0000 - fn: 6618.0000 - accuracy: 0.9464 - precision: 0.9405 - recall: 0.7241 - auc: 0.9845 - prc: 0.9371\n",
      "Epoch 80: val_loss did not improve from 0.05688\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0757 - tp: 17378.0000 - fp: 1099.0000 - tn: 118901.0000 - fn: 6622.0000 - accuracy: 0.9464 - precision: 0.9405 - recall: 0.7241 - auc: 0.9845 - prc: 0.9372 - val_loss: 0.0600 - val_tp: 2203.0000 - val_fp: 75.0000 - val_tn: 14925.0000 - val_fn: 797.0000 - val_accuracy: 0.9516 - val_precision: 0.9671 - val_recall: 0.7343 - val_auc: 0.9904 - val_prc: 0.9604\n",
      "Epoch 81/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0756 - tp: 17262.0000 - fp: 1137.0000 - tn: 118543.0000 - fn: 6674.0000 - accuracy: 0.9456 - precision: 0.9382 - recall: 0.7212 - auc: 0.9844 - prc: 0.9372\n",
      "Epoch 81: val_loss improved from 0.05688 to 0.05651, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0757 - tp: 17297.0000 - fp: 1140.0000 - tn: 118860.0000 - fn: 6703.0000 - accuracy: 0.9455 - precision: 0.9382 - recall: 0.7207 - auc: 0.9844 - prc: 0.9370 - val_loss: 0.0565 - val_tp: 2367.0000 - val_fp: 113.0000 - val_tn: 14887.0000 - val_fn: 633.0000 - val_accuracy: 0.9586 - val_precision: 0.9544 - val_recall: 0.7890 - val_auc: 0.9913 - val_prc: 0.9639\n",
      "Epoch 82/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0763 - tp: 17155.0000 - fp: 1079.0000 - tn: 118441.0000 - fn: 6749.0000 - accuracy: 0.9454 - precision: 0.9408 - recall: 0.7177 - auc: 0.9841 - prc: 0.9356\n",
      "Epoch 82: val_loss did not improve from 0.05651\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0763 - tp: 17225.0000 - fp: 1081.0000 - tn: 118919.0000 - fn: 6775.0000 - accuracy: 0.9454 - precision: 0.9409 - recall: 0.7177 - auc: 0.9841 - prc: 0.9356 - val_loss: 0.0565 - val_tp: 2356.0000 - val_fp: 105.0000 - val_tn: 14895.0000 - val_fn: 644.0000 - val_accuracy: 0.9584 - val_precision: 0.9573 - val_recall: 0.7853 - val_auc: 0.9915 - val_prc: 0.9640\n",
      "Epoch 83/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0758 - tp: 17354.0000 - fp: 1127.0000 - tn: 118793.0000 - fn: 6630.0000 - accuracy: 0.9461 - precision: 0.9390 - recall: 0.7236 - auc: 0.9843 - prc: 0.9373\n",
      "Epoch 83: val_loss improved from 0.05651 to 0.05624, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0758 - tp: 17365.0000 - fp: 1130.0000 - tn: 118870.0000 - fn: 6635.0000 - accuracy: 0.9461 - precision: 0.9389 - recall: 0.7235 - auc: 0.9843 - prc: 0.9373 - val_loss: 0.0562 - val_tp: 2387.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 613.0000 - val_accuracy: 0.9599 - val_precision: 0.9567 - val_recall: 0.7957 - val_auc: 0.9916 - val_prc: 0.9643\n",
      "Epoch 84/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0743 - tp: 17333.0000 - fp: 1075.0000 - tn: 118765.0000 - fn: 6635.0000 - accuracy: 0.9464 - precision: 0.9416 - recall: 0.7232 - auc: 0.9850 - prc: 0.9394\n",
      "Epoch 84: val_loss improved from 0.05624 to 0.05591, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0743 - tp: 17360.0000 - fp: 1075.0000 - tn: 118925.0000 - fn: 6640.0000 - accuracy: 0.9464 - precision: 0.9417 - recall: 0.7233 - auc: 0.9850 - prc: 0.9395 - val_loss: 0.0559 - val_tp: 2389.0000 - val_fp: 114.0000 - val_tn: 14886.0000 - val_fn: 611.0000 - val_accuracy: 0.9597 - val_precision: 0.9545 - val_recall: 0.7963 - val_auc: 0.9918 - val_prc: 0.9650\n",
      "Epoch 85/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0748 - tp: 17279.0000 - fp: 1079.0000 - tn: 118601.0000 - fn: 6657.0000 - accuracy: 0.9461 - precision: 0.9412 - recall: 0.7219 - auc: 0.9847 - prc: 0.9385\n",
      "Epoch 85: val_loss improved from 0.05591 to 0.05566, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0748 - tp: 17328.0000 - fp: 1084.0000 - tn: 118916.0000 - fn: 6672.0000 - accuracy: 0.9461 - precision: 0.9411 - recall: 0.7220 - auc: 0.9847 - prc: 0.9385 - val_loss: 0.0557 - val_tp: 2328.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 672.0000 - val_accuracy: 0.9576 - val_precision: 0.9620 - val_recall: 0.7760 - val_auc: 0.9917 - val_prc: 0.9649\n",
      "Epoch 86/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 17483.0000 - fp: 1103.0000 - tn: 118817.0000 - fn: 6501.0000 - accuracy: 0.9472 - precision: 0.9407 - recall: 0.7289 - auc: 0.9852 - prc: 0.9397\n",
      "Epoch 86: val_loss did not improve from 0.05566\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0742 - tp: 17492.0000 - fp: 1104.0000 - tn: 118896.0000 - fn: 6508.0000 - accuracy: 0.9471 - precision: 0.9406 - recall: 0.7288 - auc: 0.9852 - prc: 0.9396 - val_loss: 0.0560 - val_tp: 2386.0000 - val_fp: 119.0000 - val_tn: 14881.0000 - val_fn: 614.0000 - val_accuracy: 0.9593 - val_precision: 0.9525 - val_recall: 0.7953 - val_auc: 0.9916 - val_prc: 0.9642\n",
      "Epoch 87/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0748 - tp: 17358.0000 - fp: 1069.0000 - tn: 118611.0000 - fn: 6578.0000 - accuracy: 0.9468 - precision: 0.9420 - recall: 0.7252 - auc: 0.9851 - prc: 0.9391\n",
      "Epoch 87: val_loss improved from 0.05566 to 0.05503, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0748 - tp: 17398.0000 - fp: 1073.0000 - tn: 118927.0000 - fn: 6602.0000 - accuracy: 0.9467 - precision: 0.9419 - recall: 0.7249 - auc: 0.9850 - prc: 0.9391 - val_loss: 0.0550 - val_tp: 2358.0000 - val_fp: 106.0000 - val_tn: 14894.0000 - val_fn: 642.0000 - val_accuracy: 0.9584 - val_precision: 0.9570 - val_recall: 0.7860 - val_auc: 0.9918 - val_prc: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0757 - tp: 17302.0000 - fp: 1100.0000 - tn: 118020.0000 - fn: 6522.0000 - accuracy: 0.9467 - precision: 0.9402 - recall: 0.7262 - auc: 0.9844 - prc: 0.9372\n",
      "Epoch 88: val_loss did not improve from 0.05503\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0758 - tp: 17423.0000 - fp: 1108.0000 - tn: 118892.0000 - fn: 6577.0000 - accuracy: 0.9466 - precision: 0.9402 - recall: 0.7260 - auc: 0.9843 - prc: 0.9371 - val_loss: 0.0575 - val_tp: 2362.0000 - val_fp: 114.0000 - val_tn: 14886.0000 - val_fn: 638.0000 - val_accuracy: 0.9582 - val_precision: 0.9540 - val_recall: 0.7873 - val_auc: 0.9911 - val_prc: 0.9628\n",
      "Epoch 89/200\n",
      "1484/1500 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 17184.0000 - fp: 1094.0000 - tn: 117626.0000 - fn: 6560.0000 - accuracy: 0.9463 - precision: 0.9401 - recall: 0.7237 - auc: 0.9844 - prc: 0.9375\n",
      "Epoch 89: val_loss did not improve from 0.05503\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0754 - tp: 17372.0000 - fp: 1104.0000 - tn: 118896.0000 - fn: 6628.0000 - accuracy: 0.9463 - precision: 0.9402 - recall: 0.7238 - auc: 0.9844 - prc: 0.9376 - val_loss: 0.0554 - val_tp: 2375.0000 - val_fp: 99.0000 - val_tn: 14901.0000 - val_fn: 625.0000 - val_accuracy: 0.9598 - val_precision: 0.9600 - val_recall: 0.7917 - val_auc: 0.9919 - val_prc: 0.9657\n",
      "Epoch 90/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 17283.0000 - fp: 1100.0000 - tn: 118020.0000 - fn: 6541.0000 - accuracy: 0.9465 - precision: 0.9402 - recall: 0.7254 - auc: 0.9846 - prc: 0.9381\n",
      "Epoch 90: val_loss did not improve from 0.05503\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0754 - tp: 17402.0000 - fp: 1108.0000 - tn: 118892.0000 - fn: 6598.0000 - accuracy: 0.9465 - precision: 0.9401 - recall: 0.7251 - auc: 0.9846 - prc: 0.9380 - val_loss: 0.0569 - val_tp: 2295.0000 - val_fp: 87.0000 - val_tn: 14913.0000 - val_fn: 705.0000 - val_accuracy: 0.9560 - val_precision: 0.9635 - val_recall: 0.7650 - val_auc: 0.9914 - val_prc: 0.9636\n",
      "Epoch 91/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0748 - tp: 17411.0000 - fp: 1089.0000 - tn: 118191.0000 - fn: 6445.0000 - accuracy: 0.9474 - precision: 0.9411 - recall: 0.7298 - auc: 0.9849 - prc: 0.9387\n",
      "Epoch 91: val_loss did not improve from 0.05503\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0749 - tp: 17512.0000 - fp: 1097.0000 - tn: 118903.0000 - fn: 6488.0000 - accuracy: 0.9473 - precision: 0.9411 - recall: 0.7297 - auc: 0.9849 - prc: 0.9387 - val_loss: 0.0565 - val_tp: 2294.0000 - val_fp: 83.0000 - val_tn: 14917.0000 - val_fn: 706.0000 - val_accuracy: 0.9562 - val_precision: 0.9651 - val_recall: 0.7647 - val_auc: 0.9917 - val_prc: 0.9650\n",
      "Epoch 92/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0744 - tp: 17275.0000 - fp: 1093.0000 - tn: 118107.0000 - fn: 6565.0000 - accuracy: 0.9465 - precision: 0.9405 - recall: 0.7246 - auc: 0.9851 - prc: 0.9391\n",
      "Epoch 92: val_loss did not improve from 0.05503\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0743 - tp: 17396.0000 - fp: 1098.0000 - tn: 118902.0000 - fn: 6604.0000 - accuracy: 0.9465 - precision: 0.9406 - recall: 0.7248 - auc: 0.9852 - prc: 0.9393 - val_loss: 0.0570 - val_tp: 2347.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 653.0000 - val_accuracy: 0.9577 - val_precision: 0.9560 - val_recall: 0.7823 - val_auc: 0.9913 - val_prc: 0.9634\n",
      "Epoch 93/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0752 - tp: 17419.0000 - fp: 1141.0000 - tn: 118779.0000 - fn: 6565.0000 - accuracy: 0.9464 - precision: 0.9385 - recall: 0.7263 - auc: 0.9849 - prc: 0.9380\n",
      "Epoch 93: val_loss did not improve from 0.05503\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0752 - tp: 17428.0000 - fp: 1142.0000 - tn: 118858.0000 - fn: 6572.0000 - accuracy: 0.9464 - precision: 0.9385 - recall: 0.7262 - auc: 0.9849 - prc: 0.9380 - val_loss: 0.0554 - val_tp: 2340.0000 - val_fp: 90.0000 - val_tn: 14910.0000 - val_fn: 660.0000 - val_accuracy: 0.9583 - val_precision: 0.9630 - val_recall: 0.7800 - val_auc: 0.9919 - val_prc: 0.9657\n",
      "Epoch 94/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0750 - tp: 17339.0000 - fp: 1050.0000 - tn: 118150.0000 - fn: 6501.0000 - accuracy: 0.9472 - precision: 0.9429 - recall: 0.7273 - auc: 0.9850 - prc: 0.9387\n",
      "Epoch 94: val_loss improved from 0.05503 to 0.05434, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0751 - tp: 17455.0000 - fp: 1061.0000 - tn: 118939.0000 - fn: 6545.0000 - accuracy: 0.9472 - precision: 0.9427 - recall: 0.7273 - auc: 0.9849 - prc: 0.9385 - val_loss: 0.0543 - val_tp: 2344.0000 - val_fp: 86.0000 - val_tn: 14914.0000 - val_fn: 656.0000 - val_accuracy: 0.9588 - val_precision: 0.9646 - val_recall: 0.7813 - val_auc: 0.9923 - val_prc: 0.9676\n",
      "Epoch 95/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0736 - tp: 17531.0000 - fp: 1092.0000 - tn: 118828.0000 - fn: 6453.0000 - accuracy: 0.9476 - precision: 0.9414 - recall: 0.7309 - auc: 0.9853 - prc: 0.9406\n",
      "Epoch 95: val_loss did not improve from 0.05434\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0736 - tp: 17543.0000 - fp: 1092.0000 - tn: 118908.0000 - fn: 6457.0000 - accuracy: 0.9476 - precision: 0.9414 - recall: 0.7310 - auc: 0.9853 - prc: 0.9406 - val_loss: 0.0576 - val_tp: 2329.0000 - val_fp: 102.0000 - val_tn: 14898.0000 - val_fn: 671.0000 - val_accuracy: 0.9571 - val_precision: 0.9580 - val_recall: 0.7763 - val_auc: 0.9913 - val_prc: 0.9627\n",
      "Epoch 96/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0740 - tp: 17392.0000 - fp: 1149.0000 - tn: 118131.0000 - fn: 6464.0000 - accuracy: 0.9468 - precision: 0.9380 - recall: 0.7290 - auc: 0.9853 - prc: 0.9393\n",
      "Epoch 96: val_loss did not improve from 0.05434\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0740 - tp: 17509.0000 - fp: 1155.0000 - tn: 118845.0000 - fn: 6491.0000 - accuracy: 0.9469 - precision: 0.9381 - recall: 0.7295 - auc: 0.9853 - prc: 0.9393 - val_loss: 0.0551 - val_tp: 2376.0000 - val_fp: 95.0000 - val_tn: 14905.0000 - val_fn: 624.0000 - val_accuracy: 0.9601 - val_precision: 0.9616 - val_recall: 0.7920 - val_auc: 0.9919 - val_prc: 0.9657\n",
      "Epoch 97/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0736 - tp: 17629.0000 - fp: 1093.0000 - tn: 118267.0000 - fn: 6243.0000 - accuracy: 0.9488 - precision: 0.9416 - recall: 0.7385 - auc: 0.9855 - prc: 0.9407\n",
      "Epoch 97: val_loss did not improve from 0.05434\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0736 - tp: 17725.0000 - fp: 1100.0000 - tn: 118900.0000 - fn: 6275.0000 - accuracy: 0.9488 - precision: 0.9416 - recall: 0.7385 - auc: 0.9855 - prc: 0.9407 - val_loss: 0.0556 - val_tp: 2385.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 615.0000 - val_accuracy: 0.9604 - val_precision: 0.9605 - val_recall: 0.7950 - val_auc: 0.9918 - val_prc: 0.9656\n",
      "Epoch 98/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0733 - tp: 17599.0000 - fp: 1069.0000 - tn: 118371.0000 - fn: 6289.0000 - accuracy: 0.9487 - precision: 0.9427 - recall: 0.7367 - auc: 0.9854 - prc: 0.9412\n",
      "Epoch 98: val_loss improved from 0.05434 to 0.05402, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0735 - tp: 17675.0000 - fp: 1075.0000 - tn: 118925.0000 - fn: 6325.0000 - accuracy: 0.9486 - precision: 0.9427 - recall: 0.7365 - auc: 0.9854 - prc: 0.9410 - val_loss: 0.0540 - val_tp: 2377.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 623.0000 - val_accuracy: 0.9599 - val_precision: 0.9604 - val_recall: 0.7923 - val_auc: 0.9921 - val_prc: 0.9672\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0737 - tp: 17512.0000 - fp: 1127.0000 - tn: 117993.0000 - fn: 6312.0000 - accuracy: 0.9480 - precision: 0.9395 - recall: 0.7351 - auc: 0.9854 - prc: 0.9410\n",
      "Epoch 99: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0736 - tp: 17647.0000 - fp: 1134.0000 - tn: 118866.0000 - fn: 6353.0000 - accuracy: 0.9480 - precision: 0.9396 - recall: 0.7353 - auc: 0.9855 - prc: 0.9411 - val_loss: 0.0559 - val_tp: 2365.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 635.0000 - val_accuracy: 0.9595 - val_precision: 0.9618 - val_recall: 0.7883 - val_auc: 0.9917 - val_prc: 0.9649\n",
      "Epoch 100/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0739 - tp: 17450.0000 - fp: 1107.0000 - tn: 118493.0000 - fn: 6470.0000 - accuracy: 0.9472 - precision: 0.9403 - recall: 0.7295 - auc: 0.9852 - prc: 0.9402\n",
      "Epoch 100: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0739 - tp: 17511.0000 - fp: 1110.0000 - tn: 118890.0000 - fn: 6489.0000 - accuracy: 0.9472 - precision: 0.9404 - recall: 0.7296 - auc: 0.9852 - prc: 0.9402 - val_loss: 0.0570 - val_tp: 2304.0000 - val_fp: 90.0000 - val_tn: 14910.0000 - val_fn: 696.0000 - val_accuracy: 0.9563 - val_precision: 0.9624 - val_recall: 0.7680 - val_auc: 0.9915 - val_prc: 0.9639\n",
      "Epoch 101/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0731 - tp: 17571.0000 - fp: 1098.0000 - tn: 118422.0000 - fn: 6333.0000 - accuracy: 0.9482 - precision: 0.9412 - recall: 0.7351 - auc: 0.9855 - prc: 0.9416\n",
      "Epoch 101: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0730 - tp: 17646.0000 - fp: 1101.0000 - tn: 118899.0000 - fn: 6354.0000 - accuracy: 0.9482 - precision: 0.9413 - recall: 0.7352 - auc: 0.9856 - prc: 0.9417 - val_loss: 0.0563 - val_tp: 2363.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 637.0000 - val_accuracy: 0.9579 - val_precision: 0.9517 - val_recall: 0.7877 - val_auc: 0.9916 - val_prc: 0.9642\n",
      "Epoch 102/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0743 - tp: 17402.0000 - fp: 1083.0000 - tn: 117957.0000 - fn: 6406.0000 - accuracy: 0.9476 - precision: 0.9414 - recall: 0.7309 - auc: 0.9850 - prc: 0.9396\n",
      "Epoch 102: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0742 - tp: 17547.0000 - fp: 1091.0000 - tn: 118909.0000 - fn: 6453.0000 - accuracy: 0.9476 - precision: 0.9415 - recall: 0.7311 - auc: 0.9851 - prc: 0.9397 - val_loss: 0.0572 - val_tp: 2396.0000 - val_fp: 133.0000 - val_tn: 14867.0000 - val_fn: 604.0000 - val_accuracy: 0.9591 - val_precision: 0.9474 - val_recall: 0.7987 - val_auc: 0.9913 - val_prc: 0.9633\n",
      "Epoch 103/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0739 - tp: 17506.0000 - fp: 1098.0000 - tn: 118262.0000 - fn: 6366.0000 - accuracy: 0.9479 - precision: 0.9410 - recall: 0.7333 - auc: 0.9852 - prc: 0.9401\n",
      "Epoch 103: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0740 - tp: 17597.0000 - fp: 1105.0000 - tn: 118895.0000 - fn: 6403.0000 - accuracy: 0.9479 - precision: 0.9409 - recall: 0.7332 - auc: 0.9852 - prc: 0.9400 - val_loss: 0.0556 - val_tp: 2257.0000 - val_fp: 74.0000 - val_tn: 14926.0000 - val_fn: 743.0000 - val_accuracy: 0.9546 - val_precision: 0.9683 - val_recall: 0.7523 - val_auc: 0.9919 - val_prc: 0.9662\n",
      "Epoch 104/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 17438.0000 - fp: 1127.0000 - tn: 117913.0000 - fn: 6370.0000 - accuracy: 0.9475 - precision: 0.9393 - recall: 0.7324 - auc: 0.9853 - prc: 0.9397\n",
      "Epoch 104: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0741 - tp: 17571.0000 - fp: 1128.0000 - tn: 118872.0000 - fn: 6429.0000 - accuracy: 0.9475 - precision: 0.9397 - recall: 0.7321 - auc: 0.9853 - prc: 0.9398 - val_loss: 0.0578 - val_tp: 2246.0000 - val_fp: 74.0000 - val_tn: 14926.0000 - val_fn: 754.0000 - val_accuracy: 0.9540 - val_precision: 0.9681 - val_recall: 0.7487 - val_auc: 0.9912 - val_prc: 0.9631\n",
      "Epoch 105/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0738 - tp: 17465.0000 - fp: 1062.0000 - tn: 118218.0000 - fn: 6391.0000 - accuracy: 0.9479 - precision: 0.9427 - recall: 0.7321 - auc: 0.9853 - prc: 0.9407\n",
      "Epoch 105: val_loss did not improve from 0.05402\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0737 - tp: 17569.0000 - fp: 1065.0000 - tn: 118935.0000 - fn: 6431.0000 - accuracy: 0.9479 - precision: 0.9428 - recall: 0.7320 - auc: 0.9853 - prc: 0.9409 - val_loss: 0.0549 - val_tp: 2369.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 631.0000 - val_accuracy: 0.9596 - val_precision: 0.9611 - val_recall: 0.7897 - val_auc: 0.9921 - val_prc: 0.9662\n",
      "Epoch 106/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0738 - tp: 17495.0000 - fp: 1110.0000 - tn: 118730.0000 - fn: 6473.0000 - accuracy: 0.9473 - precision: 0.9403 - recall: 0.7299 - auc: 0.9852 - prc: 0.9401\n",
      "Epoch 106: val_loss improved from 0.05402 to 0.05385, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0737 - tp: 17524.0000 - fp: 1111.0000 - tn: 118889.0000 - fn: 6476.0000 - accuracy: 0.9473 - precision: 0.9404 - recall: 0.7302 - auc: 0.9852 - prc: 0.9401 - val_loss: 0.0538 - val_tp: 2322.0000 - val_fp: 85.0000 - val_tn: 14915.0000 - val_fn: 678.0000 - val_accuracy: 0.9576 - val_precision: 0.9647 - val_recall: 0.7740 - val_auc: 0.9923 - val_prc: 0.9675\n",
      "Epoch 107/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0733 - tp: 17581.0000 - fp: 1102.0000 - tn: 118818.0000 - fn: 6403.0000 - accuracy: 0.9478 - precision: 0.9410 - recall: 0.7330 - auc: 0.9854 - prc: 0.9412\n",
      "Epoch 107: val_loss did not improve from 0.05385\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0733 - tp: 17594.0000 - fp: 1103.0000 - tn: 118897.0000 - fn: 6406.0000 - accuracy: 0.9479 - precision: 0.9410 - recall: 0.7331 - auc: 0.9854 - prc: 0.9412 - val_loss: 0.0553 - val_tp: 2377.0000 - val_fp: 107.0000 - val_tn: 14893.0000 - val_fn: 623.0000 - val_accuracy: 0.9594 - val_precision: 0.9569 - val_recall: 0.7923 - val_auc: 0.9918 - val_prc: 0.9653\n",
      "Epoch 108/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0731 - tp: 17574.0000 - fp: 1068.0000 - tn: 118692.0000 - fn: 6378.0000 - accuracy: 0.9482 - precision: 0.9427 - recall: 0.7337 - auc: 0.9855 - prc: 0.9414\n",
      "Epoch 108: val_loss improved from 0.05385 to 0.05256, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0731 - tp: 17609.0000 - fp: 1070.0000 - tn: 118930.0000 - fn: 6391.0000 - accuracy: 0.9482 - precision: 0.9427 - recall: 0.7337 - auc: 0.9855 - prc: 0.9414 - val_loss: 0.0526 - val_tp: 2417.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 583.0000 - val_accuracy: 0.9616 - val_precision: 0.9568 - val_recall: 0.8057 - val_auc: 0.9926 - val_prc: 0.9688\n",
      "Epoch 109/200\n",
      "1480/1500 [============================>.] - ETA: 0s - loss: 0.0731 - tp: 17461.0000 - fp: 1081.0000 - tn: 117319.0000 - fn: 6219.0000 - accuracy: 0.9486 - precision: 0.9417 - recall: 0.7374 - auc: 0.9856 - prc: 0.9414\n",
      "Epoch 109: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0728 - tp: 17716.0000 - fp: 1093.0000 - tn: 118907.0000 - fn: 6284.0000 - accuracy: 0.9488 - precision: 0.9419 - recall: 0.7382 - auc: 0.9857 - prc: 0.9418 - val_loss: 0.0536 - val_tp: 2417.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 583.0000 - val_accuracy: 0.9616 - val_precision: 0.9568 - val_recall: 0.8057 - val_auc: 0.9924 - val_prc: 0.9677\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0743 - tp: 17316.0000 - fp: 1084.0000 - tn: 118036.0000 - fn: 6508.0000 - accuracy: 0.9469 - precision: 0.9411 - recall: 0.7268 - auc: 0.9852 - prc: 0.9393\n",
      "Epoch 110: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0742 - tp: 17452.0000 - fp: 1094.0000 - tn: 118906.0000 - fn: 6548.0000 - accuracy: 0.9469 - precision: 0.9410 - recall: 0.7272 - auc: 0.9852 - prc: 0.9394 - val_loss: 0.0543 - val_tp: 2388.0000 - val_fp: 106.0000 - val_tn: 14894.0000 - val_fn: 612.0000 - val_accuracy: 0.9601 - val_precision: 0.9575 - val_recall: 0.7960 - val_auc: 0.9923 - val_prc: 0.9666\n",
      "Epoch 111/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0744 - tp: 17561.0000 - fp: 1046.0000 - tn: 118634.0000 - fn: 6375.0000 - accuracy: 0.9483 - precision: 0.9438 - recall: 0.7337 - auc: 0.9852 - prc: 0.9399\n",
      "Epoch 111: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0744 - tp: 17608.0000 - fp: 1047.0000 - tn: 118953.0000 - fn: 6392.0000 - accuracy: 0.9483 - precision: 0.9439 - recall: 0.7337 - auc: 0.9852 - prc: 0.9399 - val_loss: 0.0544 - val_tp: 2367.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 633.0000 - val_accuracy: 0.9595 - val_precision: 0.9610 - val_recall: 0.7890 - val_auc: 0.9923 - val_prc: 0.9670\n",
      "Epoch 112/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0723 - tp: 17689.0000 - fp: 1071.0000 - tn: 118529.0000 - fn: 6231.0000 - accuracy: 0.9491 - precision: 0.9429 - recall: 0.7395 - auc: 0.9859 - prc: 0.9428\n",
      "Epoch 112: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0723 - tp: 17749.0000 - fp: 1075.0000 - tn: 118925.0000 - fn: 6251.0000 - accuracy: 0.9491 - precision: 0.9429 - recall: 0.7395 - auc: 0.9859 - prc: 0.9429 - val_loss: 0.0551 - val_tp: 2342.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 658.0000 - val_accuracy: 0.9584 - val_precision: 0.9626 - val_recall: 0.7807 - val_auc: 0.9920 - val_prc: 0.9658\n",
      "Epoch 113/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0739 - tp: 17435.0000 - fp: 1140.0000 - tn: 118300.0000 - fn: 6453.0000 - accuracy: 0.9470 - precision: 0.9386 - recall: 0.7299 - auc: 0.9853 - prc: 0.9401\n",
      "Epoch 113: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0738 - tp: 17510.0000 - fp: 1142.0000 - tn: 118858.0000 - fn: 6490.0000 - accuracy: 0.9470 - precision: 0.9388 - recall: 0.7296 - auc: 0.9853 - prc: 0.9402 - val_loss: 0.0563 - val_tp: 2308.0000 - val_fp: 85.0000 - val_tn: 14915.0000 - val_fn: 692.0000 - val_accuracy: 0.9568 - val_precision: 0.9645 - val_recall: 0.7693 - val_auc: 0.9917 - val_prc: 0.9650\n",
      "Epoch 114/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0733 - tp: 17579.0000 - fp: 1111.0000 - tn: 118169.0000 - fn: 6277.0000 - accuracy: 0.9484 - precision: 0.9406 - recall: 0.7369 - auc: 0.9855 - prc: 0.9413\n",
      "Epoch 114: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0733 - tp: 17685.0000 - fp: 1120.0000 - tn: 118880.0000 - fn: 6315.0000 - accuracy: 0.9484 - precision: 0.9404 - recall: 0.7369 - auc: 0.9855 - prc: 0.9413 - val_loss: 0.0566 - val_tp: 2411.0000 - val_fp: 120.0000 - val_tn: 14880.0000 - val_fn: 589.0000 - val_accuracy: 0.9606 - val_precision: 0.9526 - val_recall: 0.8037 - val_auc: 0.9915 - val_prc: 0.9639\n",
      "Epoch 115/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0717 - tp: 17623.0000 - fp: 1079.0000 - tn: 118361.0000 - fn: 6265.0000 - accuracy: 0.9488 - precision: 0.9423 - recall: 0.7377 - auc: 0.9861 - prc: 0.9434\n",
      "Epoch 115: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0717 - tp: 17698.0000 - fp: 1085.0000 - tn: 118915.0000 - fn: 6302.0000 - accuracy: 0.9487 - precision: 0.9422 - recall: 0.7374 - auc: 0.9860 - prc: 0.9433 - val_loss: 0.0535 - val_tp: 2421.0000 - val_fp: 125.0000 - val_tn: 14875.0000 - val_fn: 579.0000 - val_accuracy: 0.9609 - val_precision: 0.9509 - val_recall: 0.8070 - val_auc: 0.9924 - val_prc: 0.9677\n",
      "Epoch 116/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0711 - tp: 17645.0000 - fp: 1143.0000 - tn: 118057.0000 - fn: 6195.0000 - accuracy: 0.9487 - precision: 0.9392 - recall: 0.7401 - auc: 0.9863 - prc: 0.9441\n",
      "Epoch 116: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0711 - tp: 17766.0000 - fp: 1150.0000 - tn: 118850.0000 - fn: 6234.0000 - accuracy: 0.9487 - precision: 0.9392 - recall: 0.7402 - auc: 0.9863 - prc: 0.9440 - val_loss: 0.0535 - val_tp: 2370.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 630.0000 - val_accuracy: 0.9593 - val_precision: 0.9584 - val_recall: 0.7900 - val_auc: 0.9924 - val_prc: 0.9677\n",
      "Epoch 117/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0733 - tp: 17586.0000 - fp: 1101.0000 - tn: 118419.0000 - fn: 6318.0000 - accuracy: 0.9483 - precision: 0.9411 - recall: 0.7357 - auc: 0.9857 - prc: 0.9411\n",
      "Epoch 117: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0733 - tp: 17659.0000 - fp: 1104.0000 - tn: 118896.0000 - fn: 6341.0000 - accuracy: 0.9483 - precision: 0.9412 - recall: 0.7358 - auc: 0.9857 - prc: 0.9411 - val_loss: 0.0544 - val_tp: 2322.0000 - val_fp: 82.0000 - val_tn: 14918.0000 - val_fn: 678.0000 - val_accuracy: 0.9578 - val_precision: 0.9659 - val_recall: 0.7740 - val_auc: 0.9922 - val_prc: 0.9672\n",
      "Epoch 118/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 17674.0000 - fp: 1089.0000 - tn: 118191.0000 - fn: 6182.0000 - accuracy: 0.9492 - precision: 0.9420 - recall: 0.7409 - auc: 0.9862 - prc: 0.9436\n",
      "Epoch 118: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0713 - tp: 17790.0000 - fp: 1093.0000 - tn: 118907.0000 - fn: 6210.0000 - accuracy: 0.9493 - precision: 0.9421 - recall: 0.7412 - auc: 0.9862 - prc: 0.9438 - val_loss: 0.0530 - val_tp: 2439.0000 - val_fp: 110.0000 - val_tn: 14890.0000 - val_fn: 561.0000 - val_accuracy: 0.9627 - val_precision: 0.9568 - val_recall: 0.8130 - val_auc: 0.9925 - val_prc: 0.9683\n",
      "Epoch 119/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0720 - tp: 17744.0000 - fp: 1086.0000 - tn: 118274.0000 - fn: 6128.0000 - accuracy: 0.9496 - precision: 0.9423 - recall: 0.7433 - auc: 0.9861 - prc: 0.9431\n",
      "Epoch 119: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0720 - tp: 17839.0000 - fp: 1093.0000 - tn: 118907.0000 - fn: 6161.0000 - accuracy: 0.9496 - precision: 0.9423 - recall: 0.7433 - auc: 0.9861 - prc: 0.9431 - val_loss: 0.0547 - val_tp: 2341.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 659.0000 - val_accuracy: 0.9582 - val_precision: 0.9614 - val_recall: 0.7803 - val_auc: 0.9921 - val_prc: 0.9665\n",
      "Epoch 120/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0727 - tp: 17585.0000 - fp: 1123.0000 - tn: 118317.0000 - fn: 6303.0000 - accuracy: 0.9482 - precision: 0.9400 - recall: 0.7361 - auc: 0.9857 - prc: 0.9418\n",
      "Epoch 120: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0726 - tp: 17664.0000 - fp: 1128.0000 - tn: 118872.0000 - fn: 6336.0000 - accuracy: 0.9482 - precision: 0.9400 - recall: 0.7360 - auc: 0.9857 - prc: 0.9418 - val_loss: 0.0530 - val_tp: 2437.0000 - val_fp: 107.0000 - val_tn: 14893.0000 - val_fn: 563.0000 - val_accuracy: 0.9628 - val_precision: 0.9579 - val_recall: 0.8123 - val_auc: 0.9925 - val_prc: 0.9687\n",
      "Epoch 121/200\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.0712 - tp: 17582.0000 - fp: 1062.0000 - tn: 117498.0000 - fn: 6130.0000 - accuracy: 0.9494 - precision: 0.9430 - recall: 0.7415 - auc: 0.9863 - prc: 0.9445\n",
      "Epoch 121: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0710 - tp: 17803.0000 - fp: 1072.0000 - tn: 118928.0000 - fn: 6197.0000 - accuracy: 0.9495 - precision: 0.9432 - recall: 0.7418 - auc: 0.9863 - prc: 0.9447 - val_loss: 0.0537 - val_tp: 2422.0000 - val_fp: 112.0000 - val_tn: 14888.0000 - val_fn: 578.0000 - val_accuracy: 0.9617 - val_precision: 0.9558 - val_recall: 0.8073 - val_auc: 0.9923 - val_prc: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 17684.0000 - fp: 1104.0000 - tn: 118016.0000 - fn: 6140.0000 - accuracy: 0.9493 - precision: 0.9412 - recall: 0.7423 - auc: 0.9862 - prc: 0.9440\n",
      "Epoch 122: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0715 - tp: 17818.0000 - fp: 1110.0000 - tn: 118890.0000 - fn: 6182.0000 - accuracy: 0.9494 - precision: 0.9414 - recall: 0.7424 - auc: 0.9863 - prc: 0.9440 - val_loss: 0.0535 - val_tp: 2391.0000 - val_fp: 95.0000 - val_tn: 14905.0000 - val_fn: 609.0000 - val_accuracy: 0.9609 - val_precision: 0.9618 - val_recall: 0.7970 - val_auc: 0.9924 - val_prc: 0.9677\n",
      "Epoch 123/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 17591.0000 - fp: 1109.0000 - tn: 118171.0000 - fn: 6265.0000 - accuracy: 0.9485 - precision: 0.9407 - recall: 0.7374 - auc: 0.9860 - prc: 0.9427\n",
      "Epoch 123: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0722 - tp: 17699.0000 - fp: 1116.0000 - tn: 118884.0000 - fn: 6301.0000 - accuracy: 0.9485 - precision: 0.9407 - recall: 0.7375 - auc: 0.9860 - prc: 0.9428 - val_loss: 0.0551 - val_tp: 2369.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 631.0000 - val_accuracy: 0.9596 - val_precision: 0.9611 - val_recall: 0.7897 - val_auc: 0.9918 - val_prc: 0.9655\n",
      "Epoch 124/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0724 - tp: 17709.0000 - fp: 1081.0000 - tn: 118759.0000 - fn: 6259.0000 - accuracy: 0.9490 - precision: 0.9425 - recall: 0.7389 - auc: 0.9859 - prc: 0.9432\n",
      "Epoch 124: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0724 - tp: 17729.0000 - fp: 1083.0000 - tn: 118917.0000 - fn: 6271.0000 - accuracy: 0.9489 - precision: 0.9424 - recall: 0.7387 - auc: 0.9859 - prc: 0.9431 - val_loss: 0.0550 - val_tp: 2388.0000 - val_fp: 105.0000 - val_tn: 14895.0000 - val_fn: 612.0000 - val_accuracy: 0.9602 - val_precision: 0.9579 - val_recall: 0.7960 - val_auc: 0.9920 - val_prc: 0.9658\n",
      "Epoch 125/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0720 - tp: 17651.0000 - fp: 1094.0000 - tn: 118266.0000 - fn: 6221.0000 - accuracy: 0.9489 - precision: 0.9416 - recall: 0.7394 - auc: 0.9862 - prc: 0.9434\n",
      "Epoch 125: val_loss did not improve from 0.05256\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0721 - tp: 17742.0000 - fp: 1102.0000 - tn: 118898.0000 - fn: 6258.0000 - accuracy: 0.9489 - precision: 0.9415 - recall: 0.7393 - auc: 0.9862 - prc: 0.9433 - val_loss: 0.0536 - val_tp: 2432.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 568.0000 - val_accuracy: 0.9624 - val_precision: 0.9571 - val_recall: 0.8107 - val_auc: 0.9923 - val_prc: 0.9676\n",
      "Epoch 126/200\n",
      "1485/1500 [============================>.] - ETA: 0s - loss: 0.0704 - tp: 17758.0000 - fp: 1039.0000 - tn: 117761.0000 - fn: 6002.0000 - accuracy: 0.9506 - precision: 0.9447 - recall: 0.7474 - auc: 0.9864 - prc: 0.9456\n",
      "Epoch 126: val_loss improved from 0.05256 to 0.05236, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0704 - tp: 17931.0000 - fp: 1053.0000 - tn: 118947.0000 - fn: 6069.0000 - accuracy: 0.9505 - precision: 0.9445 - recall: 0.7471 - auc: 0.9864 - prc: 0.9456 - val_loss: 0.0524 - val_tp: 2430.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 570.0000 - val_accuracy: 0.9631 - val_precision: 0.9628 - val_recall: 0.8100 - val_auc: 0.9927 - val_prc: 0.9693\n",
      "Epoch 127/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0721 - tp: 17631.0000 - fp: 1089.0000 - tn: 118351.0000 - fn: 6257.0000 - accuracy: 0.9487 - precision: 0.9418 - recall: 0.7381 - auc: 0.9860 - prc: 0.9433\n",
      "Epoch 127: val_loss did not improve from 0.05236\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0719 - tp: 17721.0000 - fp: 1091.0000 - tn: 118909.0000 - fn: 6279.0000 - accuracy: 0.9488 - precision: 0.9420 - recall: 0.7384 - auc: 0.9860 - prc: 0.9435 - val_loss: 0.0536 - val_tp: 2418.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 582.0000 - val_accuracy: 0.9617 - val_precision: 0.9572 - val_recall: 0.8060 - val_auc: 0.9924 - val_prc: 0.9680\n",
      "Epoch 128/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0716 - tp: 17542.0000 - fp: 1115.0000 - tn: 118005.0000 - fn: 6282.0000 - accuracy: 0.9483 - precision: 0.9402 - recall: 0.7363 - auc: 0.9864 - prc: 0.9435\n",
      "Epoch 128: val_loss did not improve from 0.05236\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0715 - tp: 17672.0000 - fp: 1122.0000 - tn: 118878.0000 - fn: 6328.0000 - accuracy: 0.9483 - precision: 0.9403 - recall: 0.7363 - auc: 0.9864 - prc: 0.9436 - val_loss: 0.0535 - val_tp: 2397.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 603.0000 - val_accuracy: 0.9612 - val_precision: 0.9615 - val_recall: 0.7990 - val_auc: 0.9923 - val_prc: 0.9680\n",
      "Epoch 129/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 17908.0000 - fp: 1065.0000 - tn: 118535.0000 - fn: 6012.0000 - accuracy: 0.9507 - precision: 0.9439 - recall: 0.7487 - auc: 0.9867 - prc: 0.9458\n",
      "Epoch 129: val_loss did not improve from 0.05236\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0702 - tp: 17966.0000 - fp: 1069.0000 - tn: 118931.0000 - fn: 6034.0000 - accuracy: 0.9507 - precision: 0.9438 - recall: 0.7486 - auc: 0.9867 - prc: 0.9457 - val_loss: 0.0536 - val_tp: 2450.0000 - val_fp: 117.0000 - val_tn: 14883.0000 - val_fn: 550.0000 - val_accuracy: 0.9629 - val_precision: 0.9544 - val_recall: 0.8167 - val_auc: 0.9923 - val_prc: 0.9675\n",
      "Epoch 130/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0707 - tp: 17816.0000 - fp: 1090.0000 - tn: 118350.0000 - fn: 6072.0000 - accuracy: 0.9500 - precision: 0.9423 - recall: 0.7458 - auc: 0.9866 - prc: 0.9453\n",
      "Epoch 130: val_loss did not improve from 0.05236\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0708 - tp: 17896.0000 - fp: 1098.0000 - tn: 118902.0000 - fn: 6104.0000 - accuracy: 0.9500 - precision: 0.9422 - recall: 0.7457 - auc: 0.9866 - prc: 0.9453 - val_loss: 0.0540 - val_tp: 2404.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 596.0000 - val_accuracy: 0.9618 - val_precision: 0.9635 - val_recall: 0.8013 - val_auc: 0.9923 - val_prc: 0.9675\n",
      "Epoch 131/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0718 - tp: 17740.0000 - fp: 1085.0000 - tn: 118595.0000 - fn: 6196.0000 - accuracy: 0.9493 - precision: 0.9424 - recall: 0.7411 - auc: 0.9863 - prc: 0.9438\n",
      "Epoch 131: val_loss improved from 0.05236 to 0.05233, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0717 - tp: 17786.0000 - fp: 1087.0000 - tn: 118913.0000 - fn: 6214.0000 - accuracy: 0.9493 - precision: 0.9424 - recall: 0.7411 - auc: 0.9863 - prc: 0.9438 - val_loss: 0.0523 - val_tp: 2423.0000 - val_fp: 95.0000 - val_tn: 14905.0000 - val_fn: 577.0000 - val_accuracy: 0.9627 - val_precision: 0.9623 - val_recall: 0.8077 - val_auc: 0.9927 - val_prc: 0.9693\n",
      "Epoch 132/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0712 - tp: 18004.0000 - fp: 1096.0000 - tn: 118664.0000 - fn: 5948.0000 - accuracy: 0.9510 - precision: 0.9426 - recall: 0.7517 - auc: 0.9864 - prc: 0.9445\n",
      "Epoch 132: val_loss improved from 0.05233 to 0.05203, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0712 - tp: 18040.0000 - fp: 1097.0000 - tn: 118903.0000 - fn: 5960.0000 - accuracy: 0.9510 - precision: 0.9427 - recall: 0.7517 - auc: 0.9864 - prc: 0.9445 - val_loss: 0.0520 - val_tp: 2430.0000 - val_fp: 105.0000 - val_tn: 14895.0000 - val_fn: 570.0000 - val_accuracy: 0.9625 - val_precision: 0.9586 - val_recall: 0.8100 - val_auc: 0.9928 - val_prc: 0.9698\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 17918.0000 - fp: 1104.0000 - tn: 118416.0000 - fn: 5986.0000 - accuracy: 0.9506 - precision: 0.9420 - recall: 0.7496 - auc: 0.9867 - prc: 0.9458\n",
      "Epoch 133: val_loss did not improve from 0.05203\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0700 - tp: 17994.0000 - fp: 1107.0000 - tn: 118893.0000 - fn: 6006.0000 - accuracy: 0.9506 - precision: 0.9420 - recall: 0.7498 - auc: 0.9867 - prc: 0.9458 - val_loss: 0.0539 - val_tp: 2331.0000 - val_fp: 80.0000 - val_tn: 14920.0000 - val_fn: 669.0000 - val_accuracy: 0.9584 - val_precision: 0.9668 - val_recall: 0.7770 - val_auc: 0.9924 - val_prc: 0.9679\n",
      "Epoch 134/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0714 - tp: 17831.0000 - fp: 1074.0000 - tn: 118766.0000 - fn: 6137.0000 - accuracy: 0.9499 - precision: 0.9432 - recall: 0.7440 - auc: 0.9862 - prc: 0.9443\n",
      "Epoch 134: val_loss did not improve from 0.05203\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0714 - tp: 17855.0000 - fp: 1075.0000 - tn: 118925.0000 - fn: 6145.0000 - accuracy: 0.9499 - precision: 0.9432 - recall: 0.7440 - auc: 0.9862 - prc: 0.9443 - val_loss: 0.0567 - val_tp: 2359.0000 - val_fp: 107.0000 - val_tn: 14893.0000 - val_fn: 641.0000 - val_accuracy: 0.9584 - val_precision: 0.9566 - val_recall: 0.7863 - val_auc: 0.9914 - val_prc: 0.9637\n",
      "Epoch 135/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 17872.0000 - fp: 1101.0000 - tn: 118739.0000 - fn: 6096.0000 - accuracy: 0.9500 - precision: 0.9420 - recall: 0.7457 - auc: 0.9863 - prc: 0.9438\n",
      "Epoch 135: val_loss did not improve from 0.05203\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0719 - tp: 17896.0000 - fp: 1103.0000 - tn: 118897.0000 - fn: 6104.0000 - accuracy: 0.9500 - precision: 0.9419 - recall: 0.7457 - auc: 0.9863 - prc: 0.9438 - val_loss: 0.0527 - val_tp: 2367.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 633.0000 - val_accuracy: 0.9594 - val_precision: 0.9602 - val_recall: 0.7890 - val_auc: 0.9926 - val_prc: 0.9689\n",
      "Epoch 136/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 17821.0000 - fp: 1097.0000 - tn: 118103.0000 - fn: 6019.0000 - accuracy: 0.9503 - precision: 0.9420 - recall: 0.7475 - auc: 0.9868 - prc: 0.9463\n",
      "Epoch 136: val_loss improved from 0.05203 to 0.05197, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0697 - tp: 17949.0000 - fp: 1103.0000 - tn: 118897.0000 - fn: 6051.0000 - accuracy: 0.9503 - precision: 0.9421 - recall: 0.7479 - auc: 0.9869 - prc: 0.9465 - val_loss: 0.0520 - val_tp: 2447.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 553.0000 - val_accuracy: 0.9632 - val_precision: 0.9574 - val_recall: 0.8157 - val_auc: 0.9927 - val_prc: 0.9694\n",
      "Epoch 137/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0712 - tp: 17795.0000 - fp: 1095.0000 - tn: 118585.0000 - fn: 6141.0000 - accuracy: 0.9496 - precision: 0.9420 - recall: 0.7434 - auc: 0.9865 - prc: 0.9442\n",
      "Epoch 137: val_loss did not improve from 0.05197\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0714 - tp: 17847.0000 - fp: 1098.0000 - tn: 118902.0000 - fn: 6153.0000 - accuracy: 0.9496 - precision: 0.9420 - recall: 0.7436 - auc: 0.9864 - prc: 0.9441 - val_loss: 0.0539 - val_tp: 2405.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 595.0000 - val_accuracy: 0.9609 - val_precision: 0.9566 - val_recall: 0.8017 - val_auc: 0.9923 - val_prc: 0.9670\n",
      "Epoch 138/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0716 - tp: 17870.0000 - fp: 1101.0000 - tn: 118819.0000 - fn: 6114.0000 - accuracy: 0.9499 - precision: 0.9420 - recall: 0.7451 - auc: 0.9863 - prc: 0.9448\n",
      "Epoch 138: val_loss did not improve from 0.05197\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0717 - tp: 17880.0000 - fp: 1103.0000 - tn: 118897.0000 - fn: 6120.0000 - accuracy: 0.9498 - precision: 0.9419 - recall: 0.7450 - auc: 0.9863 - prc: 0.9447 - val_loss: 0.0535 - val_tp: 2316.0000 - val_fp: 80.0000 - val_tn: 14920.0000 - val_fn: 684.0000 - val_accuracy: 0.9576 - val_precision: 0.9666 - val_recall: 0.7720 - val_auc: 0.9925 - val_prc: 0.9685\n",
      "Epoch 139/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 17682.0000 - fp: 1051.0000 - tn: 118069.0000 - fn: 6142.0000 - accuracy: 0.9497 - precision: 0.9439 - recall: 0.7422 - auc: 0.9867 - prc: 0.9454\n",
      "Epoch 139: val_loss did not improve from 0.05197\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0703 - tp: 17811.0000 - fp: 1058.0000 - tn: 118942.0000 - fn: 6189.0000 - accuracy: 0.9497 - precision: 0.9439 - recall: 0.7421 - auc: 0.9867 - prc: 0.9455 - val_loss: 0.0528 - val_tp: 2407.0000 - val_fp: 97.0000 - val_tn: 14903.0000 - val_fn: 593.0000 - val_accuracy: 0.9617 - val_precision: 0.9613 - val_recall: 0.8023 - val_auc: 0.9926 - val_prc: 0.9688\n",
      "Epoch 140/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0702 - tp: 17952.0000 - fp: 1089.0000 - tn: 118671.0000 - fn: 6000.0000 - accuracy: 0.9507 - precision: 0.9428 - recall: 0.7495 - auc: 0.9867 - prc: 0.9455\n",
      "Epoch 140: val_loss improved from 0.05197 to 0.05167, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0702 - tp: 17992.0000 - fp: 1089.0000 - tn: 118911.0000 - fn: 6008.0000 - accuracy: 0.9507 - precision: 0.9429 - recall: 0.7497 - auc: 0.9867 - prc: 0.9456 - val_loss: 0.0517 - val_tp: 2443.0000 - val_fp: 106.0000 - val_tn: 14894.0000 - val_fn: 557.0000 - val_accuracy: 0.9632 - val_precision: 0.9584 - val_recall: 0.8143 - val_auc: 0.9929 - val_prc: 0.9698\n",
      "Epoch 141/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0706 - tp: 17801.0000 - fp: 1047.0000 - tn: 118393.0000 - fn: 6087.0000 - accuracy: 0.9502 - precision: 0.9445 - recall: 0.7452 - auc: 0.9865 - prc: 0.9453\n",
      "Epoch 141: val_loss did not improve from 0.05167\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0707 - tp: 17879.0000 - fp: 1051.0000 - tn: 118949.0000 - fn: 6121.0000 - accuracy: 0.9502 - precision: 0.9445 - recall: 0.7450 - auc: 0.9864 - prc: 0.9452 - val_loss: 0.0520 - val_tp: 2411.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 589.0000 - val_accuracy: 0.9618 - val_precision: 0.9609 - val_recall: 0.8037 - val_auc: 0.9928 - val_prc: 0.9696\n",
      "Epoch 142/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 18015.0000 - fp: 1101.0000 - tn: 118579.0000 - fn: 5921.0000 - accuracy: 0.9511 - precision: 0.9424 - recall: 0.7526 - auc: 0.9867 - prc: 0.9468\n",
      "Epoch 142: val_loss improved from 0.05167 to 0.05087, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0697 - tp: 18065.0000 - fp: 1105.0000 - tn: 118895.0000 - fn: 5935.0000 - accuracy: 0.9511 - precision: 0.9424 - recall: 0.7527 - auc: 0.9867 - prc: 0.9468 - val_loss: 0.0509 - val_tp: 2447.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 553.0000 - val_accuracy: 0.9633 - val_precision: 0.9577 - val_recall: 0.8157 - val_auc: 0.9931 - val_prc: 0.9708\n",
      "Epoch 143/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0709 - tp: 17909.0000 - fp: 1100.0000 - tn: 118900.0000 - fn: 6091.0000 - accuracy: 0.9501 - precision: 0.9421 - recall: 0.7462 - auc: 0.9864 - prc: 0.9452\n",
      "Epoch 143: val_loss did not improve from 0.05087\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0709 - tp: 17909.0000 - fp: 1100.0000 - tn: 118900.0000 - fn: 6091.0000 - accuracy: 0.9501 - precision: 0.9421 - recall: 0.7462 - auc: 0.9864 - prc: 0.9452 - val_loss: 0.0514 - val_tp: 2467.0000 - val_fp: 110.0000 - val_tn: 14890.0000 - val_fn: 533.0000 - val_accuracy: 0.9643 - val_precision: 0.9573 - val_recall: 0.8223 - val_auc: 0.9930 - val_prc: 0.9706\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0704 - tp: 17862.0000 - fp: 1053.0000 - tn: 118707.0000 - fn: 6090.0000 - accuracy: 0.9503 - precision: 0.9443 - recall: 0.7457 - auc: 0.9867 - prc: 0.9457\n",
      "Epoch 144: val_loss did not improve from 0.05087\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0704 - tp: 17897.0000 - fp: 1055.0000 - tn: 118945.0000 - fn: 6103.0000 - accuracy: 0.9503 - precision: 0.9443 - recall: 0.7457 - auc: 0.9867 - prc: 0.9456 - val_loss: 0.0520 - val_tp: 2450.0000 - val_fp: 105.0000 - val_tn: 14895.0000 - val_fn: 550.0000 - val_accuracy: 0.9636 - val_precision: 0.9589 - val_recall: 0.8167 - val_auc: 0.9928 - val_prc: 0.9694\n",
      "Epoch 145/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 17840.0000 - fp: 1092.0000 - tn: 118348.0000 - fn: 6048.0000 - accuracy: 0.9502 - precision: 0.9423 - recall: 0.7468 - auc: 0.9867 - prc: 0.9461\n",
      "Epoch 145: val_loss improved from 0.05087 to 0.05069, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0702 - tp: 17918.0000 - fp: 1096.0000 - tn: 118904.0000 - fn: 6082.0000 - accuracy: 0.9502 - precision: 0.9424 - recall: 0.7466 - auc: 0.9867 - prc: 0.9460 - val_loss: 0.0507 - val_tp: 2394.0000 - val_fp: 83.0000 - val_tn: 14917.0000 - val_fn: 606.0000 - val_accuracy: 0.9617 - val_precision: 0.9665 - val_recall: 0.7980 - val_auc: 0.9933 - val_prc: 0.9715\n",
      "Epoch 146/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 17709.0000 - fp: 1087.0000 - tn: 118273.0000 - fn: 6163.0000 - accuracy: 0.9494 - precision: 0.9422 - recall: 0.7418 - auc: 0.9864 - prc: 0.9443\n",
      "Epoch 146: val_loss did not improve from 0.05069\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0713 - tp: 17802.0000 - fp: 1092.0000 - tn: 118908.0000 - fn: 6198.0000 - accuracy: 0.9494 - precision: 0.9422 - recall: 0.7418 - auc: 0.9864 - prc: 0.9443 - val_loss: 0.0522 - val_tp: 2369.0000 - val_fp: 82.0000 - val_tn: 14918.0000 - val_fn: 631.0000 - val_accuracy: 0.9604 - val_precision: 0.9665 - val_recall: 0.7897 - val_auc: 0.9929 - val_prc: 0.9698\n",
      "Epoch 147/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 17739.0000 - fp: 1096.0000 - tn: 118104.0000 - fn: 6101.0000 - accuracy: 0.9497 - precision: 0.9418 - recall: 0.7441 - auc: 0.9868 - prc: 0.9457\n",
      "Epoch 147: val_loss did not improve from 0.05069\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0702 - tp: 17860.0000 - fp: 1101.0000 - tn: 118899.0000 - fn: 6140.0000 - accuracy: 0.9497 - precision: 0.9419 - recall: 0.7442 - auc: 0.9868 - prc: 0.9457 - val_loss: 0.0514 - val_tp: 2390.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 610.0000 - val_accuracy: 0.9607 - val_precision: 0.9606 - val_recall: 0.7967 - val_auc: 0.9929 - val_prc: 0.9701\n",
      "Epoch 148/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0716 - tp: 17749.0000 - fp: 1113.0000 - tn: 118087.0000 - fn: 6091.0000 - accuracy: 0.9496 - precision: 0.9410 - recall: 0.7445 - auc: 0.9862 - prc: 0.9437\n",
      "Epoch 148: val_loss did not improve from 0.05069\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0716 - tp: 17865.0000 - fp: 1124.0000 - tn: 118876.0000 - fn: 6135.0000 - accuracy: 0.9496 - precision: 0.9408 - recall: 0.7444 - auc: 0.9862 - prc: 0.9437 - val_loss: 0.0515 - val_tp: 2391.0000 - val_fp: 90.0000 - val_tn: 14910.0000 - val_fn: 609.0000 - val_accuracy: 0.9612 - val_precision: 0.9637 - val_recall: 0.7970 - val_auc: 0.9929 - val_prc: 0.9703\n",
      "Epoch 149/200\n",
      "1479/1500 [============================>.] - ETA: 0s - loss: 0.0696 - tp: 17763.0000 - fp: 1078.0000 - tn: 117242.0000 - fn: 5901.0000 - accuracy: 0.9508 - precision: 0.9428 - recall: 0.7506 - auc: 0.9870 - prc: 0.9475\n",
      "Epoch 149: val_loss did not improve from 0.05069\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0695 - tp: 18012.0000 - fp: 1090.0000 - tn: 118910.0000 - fn: 5988.0000 - accuracy: 0.9508 - precision: 0.9429 - recall: 0.7505 - auc: 0.9870 - prc: 0.9476 - val_loss: 0.0513 - val_tp: 2401.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 599.0000 - val_accuracy: 0.9616 - val_precision: 0.9631 - val_recall: 0.8003 - val_auc: 0.9930 - val_prc: 0.9704\n",
      "Epoch 150/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0700 - tp: 17970.0000 - fp: 1006.0000 - tn: 118674.0000 - fn: 5966.0000 - accuracy: 0.9515 - precision: 0.9470 - recall: 0.7508 - auc: 0.9867 - prc: 0.9462\n",
      "Epoch 150: val_loss did not improve from 0.05069\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0700 - tp: 18022.0000 - fp: 1010.0000 - tn: 118990.0000 - fn: 5978.0000 - accuracy: 0.9515 - precision: 0.9469 - recall: 0.7509 - auc: 0.9867 - prc: 0.9462 - val_loss: 0.0529 - val_tp: 2372.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 628.0000 - val_accuracy: 0.9600 - val_precision: 0.9627 - val_recall: 0.7907 - val_auc: 0.9927 - val_prc: 0.9687\n",
      "Epoch 151/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0700 - tp: 18041.0000 - fp: 1076.0000 - tn: 118604.0000 - fn: 5895.0000 - accuracy: 0.9515 - precision: 0.9437 - recall: 0.7537 - auc: 0.9868 - prc: 0.9466\n",
      "Epoch 151: val_loss improved from 0.05069 to 0.05043, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0700 - tp: 18088.0000 - fp: 1078.0000 - tn: 118922.0000 - fn: 5912.0000 - accuracy: 0.9515 - precision: 0.9438 - recall: 0.7537 - auc: 0.9868 - prc: 0.9466 - val_loss: 0.0504 - val_tp: 2433.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 567.0000 - val_accuracy: 0.9634 - val_precision: 0.9636 - val_recall: 0.8110 - val_auc: 0.9932 - val_prc: 0.9717\n",
      "Epoch 152/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 17838.0000 - fp: 1060.0000 - tn: 118220.0000 - fn: 6018.0000 - accuracy: 0.9506 - precision: 0.9439 - recall: 0.7477 - auc: 0.9866 - prc: 0.9461\n",
      "Epoch 152: val_loss did not improve from 0.05043\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0702 - tp: 17947.0000 - fp: 1067.0000 - tn: 118933.0000 - fn: 6053.0000 - accuracy: 0.9506 - precision: 0.9439 - recall: 0.7478 - auc: 0.9866 - prc: 0.9462 - val_loss: 0.0518 - val_tp: 2366.0000 - val_fp: 83.0000 - val_tn: 14917.0000 - val_fn: 634.0000 - val_accuracy: 0.9602 - val_precision: 0.9661 - val_recall: 0.7887 - val_auc: 0.9929 - val_prc: 0.9703\n",
      "Epoch 153/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 18025.0000 - fp: 1041.0000 - tn: 118799.0000 - fn: 5943.0000 - accuracy: 0.9514 - precision: 0.9454 - recall: 0.7520 - auc: 0.9873 - prc: 0.9477\n",
      "Epoch 153: val_loss did not improve from 0.05043\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0693 - tp: 18044.0000 - fp: 1044.0000 - tn: 118956.0000 - fn: 5956.0000 - accuracy: 0.9514 - precision: 0.9453 - recall: 0.7518 - auc: 0.9872 - prc: 0.9476 - val_loss: 0.0514 - val_tp: 2408.0000 - val_fp: 100.0000 - val_tn: 14900.0000 - val_fn: 592.0000 - val_accuracy: 0.9616 - val_precision: 0.9601 - val_recall: 0.8027 - val_auc: 0.9931 - val_prc: 0.9702\n",
      "Epoch 154/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 17944.0000 - fp: 1104.0000 - tn: 118816.0000 - fn: 6040.0000 - accuracy: 0.9504 - precision: 0.9420 - recall: 0.7482 - auc: 0.9868 - prc: 0.9467\n",
      "Epoch 154: val_loss improved from 0.05043 to 0.05038, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0698 - tp: 17955.0000 - fp: 1105.0000 - tn: 118895.0000 - fn: 6045.0000 - accuracy: 0.9503 - precision: 0.9420 - recall: 0.7481 - auc: 0.9869 - prc: 0.9467 - val_loss: 0.0504 - val_tp: 2470.0000 - val_fp: 106.0000 - val_tn: 14894.0000 - val_fn: 530.0000 - val_accuracy: 0.9647 - val_precision: 0.9589 - val_recall: 0.8233 - val_auc: 0.9933 - val_prc: 0.9714\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487/1500 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 17844.0000 - fp: 1082.0000 - tn: 117878.0000 - fn: 5948.0000 - accuracy: 0.9508 - precision: 0.9428 - recall: 0.7500 - auc: 0.9870 - prc: 0.9466\n",
      "Epoch 155: val_loss did not improve from 0.05038\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0699 - tp: 17999.0000 - fp: 1089.0000 - tn: 118911.0000 - fn: 6001.0000 - accuracy: 0.9508 - precision: 0.9429 - recall: 0.7500 - auc: 0.9870 - prc: 0.9466 - val_loss: 0.0518 - val_tp: 2476.0000 - val_fp: 133.0000 - val_tn: 14867.0000 - val_fn: 524.0000 - val_accuracy: 0.9635 - val_precision: 0.9490 - val_recall: 0.8253 - val_auc: 0.9929 - val_prc: 0.9699\n",
      "Epoch 156/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 18022.0000 - fp: 1102.0000 - tn: 118098.0000 - fn: 5818.0000 - accuracy: 0.9516 - precision: 0.9424 - recall: 0.7560 - auc: 0.9871 - prc: 0.9475\n",
      "Epoch 156: val_loss did not improve from 0.05038\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0695 - tp: 18129.0000 - fp: 1111.0000 - tn: 118889.0000 - fn: 5871.0000 - accuracy: 0.9515 - precision: 0.9423 - recall: 0.7554 - auc: 0.9871 - prc: 0.9471 - val_loss: 0.0517 - val_tp: 2392.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 608.0000 - val_accuracy: 0.9610 - val_precision: 0.9622 - val_recall: 0.7973 - val_auc: 0.9929 - val_prc: 0.9702\n",
      "Epoch 157/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 18078.0000 - fp: 1099.0000 - tn: 118821.0000 - fn: 5906.0000 - accuracy: 0.9513 - precision: 0.9427 - recall: 0.7538 - auc: 0.9871 - prc: 0.9468\n",
      "Epoch 157: val_loss did not improve from 0.05038\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0697 - tp: 18091.0000 - fp: 1100.0000 - tn: 118900.0000 - fn: 5909.0000 - accuracy: 0.9513 - precision: 0.9427 - recall: 0.7538 - auc: 0.9871 - prc: 0.9468 - val_loss: 0.0525 - val_tp: 2394.0000 - val_fp: 101.0000 - val_tn: 14899.0000 - val_fn: 606.0000 - val_accuracy: 0.9607 - val_precision: 0.9595 - val_recall: 0.7980 - val_auc: 0.9926 - val_prc: 0.9689\n",
      "Epoch 158/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0702 - tp: 17854.0000 - fp: 1096.0000 - tn: 118344.0000 - fn: 6034.0000 - accuracy: 0.9503 - precision: 0.9422 - recall: 0.7474 - auc: 0.9867 - prc: 0.9458\n",
      "Epoch 158: val_loss did not improve from 0.05038\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0702 - tp: 17943.0000 - fp: 1100.0000 - tn: 118900.0000 - fn: 6057.0000 - accuracy: 0.9503 - precision: 0.9422 - recall: 0.7476 - auc: 0.9867 - prc: 0.9458 - val_loss: 0.0526 - val_tp: 2410.0000 - val_fp: 104.0000 - val_tn: 14896.0000 - val_fn: 590.0000 - val_accuracy: 0.9614 - val_precision: 0.9586 - val_recall: 0.8033 - val_auc: 0.9926 - val_prc: 0.9688\n",
      "Epoch 159/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 18010.0000 - fp: 1040.0000 - tn: 118240.0000 - fn: 5846.0000 - accuracy: 0.9519 - precision: 0.9454 - recall: 0.7549 - auc: 0.9871 - prc: 0.9477\n",
      "Epoch 159: val_loss did not improve from 0.05038\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0692 - tp: 18115.0000 - fp: 1048.0000 - tn: 118952.0000 - fn: 5885.0000 - accuracy: 0.9519 - precision: 0.9453 - recall: 0.7548 - auc: 0.9871 - prc: 0.9477 - val_loss: 0.0504 - val_tp: 2414.0000 - val_fp: 102.0000 - val_tn: 14898.0000 - val_fn: 586.0000 - val_accuracy: 0.9618 - val_precision: 0.9595 - val_recall: 0.8047 - val_auc: 0.9932 - val_prc: 0.9713\n",
      "Epoch 160/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 17936.0000 - fp: 1059.0000 - tn: 118861.0000 - fn: 6048.0000 - accuracy: 0.9506 - precision: 0.9442 - recall: 0.7478 - auc: 0.9869 - prc: 0.9463\n",
      "Epoch 160: val_loss did not improve from 0.05038\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0698 - tp: 17951.0000 - fp: 1059.0000 - tn: 118941.0000 - fn: 6049.0000 - accuracy: 0.9506 - precision: 0.9443 - recall: 0.7480 - auc: 0.9869 - prc: 0.9463 - val_loss: 0.0519 - val_tp: 2435.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 565.0000 - val_accuracy: 0.9633 - val_precision: 0.9621 - val_recall: 0.8117 - val_auc: 0.9928 - val_prc: 0.9699\n",
      "Epoch 161/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 18008.0000 - fp: 1077.0000 - tn: 118843.0000 - fn: 5976.0000 - accuracy: 0.9510 - precision: 0.9436 - recall: 0.7508 - auc: 0.9870 - prc: 0.9466\n",
      "Epoch 161: val_loss improved from 0.05038 to 0.04958, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0698 - tp: 18021.0000 - fp: 1080.0000 - tn: 118920.0000 - fn: 5979.0000 - accuracy: 0.9510 - precision: 0.9435 - recall: 0.7509 - auc: 0.9870 - prc: 0.9466 - val_loss: 0.0496 - val_tp: 2416.0000 - val_fp: 83.0000 - val_tn: 14917.0000 - val_fn: 584.0000 - val_accuracy: 0.9629 - val_precision: 0.9668 - val_recall: 0.8053 - val_auc: 0.9936 - val_prc: 0.9729\n",
      "Epoch 162/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 17908.0000 - fp: 1072.0000 - tn: 118448.0000 - fn: 5996.0000 - accuracy: 0.9507 - precision: 0.9435 - recall: 0.7492 - auc: 0.9869 - prc: 0.9461\n",
      "Epoch 162: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0700 - tp: 17983.0000 - fp: 1074.0000 - tn: 118926.0000 - fn: 6017.0000 - accuracy: 0.9508 - precision: 0.9436 - recall: 0.7493 - auc: 0.9869 - prc: 0.9463 - val_loss: 0.0521 - val_tp: 2402.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 598.0000 - val_accuracy: 0.9611 - val_precision: 0.9589 - val_recall: 0.8007 - val_auc: 0.9928 - val_prc: 0.9694\n",
      "Epoch 163/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 17937.0000 - fp: 1073.0000 - tn: 118287.0000 - fn: 5935.0000 - accuracy: 0.9511 - precision: 0.9436 - recall: 0.7514 - auc: 0.9869 - prc: 0.9465\n",
      "Epoch 163: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0698 - tp: 18044.0000 - fp: 1079.0000 - tn: 118921.0000 - fn: 5956.0000 - accuracy: 0.9511 - precision: 0.9436 - recall: 0.7518 - auc: 0.9869 - prc: 0.9466 - val_loss: 0.0503 - val_tp: 2456.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 544.0000 - val_accuracy: 0.9641 - val_precision: 0.9597 - val_recall: 0.8187 - val_auc: 0.9933 - val_prc: 0.9716\n",
      "Epoch 164/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 17942.0000 - fp: 1089.0000 - tn: 118671.0000 - fn: 6010.0000 - accuracy: 0.9506 - precision: 0.9428 - recall: 0.7491 - auc: 0.9868 - prc: 0.9458\n",
      "Epoch 164: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0702 - tp: 17982.0000 - fp: 1089.0000 - tn: 118911.0000 - fn: 6018.0000 - accuracy: 0.9506 - precision: 0.9429 - recall: 0.7492 - auc: 0.9868 - prc: 0.9459 - val_loss: 0.0509 - val_tp: 2429.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 571.0000 - val_accuracy: 0.9632 - val_precision: 0.9639 - val_recall: 0.8097 - val_auc: 0.9931 - val_prc: 0.9711\n",
      "Epoch 165/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 17863.0000 - fp: 1113.0000 - tn: 118567.0000 - fn: 6073.0000 - accuracy: 0.9500 - precision: 0.9413 - recall: 0.7463 - auc: 0.9861 - prc: 0.9444\n",
      "Epoch 165: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0715 - tp: 17914.0000 - fp: 1116.0000 - tn: 118884.0000 - fn: 6086.0000 - accuracy: 0.9500 - precision: 0.9414 - recall: 0.7464 - auc: 0.9861 - prc: 0.9444 - val_loss: 0.0543 - val_tp: 2390.0000 - val_fp: 115.0000 - val_tn: 14885.0000 - val_fn: 610.0000 - val_accuracy: 0.9597 - val_precision: 0.9541 - val_recall: 0.7967 - val_auc: 0.9922 - val_prc: 0.9665\n",
      "Epoch 166/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0702 - tp: 17955.0000 - fp: 1099.0000 - tn: 118501.0000 - fn: 5965.0000 - accuracy: 0.9508 - precision: 0.9423 - recall: 0.7506 - auc: 0.9867 - prc: 0.9458\n",
      "Epoch 166: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0702 - tp: 18020.0000 - fp: 1103.0000 - tn: 118897.0000 - fn: 5980.0000 - accuracy: 0.9508 - precision: 0.9423 - recall: 0.7508 - auc: 0.9867 - prc: 0.9458 - val_loss: 0.0498 - val_tp: 2455.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 545.0000 - val_accuracy: 0.9647 - val_precision: 0.9643 - val_recall: 0.8183 - val_auc: 0.9935 - val_prc: 0.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 18066.0000 - fp: 1085.0000 - tn: 118435.0000 - fn: 5838.0000 - accuracy: 0.9517 - precision: 0.9433 - recall: 0.7558 - auc: 0.9872 - prc: 0.9474\n",
      "Epoch 167: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0692 - tp: 18142.0000 - fp: 1089.0000 - tn: 118911.0000 - fn: 5858.0000 - accuracy: 0.9518 - precision: 0.9434 - recall: 0.7559 - auc: 0.9872 - prc: 0.9475 - val_loss: 0.0507 - val_tp: 2478.0000 - val_fp: 97.0000 - val_tn: 14903.0000 - val_fn: 522.0000 - val_accuracy: 0.9656 - val_precision: 0.9623 - val_recall: 0.8260 - val_auc: 0.9933 - val_prc: 0.9714\n",
      "Epoch 168/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0693 - tp: 17937.0000 - fp: 1064.0000 - tn: 118376.0000 - fn: 5951.0000 - accuracy: 0.9511 - precision: 0.9440 - recall: 0.7509 - auc: 0.9870 - prc: 0.9473\n",
      "Epoch 168: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0693 - tp: 18016.0000 - fp: 1070.0000 - tn: 118930.0000 - fn: 5984.0000 - accuracy: 0.9510 - precision: 0.9439 - recall: 0.7507 - auc: 0.9870 - prc: 0.9472 - val_loss: 0.0504 - val_tp: 2440.0000 - val_fp: 87.0000 - val_tn: 14913.0000 - val_fn: 560.0000 - val_accuracy: 0.9641 - val_precision: 0.9656 - val_recall: 0.8133 - val_auc: 0.9933 - val_prc: 0.9713\n",
      "Epoch 169/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 17999.0000 - fp: 1077.0000 - tn: 118683.0000 - fn: 5953.0000 - accuracy: 0.9511 - precision: 0.9435 - recall: 0.7515 - auc: 0.9869 - prc: 0.9469\n",
      "Epoch 169: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0697 - tp: 18037.0000 - fp: 1078.0000 - tn: 118922.0000 - fn: 5963.0000 - accuracy: 0.9511 - precision: 0.9436 - recall: 0.7515 - auc: 0.9869 - prc: 0.9469 - val_loss: 0.0514 - val_tp: 2399.0000 - val_fp: 93.0000 - val_tn: 14907.0000 - val_fn: 601.0000 - val_accuracy: 0.9614 - val_precision: 0.9627 - val_recall: 0.7997 - val_auc: 0.9929 - val_prc: 0.9699\n",
      "Epoch 170/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0683 - tp: 18102.0000 - fp: 1048.0000 - tn: 118472.0000 - fn: 5802.0000 - accuracy: 0.9522 - precision: 0.9453 - recall: 0.7573 - auc: 0.9874 - prc: 0.9485\n",
      "Epoch 170: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0683 - tp: 18179.0000 - fp: 1050.0000 - tn: 118950.0000 - fn: 5821.0000 - accuracy: 0.9523 - precision: 0.9454 - recall: 0.7575 - auc: 0.9874 - prc: 0.9486 - val_loss: 0.0521 - val_tp: 2446.0000 - val_fp: 109.0000 - val_tn: 14891.0000 - val_fn: 554.0000 - val_accuracy: 0.9632 - val_precision: 0.9573 - val_recall: 0.8153 - val_auc: 0.9929 - val_prc: 0.9694\n",
      "Epoch 171/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 17987.0000 - fp: 1097.0000 - tn: 118743.0000 - fn: 5981.0000 - accuracy: 0.9508 - precision: 0.9425 - recall: 0.7505 - auc: 0.9869 - prc: 0.9464\n",
      "Epoch 171: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0699 - tp: 18011.0000 - fp: 1097.0000 - tn: 118903.0000 - fn: 5989.0000 - accuracy: 0.9508 - precision: 0.9426 - recall: 0.7505 - auc: 0.9869 - prc: 0.9464 - val_loss: 0.0532 - val_tp: 2365.0000 - val_fp: 81.0000 - val_tn: 14919.0000 - val_fn: 635.0000 - val_accuracy: 0.9602 - val_precision: 0.9669 - val_recall: 0.7883 - val_auc: 0.9925 - val_prc: 0.9682\n",
      "Epoch 172/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0682 - tp: 18180.0000 - fp: 1048.0000 - tn: 118952.0000 - fn: 5820.0000 - accuracy: 0.9523 - precision: 0.9455 - recall: 0.7575 - auc: 0.9875 - prc: 0.9488\n",
      "Epoch 172: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0682 - tp: 18180.0000 - fp: 1048.0000 - tn: 118952.0000 - fn: 5820.0000 - accuracy: 0.9523 - precision: 0.9455 - recall: 0.7575 - auc: 0.9875 - prc: 0.9488 - val_loss: 0.0510 - val_tp: 2397.0000 - val_fp: 89.0000 - val_tn: 14911.0000 - val_fn: 603.0000 - val_accuracy: 0.9616 - val_precision: 0.9642 - val_recall: 0.7990 - val_auc: 0.9931 - val_prc: 0.9706\n",
      "Epoch 173/200\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 18015.0000 - fp: 1082.0000 - tn: 118598.0000 - fn: 5921.0000 - accuracy: 0.9512 - precision: 0.9433 - recall: 0.7526 - auc: 0.9869 - prc: 0.9464\n",
      "Epoch 173: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0699 - tp: 18057.0000 - fp: 1089.0000 - tn: 118911.0000 - fn: 5943.0000 - accuracy: 0.9512 - precision: 0.9431 - recall: 0.7524 - auc: 0.9869 - prc: 0.9463 - val_loss: 0.0520 - val_tp: 2356.0000 - val_fp: 79.0000 - val_tn: 14921.0000 - val_fn: 644.0000 - val_accuracy: 0.9598 - val_precision: 0.9676 - val_recall: 0.7853 - val_auc: 0.9928 - val_prc: 0.9696\n",
      "Epoch 174/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0687 - tp: 17993.0000 - fp: 1060.0000 - tn: 118300.0000 - fn: 5879.0000 - accuracy: 0.9516 - precision: 0.9444 - recall: 0.7537 - auc: 0.9871 - prc: 0.9482\n",
      "Epoch 174: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0687 - tp: 18081.0000 - fp: 1068.0000 - tn: 118932.0000 - fn: 5919.0000 - accuracy: 0.9515 - precision: 0.9442 - recall: 0.7534 - auc: 0.9871 - prc: 0.9481 - val_loss: 0.0510 - val_tp: 2450.0000 - val_fp: 97.0000 - val_tn: 14903.0000 - val_fn: 550.0000 - val_accuracy: 0.9641 - val_precision: 0.9619 - val_recall: 0.8167 - val_auc: 0.9930 - val_prc: 0.9703\n",
      "Epoch 175/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 18057.0000 - fp: 1106.0000 - tn: 118494.0000 - fn: 5863.0000 - accuracy: 0.9514 - precision: 0.9423 - recall: 0.7549 - auc: 0.9869 - prc: 0.9462\n",
      "Epoch 175: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0701 - tp: 18114.0000 - fp: 1111.0000 - tn: 118889.0000 - fn: 5886.0000 - accuracy: 0.9514 - precision: 0.9422 - recall: 0.7548 - auc: 0.9868 - prc: 0.9461 - val_loss: 0.0515 - val_tp: 2383.0000 - val_fp: 88.0000 - val_tn: 14912.0000 - val_fn: 617.0000 - val_accuracy: 0.9608 - val_precision: 0.9644 - val_recall: 0.7943 - val_auc: 0.9931 - val_prc: 0.9704\n",
      "Epoch 176/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0690 - tp: 18092.0000 - fp: 1070.0000 - tn: 118450.0000 - fn: 5812.0000 - accuracy: 0.9520 - precision: 0.9442 - recall: 0.7569 - auc: 0.9873 - prc: 0.9480\n",
      "Epoch 176: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0691 - tp: 18164.0000 - fp: 1074.0000 - tn: 118926.0000 - fn: 5836.0000 - accuracy: 0.9520 - precision: 0.9442 - recall: 0.7568 - auc: 0.9873 - prc: 0.9480 - val_loss: 0.0528 - val_tp: 2375.0000 - val_fp: 95.0000 - val_tn: 14905.0000 - val_fn: 625.0000 - val_accuracy: 0.9600 - val_precision: 0.9615 - val_recall: 0.7917 - val_auc: 0.9926 - val_prc: 0.9689\n",
      "Epoch 177/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0694 - tp: 17933.0000 - fp: 1021.0000 - tn: 118259.0000 - fn: 5923.0000 - accuracy: 0.9515 - precision: 0.9461 - recall: 0.7517 - auc: 0.9870 - prc: 0.9478\n",
      "Epoch 177: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0694 - tp: 18040.0000 - fp: 1028.0000 - tn: 118972.0000 - fn: 5960.0000 - accuracy: 0.9515 - precision: 0.9461 - recall: 0.7517 - auc: 0.9870 - prc: 0.9478 - val_loss: 0.0511 - val_tp: 2464.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 536.0000 - val_accuracy: 0.9641 - val_precision: 0.9569 - val_recall: 0.8213 - val_auc: 0.9931 - val_prc: 0.9708\n",
      "Epoch 178/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0675 - tp: 18104.0000 - fp: 1097.0000 - tn: 118103.0000 - fn: 5736.0000 - accuracy: 0.9522 - precision: 0.9429 - recall: 0.7594 - auc: 0.9877 - prc: 0.9498\n",
      "Epoch 178: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0675 - tp: 18224.0000 - fp: 1104.0000 - tn: 118896.0000 - fn: 5776.0000 - accuracy: 0.9522 - precision: 0.9429 - recall: 0.7593 - auc: 0.9877 - prc: 0.9498 - val_loss: 0.0500 - val_tp: 2465.0000 - val_fp: 96.0000 - val_tn: 14904.0000 - val_fn: 535.0000 - val_accuracy: 0.9649 - val_precision: 0.9625 - val_recall: 0.8217 - val_auc: 0.9935 - val_prc: 0.9719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "1483/1500 [============================>.] - ETA: 0s - loss: 0.0684 - tp: 18091.0000 - fp: 1068.0000 - tn: 117572.0000 - fn: 5637.0000 - accuracy: 0.9529 - precision: 0.9443 - recall: 0.7624 - auc: 0.9875 - prc: 0.9491\n",
      "Epoch 179: val_loss did not improve from 0.04958\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0684 - tp: 18295.0000 - fp: 1085.0000 - tn: 118915.0000 - fn: 5705.0000 - accuracy: 0.9528 - precision: 0.9440 - recall: 0.7623 - auc: 0.9875 - prc: 0.9491 - val_loss: 0.0511 - val_tp: 2415.0000 - val_fp: 89.0000 - val_tn: 14911.0000 - val_fn: 585.0000 - val_accuracy: 0.9626 - val_precision: 0.9645 - val_recall: 0.8050 - val_auc: 0.9931 - val_prc: 0.9705\n",
      "Epoch 180/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0682 - tp: 18152.0000 - fp: 1054.0000 - tn: 118866.0000 - fn: 5832.0000 - accuracy: 0.9521 - precision: 0.9451 - recall: 0.7568 - auc: 0.9874 - prc: 0.9488\n",
      "Epoch 180: val_loss improved from 0.04958 to 0.04895, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0682 - tp: 18164.0000 - fp: 1055.0000 - tn: 118945.0000 - fn: 5836.0000 - accuracy: 0.9521 - precision: 0.9451 - recall: 0.7568 - auc: 0.9874 - prc: 0.9488 - val_loss: 0.0489 - val_tp: 2439.0000 - val_fp: 89.0000 - val_tn: 14911.0000 - val_fn: 561.0000 - val_accuracy: 0.9639 - val_precision: 0.9648 - val_recall: 0.8130 - val_auc: 0.9937 - val_prc: 0.9732\n",
      "Epoch 181/200\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0689 - tp: 18126.0000 - fp: 1092.0000 - tn: 118828.0000 - fn: 5858.0000 - accuracy: 0.9517 - precision: 0.9432 - recall: 0.7558 - auc: 0.9873 - prc: 0.9481\n",
      "Epoch 181: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0689 - tp: 18140.0000 - fp: 1092.0000 - tn: 118908.0000 - fn: 5860.0000 - accuracy: 0.9517 - precision: 0.9432 - recall: 0.7558 - auc: 0.9873 - prc: 0.9481 - val_loss: 0.0510 - val_tp: 2445.0000 - val_fp: 107.0000 - val_tn: 14893.0000 - val_fn: 555.0000 - val_accuracy: 0.9632 - val_precision: 0.9581 - val_recall: 0.8150 - val_auc: 0.9932 - val_prc: 0.9709\n",
      "Epoch 182/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0684 - tp: 18235.0000 - fp: 1070.0000 - tn: 118770.0000 - fn: 5733.0000 - accuracy: 0.9527 - precision: 0.9446 - recall: 0.7608 - auc: 0.9875 - prc: 0.9489\n",
      "Epoch 182: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0684 - tp: 18258.0000 - fp: 1072.0000 - tn: 118928.0000 - fn: 5742.0000 - accuracy: 0.9527 - precision: 0.9445 - recall: 0.7607 - auc: 0.9875 - prc: 0.9489 - val_loss: 0.0509 - val_tp: 2450.0000 - val_fp: 98.0000 - val_tn: 14902.0000 - val_fn: 550.0000 - val_accuracy: 0.9640 - val_precision: 0.9615 - val_recall: 0.8167 - val_auc: 0.9932 - val_prc: 0.9709\n",
      "Epoch 183/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0683 - tp: 18082.0000 - fp: 1054.0000 - tn: 118546.0000 - fn: 5838.0000 - accuracy: 0.9520 - precision: 0.9449 - recall: 0.7559 - auc: 0.9875 - prc: 0.9488\n",
      "Epoch 183: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0683 - tp: 18151.0000 - fp: 1057.0000 - tn: 118943.0000 - fn: 5849.0000 - accuracy: 0.9520 - precision: 0.9450 - recall: 0.7563 - auc: 0.9875 - prc: 0.9489 - val_loss: 0.0512 - val_tp: 2476.0000 - val_fp: 114.0000 - val_tn: 14886.0000 - val_fn: 524.0000 - val_accuracy: 0.9646 - val_precision: 0.9560 - val_recall: 0.8253 - val_auc: 0.9930 - val_prc: 0.9706\n",
      "Epoch 184/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0683 - tp: 18049.0000 - fp: 1067.0000 - tn: 118373.0000 - fn: 5839.0000 - accuracy: 0.9518 - precision: 0.9442 - recall: 0.7556 - auc: 0.9874 - prc: 0.9487\n",
      "Epoch 184: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0685 - tp: 18128.0000 - fp: 1072.0000 - tn: 118928.0000 - fn: 5872.0000 - accuracy: 0.9518 - precision: 0.9442 - recall: 0.7553 - auc: 0.9873 - prc: 0.9485 - val_loss: 0.0549 - val_tp: 2364.0000 - val_fp: 111.0000 - val_tn: 14889.0000 - val_fn: 636.0000 - val_accuracy: 0.9585 - val_precision: 0.9552 - val_recall: 0.7880 - val_auc: 0.9918 - val_prc: 0.9658\n",
      "Epoch 185/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 17886.0000 - fp: 1028.0000 - tn: 118332.0000 - fn: 5986.0000 - accuracy: 0.9510 - precision: 0.9456 - recall: 0.7492 - auc: 0.9868 - prc: 0.9463\n",
      "Epoch 185: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0704 - tp: 17988.0000 - fp: 1033.0000 - tn: 118967.0000 - fn: 6012.0000 - accuracy: 0.9511 - precision: 0.9457 - recall: 0.7495 - auc: 0.9867 - prc: 0.9463 - val_loss: 0.0508 - val_tp: 2481.0000 - val_fp: 118.0000 - val_tn: 14882.0000 - val_fn: 519.0000 - val_accuracy: 0.9646 - val_precision: 0.9546 - val_recall: 0.8270 - val_auc: 0.9930 - val_prc: 0.9706\n",
      "Epoch 186/200\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 18117.0000 - fp: 1056.0000 - tn: 118464.0000 - fn: 5787.0000 - accuracy: 0.9523 - precision: 0.9449 - recall: 0.7579 - auc: 0.9874 - prc: 0.9484\n",
      "Epoch 186: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0685 - tp: 18195.0000 - fp: 1058.0000 - tn: 118942.0000 - fn: 5805.0000 - accuracy: 0.9523 - precision: 0.9450 - recall: 0.7581 - auc: 0.9874 - prc: 0.9486 - val_loss: 0.0503 - val_tp: 2411.0000 - val_fp: 93.0000 - val_tn: 14907.0000 - val_fn: 589.0000 - val_accuracy: 0.9621 - val_precision: 0.9629 - val_recall: 0.8037 - val_auc: 0.9932 - val_prc: 0.9716\n",
      "Epoch 187/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0698 - tp: 18220.0000 - fp: 1075.0000 - tn: 118925.0000 - fn: 5780.0000 - accuracy: 0.9524 - precision: 0.9443 - recall: 0.7592 - auc: 0.9872 - prc: 0.9472\n",
      "Epoch 187: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0698 - tp: 18220.0000 - fp: 1075.0000 - tn: 118925.0000 - fn: 5780.0000 - accuracy: 0.9524 - precision: 0.9443 - recall: 0.7592 - auc: 0.9872 - prc: 0.9472 - val_loss: 0.0516 - val_tp: 2436.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 564.0000 - val_accuracy: 0.9629 - val_precision: 0.9594 - val_recall: 0.8120 - val_auc: 0.9929 - val_prc: 0.9699\n",
      "Epoch 188/200\n",
      "1491/1500 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 18213.0000 - fp: 1044.0000 - tn: 118236.0000 - fn: 5643.0000 - accuracy: 0.9533 - precision: 0.9458 - recall: 0.7635 - auc: 0.9874 - prc: 0.9492\n",
      "Epoch 188: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0687 - tp: 18313.0000 - fp: 1053.0000 - tn: 118947.0000 - fn: 5687.0000 - accuracy: 0.9532 - precision: 0.9456 - recall: 0.7630 - auc: 0.9874 - prc: 0.9491 - val_loss: 0.0511 - val_tp: 2419.0000 - val_fp: 92.0000 - val_tn: 14908.0000 - val_fn: 581.0000 - val_accuracy: 0.9626 - val_precision: 0.9634 - val_recall: 0.8063 - val_auc: 0.9930 - val_prc: 0.9708\n",
      "Epoch 189/200\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0693 - tp: 18096.0000 - fp: 1066.0000 - tn: 118374.0000 - fn: 5792.0000 - accuracy: 0.9522 - precision: 0.9444 - recall: 0.7575 - auc: 0.9873 - prc: 0.9478\n",
      "Epoch 189: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0693 - tp: 18177.0000 - fp: 1070.0000 - tn: 118930.0000 - fn: 5823.0000 - accuracy: 0.9521 - precision: 0.9444 - recall: 0.7574 - auc: 0.9873 - prc: 0.9479 - val_loss: 0.0490 - val_tp: 2409.0000 - val_fp: 78.0000 - val_tn: 14922.0000 - val_fn: 591.0000 - val_accuracy: 0.9628 - val_precision: 0.9686 - val_recall: 0.8030 - val_auc: 0.9936 - val_prc: 0.9735\n",
      "Epoch 190/200\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0674 - tp: 18292.0000 - fp: 1047.0000 - tn: 118713.0000 - fn: 5660.0000 - accuracy: 0.9533 - precision: 0.9459 - recall: 0.7637 - auc: 0.9879 - prc: 0.9508\n",
      "Epoch 190: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0675 - tp: 18326.0000 - fp: 1050.0000 - tn: 118950.0000 - fn: 5674.0000 - accuracy: 0.9533 - precision: 0.9458 - recall: 0.7636 - auc: 0.9878 - prc: 0.9507 - val_loss: 0.0506 - val_tp: 2454.0000 - val_fp: 110.0000 - val_tn: 14890.0000 - val_fn: 546.0000 - val_accuracy: 0.9636 - val_precision: 0.9571 - val_recall: 0.8180 - val_auc: 0.9933 - val_prc: 0.9710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0684 - tp: 18253.0000 - fp: 1087.0000 - tn: 118753.0000 - fn: 5715.0000 - accuracy: 0.9527 - precision: 0.9438 - recall: 0.7616 - auc: 0.9876 - prc: 0.9490\n",
      "Epoch 191: val_loss did not improve from 0.04895\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0684 - tp: 18277.0000 - fp: 1088.0000 - tn: 118912.0000 - fn: 5723.0000 - accuracy: 0.9527 - precision: 0.9438 - recall: 0.7615 - auc: 0.9876 - prc: 0.9490 - val_loss: 0.0509 - val_tp: 2438.0000 - val_fp: 101.0000 - val_tn: 14899.0000 - val_fn: 562.0000 - val_accuracy: 0.9632 - val_precision: 0.9602 - val_recall: 0.8127 - val_auc: 0.9932 - val_prc: 0.9709\n",
      "Epoch 192/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0679 - tp: 18181.0000 - fp: 1025.0000 - tn: 118335.0000 - fn: 5691.0000 - accuracy: 0.9531 - precision: 0.9466 - recall: 0.7616 - auc: 0.9877 - prc: 0.9498\n",
      "Epoch 192: val_loss improved from 0.04895 to 0.04768, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0678 - tp: 18284.0000 - fp: 1032.0000 - tn: 118968.0000 - fn: 5716.0000 - accuracy: 0.9531 - precision: 0.9466 - recall: 0.7618 - auc: 0.9877 - prc: 0.9498 - val_loss: 0.0477 - val_tp: 2480.0000 - val_fp: 94.0000 - val_tn: 14906.0000 - val_fn: 520.0000 - val_accuracy: 0.9659 - val_precision: 0.9635 - val_recall: 0.8267 - val_auc: 0.9939 - val_prc: 0.9745\n",
      "Epoch 193/200\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0690 - tp: 18088.0000 - fp: 1096.0000 - tn: 118264.0000 - fn: 5784.0000 - accuracy: 0.9520 - precision: 0.9429 - recall: 0.7577 - auc: 0.9873 - prc: 0.9482\n",
      "Epoch 193: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0689 - tp: 18181.0000 - fp: 1098.0000 - tn: 118902.0000 - fn: 5819.0000 - accuracy: 0.9520 - precision: 0.9430 - recall: 0.7575 - auc: 0.9873 - prc: 0.9483 - val_loss: 0.0500 - val_tp: 2446.0000 - val_fp: 103.0000 - val_tn: 14897.0000 - val_fn: 554.0000 - val_accuracy: 0.9635 - val_precision: 0.9596 - val_recall: 0.8153 - val_auc: 0.9933 - val_prc: 0.9716\n",
      "Epoch 194/200\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0690 - tp: 18206.0000 - fp: 1056.0000 - tn: 118544.0000 - fn: 5714.0000 - accuracy: 0.9528 - precision: 0.9452 - recall: 0.7611 - auc: 0.9872 - prc: 0.9482\n",
      "Epoch 194: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0691 - tp: 18263.0000 - fp: 1061.0000 - tn: 118939.0000 - fn: 5737.0000 - accuracy: 0.9528 - precision: 0.9451 - recall: 0.7610 - auc: 0.9872 - prc: 0.9482 - val_loss: 0.0500 - val_tp: 2508.0000 - val_fp: 122.0000 - val_tn: 14878.0000 - val_fn: 492.0000 - val_accuracy: 0.9659 - val_precision: 0.9536 - val_recall: 0.8360 - val_auc: 0.9933 - val_prc: 0.9717\n",
      "Epoch 195/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0685 - tp: 18268.0000 - fp: 1065.0000 - tn: 118775.0000 - fn: 5700.0000 - accuracy: 0.9530 - precision: 0.9449 - recall: 0.7622 - auc: 0.9875 - prc: 0.9490\n",
      "Epoch 195: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0684 - tp: 18294.0000 - fp: 1065.0000 - tn: 118935.0000 - fn: 5706.0000 - accuracy: 0.9530 - precision: 0.9450 - recall: 0.7623 - auc: 0.9875 - prc: 0.9491 - val_loss: 0.0499 - val_tp: 2468.0000 - val_fp: 99.0000 - val_tn: 14901.0000 - val_fn: 532.0000 - val_accuracy: 0.9649 - val_precision: 0.9614 - val_recall: 0.8227 - val_auc: 0.9933 - val_prc: 0.9718\n",
      "Epoch 196/200\n",
      "1489/1500 [============================>.] - ETA: 0s - loss: 0.0689 - tp: 18172.0000 - fp: 1040.0000 - tn: 118080.0000 - fn: 5652.0000 - accuracy: 0.9532 - precision: 0.9459 - recall: 0.7628 - auc: 0.9873 - prc: 0.9486\n",
      "Epoch 196: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0689 - tp: 18297.0000 - fp: 1045.0000 - tn: 118955.0000 - fn: 5703.0000 - accuracy: 0.9531 - precision: 0.9460 - recall: 0.7624 - auc: 0.9873 - prc: 0.9486 - val_loss: 0.0493 - val_tp: 2390.0000 - val_fp: 70.0000 - val_tn: 14930.0000 - val_fn: 610.0000 - val_accuracy: 0.9622 - val_precision: 0.9715 - val_recall: 0.7967 - val_auc: 0.9937 - val_prc: 0.9733\n",
      "Epoch 197/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0679 - tp: 18227.0000 - fp: 1055.0000 - tn: 118945.0000 - fn: 5773.0000 - accuracy: 0.9526 - precision: 0.9453 - recall: 0.7595 - auc: 0.9876 - prc: 0.9493\n",
      "Epoch 197: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0679 - tp: 18227.0000 - fp: 1055.0000 - tn: 118945.0000 - fn: 5773.0000 - accuracy: 0.9526 - precision: 0.9453 - recall: 0.7595 - auc: 0.9876 - prc: 0.9493 - val_loss: 0.0488 - val_tp: 2443.0000 - val_fp: 91.0000 - val_tn: 14909.0000 - val_fn: 557.0000 - val_accuracy: 0.9640 - val_precision: 0.9641 - val_recall: 0.8143 - val_auc: 0.9936 - val_prc: 0.9734\n",
      "Epoch 198/200\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.0675 - tp: 18174.0000 - fp: 1061.0000 - tn: 117979.0000 - fn: 5634.0000 - accuracy: 0.9531 - precision: 0.9448 - recall: 0.7634 - auc: 0.9877 - prc: 0.9504\n",
      "Epoch 198: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0675 - tp: 18319.0000 - fp: 1071.0000 - tn: 118929.0000 - fn: 5681.0000 - accuracy: 0.9531 - precision: 0.9448 - recall: 0.7633 - auc: 0.9877 - prc: 0.9504 - val_loss: 0.0497 - val_tp: 2458.0000 - val_fp: 89.0000 - val_tn: 14911.0000 - val_fn: 542.0000 - val_accuracy: 0.9649 - val_precision: 0.9651 - val_recall: 0.8193 - val_auc: 0.9934 - val_prc: 0.9719\n",
      "Epoch 199/200\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 18130.0000 - fp: 1081.0000 - tn: 118119.0000 - fn: 5710.0000 - accuracy: 0.9525 - precision: 0.9437 - recall: 0.7605 - auc: 0.9873 - prc: 0.9485\n",
      "Epoch 199: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0686 - tp: 18254.0000 - fp: 1091.0000 - tn: 118909.0000 - fn: 5746.0000 - accuracy: 0.9525 - precision: 0.9436 - recall: 0.7606 - auc: 0.9874 - prc: 0.9486 - val_loss: 0.0486 - val_tp: 2475.0000 - val_fp: 93.0000 - val_tn: 14907.0000 - val_fn: 525.0000 - val_accuracy: 0.9657 - val_precision: 0.9638 - val_recall: 0.8250 - val_auc: 0.9937 - val_prc: 0.9735\n",
      "Epoch 200/200\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0687 - tp: 18205.0000 - fp: 1034.0000 - tn: 118806.0000 - fn: 5763.0000 - accuracy: 0.9527 - precision: 0.9463 - recall: 0.7596 - auc: 0.9874 - prc: 0.9485\n",
      "Epoch 200: val_loss did not improve from 0.04768\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0687 - tp: 18231.0000 - fp: 1034.0000 - tn: 118966.0000 - fn: 5769.0000 - accuracy: 0.9528 - precision: 0.9463 - recall: 0.7596 - auc: 0.9874 - prc: 0.9486 - val_loss: 0.0501 - val_tp: 2479.0000 - val_fp: 108.0000 - val_tn: 14892.0000 - val_fn: 521.0000 - val_accuracy: 0.9651 - val_precision: 0.9583 - val_recall: 0.8263 - val_auc: 0.9933 - val_prc: 0.9716\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),#'categorical_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "#checkpoint_path = \"weights.best.hdf5\"\n",
    "\n",
    "checkpoint_path = \"weights.best.onlyfocalloss\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f913d8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9108db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1cf93ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 4ms/step - loss: 0.0798 - tp: 2062.0000 - fp: 95.0000 - tn: 14905.0000 - fn: 938.0000 - accuracy: 0.9426 - precision: 0.9560 - recall: 0.6873 - auc: 0.9813 - prc: 0.9300\n"
     ]
    }
   ],
   "source": [
    "loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b7826a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88       520\n",
      "           1       0.78      0.84      0.80       504\n",
      "           2       0.84      0.86      0.85       495\n",
      "           3       0.81      0.68      0.74       477\n",
      "           4       0.81      0.94      0.87       496\n",
      "           5       0.92      1.00      0.96       508\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.86      0.85      0.85      3000\n",
      "weighted avg       0.86      0.85      0.85      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAEYCAYAAADMJjphAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABJ0UlEQVR4nO2dd3wVVfqHnzcJLUAAAUlyI70EQicJCFiwQOg2BBELFmAXxLaru/vb1V1d14KiuBZQ1FURKTY6oQgWlBJCUUAkFCU3AQHpxYSb9/fHTMK9afeSe0Nu4nn4zIfMzHvO+c6Zc985bc6IqmIwGAwVmZCyFmAwGAyljXF0BoOhwmMcncFgqPAYR2cwGCo8xtEZDIYKj3F0BoOhwlPmjk5EqonIPBE5KiKz/YjnVhFZEkhtZYGILBKRO0oh3utFZK+InBCRToGOv7QRERWR5qUUt0fZEZEeIrLDzqvrSvGeTBaRfwQ63tJCRFaKyD0+2pba/SoRqurTBgwHUoATQCawCOjpa/hi4r0NWAuE+RtXaWzAlYACn+Q73sE+vtLHeP4JTCvD69gJDC7mvAIn7fvrBCYCoRdQXxTwll22jgM/AP8Cqrvpa36BtCwH7g9wnHcCX18g/f+082t8vuMP2Mf/WcJ4VwL3+Gh7we6XL5tPNToReQh4CfgP0ABoCLwGDPYlvBcaAT+q6tkAxFVaHAC6i0hdt2N3AD8GKgGxKM0adiNgixebDqpaA7ga68F2bynqyUNELgK+BaoBl6pqTeBaoDbQ7EJoyIcveRXs/IhVRt25nQCW2XKFD565FtZTfkgxNlWwHGGGvb0EVLHPXQmkAw8Dv2A9sUfa5/4FZAHZdhp3k6/mAzTGejqEuT0Zd2E99XcDtxb2xAS6A+uAo/b/3fM9mZ4EVtnxLAHqFXFtufonA2PtY6H2scdwq9EBk4C9wDFgPXCZfTwp33VuctPxlK3jNNAct6cm8DrwkVv8z2LVNqQQnSHA34Gf7Hx+z753Vew0c2tsO315AgOzgVfsv+8F0oBfgblAtH1cgBft9I4Cm4G2bmXieeBnYL+df9WKSPvfwHdAiC81BKA/sMHO57241VCAqsA04BBwxL73DXwtO1g13xz7fpywryPvnrjlxzY7nq1AZ/v4X+zwucevt4+3Bs4ALjvOI/bx/wH/zhdvgXx2u/4xwA7gMPBqYeXAtv2nnQfbgDj7WJy9Py1ffhWX5rVYNeujwCvAF/ny4S47zsNAMtCoqPJU1psvji4JOEsxTUvgCWA1cDFQH/gGeNLNUZy1bSoB/YBTQB33m5L/JhXm6IDqWIW7lX0uyu1GuhfWi+zMv80Od4u9X9fNwewEWmLVIlYCz3hxdN2BNfaxfvaNvQdPRzcCqGun+TCwD6ha2HW56fjZLoRhdv6s5JyjC8d6At8JXAYcBGKK0HmXXWCbAjWAT4D3fS14eDqSNrb2u4Gr7HQ7Y/3o/wt8adv1wXLotbGcXmsgyj73EtYP5yKgJjAPeLqItFcD//JSDt31XQm0w3Lu7bEc6XX2udF2WuFYD6QuQISvZcfe3wNck+8+5d6TIVhN+wT7mptj/8Dtc9G2rqFYD5aowtKwj/0P29EVl89u1z/fzuuGWK2MpCLy6p9YDu1vwLP2seeAv+Lm6Lzc23p2ft2EVS4fxPod5+bDdVjlrTVW2f078E2wOjpfmkp1gYNafNPyVuAJVf1FVQ9g1dRuczufbZ/PVtWFWE+1Vj6kXRg5QFsRqaaqmapaWBOjP7BDVd9X1bOq+iHWk2mgm807qvqjqp4GZgEdi0tUVb8BLhKRVlhNgPcKsZmmqofsNF/AKjzervN/qrrFDpOdL75TWM5zIlYBvU9V04uI51ZgoqruUtUTWIV6mIiEeUnfnVQROYzlKKYC79jxvq2qqar6mx3vpSLSGOu+1gRisWoX21Q1U0QEq6bwoKr+qqrHsbo9hhWRbl2smr5PqOpKVf1OVXNUdTPwIXCFfTrbjq+5qrpUdb2qHrPP+VJ2vHEP8JyqrlOLNFX9ydY1W1UzbF0zsWpfiT7GW1w+5/KMqh5R1Z+BFXgps1hl5hYRqYSV99POI81+wFZV/cguly9hPfxyGY314Npm+4b/AB1FpJGP13tB8cXRHQLqefnBRGM1mXL5yT6WF0c+R3kKq9ZxXqjqSawn5RggU0QWiEisD3pyNTnc9t1vmq963gfGAb2AT/OfFJGHRWSbPYJ8BKvpWM9LnHuLO6mqa7GaW4LlkIuisHsQhtWn6iudVbWOqjZT1b+rak7+eG0neghwqOrnWE2aV4H9IvKGiERg1erDgfUicsTOi8X28cI4hFXD8gkR6SoiK0TkgIgcxSoPufn8PlZte4aIZIjIcyJS6TzKjjcuwWoNFKbrdhHZ6HbNbfF+/3MpMp/dbM6rzNoOMQ3LCe1Q1fxlrbg0o3Erm2pV09zDNwImuV3rr1hl1F1v0OCLo/sWq3/humJsMrAuPJeG9rGScBLrR5JLpPtJVU1W1Wuxfhg/AG/6oCdXk7OEmnJ5H/gjsNCubeUhIpcBjwI3YzXLa2P1bUiu9CLiLOp4brxjsWqGGcAjxZgWdg/OYjXr/MEjXhGpjlVjcgKo6suq2gWr+d0S+DNWc+g0VtOwtr3VUmugozCWAdefx2DMdKxm8SWqWgur/09sPdmq+i9VbYPV3TAAqwbua9nxxl4KGSCxazJvYj0I69r3/3u83/9cis1nP3gPqxulQAvES5qZWE4995y472Plw2i3+1tbVavZLZ+gw2vBUtWjWJ3ur9pzisJFpJKI9BWR52yzD4G/i0h9Ealn2+evJvvKRuByEWkoIrWwqtMAiEgDERlk35DfsJrArkLiWAi0FJHhIhImIkOx+p3ml1ATAKq6G6uJ9H+FnK6J5VgOAGEi8hhW31Au+4HG5zOyKiItsTrqR2B1BTwiIh2LMP8QeFBEmohIDayn+EwvXQ6+MB0YKSIdRaSKHe8aVd0jIgl27aoS1gPqDOCya4JvAi+KyMX2tThEpE8RaUzEyqt3c5s+tv1EEWlfiH1N4FdVPSMiiVgjxNjheolIOxEJxepjygZc51F2vDEV+JOIdLFHypvbmqtjObMDto6RWDW6XPYDMSJSuYh4i8znEmh0ZybQm8JbA8WluQCIE5Eb7NbceDwrHZOBv4pIHICI1BKRIX5qLTV8+tGp6kTgIawOxwNY3nwc8Jlt8m+sOXabsUbPUu1j542qLsW6OZuxOrrdnVMI1tMpA6uqfAVWDSt/HIewnuQPY1XFHwEGqOrBkmjKF/fXqlpYbTUZa27hj1jNgTN4VvVzJ0MfEpFUb+nYhWsaVmfyJlXdgdW5/L5dKPPzNlaN80usEcUzwH2+XVXRqOpy4B/Ax1hP+Wac62uLwHJoh7Gu+RDWSCtYtds0YLWIHMOqtRXaX6mqv2LVvrKBNSJyHGt0+agdR37+CDxh2z2G5484EvgIy8ltwxopnIaPZccbqjoba6R8Otbo6mfARaq6FXgBqwW0H2uwZJVb0M+xpqzsE5EC5dBLPpcYVT2tqsvsvmif07R/K0OAZ7Duawv361HVT7FmAcyw7+/3QF9/9ZYWYjW9DQaDoeJS5q+AGQwGQ2ljHJ3BYAgqRORtEflFRL4v4ryIyMsikiYim0Wks7c4jaMzGAzBxv+wXlQoir5YfYYtgFFYbxAVi3F0BoMhqFDVL7EGjIpiMPCePWF7NVBbRIqdh3k+s+ZLnZCqERpas6g5pRee1o7aZS2hAGGh4t3oAuLKCb7BrLCQ4MqjYOOnn/Zw8ODBgGZSaEQj1bMFBnYLoKcPbMGaEZDLG6r6xnkm58BzRkO6fazIt2uCytGF1qxP3eueLWsZeSx4dqB3owtMvZpFTcMqGw6fzPZudIG5qEZw5VGw0aNrfMDj1LNnqBLrfTbMmQ3/PaOq/goozEkX+8QNKkdnMBjKKQLIBatJp+P5lkYMXt7EMn10BoMhMEiI9y0wzAVut0dfuwFHVbXYRSFMjc5gMASGANXoRORDrKW46olIOvA41lJRqOpkrFc8+2G9NXMKGOktTuPoDAZDAJCA1dhU9RYv5xUYez5xGkdnMBj8R4CQ0LJWUSTG0RkMhgAgF3Iw4rwxjs5gMASGUv22k38YR2cwGAKDqdEZDIaKTeAGI0qD4FVWCL3iGvD1k3349qkkxiUVXMOxZrUw3hvXneWPXcMX/7qWYd0b+Ry2pKxcvoQrE9txWXwbXn1pQoHzaT9u57o+V9A8KoIpr7x4XmFLwpLkxXSIi6Vt6xY8/9wzBc6rKg8/OJ62rVuQ2LkDGzacWwN09L130cjRgPiO7QKiBWDFsmQuS2hLj86teeXFgteoqvzj0Qfp0bk11/TownebNuSdmzr5v1x1aSd6XdqRN19/OWCaliQvpn1cK+JimzOhiDx66IHxxMU2J6FTezakpvoctiLoKRG5gxHetjKi3Di6EIGnh3di+KSvufyxZK5PvISWUTU9bEb2as6Pmce5+oll3DDhCx6/uQOVQsWnsCXB5XLx90fu591Zc1j+zUbmfjKLH3/Y5mFTu04d/vX0C4wa+8B5hy2JngfvH8dn8xaSumkLs2fOYNvWrR42yYsXkZaWxndbf+SV16dw/7hzi+zedvudfDZ/kV8a8uv5vz/fz7TZc1mxehOffTyzwDV+vnQxu3em8fX6rTz70mv89WFrUeQftm5h+rtvs2D5KpZ+lcKy5IXs2rkjIJoeGD+WOfMWsWHzVmbP+LDQPNqZtoPvt+3gldffYPy4P/gctrzrKTlyIScMnzflxtF1anIRuw+c4OeDJ8l2KZ+t20ufjtEeNqpKjSpWa7x61TCOnMzibI76FLYkbExdR+MmzWjUuCmVK1dm4PVDWLJonodNvfoX06FzPGGVKp132PMlZd1amjVrTpOmVpw33TyU+fPmeNjMnzeHW2+9DREhsWs3jh45QmamNam852WXc1Gdi/zS4M6G9eto3PTcNQ6+4WaSF3peY/LCedw0bAQiQpeErhw9eoT9+zLZ8eMPdE7oSrXwcMLCwujW43IWz59TREq+s26tZx4NGTqsYB7NncPwEbcjInTt1o2jR6088iVsedfjFyHifSsraWWW8nkSVbsaGb+eWx0h8/BpompX87B5+/OdtIiqyaYJ/VnxeG/+MWMjqr6FLQn7MjOIdsSc0xjtYH+mbx8/8ydsUWQ4nThizsXpcMSQkeH5EamMjAxiLjn3mqAjpqBNoLCu8VxaUdEO9mU6C7GJyWeTQWzrNqz+5it+/fUQp0+d4vOli8lwFvVJW9/JyHASE+N2/Y4YnM78eVTQJsPp9ClseddTYoSgrtGV6mCEiCQBk7C+mD5VVUvciVDYgE7+5Qp6xTXg+71HufGFL2lcvzqzHrqc1f9a6lPYklDY9zbEx5Enf8L6E2dppFsaelq0as3Y+//ELdf3o3r1GrSJa0domP/F1R9NwXbPLuS99IkgHnUtNRdrf27uVazVQNtgfTG8TUnjyzh8muiLztXCoupUY98Rz/WvhvVozMIN1hNtz4GT/HzwJC0ia/oUtiRERTs8ahmZGU4ujvTtO8z+hC0KR0wMzvRzcTqd6URFeTbRHQ4H6XvPLeXlTC9oEyisazyXVmaGkwaR0YXYpOezsfLhlttGkvzFGj5ZuJzadS6iSdPmfmtyOGJIT3e7fmc60dH586igTVR0tE9hy7uekvP77aNLBNJUdZeqZgEzsFYGLREb9xym6cU1aFgvnEqhwnUJl7Bkk+eCBc5fT3FZ7MUA1KtZhWYNavLTwZM+hS0JHTrFs3tXGj//tJusrCzmfTqba/sOKPWwRdElPoG0tB3s2W3F+dGsmfQfMMjDpv+AQXzwwfuoKmvXrCaiVi2iovxzsEXRsXM8u3eeu8Y5n8yid75r7N13AB/NmIaqsn7dGiIiauU5uoMHfgHAufdnFs3/jOtuGuq3pvgEzzyaPXNGwTwaOIjp095DVVmzejUREVYe+RK2vOvxiyAedS3Npmthq4B2LWlkrhzlb9M38uEDlxEqwoer9rA94xi3X9EUgPe+2MXE+duYNDKBFY9fiwj8++Pv+PVEFkChYf0lLCyMJ599iduGDMTlcjF0+B20im3D++9YH4C/beS9/LJ/HwOu7sGJ48cICQnhrcmvsPybDdSMiCg0rL96Jr70Xwb1T8KV4+L2O0bSJi6ON9+YDMC9o8aQ1LcfyYsX0rZ1C8KrhTN56tt54e8YMZwvv1zJoYMHad7kEv7+2D+5c+Tdfun593MvMfzGAeS4XAy99U5atW7De29bC8reftcoru7dl8+XLqZH59ZUqxbOxFffzAt/7+3DOHz4EGFhlXhqwiRq165TYi3uml6c9AoD+/fB5XJxx513WXk0xc6j0XYeLVpIXGxzwquFM2XqO8WGrUh6SowE9ytgpfZdV/ur3X1U9R57/zYgUVXvy2c3CusDF4TUqNel/jCv37m4YKwzKwx7xawwXP7o0TWe9etTAuqVQmpdolUufdCr3Znkh9cHYIXh86Y0m64+rQKqqm+oaryqxodUjShFOQaDoVTJrdUVt5URpeno1gEtRKSJiFQGhmGtDGowGCocwT0YUWp9dKp6VkTGAclY00veVtUtpZWewWAoY4K4j65U59Gp6kKsZY8NBkNFRgRCgneNkOBVZjAYyhe/1xqdwWD4HRHEyzQZR2cwGAKDqdEZDIYKjQT3wpvG0RkMhsBganQGg6EiI0BIiKnRGQyGiozYW5BiHJ3BYAgAUrZr4XnBODqDwRAQjKMzGAwVHuPoDAZDhcc4OoPBUKEREaQMv/LljaBydO0b1mHV6zeVtYw8Iu+cVtYSCpA2eVhZS/CgSljwTSk468opawke5JTO2rYlprRyx9ToDAZDhcc4OoPBUOExjs5gMFRszIRhg8HweyCYa3TB15NsMBjKHYIQEhLidfMpLpEkEdkuImki8pdCztcSkXkisklEtojISG9xGkdnMBgCg/iweYtCJBR4FegLtAFuEZH8HzweC2xV1Q7AlcAL9ge4isQ4OoPB4D9iz6XzsvlAIpCmqrtUNQuYAQzOZ6NATbEirAH8CpwtLlLTR2cwGAKCj46snoikuO2/oapvuO07gL1u++lA13xxvIL16dQMoCYwVFWLnR5oHJ3BYAgIPjq6g6oaX1w0hRzLP+W6D7ARuApoBiwVka9U9VhRkZqmq8Fg8BvBegXM2+YD6cAlbvsxWDU3d0YCn6hFGrAbiC0uUuPoDAaD/wSuj24d0EJEmtgDDMOwmqnu/AxcDSAiDYBWwK7iIi1Xjm5J8mLax7UiLrY5E557psB5VeWhB8YTF9uchE7t2ZCa6nPYknJ1+yjWTRhE6guDeWBgXIHzEdUqMeOhK/n6qf58+8wAbr28qcf5EBG+/Hc/Zjx8ZUD0LF+aTLdOcSR0iGXSC88VOK+q/PXPD5DQIZYrunVi08ZzeXT0yBFGjhjKpZ3b0r1LO9at+TYgerr6qOfyIvR069yWSwOkB2DpksV0ateaDm1a8sKEZwvV9OeH7qdDm5Z0i+/Ixg2WpvS9e+nX+2q6dIgjoVM7Xnvl5YDoWbZkMV3at6ZjXEsmFqHnkYfup2NcS7onnNNz5swZevXsRo/ETnTt3I7/PPnPgOgpKYFwdKp6FhgHJAPbgFmqukVExojIGNvsSaC7iHwHLAceVdWDxcVbbvroXC4XD4wfy4JFS3HExNCzWwIDBgyidZtzI8/JixexM20H32/bwdo1axg/7g989c0an8KWhBARnr8jkeueWU7Gr6dY8URfFq1PZ3vG0Tybe65tyQ/OowybuJK6NauQMmEQs1btIdt+8fwPSbFszzhKzWqV/NICVh795eHxzJ6ziGhHDL2v6EZS/wG0ij13ncuWLGbXzjTWbtzG+nVreOTBcSSv+AaAvz3yIFdd05t3ps0kKyuL06dO+a3n0YfH85Gt51of9Pz5wXEsKSU9uZoevv8+5ixIxhETwxU9utJ/wEBiW5/TtCTZKkcbt2xn3do1PDh+LCu++pawsDD+8+wEOnbqzPHjx7ns0gSuuvoaj7Al0vPAfXy2IBmHI4ZePbvSL5+epcmL2LlzBxu+307K2jU8NH4sn3/1LVWqVGHe4mXUqFGD7Oxs+lx1Odf2TiKhaze/8qikBGrCsKouBBbmOzbZ7e8MoPf5xFluanTr1q6lWbPmNGnalMqVKzNk6DDmz5vjYTN/7hyGj7gdEaFrt24cPXqEzMxMn8KWhC7N6rJr/3F+OnCCbFcOH6/eQ78uMR42qlCjmvU8qVE1jMMnszibYzm56IvC6d0xmvdXpvmtBSA1ZS2NmzajcRPrOq+7cSiL5s/zsFm8YC5DbxmBiBCf2I2jR46yb18mx48dY/U3XzPijrsAqFy5MrVq1/ZbTxM3PdcXomfRgrncXISebwOsByBl3VqaNmuWVxZuHDKU+fM8W0YL5s3llltvQ0RI7NqNI0eOsC8zk8ioKDp26gxAzZo1aRUbS4bT6Zee9bl67Dy6YchQFszPp2f+XG4ZbulJ6GqV632ZmYgINWrUACA7O5vss9ll+3ZCAObRlRblxtFlZDiJiTnXR+lwxODMV8gKs8lwOn0KWxKi6oTj/PVcLSPj11NE1Qn3sHlz6XZaRdfih1duZNXTA/jL+ymoPYb09IguPPbhhoAt45OZmYHDcc7RRjscZGZ6XmdmRgbR+Wz2ZTjZs2cXdevV474xd9OrRzwPjB3FyZMn/daTP63C9BTQXIie+wOgx0rPicOjLFjpuZNRwCaGjHw2P+3Zw+aNG4lPzD/z4fwomJaDTGf+PPK0iXbT43K56Nm1M80bRtLrqmv81uMPAeqjKxVKzdGJyNsi8ouIfB+I+FQLeoP8GVeUjS9hS0LhUXimdVW7aL776TCx4z7msv9bwITbE6hZrRJ9Ojo4cOwMm/b86reOvJT9yCPX2bNs3riBkfeMZsWqFMKrV+fliQX71C6UnrP59FQPgB5/NeVy4sQJRtwyhGeen0hERESZ6gkNDeXrNalsTfuZ1JR1bN0SkJ/beSMSuFfASoPSTPl/QFKgInM4YkhPPzeP0OlMJzo62qtNVHS0T2FLQsavp3BcdK4GF31ROJmHT3vY3HpFM+al/AzA7v0n+OnACVpERdC1ZX36do5h84vX8dbYnlzeJpIpf+jhl57oaAdOZ/o5fU4nkZGe1xntcJCRz6ZBVDRRjhiiHTF0SbBqBAMH38jmjRv81pM/rcL0FNAcFU10IXo2+anHSi8Gp0dZsNJzx1HAJp0o2yY7O5sRw27i5mHDGXzdDX7rKZiWk8jo/HnkaZPhpieX2rVr0/PyK1i2JNlvTSXld1mjU9UvsV7NCAjxCQmkpe1gz+7dZGVlMXvmDPoPGORh03/gIKZPew9VZc3q1URE1CIqKsqnsCUhddchmkXWpFH96lQKDeHGbo1ZlJruYZN+8CRXxEUBUD+iKs2jItjzywmemLWRuPGf0v7Bz7j71a/5cus+Rr++yi89nboksHtnGj/tsa7zs49nktR/gIdNn34DmfnhNFSVlLWriagVQWRkFA0aRBLtiCHtx+0AfPXF57SKbe23nl1uej4tRE9Sv4HMKkKPwxHDDlvPlwHQA9AlPoGdaWl5ZeHj2TPpP2Cgh02/AQP58IP3UVXWrllNrVq1iIyKQlUZO/oeWsW25r77H/RbC0DnXD12Hn0yeyb9+ufT038gH0639KxbY5XryKgoDh44wJEjRwA4ffo0Kz9fTstWrQKiq0QEcR9dmY+6isgoYBTAJQ0bFmkXFhbGi5NeYWD/PrhcLu648y7axMXx5hRrMObe0WNI6tuP5EULiYttTni1cKZMfafYsP7iylH+/O46Pn7kakJDhGlf7OQH51FGXtUCgHc+38GEz77jtdGXsurp/gjCP2du4NcTv/mddmGEhYXx9POTuPm6/uTkuLjltjuJbR3H/96aAsCdd4/m2j59WbZkEYkdYqlWrRovvz41L/zTz7/EmHtuJzsri0aNm3qcK6meZ56fxBBbz3Bbzzu2npFuehJ80PNfP/Xkanr+pZe5bmBfclwubrtjJK3bxPHWm1Y5uvveMfRJ6seSxYvo0KYl1cLDef2NtwD49ptVfDh9GnFt29E90RqUePyJf9MnqZ9/el58mRsG9sXlcjGiED29k/qxJHkRHeNaEh4ezqtTLD379mUy5t6R5Lhc5OTkcP2NQ0jqN6C45EqVYF6mSQpr/wcscpHGwHxVbeuLfZcu8bpqTYp3wwuE+WaEd4KxaFepFFxjbMH2zYgreiSyYX1KQG9dlcgWGnOr93mFuyb2W+/lFbBSocxrdAaDofwjFDU4FxwYR2cwGAKAEBLEnzsszeklHwLfAq1EJF1E7i6ttAwGQ9kTzKOupVajU9VbSitug8EQZIhpuhoMhgqOQFA3XY2jMxgMAcHU6AwGQ4UnmOfRGUdnMBj8RsQ0XQ0GQ4WnbEdVvWEcncFgCAhB7OeMozMYDIHB1OgMBkPFxsyjMxgMFR3rXdfg9XTG0RkMhoBgRl0NBkOFJ4grdMbRGQyGACCm6Vpu2f1G8K1LcMmd75e1BA8OTr+zrCUU4Pjp7LKW4EHlsOBaCJRSWAjUrEdnMBh+B5gJwwaD4XeAGYwwGAwVGzOPzmAwVHTMPDqDwfC7wDg6g8FQ4QliP2ccncFgCAymRmcwGCo0IsH9uUPj6AwGQ0AI4gqdcXQGgyEwhASxpwuyd1OKZ0nyYtrHtSIutjkTnnumwHlV5aEHxhMX25yETu3ZkJrqc9iSsmzJYhI7tqFLu1a89PyzhWr6y58eoEu7VvRM7MSmDec0dWjdjB4JHbm8Wxeu6tk1IHqu6eAg9aXr2fTyDTw0uF2B8xHVKjHr0av59rlBrHthMCOubJ53rlZ4ZaY9dCWpL17P+onXkdiivt96gvGefb40mUs7x5HYoTUvT3yuUE1/+/ODJHZozRWXdmbzxg15544eOcJdtw2le5e29Ihvx7o1q/3Ws2zJYuI7tKFT21a8WEQZeuThB+jUthXdEzux0S5DZ86c4arLutGja2e6dWnPf578p99a/EHE+1ZWlJsancvl4oHxY1mwaCmOmBh6dktgwIBBtG7TJs8mefEidqbt4PttO1i7Zg3jx/2Br75Z41PYkmp65KHxfDJvMdGOGK6+rBtJ/QcS2/pcvMuSLU0pm38gZd0aHn5gLMu++Dbv/NxFy6hbr55fOnIJEWHi3V0Z9O8lOA+d4sunB7Aw5Wd+cB7NsxmVFMsP6Ue4+dnl1KtZhdRJNzDzq11ku3J4bmQiSzc6GTFxJZVCQwiv4l/xCNZ79ujD9zN7zkKiHTH0vvJS+vQbQKvYc/EuX7KYXTvTWLNxK+vXreWRB8exeMUqAP7v0Ye46po+vP3+TLKysjh96pTfev704Hg+m2+VoV6XdaNvvjK0NHkRu9J2kPqdXYbuH8vyL7+lSpUqzF20jBo1apCdnU3S1ZdzbZ8kEhK7+aWpJEgAX+oXkSRgEhAKTFXVAk85EbkSeAmoBBxU1SuKi7Pc1OjWrV1Ls2bNadK0KZUrV2bI0GHMnzfHw2b+3DkMH3E7IkLXbt04evQImZmZPoUtCetT1tKkaTMaN7HiveGmm1k0f66HzcIF8xg2/DZEhITEbhw7epR9mZl+p10Y8c3rsWvfcfb8coJsVw4ffbOb/gkNPWxUoWbVSgBUr1qJwyd+42xODjWrVaJH6wa8+/kOALJdORw9leWXnmC8Z6kp6zzu2fU33sziBfM8bBYtnMfNt9yKiBCf2JWjR4+wf18mx48dY/U3X3Pr7SMBqFy5MrVq1/ZLz/qUtTRtdk7PjTfdzML8ZWj+PIbdeq4MHbXLkIhQo0YNALKzs8nOPotQdtWmEPG+eUNEQoFXgb5AG+AWEWmTz6Y28BowSFXjgCFetZ3/5ZQNGRlOYmIuydt3OGJwOp1ebTKcTp/CloTMjAwcbvFGO2LIzMzIZ+PEERNzzibaQWamlbaIcOOgvvTqkcj/3n7Tbz3RF4WTfuhk3r7z0EmiLwr3sJmyeButHLVIm3Iza14YzCPvrEUVGl9ck4PHzjD5jz1Z9exAXhnd3e8aXTDes32ZnvcjKtpBZobnPduXkUF0/vuakcGePbuoW7ce4/9wD1f1TODBcaM5efIk/pCZkYHDUTAtT5t8ZcjhIDPDyguXy0XPrl1o0SiKXldfTXxiYLpASkJIiHjdfCARSFPVXaqaBcwABuezGQ58oqo/A6jqL161FXVCRP4rIi8XtXmLWEQuEZEVIrJNRLaIyP3ewhSHasG1ZfJXlYuy8SXshdYEsGj5l6z8Zh2zPp3PW1Ne55uvv/RLT2GXlD/5azo42PzTrzQfPYvuf57LC3d3pWa1SoSFCh2b1GXqkh/o8eg8Tv12loevK9jHdz5UtHvmOuti86YN3Hn3aD7/eh3h4dX5byF9fP7qyX8ji9McGhrK12vWs2XHT6xPWcfWLd/7paekCCA+/APqiUiK2zYqX1QOYK/bfrp9zJ2WQB0RWSki60Xkdm/6intkp3i/vGI5CzysqqkiUhNYLyJLVXVrSSJzOGJITz93/U5nOtHR0V5toqKjycrK8hq2JEQ7HDjd4s1wphMZGZXPJgZnevo5mwwnkZFW2lFR1v/1L76Y/oMGsz5lHd17Xl5iPc5Dp4ipWz1v31G3OpmHPfuQRvRqzsTPvgNg1/7j/PTLCVpG12LvwZM4D50iJe0gAJ+t3sNDfjq6YLxnUdGe9yMzw0lklOc9i3I4yMh/X6OiQIRoRwxdEhIBGHjdDbw8cYJfeqIdDpxOz7SioryUIaeTyCjPvKhduzY9L7uC5UuTaRPX1i9NJcXHaXQHVTW+mPOFxZLf04cBXYCrgWrAtyKyWlV/LFJbUSdU9V33Dfgo336xqGqmqqbafx8HtlHQM/tMfEICaWk72LN7N1lZWcyeOYP+AwZ52PQfOIjp095DVVmzejUREbWIioryKWxJ6NwlgV070/hpjxXvJx/NIqn/QA+bvv0HMGP6+6gq69auJiIigsioKE6ePMnx48cBOHnyJCuWL6V1mzi/9KzfeZBmURE0ql+DSqEh3NS9CQtT9nrYpB88yZXtrB/JxbWq0iI6gj2/HOeXo6dxHjpJi6gIAK5sF80P6UcLpHE+BOM969Qlnl27zt2zTz+eRZ9+AzxskvoOYNaHH6CqpKxdQ0RELRpERtGgQSTRjhjSdmwH4MuVn9MytrVfejp3SWBnWhp7bD0ffzSLvoWVoQ8KlqGDBw5w5MgRAE6fPs0XK5bTomUrv/SUGLHWo/O2+UA6cInbfgyQUYjNYlU9qaoHgS+BDsVF6rUTRkQuBd4CagANRaQDMFpV/+iLajuOxkAnYE0h50YBowAuadgw/+lzQsPCeHHSKwzs3weXy8Udd95Fm7g43pwyGYB7R48hqW8/khctJC62OeHVwpky9Z1iw/pLWFgYz70wiZsG98PlcnHr7XfSuk0c70ydAsDIe0ZzbZ9+LE1eTJd2rahWLZxXpkwF4MAv+7lt2E0AnHWd5aabh3FN7yS/9LhylIffXs1n/3ctoSHC+yvS2JZ+hLuvtQr/W0u388zHm5jyx56seX4wAvzjg/UcOv4bAA+/vYa3xl9O5bAQdv9ygj+89rVfeoL1nj0z4SWGXt8flyuH4bfdQWzrOP731hsA3Hn3KK7p09eaNtShNeHh1Zj02tS88P+Z8CJ/uOcOsrKyaNS4CS+7nSupngkTJ3HjIKsMjbDL0NtvWmXorntH0zvJKkOd2rYiPDycVydbae7bl8kf7r0LV44LzcnhuhtuIimf076QBGjQdR3QQkSaAE5gGFafnDtzgFdEJAyoDHQFXixWW6F9BO4GImuAm4C5qtrJPva9qvpUPxaRGsAXwFOq+klxtl26xOuqNf62mAPH6SxXWUsogFlK3TtmKfXiubJHVzakpgR0eLZO4zba6x/ey+an98Sv99J0RUT6YU0dCQXeVtWnRGQMgKpOtm3+DIwEcrCmoLxUXJw+Daup6t581U6fPICIVAI+Bj7w5uQMBkP5JlDvuqrqQmBhvmOT8+1PAHzuIPXF0e0Vke6AikhlYDxWf1uxiOUZ3wK2qepEXwUZDIbyR1m/+eANX+rUY4CxWAMJTqCjve+NHsBtwFUistHe+pVUqMFgCG5CRLxuZYXXGp09qnHr+Uasql9T+FCxwWCogATzj91rjU5EmorIPBE5ICK/iMgcEWl6IcQZDIbyQ4Cml5QKvjRdpwOzgCggGpgNfFiaogwGQ/lCCMy7rqWFL45OVPV9VT1rb9MolW99GwyGcot4f8+1LFcgLrKPTkQusv9cISJ/wXq5VoGhwIILoM1gMJQjyus3I9ZjObZc9aPdzinwZGmJMhgM5YvcpmuwUqSjU9UmF1KIwWAo35TXGl0eItIWaxG8qrnHVPW90hJlMBjKH8Hr5nx7qf9x4EosR7cQa+XPrwHj6AwGA2C9FVHeP45zE9a6T/tUdSTWcihVSlWVwWAod5TLUVc3TqtqjoicFZEI4BfATBg2GAweBHGFzidHl2J/jOJNrJHYE8Da0hRlMBjKF0LZvsvqDV/edc1dYHOyiCwGIlR1c+nKMhgM5YogX72kuAnDnYs7l7tMeiBRIPtsTqCjLTGnfjtb1hIKkPGe1++AXFB6PL2irCUUYMaosvsSVmFE1qrq3egCUloOqbxOL3mhmHMKXBVgLQaDoZwiQGh5dHSq2utCCjEYDOWbcvlmhMFgMJwPxtEZDIYKjbWUevB6OuPoDAZDQAjmGp0vKwyLiIwQkcfs/YYiklj60gwGQ3ki9wM5xW1lhS+vgL0GXArcYu8fB14tNUUGg6HcIUCYiNetrPCl6dpVVTuLyAYAVT1sf/bQYDAY8gjiLjqfHF22iIRiL58uIvWxvo5tMBgMgDUQEcyvgPnSdH0Z+BS4WESewlqi6T+lqspgMJQ7grmPzpd3XT8QkfVYSzUJcJ2qbit1ZQaDoVxR3kddGwKngHnAXOCkfeyCs3TJYjq3b02HuJZMnPBsgfOqyp8fup8OcS25NKEjGzdYr+OeOXOGK3t2o3tiJxI7t+OpJ/8ZME0rli3h8sR29OjShldemlDgfNqP2xnU+wqaRkYw+b8vnlfYkrBsyWK6tG9Nx2Ly6JGH7qdjXEu658ujXj270SOxE107t+M/AcqjS5tdxMd/7MpnY7tyZ/fCi02XRrWZfm88s8Yk8sbtnfKOD+8aw6wxicwcncBT17ehcqgvDRDvfPn5Evr06Mg13dox5b/PFzi/c8d2bu7fi7iGdXjrtZcKnHe5XAy+5lJGjbgxIHqCsVyfL9Y3I8TrVlb40ke3gHMfyakKNAG2A3GlqKsALpeLhx+4jzkLknE4YriyZ1f6DRhIbOs2eTZLkhexc+cONn6/nXVr1/Dg+LGs+OpbqlSpwvzFy6hRowbZ2dn0vupyru2dRGLXbn5r+vsj9zP9kwVERcfQ/+oe9E4aQMvY1nk2tevU4YlnXiB54dzzDlsSPQ8/cB+f2XnUq5A8Wmrn0Ybvt5Oydg0PjR/L53YezXPLoz52HiX4kUchAn9JaskfP9jI/mO/8f498Xzx40F2HzyVZ1OjShh/6duS+6ZvYt+x36gTXgmA+jUrMywhhiGT1/Lb2RyeuTGOPnEXM2/zvhLrASuP/vXXh3hn1jwioxzcmHQZV/fuT/NWbvesdh3+/u/nWbZ4XqFxvPvmqzRr0YoTx4/7pSVXT7CV6xIhEKDnUKngVZqqtlPV9vb/LYBErH66C0rKurU0bdaMJk2aUrlyZW4cMpQF8z2dx8L5c7ll+G2ICIldu3H06BH2ZWYiItSoUQOA7Oxszp7NDsgs7o3r19G4STMaNbY0Db5hCEsWef446tW/mI6d4wkLq3TeYc+X9fny6IZC8miBWx4lFJNH2QHIo7joCPYePo3zyBnO5ihLtuznylb1PGz6tr2Yz384wL5jvwFw+FR23rnQEKFKWAihIlQNC+HAid/80gOweUMKjZo0pWGjJlSuXJn+193EsuT5HjZ1619M+05dCtwzgH0ZTlYuW8yQW+/0WwsEZ7kuKeLDv7LivH2wvTxTQiloKZbMDCcxMZfk7Uc7HGQ4nR42GflsHI4YMjIsG5fLRY+unWnWMJJeV11DQqL/S/lkZmYQ5YjJ24+MdpCZmVHqYYsiI8OJw+P6HWTmy6PMfDbR+fKoZ9fONLfzKN7PPLo4ogr7j53J299/7Dfq1/Rchb9h3XAiqoYx5baOTLsnnv7tGwBw4HgW01bvZcH9l5L8YHdO/HaW1bsO+6UHYH9mBpHRbvke5WB/ZqbP4Z/6xyM88o+nCJHAVF+CsVyXhNzPHXrbygpf+ugectv+JCLTgQM+hKsqImtFZJOIbBGRf/kjVFULS8Nnm9DQUFatSWVb2s+sT1nH1i3f+yMnN0GvmkolbJFR+p9HX69JZWvaz6QGII8Ku5r8yYeGCK2janL/jM2M+2AT9/RsTMOLqlGzahhXtKzHwP+uJumlb6hWOZS+7Rr4pcdKv+T5vmLJIurWq0/bDp28GwdQzwUv1yWkXDs6oKbbVgWrz26wD+F+A65S1Q5ARyBJRErceRDtiCE9fW/efobTSVR0tIeNI5+N05lOVJSnTe3atel5+RUsW5JcUil5REU7yHSm5+3vy3ASGRlV6mGLwuGIwelx/U4i8+VRdD6bjFLMo/3HfqNBxLlFJxtEVOFgvubnL8d+45udv3ImO4cjp7NJ/fkILRvUoGuTOjiPnObIqWzO5iif/3CADjG1/NIDVs15X4Zbvmc6uTgy0qew69d9y/IlC+gV35oHx9zB6lVf8Kexd/mlJxjLdUkREa9bWVGso7MnCtdQ1X/Z21Oq+oGqnikuHIBanLB3K9lbwUeTj3SJT2BXWhp79uwmKyuLj2fPpF//gR42ffsP5MPp76OqrF2zmoiIWkRGRXHwwAGOHDkCwOnTp1n5+XJatGpVUil5dOgcz+5dafz8k6VpziezuTZpQKmHLYrO8QnsdMujTwrJo35uebTOSx619DOPtmYc55KLqhFduyphIULvuAZ88eNBD5uVPx6kU8Paef1wbR0R7D54in1Hf6NdTC2qhllFNLFxHXYfPOmXHoB2HbuwZ9dO9v60h6ysLBZ89hFX9+7vU9g//d8TfLVhBytStvHi5Hfp1uMKnn/1bb/0BGO5LgnB3nQtbin1MFU9W9yS6t6wHeV6oDnwqqquKcRmFDAK4JJLip61EhYWxoQXX+b6gX1xuVzcdsdIWreJ4603JwNw971j6JPUjyXJi+gQ15Lw8HBem/IWAPv2ZTLm3pG4XC5ycnK4/sYh9O3nn1PJ1fTkcy9x600DyXG5GHrrHbRq3Yb333kTgNtG3ssv+/fR76oenDh+jJCQEKZOfoUV326gZkREoWH91fP8iy9zg51HIwrJo952HnW08+jVfHmU45ZHSX7mkUuV5xb/yCvDOxAqwpxNmew6cIobO1u1kY9TM9hz8BTf7DzEjNEJ5Kjy2YZMdh6wHNrybb/wwb3xnM1Rtu87wSep/vVhgpVHj/3nBe6+ZTAul4ubbrmdFrFt+PDdqQDccsc9HPhlHzf0uYwTx48TEhLC/958lUVfrqdGzQi/0y9MT7CV6xIhVjdEQKISSQImAaHAVFV9pgi7BGA1MFRVPyo2zsLa/3YkqfY7ri8ALYDZQN4jVVU/OQ/htbHerrhPVYvsROjcJV6/WBU8Hxg7djrbu9EFpma1giOBZUmvCV+UtYQCmG9GFM8VPRJJXZ8S0PpVw9h2+qepc73a3X9Z0/WqGl/Uebty9CNwLZAOrANuUdWthdgtBc4Ab3tzdL7Mo7sIOIT1jYjc+XQK+OzoVPWIiKwEkoCy6y01GAylRoC64BKBNFXdZcUpM7DGBLbms7sP+BgfZ4AU5+guFpGHsBxTroPLxWtfm/3yf7bt5KoB1wAFp30bDIYKgBDi2zy5eiKS4rb/hqq+4bbvAPa67acDHlV0EXEA12NVvvx2dKFADYqYJeBD3FHAu3YVMwSYparzvYQxGAzlEMHnGt3B4pqu+OZvXgIeVVWXryO5xTm6TFV9wqdYCsH+yHXgJhwZDIbgJXCjqunAJW77MUD+Uah4YIbt5OoB/UTkrKp+VlSkxTm6IF6LwGAwBBNCwEZd1wEtRKQJ4ASGAcPdDVS1SV66Iv8D5hfn5KB4R3d1SZUaDIbfH4FYncSe0jYOSMbqPntbVbeIyBj7/OSSxFvcB6x/LZFSg8HwuyRQLz6o6kJgYb5jhTo4Vb3TlzjN5w4NBoPfCCVYIeQCYhydwWDwH/MBa4PBUNERINQ4OoPBUNEJXjdnHJ3BYAgQQVyhM47OYDAEgrJdb84bxtEZDAa/MaOuBoPhd4Gp0RkMhoqNBObNiNIiqBydAJXCgqcCXDffF6uCgZNnzpa1BA9W/bVXWUsoQJ1rnixrCR4cXvaPspbgQWm4I9N0NRgMvwtM09VgMFR4gtfNGUdnMBgCRBBX6IyjMxgM/mP10QWvpzOOzmAwBAAxo64Gg6HiE8R+zjg6g8HgP6bpajAYKj5ianQGg+F3gHF0BoOhwiNB3HQN5rc2CrAkeTHt41oRF9ucCc89U+C8qvLQA+OJi21OQqf2bEhN9TlsRdG0fGkyXTvFkdAhlkkvPFeonr/++QESOsRyebdObNp4Ts/RI0cYOWIo3Tq35dIu7Vi35lu/9QRb/gBcm9iMTe/9ke8/GMufhncvcL52jarMfHIIa98axVev30WbJvU9zoeECN++eS8fPz00IHqCMY/Ol9wVhr1tZUW5cXQul4sHxo9lzrxFbNi8ldkzPmTb1q0eNsmLF7EzbQffb9vBK6+/wfhxf/A5bEXQ5HK5ePTh8cz8ZB6r1m3mk49msP0HzziXLVnMrp1prN24jYkvv86fHxyXd+5vjzzIVdf0ZnXq93zx7Xpatmrtt55gyh+wnNRL9ycx+NHpdLrjdYZc1ZbYRvU8bB4Z0YNNaftJvPsN7n56Ds+P6+NxftyNiWz/6aDfWiA486ikiHjfyopy4+jWrV1Ls2bNadK0KZUrV2bI0GHMnzfHw2b+3DkMH3E7IkLXbt04evQImZmZPoWtCJpSU9bSpGkzGjex4rz+xqEsmj/Pw2bRgrncfMsIRIT4xG4cPXKUffsyOX7sGN9+8zUj7rgLgMqVK1Ordm2/9ARb/gAkxEaz03mYPZlHyD6bw+zPtzCgRysPm9hG9VmZuhuAH38+RKPIWlxcpzoAjvo1SerWgncWbPBbCwRnHpUU8eFfWVFuHF1GhpOYmEvy9h2OGJxOp1ebDKfTp7AVQVNmZgbRjpi8/WiHg8xMzzgzMzJw5LfJcLJnzy7q1qvHfWPuplePeO4fO4qTJ0/6pSfY8gcgun4E6QeO5e07DxzDUb+mh813O/cz+LJYAOJjo2kYWTvPZsK4PvzflGXkqPqtBYIzj0qCACHifSsrSt3RiUioiGwQkfn+xKOFFKz8qyUUZeNL2IqgyR89Z8+eZfPGDYy8ZzQrVqVQvXp1Xp5YsI/vQukprXtWWAz503p++ipq16zK6qn38ocbEti0Yx9nXUrfS1vwy+GTbPhxn986ikobyj6PSoYv9bmy83QXYtT1fmAbEOFPJA5HDOnpe/P2nc50oqOjvdpERUeTlZXlNWxF0BQd7SDDmZ63n+F0EhnpGWe0w4Ezv01UNCJCtCOGLgldARg4+EYm+enogi1/wKrBxdQ/VxQd9SPIOHjCw+b4qSxGP3uuyf/DjPvYk3mYIVfFMaBHS5K6NadK5TAiwqvw9v9dx11PfVZiPcGYRyUiyOfRlWqNTkRigP7AVH/jik9IIC1tB3t27yYrK4vZM2fQf8AgD5v+Awcxfdp7qCprVq8mIqIWUVFRPoWtCJo6dUlg1840ftpjxfnpxzNJ6j/Awyap30BmfTgNVSVl7WoiakUQGRlFgwaROBwx7PhxOwBffvE5rWL9G4wItvwBSNmeQfOYi2gUWZtKYSEMuSqOBd/86GFTq0aVvAVgR/bvxNebfub4qSwee/Nzmg+ZROyw/3L7E5+wcsNuv5wcBGcelYRgH3Ut7RrdS8AjQM2iDERkFDAK4JKGDYuMKCwsjBcnvcLA/n1wuVzcceddtImL480pkwG4d/QYkvr2I3nRQuJimxNeLZwpU98pNqy/BJumsLAwnnl+EkOu609Ojovht91JbOs43nlrCgAj7x7NtX36smzJIhI6xFKtWjVefv3cM+jp519izD23k52VRaPGTfnv6/49n4ItfwBcLuXBSYuZN2E4oSHCu4s2sW3PAe4Z1BmAqXNTiW1Yj6l/G4wrR/lhz0HGPDfPS6wlJxjzqKQEcYUOKaydH5CIRQYA/VT1jyJyJfAnVR1QXJguXeJ11ZqUUtFTUQi2pdSrVw2+OedmKfXi6dE1nvXrUwLql1q366TvfLbCq92lzeusV9X4QKbtC6VZSnsAg0SkH1AViBCRaao6ohTTNBgMZcTv8s0IVf2rqsaoamNgGPC5cXIGQ8UlmCcMB1+7w2AwlEuCedT1gjg6VV0JrLwQaRkMhguPENxNV1OjMxgM/hPk8+iMozMYDAEhiP1c+XnX1WAwBDniw+ZLNCJJIrJdRNJE5C+FnL9VRDbb2zci0sFbnKZGZzAYAkBg3mUVkVDgVeBaIB1YJyJzVdV9/andwBWqelhE+gJvAF2Li9c4OoPB4De5q5cEgEQgTVV3AYjIDGAwkOfoVPUbN/vVQAxeME1Xg8EQGHxrutYTkRS3bVS+WBzAXrf9dPtYUdwNLPImzdToDAZDQPCx6XrQyytgha6kVaihSC8sR9fTW6LG0RkMhoAQoOkl6cAlbvsxQEbBtKQ91qpIfVX1kLdITdPVYDAEhAANuq4DWohIExGpjPX66FyPdEQaAp8At6nqj4XEUQBTozMYDP5zHp6sOFT1rIiMA5KBUOBtVd0iImPs85OBx4C6wGv2ispnva2IYhydwWDwG2vUNTBtV1VdCCzMd2yy29/3APecT5zG0RkMhoAQzG9GGEdXzgjGhS6DjWBb6LJOwjjvRheQ37b/XDoRB7GnM78ag8EQEMzqJQaDocJjVi8xGAwVniD2c8bRGQwG/xHK8uPZ3jGOzmAw+I9ZeNNgMPweCGI/ZxydwWAIEEHs6YyjMxgMASAwC2+WFsbRGQyGgGD66AwGQ4XGGnUtaxVFU66WaVqSvJj2ca2Ii23OhOeeKXBeVXnogfHExTYnoVN7NqSm+hy2omgyesqfpsmP38pPy58mZfbfirR54ZGb+H7O46yd+Vc6xp5bOfza7q3Z9Ok/+H7O4/xp5LUB0VNSxId/ZYaqBs3WuXMXPZ2thW4nzpzVJk2b6tbtO/Xoyd+0Xbv2mrppi4fNp3MXaO8+SXoqK0dXfvWtxick+hy2JFuwaTJ6glNT1Y5ji92uvmuidhv2tH6/w1no+cHjXtXFX3+vVTuO1ctvm6BrN+/Wqh3Hanjncbrz5180tv9jWjN+vG7avlc73vCk1/SkWn0N9G+3XYfO+tOhM143IKUsfEu5qdGtW7uWZs2a06RpUypXrsyQocOYP2+Oh838uXMYPuJ2RISu3bpx9OgRMjMzfQpbETQZPeVT06rUnfx69FSR5wdc0Z7p89cCsPa7PdSqWY3IehEktG3Mzr0H2eM8RPZZF7OTUxlwZXu/9ZSUAC28WSqUG0eXkeEkJubcCssORwxOp9OrTYbT6VPYiqDJ6CmfmrwRfXFt0vcdztt37j9C9MW1ib64Fun73Y8fxlG/VqnrKRR7wrC3rawo1cEIEdkDHAdc+LAKaHGoFvw+Rv5XToqy8SVsRdBk9JRPTd4oLAlVLbTPq9CvyFwwgnc04kKMuvZS1YP+RuJwxJCefu4raE5nOtHR0V5toqKjycrK8hq2ImgyesqnJm849x8hJrLOOX0NapN54CiVK4UR08D9eB0yDhwtdT2FEcDvupYK5abpGp+QQFraDvbs3k1WVhazZ86g/4BBHjb9Bw5i+rT3UFXWrF5NREQtoqKifApbETQZPeVTkzcWfPEdwwckApDYrjHHTpxm38FjpGz5ieYN69Moui6VwkIZ0qczC1ZuLnU9RfG7bbpi1aSXiIgCU1T1jZJGFBYWxouTXmFg/z64XC7uuPMu2sTF8eYUayn5e0ePIalvP5IXLSQutjnh1cKZMvWdYsP6S7BpMnrKp6Z3n76Ty7q0oF7tGqQtfpInJy+kUlgoAFM/+prFX2+hT884tsx9nFNnshn9z2kAuFw5PPjsLOa9NpbQEOHdOavZtmuf33pKSjC/GSGF9TsELHKRaFXNEJGLgaXAfar6ZT6bUcAogEsaNuzy486fSk2PwVAWBN9S6rPIOfVLQL1Sh05dNPmL1V7tompVXu9PX31JKdWmq6pm2P//AnwKJBZi84aqxqtqfP169UtTjsFgKEV+l9NLRKS6iNTM/RvoDXxfWukZDIayQ8T63KG3rawozT66BsCn9vB7GDBdVReXYnoGg6EsCd4uutJzdKq6C+hQWvEbDIbgIoj9nFm9xGAwBIZgXr3EODqDwRAAzMKbBoOhghPs69EZR2cwGAKCcXQGg6HCY5quBoOhYmO+62owGCo6Zf3mgzeMozMYDIEhiD2dcXQGgyEgmD46g8FQ4TELbxoMhopPgJYvEZEkEdkuImki8pdCzouIvGyf3ywinb3FaRydwWAICIH4rquIhAKvAn2BNsAtItImn1lfoIW9jQJe9xavcXQGg8Fvct+MCMBS6olAmqruUtUsYAYwOJ/NYOA9tVgN1BaRqOIiDao+utTU9QerVZJALDFcD/D7gzwBJNj0QPBpMnq8EyhNjQIQhwepqeuTq1WSej6YVhWRFLf9N/J9YsEB7HXbTwe65oujMBsHkFlUokHl6FQ1IEsMi0hKWSzXXBTBpgeCT5PR451g1JSLqiYFKKrC6n35v/fgi40HpulqMBiCiXTgErf9GCCjBDYeGEdnMBiCiXVACxFpIiKVgWHA3Hw2c4Hb7dHXbsBRVS2y2QpB1nQNICX+rGIpEWx6IPg0GT3eCUZNAUVVz4rIOCAZCAXeVtUtIjLGPj8ZWAj0A9KAU8BIb/GW6ucODQaDIRgwTVeDwVDhMY7OYDBUeCqEoxORCnEdvyeC7Z7lfoPY/jso3toUEfNF9wBR7vvoRKQu8EegFrAa2KOqKcWHujCISKiquoJAx0XAXViTKmcD32oZ3ngRqQc8DFQGPlLVb8tKi5ueGcCHqvqWfSxEVXPKUFMksBzoo6rpZaWjohBUT9USMh+oBpwG4oBRInKviFQqK0EikgSgqq4gqblMB+oClYC/ApeVrRzeAnKwJn7+3X5YlSUdgaZAXxF5R0Saq2qO/d5lWTERmKGq6SJSWUSq29MtDCWgXNfoRKQB8JaqDrD3G2O9K3cpsEFV3xMRuZC1FxF5FHgKWAw8oKpp9vEyqd2JyD3Araray94fBfRU1dsvtBY7/fHAdap6lb2/CmsCqBPYCHxQRvn0PPAN0ByrDO0FTqrq3y907U5ERgOPqmpTN22tgf3A58D0sqxtlkeCobbhD8eAGiIyAUBV92DV8L4BbhMRxwV2chFAEtYcny+AT2xHQ+6PV0Qu9NzFn4EJdtqVsBxwWxGJto9dISLVL6CeNcBoO+2/ATWBB7Cc3DCg1QXU4t4ftx5IVNXnsJqMo4FGIhJWBk5lE5AlIi+IyJNAQ2A88CUwHGh5gfWUe8p1jQ5ARBzAv4ADwFRV3Wkfnwp8oarvX2A9DYAcVT0gItcAjwN7VXW4iLQHYlV11gXUEwJUV9Xjbsc+A+7Hqr08BvQqixqCiDTEqjUdsvdfBVJU9Z0y0HIxMAmrv/ddrBfEjwF1VPWeMtBTCauJfzXQXVV/so9PBr5R1fcutKbyTLl3dAC2A7kR64e7HvgU+Bq4KQg6uqOAh7DW0GoKJKnql2WkJcyeef4PIBzoCTymqivKQEuI3Q8mqqoiUgNYBYy2l9654IjISKya3BlVvdIeEBBvrxeVsqYmqrrb/rvM86i8UiEcHeSNLHbDciq7gR9VdULZqjqHiGwDPlXVvwWBlqHAh8DfVfU/QaAnFPgM2KSqfy9DHZHA34Fn7EGAMh15zY+ILMDqey6zPCqvVBhH546IVFLV7LLWkYuIXA78Q1WvLWstACISjtXZ/XgQaBGgAdYAxeQg0BNqj5YHxdSgXOx5fjfnTn8xnB8V0tEFIyJSQ1VPlLWOXIKttmIwlCbG0RkMhgpPeZ9eYjAYDF4xjs5gMFR4jKMzGAwVHuPoDAZDhcc4unKGiLhEZKOIfC8is+2pIiWN638icpP999RCPhTsbnuliHQvQRp77NVBfDqez+a8RqlF5J8i8qfz1Wio+BhHV/44raodVbUtkAWMcT9Z0hU3VPUeVd1ajMmVwHk7OoMhGDCOrnzzFdDcrm2tEJHpwHciEioiE0RknYhstlfDwP5q0isistWeZX9xbkQislJE4u2/k0QkVUQ2ichye1WYMcCDdm3yMhGpLyIf22msE5Eedti6IrJERDaIyBQK/wanByLymYisF5Et9uoq7udesLUsF3shShFpJiKL7TBfiUhsQHLTUGGpqF8Bq/DYq6D0xVqNBKylhdqq6m7bWRxV1QQRqQKsEpElQCes1UHaYb2NsBV4O1+89YE3gcvtuC5S1V/tl8lPqOrztt104EVV/dp+OT8Zaymhx4GvVfUJEekPeDiuIrjLTqMasE5EPrZf9K8OpKrqwyLymB33OKyvYY1R1R0i0hV4DbiqBNlo+J1gHF35o5qIbLT//gprhYvuwNrcl7+B3kD73P43rNWXWwCXY62i6wIyROTzQuLvBnyZG5eq/lqEjmuANnJu1fEI+zWly4Eb7LALROSwD9c0XkSut/++xNZ6CGtxzpn28WlYy17VsK93tlvaVXxIw/A7xji68sdpVe3ofsD+wZ90PwTcp6rJ+ez6Ad5ehREfbMDq9rhUVU8XosXn121E5Eosp3mpqp4SkZVA1SLM1U73SP48MBiKw/TRVUySgT/Ya5ohIi3FWlzzS2CY3YcXBfQqJOy3wBUi0sQOe5F9/DjWIpm5LMFqRmLbdbT//BK41T7WF6jjRWst4LDt5GKxapS5hAC5tdLhWE3iY8BuERlipyEi0sFLGobfOcbRVUymYvW/pYrI98AUrNr7p8AO4DvgdaxVkD1Q1QNY/WqfiMgmzjUd5wHX5w5GYK14G28Pdmzl3Ojvv4DLRSQVqwn9sxeti4EwEdkMPIn1gaNcTgJxIrIeqw/uCfv4rcDdtr4twGAf8sTwO8a81G8wGCo8pkZnMBgqPMbRGQyGCo9xdAaDocJjHJ3BYKjwGEdnMBgqPMbRGQyGCo9xdAaDocLz/4JjLOWOphzuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
    "y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names,normalize=True,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes 3, 4 Need to be weighted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
