{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5491b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947d0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
    "sys.path.append(pose_sample_rpi_path)\n",
    "\n",
    "# Load MoveNet Thunder model\n",
    "import utils\n",
    "from data import BodyPart\n",
    "from ml import Movenet\n",
    "movenet = Movenet('movenet_thunder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e4b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/shellygoel2324/data_merged.csv'\n",
    "#labels_path = '/home/shellygoel2324/processedLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d37956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pose_landmarks(csv_path):\n",
    "    \"\"\"Loads a CSV created by MoveNetPreprocessor.\n",
    "    Returns:\n",
    "        X: Detected landmark coordinates and scores of shape (N, 17 * 3)\n",
    "        y: Ground truth labels of shape (N, label_count)\n",
    "        classes: The list of all class names found in the dataset\n",
    "        dataframe: The CSV loaded as a Pandas dataframe features (X) and ground\n",
    "        truth labels (y) to use later to train a pose classification model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    \n",
    "    dataframe[\"label\"] = dataframe[\"label\"] - 1\n",
    "  \n",
    "    print(dataframe[\"label\"].unique())\n",
    "    \n",
    "    \n",
    "    curr_num = dataframe.loc[dataframe['label'] == 0]\n",
    "    \n",
    "    dataFinal = curr_num.sample(n=5000)\n",
    "    #print(f\"{i}:{curr_num_sub.shape}\")\n",
    "    #dataFinal.append(curr_num_sub)\n",
    "    \n",
    "    print(f\"{0}:{dataFinal.shape}\")\n",
    "    \n",
    "    '''\n",
    "    0: 5000\n",
    "    1:2500*2\n",
    "        2: 1000*5\n",
    "            3:250*20\n",
    "                4: 250*20\n",
    "                    5: 50*100\n",
    "                \n",
    "    '''\n",
    "        \n",
    "    for i in range(1, 6):\n",
    "        \n",
    "        curr_num = dataframe.loc[dataframe['label'] == i]\n",
    "        \n",
    "        '''\n",
    "        num_s = 0\n",
    "        if i == 1:\n",
    "            num_s = 2\n",
    "        if i == 2:\n",
    "            num_s = 5\n",
    "        if i == 3:\n",
    "            num_s = 20\n",
    "        if i == 4:\n",
    "            num_s = 20     \n",
    "        if i == 5:\n",
    "            num_s = 100\n",
    "            '''\n",
    "        \n",
    "        if i in [2,4]:\n",
    "            sample_n = 7500\n",
    "            \n",
    "        if i == 3:\n",
    "            sample_n = 8500\n",
    "        elif i == 0:\n",
    "            sample_n = 8000\n",
    "        elif i == 1:\n",
    "            sample_n = 8500\n",
    "            \n",
    "        else:\n",
    "            sample_n = 5000\n",
    "        \n",
    "        curr_num_sub = curr_num.sample(n=sample_n, replace = True)\n",
    "        print(f\"{i}:{curr_num_sub.shape}\")\n",
    "        dataFinal = dataFinal.append(curr_num_sub, ignore_index=True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(dataFinal.shape)\n",
    "    \n",
    "    dataframe = dataFinal\n",
    "    labels = dataframe[\"label\"]#pd.read_csv(labels_path, header=None)\n",
    "    \n",
    "    print(labels.unique())\n",
    "    df_to_process = dataframe.copy()\n",
    "\n",
    "    # Drop the file_name columns as you don't need it during training.\n",
    "    df_to_process.drop(columns=['file_name'], inplace=True)\n",
    "\n",
    "    # Extract the list of class names\n",
    "    df_to_process.pop('class_name')\n",
    "    df_to_process.pop('class_no')\n",
    "    df_to_process.pop('label')\n",
    "\n",
    "    # Extract the labels\n",
    "    y = labels\n",
    "    classes = range(6)\n",
    "\n",
    "    # Convert the input features and labels into the correct format for training.\n",
    "    X = df_to_process.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "\n",
    "    return X, y, classes, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93bd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 1. 2. 4. 5.]\n",
      "0:(5000, 55)\n",
      "1:(8500, 55)\n",
      "2:(5000, 55)\n",
      "3:(8500, 55)\n",
      "4:(5000, 55)\n",
      "5:(5000, 55)\n",
      "(37000, 55)\n",
      "[0. 1. 2. 3. 4. 5.]\n",
      "(37000, 51) (37000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the train data\n",
    "X, y, class_names, _ = load_pose_landmarks(data_path)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Split training data (X, y) into (X_train, y_train) and (X_val, y_val)\n",
    "\n",
    "# 80/10/10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "#print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "#60/20/20\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ead317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DISTRIBUTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 06:01:26.572806: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-31 06:01:26.572879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cs229-vm-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-05-31 06:01:26.577900: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.13439189189189188\n",
      "0: 3978\n",
      "1: 0.22797297297297298\n",
      "1: 6748\n",
      "2: 0.13577702702702701\n",
      "2: 4019\n",
      "3: 0.23087837837837838\n",
      "3: 6834\n",
      "4: 0.1347635135135135\n",
      "4: 3989\n",
      "5: 0.1362162162162162\n",
      "5: 4032\n",
      "\n",
      "TEST DISTRIBUTION\n",
      "0: 0.1437837837837838\n",
      "1: 0.2308108108108108\n",
      "2: 0.1308108108108108\n",
      "3: 0.21945945945945947\n",
      "4: 0.1362162162162162\n",
      "5: 0.13891891891891892\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DISTRIBUTION\")\n",
    "\n",
    "sample_dist = []\n",
    "for i in range(0,6):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_train:\n",
    "            if tf.argmax(sample) == i:\n",
    "                num_i+=1\n",
    "    dist = num_i/len(y_train)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    print(f\"{i}: {num_i}\")\n",
    "    sample_dist.append(dist)\n",
    "\n",
    "\n",
    "print(\"\\nTEST DISTRIBUTION\")\n",
    "for i in range(0,6):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_test:\n",
    "            if tf.argmax(sample) == i:\n",
    "                num_i+=1\n",
    "\n",
    "    dist = num_i/len(y_test)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    #sample_dist.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14b5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134c92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31810256 0.53960685 0.32138114 0.54648388 0.31898218 0.32242069]\n",
      "[3.143640229572653, 1.8532010719087155, 3.111570249624288, 1.8298801336318424, 3.134971379603914, 3.1015379050694474]\n"
     ]
    }
   ],
   "source": [
    "sample_dist = sample_dist/np.linalg.norm(sample_dist)\n",
    "weight_balanced= [1/s for s in sample_dist]\n",
    "\n",
    "print(sample_dist)\n",
    "print(weight_balanced)\n",
    "#weight_balanced = weight_balanced/np.linalg.norm(weight_balanced)\n",
    "#print(weight_balanced)\n",
    "#print(np.sum(weight_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5e271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "for i in range(6):\n",
    "    class_weights[i] = weight_balanced[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    \n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center\n",
    "\n",
    "\n",
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "\n",
    "        It is the maximum of two values:\n",
    "        * Torso size multiplied by `torso_size_multiplier`\n",
    "        * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "    return pose_size\n",
    "\n",
    "\n",
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "        scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "    # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def no_normalization(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    landmarks = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Flatten the landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks[:, :, :2])\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea2f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c23041",
   "metadata": {},
   "source": [
    "## Normalize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28566ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 51)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 17, 3)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 17, 2)       0           ['reshape[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpLambd  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " a)                                                              ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_1 (TFOpLam  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " bda)                                                            ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2)            0           ['tf.compat.v1.gather[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_1[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['tf.math.multiply[0][0]',       \n",
      " da)                                                              'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size (TFOpLambda)  ()                  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 2)         0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div (TFOpLa  ()                  0           ['tf.compat.v1.size[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.broadcast_to (TFOpLambda)   (None, 17, 2)        0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.compat.v1.floor_div[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 17, 2)        0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.broadcast_to[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_6 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_7 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_6[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_7[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 2)           0           ['tf.math.multiply_6[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_1 (TFOpLambd  ()                  0           ['tf.math.subtract[0][0]']       \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_4 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_5 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_2 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_3 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_1 (TFOp  ()                  0           ['tf.compat.v1.size_1[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_5[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_3[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.broadcast_to_1 (TFOpLambda)  (None, 17, 2)       0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 2)           0           ['tf.math.multiply_4[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 2)           0           ['tf.math.multiply_2[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 17, 2)       0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.broadcast_to_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_2[0][0]', \n",
      " )                                                                'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_8 (TFOpLam  (17, 2)             0           ['tf.math.subtract_2[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm (TFOpLambda)  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_1 (TFOpLambd  (2,)                0           ['tf.compat.v1.gather_8[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  ()                  0           ['tf.compat.v1.norm[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['tf.compat.v1.norm_1[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   ()                   0           ['tf.math.multiply_8[0][0]',     \n",
      "                                                                  'tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 17, 2)        0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.maximum[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 34)           0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          4480        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,126\n",
      "Trainable params: 13,126\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = landmarks_to_embedding(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ebdb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df7224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.1843 - tp: 5144.0000 - fp: 952.0000 - tn: 146168.0000 - fn: 24280.0000 - accuracy: 0.8571 - precision: 0.8438 - recall: 0.1748 - auc: 0.8982 - prc: 0.6551\n",
      "Epoch 1: val_loss improved from inf to 0.12582, saving model to weights.best.onlyfocalloss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 06:02:26.437441: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 18s 7ms/step - loss: 0.1841 - tp: 5200.0000 - fp: 962.0000 - tn: 147038.0000 - fn: 24400.0000 - accuracy: 0.8572 - precision: 0.8439 - recall: 0.1757 - auc: 0.8984 - prc: 0.6557 - val_loss: 0.1258 - val_tp: 1342.0000 - val_fp: 118.0000 - val_tn: 18382.0000 - val_fn: 2358.0000 - val_accuracy: 0.8885 - val_precision: 0.9192 - val_recall: 0.3627 - val_auc: 0.9551 - val_prc: 0.8328\n",
      "Epoch 2/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.1352 - tp: 11304.0000 - fp: 1478.0000 - tn: 146202.0000 - fn: 18232.0000 - accuracy: 0.8888 - precision: 0.8844 - recall: 0.3827 - auc: 0.9472 - prc: 0.7952\n",
      "Epoch 2: val_loss improved from 0.12582 to 0.11027, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.1352 - tp: 11331.0000 - fp: 1483.0000 - tn: 146517.0000 - fn: 18269.0000 - accuracy: 0.8888 - precision: 0.8843 - recall: 0.3828 - auc: 0.9472 - prc: 0.7952 - val_loss: 0.1103 - val_tp: 1892.0000 - val_fp: 179.0000 - val_tn: 18321.0000 - val_fn: 1808.0000 - val_accuracy: 0.9105 - val_precision: 0.9136 - val_recall: 0.5114 - val_auc: 0.9645 - val_prc: 0.8646\n",
      "Epoch 3/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.1218 - tp: 13721.0000 - fp: 1588.0000 - tn: 146252.0000 - fn: 15847.0000 - accuracy: 0.9017 - precision: 0.8963 - recall: 0.4640 - auc: 0.9576 - prc: 0.8313\n",
      "Epoch 3: val_loss improved from 0.11027 to 0.10191, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.1218 - tp: 13736.0000 - fp: 1590.0000 - tn: 146410.0000 - fn: 15864.0000 - accuracy: 0.9017 - precision: 0.8963 - recall: 0.4641 - auc: 0.9575 - prc: 0.8314 - val_loss: 0.1019 - val_tp: 2111.0000 - val_fp: 175.0000 - val_tn: 18325.0000 - val_fn: 1589.0000 - val_accuracy: 0.9205 - val_precision: 0.9234 - val_recall: 0.5705 - val_auc: 0.9704 - val_prc: 0.8832\n",
      "Epoch 4/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.1162 - tp: 14888.0000 - fp: 1652.0000 - tn: 146028.0000 - fn: 14648.0000 - accuracy: 0.9080 - precision: 0.9001 - recall: 0.5041 - auc: 0.9617 - prc: 0.8471\n",
      "Epoch 4: val_loss improved from 0.10191 to 0.09670, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.1161 - tp: 14928.0000 - fp: 1653.0000 - tn: 146347.0000 - fn: 14672.0000 - accuracy: 0.9081 - precision: 0.9003 - recall: 0.5043 - auc: 0.9617 - prc: 0.8473 - val_loss: 0.0967 - val_tp: 2173.0000 - val_fp: 164.0000 - val_tn: 18336.0000 - val_fn: 1527.0000 - val_accuracy: 0.9238 - val_precision: 0.9298 - val_recall: 0.5873 - val_auc: 0.9735 - val_prc: 0.8952\n",
      "Epoch 5/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.1110 - tp: 15760.0000 - fp: 1631.0000 - tn: 146129.0000 - fn: 13792.0000 - accuracy: 0.9130 - precision: 0.9062 - recall: 0.5333 - auc: 0.9651 - prc: 0.8611\n",
      "Epoch 5: val_loss improved from 0.09670 to 0.09174, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 13s 7ms/step - loss: 0.1110 - tp: 15785.0000 - fp: 1631.0000 - tn: 146369.0000 - fn: 13815.0000 - accuracy: 0.9130 - precision: 0.9064 - recall: 0.5333 - auc: 0.9651 - prc: 0.8612 - val_loss: 0.0917 - val_tp: 2327.0000 - val_fp: 189.0000 - val_tn: 18311.0000 - val_fn: 1373.0000 - val_accuracy: 0.9296 - val_precision: 0.9249 - val_recall: 0.6289 - val_auc: 0.9763 - val_prc: 0.9048\n",
      "Epoch 6/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.1082 - tp: 16290.0000 - fp: 1651.0000 - tn: 146269.0000 - fn: 13294.0000 - accuracy: 0.9158 - precision: 0.9080 - recall: 0.5506 - auc: 0.9669 - prc: 0.8673\n",
      "Epoch 6: val_loss improved from 0.09174 to 0.09056, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.1082 - tp: 16301.0000 - fp: 1651.0000 - tn: 146349.0000 - fn: 13299.0000 - accuracy: 0.9158 - precision: 0.9080 - recall: 0.5507 - auc: 0.9669 - prc: 0.8674 - val_loss: 0.0906 - val_tp: 2352.0000 - val_fp: 188.0000 - val_tn: 18312.0000 - val_fn: 1348.0000 - val_accuracy: 0.9308 - val_precision: 0.9260 - val_recall: 0.6357 - val_auc: 0.9769 - val_prc: 0.9067\n",
      "Epoch 7/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.1051 - tp: 16807.0000 - fp: 1678.0000 - tn: 145682.0000 - fn: 12665.0000 - accuracy: 0.9189 - precision: 0.9092 - recall: 0.5703 - auc: 0.9687 - prc: 0.8751\n",
      "Epoch 7: val_loss improved from 0.09056 to 0.08813, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.1051 - tp: 16880.0000 - fp: 1684.0000 - tn: 146316.0000 - fn: 12720.0000 - accuracy: 0.9189 - precision: 0.9093 - recall: 0.5703 - auc: 0.9688 - prc: 0.8751 - val_loss: 0.0881 - val_tp: 2466.0000 - val_fp: 216.0000 - val_tn: 18284.0000 - val_fn: 1234.0000 - val_accuracy: 0.9347 - val_precision: 0.9195 - val_recall: 0.6665 - val_auc: 0.9781 - val_prc: 0.9124\n",
      "Epoch 8/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.1038 - tp: 16951.0000 - fp: 1635.0000 - tn: 145805.0000 - fn: 12537.0000 - accuracy: 0.9199 - precision: 0.9120 - recall: 0.5748 - auc: 0.9697 - prc: 0.8784\n",
      "Epoch 8: val_loss improved from 0.08813 to 0.08678, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.1039 - tp: 17019.0000 - fp: 1643.0000 - tn: 146357.0000 - fn: 12581.0000 - accuracy: 0.9199 - precision: 0.9120 - recall: 0.5750 - auc: 0.9697 - prc: 0.8784 - val_loss: 0.0868 - val_tp: 2387.0000 - val_fp: 185.0000 - val_tn: 18315.0000 - val_fn: 1313.0000 - val_accuracy: 0.9325 - val_precision: 0.9281 - val_recall: 0.6451 - val_auc: 0.9788 - val_prc: 0.9152\n",
      "Epoch 9/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.1022 - tp: 17197.0000 - fp: 1660.0000 - tn: 145540.0000 - fn: 12243.0000 - accuracy: 0.9213 - precision: 0.9120 - recall: 0.5841 - auc: 0.9706 - prc: 0.8822\n",
      "Epoch 9: val_loss improved from 0.08678 to 0.08420, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.1022 - tp: 17296.0000 - fp: 1670.0000 - tn: 146330.0000 - fn: 12304.0000 - accuracy: 0.9213 - precision: 0.9119 - recall: 0.5843 - auc: 0.9706 - prc: 0.8822 - val_loss: 0.0842 - val_tp: 2453.0000 - val_fp: 182.0000 - val_tn: 18318.0000 - val_fn: 1247.0000 - val_accuracy: 0.9356 - val_precision: 0.9309 - val_recall: 0.6630 - val_auc: 0.9804 - val_prc: 0.9194\n",
      "Epoch 10/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.1000 - tp: 17496.0000 - fp: 1649.0000 - tn: 145471.0000 - fn: 11928.0000 - accuracy: 0.9231 - precision: 0.9139 - recall: 0.5946 - auc: 0.9721 - prc: 0.8870\n",
      "Epoch 10: val_loss did not improve from 0.08420\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.1002 - tp: 17587.0000 - fp: 1661.0000 - tn: 146339.0000 - fn: 12013.0000 - accuracy: 0.9230 - precision: 0.9137 - recall: 0.5942 - auc: 0.9720 - prc: 0.8867 - val_loss: 0.0852 - val_tp: 2412.0000 - val_fp: 175.0000 - val_tn: 18325.0000 - val_fn: 1288.0000 - val_accuracy: 0.9341 - val_precision: 0.9324 - val_recall: 0.6519 - val_auc: 0.9799 - val_prc: 0.9180\n",
      "Epoch 11/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0983 - tp: 17875.0000 - fp: 1619.0000 - tn: 146381.0000 - fn: 11725.0000 - accuracy: 0.9249 - precision: 0.9169 - recall: 0.6039 - auc: 0.9731 - prc: 0.8912\n",
      "Epoch 11: val_loss did not improve from 0.08420\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0983 - tp: 17875.0000 - fp: 1619.0000 - tn: 146381.0000 - fn: 11725.0000 - accuracy: 0.9249 - precision: 0.9169 - recall: 0.6039 - auc: 0.9731 - prc: 0.8912 - val_loss: 0.0842 - val_tp: 2530.0000 - val_fp: 224.0000 - val_tn: 18276.0000 - val_fn: 1170.0000 - val_accuracy: 0.9372 - val_precision: 0.9187 - val_recall: 0.6838 - val_auc: 0.9806 - val_prc: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0982 - tp: 17662.0000 - fp: 1616.0000 - tn: 145664.0000 - fn: 11794.0000 - accuracy: 0.9241 - precision: 0.9162 - recall: 0.5996 - auc: 0.9730 - prc: 0.8917\n",
      "Epoch 12: val_loss improved from 0.08420 to 0.08227, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 7ms/step - loss: 0.0983 - tp: 17750.0000 - fp: 1625.0000 - tn: 146375.0000 - fn: 11850.0000 - accuracy: 0.9241 - precision: 0.9161 - recall: 0.5997 - auc: 0.9729 - prc: 0.8916 - val_loss: 0.0823 - val_tp: 2422.0000 - val_fp: 170.0000 - val_tn: 18330.0000 - val_fn: 1278.0000 - val_accuracy: 0.9348 - val_precision: 0.9344 - val_recall: 0.6546 - val_auc: 0.9815 - val_prc: 0.9228\n",
      "Epoch 13/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0969 - tp: 17916.0000 - fp: 1604.0000 - tn: 146316.0000 - fn: 11668.0000 - accuracy: 0.9252 - precision: 0.9178 - recall: 0.6056 - auc: 0.9739 - prc: 0.8945\n",
      "Epoch 13: val_loss improved from 0.08227 to 0.07969, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0969 - tp: 17925.0000 - fp: 1606.0000 - tn: 146394.0000 - fn: 11675.0000 - accuracy: 0.9252 - precision: 0.9178 - recall: 0.6056 - auc: 0.9739 - prc: 0.8945 - val_loss: 0.0797 - val_tp: 2500.0000 - val_fp: 202.0000 - val_tn: 18298.0000 - val_fn: 1200.0000 - val_accuracy: 0.9368 - val_precision: 0.9252 - val_recall: 0.6757 - val_auc: 0.9826 - val_prc: 0.9275\n",
      "Epoch 14/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0953 - tp: 18163.0000 - fp: 1615.0000 - tn: 145905.0000 - fn: 11341.0000 - accuracy: 0.9268 - precision: 0.9183 - recall: 0.6156 - auc: 0.9749 - prc: 0.8979\n",
      "Epoch 14: val_loss did not improve from 0.07969\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0951 - tp: 18230.0000 - fp: 1615.0000 - tn: 146385.0000 - fn: 11370.0000 - accuracy: 0.9269 - precision: 0.9186 - recall: 0.6159 - auc: 0.9749 - prc: 0.8981 - val_loss: 0.0802 - val_tp: 2490.0000 - val_fp: 199.0000 - val_tn: 18301.0000 - val_fn: 1210.0000 - val_accuracy: 0.9365 - val_precision: 0.9260 - val_recall: 0.6730 - val_auc: 0.9823 - val_prc: 0.9268\n",
      "Epoch 15/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0940 - tp: 18471.0000 - fp: 1581.0000 - tn: 146339.0000 - fn: 11113.0000 - accuracy: 0.9285 - precision: 0.9212 - recall: 0.6244 - auc: 0.9755 - prc: 0.9005\n",
      "Epoch 15: val_loss improved from 0.07969 to 0.07737, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0940 - tp: 18479.0000 - fp: 1582.0000 - tn: 146418.0000 - fn: 11121.0000 - accuracy: 0.9285 - precision: 0.9211 - recall: 0.6243 - auc: 0.9755 - prc: 0.9005 - val_loss: 0.0774 - val_tp: 2530.0000 - val_fp: 196.0000 - val_tn: 18304.0000 - val_fn: 1170.0000 - val_accuracy: 0.9385 - val_precision: 0.9281 - val_recall: 0.6838 - val_auc: 0.9836 - val_prc: 0.9318\n",
      "Epoch 16/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0932 - tp: 18468.0000 - fp: 1571.0000 - tn: 146029.0000 - fn: 11052.0000 - accuracy: 0.9287 - precision: 0.9216 - recall: 0.6256 - auc: 0.9759 - prc: 0.9024\n",
      "Epoch 16: val_loss did not improve from 0.07737\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0932 - tp: 18517.0000 - fp: 1576.0000 - tn: 146424.0000 - fn: 11083.0000 - accuracy: 0.9287 - precision: 0.9216 - recall: 0.6256 - auc: 0.9759 - prc: 0.9023 - val_loss: 0.0781 - val_tp: 2456.0000 - val_fp: 160.0000 - val_tn: 18340.0000 - val_fn: 1244.0000 - val_accuracy: 0.9368 - val_precision: 0.9388 - val_recall: 0.6638 - val_auc: 0.9836 - val_prc: 0.9309\n",
      "Epoch 17/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0934 - tp: 18437.0000 - fp: 1606.0000 - tn: 146394.0000 - fn: 11163.0000 - accuracy: 0.9281 - precision: 0.9199 - recall: 0.6229 - auc: 0.9760 - prc: 0.9018\n",
      "Epoch 17: val_loss did not improve from 0.07737\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0934 - tp: 18437.0000 - fp: 1606.0000 - tn: 146394.0000 - fn: 11163.0000 - accuracy: 0.9281 - precision: 0.9199 - recall: 0.6229 - auc: 0.9760 - prc: 0.9018 - val_loss: 0.0777 - val_tp: 2479.0000 - val_fp: 160.0000 - val_tn: 18340.0000 - val_fn: 1221.0000 - val_accuracy: 0.9378 - val_precision: 0.9394 - val_recall: 0.6700 - val_auc: 0.9835 - val_prc: 0.9320\n",
      "Epoch 18/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0925 - tp: 18602.0000 - fp: 1654.0000 - tn: 145466.0000 - fn: 10822.0000 - accuracy: 0.9293 - precision: 0.9183 - recall: 0.6322 - auc: 0.9763 - prc: 0.9040\n",
      "Epoch 18: val_loss improved from 0.07737 to 0.07663, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0925 - tp: 18712.0000 - fp: 1666.0000 - tn: 146334.0000 - fn: 10888.0000 - accuracy: 0.9293 - precision: 0.9182 - recall: 0.6322 - auc: 0.9762 - prc: 0.9039 - val_loss: 0.0766 - val_tp: 2491.0000 - val_fp: 157.0000 - val_tn: 18343.0000 - val_fn: 1209.0000 - val_accuracy: 0.9385 - val_precision: 0.9407 - val_recall: 0.6732 - val_auc: 0.9840 - val_prc: 0.9339\n",
      "Epoch 19/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0932 - tp: 18492.0000 - fp: 1509.0000 - tn: 146091.0000 - fn: 11028.0000 - accuracy: 0.9292 - precision: 0.9246 - recall: 0.6264 - auc: 0.9761 - prc: 0.9034\n",
      "Epoch 19: val_loss improved from 0.07663 to 0.07583, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0932 - tp: 18542.0000 - fp: 1513.0000 - tn: 146487.0000 - fn: 11058.0000 - accuracy: 0.9292 - precision: 0.9246 - recall: 0.6264 - auc: 0.9761 - prc: 0.9033 - val_loss: 0.0758 - val_tp: 2486.0000 - val_fp: 153.0000 - val_tn: 18347.0000 - val_fn: 1214.0000 - val_accuracy: 0.9384 - val_precision: 0.9420 - val_recall: 0.6719 - val_auc: 0.9845 - val_prc: 0.9346\n",
      "Epoch 20/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0933 - tp: 18453.0000 - fp: 1570.0000 - tn: 145550.0000 - fn: 10971.0000 - accuracy: 0.9290 - precision: 0.9216 - recall: 0.6271 - auc: 0.9761 - prc: 0.9028\n",
      "Epoch 20: val_loss did not improve from 0.07583\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0933 - tp: 18563.0000 - fp: 1583.0000 - tn: 146417.0000 - fn: 11037.0000 - accuracy: 0.9289 - precision: 0.9214 - recall: 0.6271 - auc: 0.9761 - prc: 0.9028 - val_loss: 0.0766 - val_tp: 2434.0000 - val_fp: 136.0000 - val_tn: 18364.0000 - val_fn: 1266.0000 - val_accuracy: 0.9368 - val_precision: 0.9471 - val_recall: 0.6578 - val_auc: 0.9841 - val_prc: 0.9336\n",
      "Epoch 21/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0906 - tp: 18800.0000 - fp: 1511.0000 - tn: 146009.0000 - fn: 10704.0000 - accuracy: 0.9310 - precision: 0.9256 - recall: 0.6372 - auc: 0.9773 - prc: 0.9081\n",
      "Epoch 21: val_loss improved from 0.07583 to 0.07394, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0906 - tp: 18861.0000 - fp: 1519.0000 - tn: 146481.0000 - fn: 10739.0000 - accuracy: 0.9310 - precision: 0.9255 - recall: 0.6372 - auc: 0.9773 - prc: 0.9081 - val_loss: 0.0739 - val_tp: 2633.0000 - val_fp: 188.0000 - val_tn: 18312.0000 - val_fn: 1067.0000 - val_accuracy: 0.9435 - val_precision: 0.9334 - val_recall: 0.7116 - val_auc: 0.9853 - val_prc: 0.9377\n",
      "Epoch 22/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0906 - tp: 18933.0000 - fp: 1598.0000 - tn: 146322.0000 - fn: 10651.0000 - accuracy: 0.9310 - precision: 0.9222 - recall: 0.6400 - auc: 0.9773 - prc: 0.9080\n",
      "Epoch 22: val_loss did not improve from 0.07394\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0905 - tp: 18944.0000 - fp: 1598.0000 - tn: 146402.0000 - fn: 10656.0000 - accuracy: 0.9310 - precision: 0.9222 - recall: 0.6400 - auc: 0.9773 - prc: 0.9080 - val_loss: 0.0753 - val_tp: 2461.0000 - val_fp: 132.0000 - val_tn: 18368.0000 - val_fn: 1239.0000 - val_accuracy: 0.9382 - val_precision: 0.9491 - val_recall: 0.6651 - val_auc: 0.9848 - val_prc: 0.9366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0905 - tp: 18919.0000 - fp: 1539.0000 - tn: 146461.0000 - fn: 10681.0000 - accuracy: 0.9312 - precision: 0.9248 - recall: 0.6392 - auc: 0.9774 - prc: 0.9083\n",
      "Epoch 23: val_loss did not improve from 0.07394\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0905 - tp: 18919.0000 - fp: 1539.0000 - tn: 146461.0000 - fn: 10681.0000 - accuracy: 0.9312 - precision: 0.9248 - recall: 0.6392 - auc: 0.9774 - prc: 0.9083 - val_loss: 0.0741 - val_tp: 2617.0000 - val_fp: 161.0000 - val_tn: 18339.0000 - val_fn: 1083.0000 - val_accuracy: 0.9440 - val_precision: 0.9420 - val_recall: 0.7073 - val_auc: 0.9851 - val_prc: 0.9380\n",
      "Epoch 24/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0891 - tp: 19096.0000 - fp: 1542.0000 - tn: 146138.0000 - fn: 10440.0000 - accuracy: 0.9324 - precision: 0.9253 - recall: 0.6465 - auc: 0.9782 - prc: 0.9105\n",
      "Epoch 24: val_loss improved from 0.07394 to 0.07218, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0891 - tp: 19142.0000 - fp: 1544.0000 - tn: 146456.0000 - fn: 10458.0000 - accuracy: 0.9324 - precision: 0.9254 - recall: 0.6467 - auc: 0.9782 - prc: 0.9105 - val_loss: 0.0722 - val_tp: 2603.0000 - val_fp: 164.0000 - val_tn: 18336.0000 - val_fn: 1097.0000 - val_accuracy: 0.9432 - val_precision: 0.9407 - val_recall: 0.7035 - val_auc: 0.9859 - val_prc: 0.9404\n",
      "Epoch 25/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0891 - tp: 19211.0000 - fp: 1480.0000 - tn: 146520.0000 - fn: 10389.0000 - accuracy: 0.9332 - precision: 0.9285 - recall: 0.6490 - auc: 0.9783 - prc: 0.9116\n",
      "Epoch 25: val_loss did not improve from 0.07218\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0891 - tp: 19211.0000 - fp: 1480.0000 - tn: 146520.0000 - fn: 10389.0000 - accuracy: 0.9332 - precision: 0.9285 - recall: 0.6490 - auc: 0.9783 - prc: 0.9116 - val_loss: 0.0730 - val_tp: 2556.0000 - val_fp: 157.0000 - val_tn: 18343.0000 - val_fn: 1144.0000 - val_accuracy: 0.9414 - val_precision: 0.9421 - val_recall: 0.6908 - val_auc: 0.9857 - val_prc: 0.9394\n",
      "Epoch 26/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0890 - tp: 19073.0000 - fp: 1547.0000 - tn: 146293.0000 - fn: 10495.0000 - accuracy: 0.9321 - precision: 0.9250 - recall: 0.6451 - auc: 0.9781 - prc: 0.9113\n",
      "Epoch 26: val_loss improved from 0.07218 to 0.07208, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0890 - tp: 19096.0000 - fp: 1549.0000 - tn: 146451.0000 - fn: 10504.0000 - accuracy: 0.9321 - precision: 0.9250 - recall: 0.6451 - auc: 0.9781 - prc: 0.9113 - val_loss: 0.0721 - val_tp: 2587.0000 - val_fp: 164.0000 - val_tn: 18336.0000 - val_fn: 1113.0000 - val_accuracy: 0.9425 - val_precision: 0.9404 - val_recall: 0.6992 - val_auc: 0.9860 - val_prc: 0.9406\n",
      "Epoch 27/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0879 - tp: 19220.0000 - fp: 1502.0000 - tn: 145538.0000 - fn: 10188.0000 - accuracy: 0.9337 - precision: 0.9275 - recall: 0.6536 - auc: 0.9787 - prc: 0.9136\n",
      "Epoch 27: val_loss improved from 0.07208 to 0.07023, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 7ms/step - loss: 0.0878 - tp: 19349.0000 - fp: 1505.0000 - tn: 146495.0000 - fn: 10251.0000 - accuracy: 0.9338 - precision: 0.9278 - recall: 0.6537 - auc: 0.9788 - prc: 0.9139 - val_loss: 0.0702 - val_tp: 2667.0000 - val_fp: 170.0000 - val_tn: 18330.0000 - val_fn: 1033.0000 - val_accuracy: 0.9458 - val_precision: 0.9401 - val_recall: 0.7208 - val_auc: 0.9866 - val_prc: 0.9437\n",
      "Epoch 28/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0877 - tp: 19236.0000 - fp: 1527.0000 - tn: 146153.0000 - fn: 10300.0000 - accuracy: 0.9333 - precision: 0.9265 - recall: 0.6513 - auc: 0.9789 - prc: 0.9140\n",
      "Epoch 28: val_loss improved from 0.07023 to 0.06951, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0878 - tp: 19276.0000 - fp: 1532.0000 - tn: 146468.0000 - fn: 10324.0000 - accuracy: 0.9332 - precision: 0.9264 - recall: 0.6512 - auc: 0.9789 - prc: 0.9139 - val_loss: 0.0695 - val_tp: 2693.0000 - val_fp: 162.0000 - val_tn: 18338.0000 - val_fn: 1007.0000 - val_accuracy: 0.9473 - val_precision: 0.9433 - val_recall: 0.7278 - val_auc: 0.9871 - val_prc: 0.9452\n",
      "Epoch 29/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0871 - tp: 19424.0000 - fp: 1517.0000 - tn: 146483.0000 - fn: 10176.0000 - accuracy: 0.9342 - precision: 0.9276 - recall: 0.6562 - auc: 0.9791 - prc: 0.9155\n",
      "Epoch 29: val_loss did not improve from 0.06951\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0871 - tp: 19424.0000 - fp: 1517.0000 - tn: 146483.0000 - fn: 10176.0000 - accuracy: 0.9342 - precision: 0.9276 - recall: 0.6562 - auc: 0.9791 - prc: 0.9155 - val_loss: 0.0703 - val_tp: 2645.0000 - val_fp: 154.0000 - val_tn: 18346.0000 - val_fn: 1055.0000 - val_accuracy: 0.9455 - val_precision: 0.9450 - val_recall: 0.7149 - val_auc: 0.9866 - val_prc: 0.9441\n",
      "Epoch 30/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0864 - tp: 19384.0000 - fp: 1531.0000 - tn: 145909.0000 - fn: 10104.0000 - accuracy: 0.9342 - precision: 0.9268 - recall: 0.6574 - auc: 0.9796 - prc: 0.9164\n",
      "Epoch 30: val_loss did not improve from 0.06951\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0865 - tp: 19453.0000 - fp: 1539.0000 - tn: 146461.0000 - fn: 10147.0000 - accuracy: 0.9342 - precision: 0.9267 - recall: 0.6572 - auc: 0.9796 - prc: 0.9163 - val_loss: 0.0700 - val_tp: 2601.0000 - val_fp: 147.0000 - val_tn: 18353.0000 - val_fn: 1099.0000 - val_accuracy: 0.9439 - val_precision: 0.9465 - val_recall: 0.7030 - val_auc: 0.9869 - val_prc: 0.9447\n",
      "Epoch 31/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0869 - tp: 19519.0000 - fp: 1476.0000 - tn: 146524.0000 - fn: 10081.0000 - accuracy: 0.9349 - precision: 0.9297 - recall: 0.6594 - auc: 0.9795 - prc: 0.9164\n",
      "Epoch 31: val_loss improved from 0.06951 to 0.06835, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0869 - tp: 19519.0000 - fp: 1476.0000 - tn: 146524.0000 - fn: 10081.0000 - accuracy: 0.9349 - precision: 0.9297 - recall: 0.6594 - auc: 0.9795 - prc: 0.9164 - val_loss: 0.0684 - val_tp: 2687.0000 - val_fp: 150.0000 - val_tn: 18350.0000 - val_fn: 1013.0000 - val_accuracy: 0.9476 - val_precision: 0.9471 - val_recall: 0.7262 - val_auc: 0.9873 - val_prc: 0.9471\n",
      "Epoch 32/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0866 - tp: 19403.0000 - fp: 1468.0000 - tn: 146132.0000 - fn: 10117.0000 - accuracy: 0.9346 - precision: 0.9297 - recall: 0.6573 - auc: 0.9794 - prc: 0.9164\n",
      "Epoch 32: val_loss did not improve from 0.06835\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0866 - tp: 19453.0000 - fp: 1471.0000 - tn: 146529.0000 - fn: 10147.0000 - accuracy: 0.9346 - precision: 0.9297 - recall: 0.6572 - auc: 0.9794 - prc: 0.9164 - val_loss: 0.0684 - val_tp: 2666.0000 - val_fp: 149.0000 - val_tn: 18351.0000 - val_fn: 1034.0000 - val_accuracy: 0.9467 - val_precision: 0.9471 - val_recall: 0.7205 - val_auc: 0.9872 - val_prc: 0.9471\n",
      "Epoch 33/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0856 - tp: 19682.0000 - fp: 1512.0000 - tn: 146328.0000 - fn: 9886.0000 - accuracy: 0.9358 - precision: 0.9287 - recall: 0.6657 - auc: 0.9799 - prc: 0.9182\n",
      "Epoch 33: val_loss did not improve from 0.06835\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0856 - tp: 19705.0000 - fp: 1514.0000 - tn: 146486.0000 - fn: 9895.0000 - accuracy: 0.9358 - precision: 0.9286 - recall: 0.6657 - auc: 0.9799 - prc: 0.9182 - val_loss: 0.0687 - val_tp: 2668.0000 - val_fp: 155.0000 - val_tn: 18345.0000 - val_fn: 1032.0000 - val_accuracy: 0.9465 - val_precision: 0.9451 - val_recall: 0.7211 - val_auc: 0.9873 - val_prc: 0.9464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0853 - tp: 19575.0000 - fp: 1461.0000 - tn: 146379.0000 - fn: 9993.0000 - accuracy: 0.9354 - precision: 0.9305 - recall: 0.6620 - auc: 0.9801 - prc: 0.9191\n",
      "Epoch 34: val_loss did not improve from 0.06835\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0853 - tp: 19594.0000 - fp: 1463.0000 - tn: 146537.0000 - fn: 10006.0000 - accuracy: 0.9354 - precision: 0.9305 - recall: 0.6620 - auc: 0.9801 - prc: 0.9191 - val_loss: 0.0703 - val_tp: 2630.0000 - val_fp: 139.0000 - val_tn: 18361.0000 - val_fn: 1070.0000 - val_accuracy: 0.9455 - val_precision: 0.9498 - val_recall: 0.7108 - val_auc: 0.9866 - val_prc: 0.9447\n",
      "Epoch 35/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0849 - tp: 19533.0000 - fp: 1473.0000 - tn: 145887.0000 - fn: 9939.0000 - accuracy: 0.9355 - precision: 0.9299 - recall: 0.6628 - auc: 0.9802 - prc: 0.9198\n",
      "Epoch 35: val_loss did not improve from 0.06835\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0849 - tp: 19612.0000 - fp: 1475.0000 - tn: 146525.0000 - fn: 9988.0000 - accuracy: 0.9355 - precision: 0.9301 - recall: 0.6626 - auc: 0.9802 - prc: 0.9198 - val_loss: 0.0691 - val_tp: 2664.0000 - val_fp: 167.0000 - val_tn: 18333.0000 - val_fn: 1036.0000 - val_accuracy: 0.9458 - val_precision: 0.9410 - val_recall: 0.7200 - val_auc: 0.9873 - val_prc: 0.9458\n",
      "Epoch 36/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0856 - tp: 19538.0000 - fp: 1493.0000 - tn: 145867.0000 - fn: 9934.0000 - accuracy: 0.9354 - precision: 0.9290 - recall: 0.6629 - auc: 0.9800 - prc: 0.9188\n",
      "Epoch 36: val_loss improved from 0.06835 to 0.06717, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0856 - tp: 19624.0000 - fp: 1502.0000 - tn: 146498.0000 - fn: 9976.0000 - accuracy: 0.9354 - precision: 0.9289 - recall: 0.6630 - auc: 0.9800 - prc: 0.9188 - val_loss: 0.0672 - val_tp: 2609.0000 - val_fp: 127.0000 - val_tn: 18373.0000 - val_fn: 1091.0000 - val_accuracy: 0.9451 - val_precision: 0.9536 - val_recall: 0.7051 - val_auc: 0.9879 - val_prc: 0.9489\n",
      "Epoch 37/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0848 - tp: 19756.0000 - fp: 1491.0000 - tn: 146349.0000 - fn: 9812.0000 - accuracy: 0.9363 - precision: 0.9298 - recall: 0.6682 - auc: 0.9803 - prc: 0.9199\n",
      "Epoch 37: val_loss did not improve from 0.06717\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0848 - tp: 19774.0000 - fp: 1493.0000 - tn: 146507.0000 - fn: 9826.0000 - accuracy: 0.9363 - precision: 0.9298 - recall: 0.6680 - auc: 0.9803 - prc: 0.9199 - val_loss: 0.0683 - val_tp: 2610.0000 - val_fp: 135.0000 - val_tn: 18365.0000 - val_fn: 1090.0000 - val_accuracy: 0.9448 - val_precision: 0.9508 - val_recall: 0.7054 - val_auc: 0.9872 - val_prc: 0.9471\n",
      "Epoch 38/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0847 - tp: 19642.0000 - fp: 1470.0000 - tn: 145650.0000 - fn: 9782.0000 - accuracy: 0.9363 - precision: 0.9304 - recall: 0.6676 - auc: 0.9804 - prc: 0.9201\n",
      "Epoch 38: val_loss did not improve from 0.06717\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0847 - tp: 19759.0000 - fp: 1481.0000 - tn: 146519.0000 - fn: 9841.0000 - accuracy: 0.9363 - precision: 0.9303 - recall: 0.6675 - auc: 0.9804 - prc: 0.9200 - val_loss: 0.0690 - val_tp: 2611.0000 - val_fp: 133.0000 - val_tn: 18367.0000 - val_fn: 1089.0000 - val_accuracy: 0.9450 - val_precision: 0.9515 - val_recall: 0.7057 - val_auc: 0.9873 - val_prc: 0.9468\n",
      "Epoch 39/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0842 - tp: 19713.0000 - fp: 1482.0000 - tn: 146118.0000 - fn: 9807.0000 - accuracy: 0.9363 - precision: 0.9301 - recall: 0.6678 - auc: 0.9806 - prc: 0.9206\n",
      "Epoch 39: val_loss did not improve from 0.06717\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0842 - tp: 19772.0000 - fp: 1485.0000 - tn: 146515.0000 - fn: 9828.0000 - accuracy: 0.9363 - precision: 0.9301 - recall: 0.6680 - auc: 0.9806 - prc: 0.9207 - val_loss: 0.0679 - val_tp: 2643.0000 - val_fp: 137.0000 - val_tn: 18363.0000 - val_fn: 1057.0000 - val_accuracy: 0.9462 - val_precision: 0.9507 - val_recall: 0.7143 - val_auc: 0.9877 - val_prc: 0.9478\n",
      "Epoch 40/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0825 - tp: 20049.0000 - fp: 1465.0000 - tn: 146295.0000 - fn: 9503.0000 - accuracy: 0.9381 - precision: 0.9319 - recall: 0.6784 - auc: 0.9813 - prc: 0.9242\n",
      "Epoch 40: val_loss improved from 0.06717 to 0.06601, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 14s 7ms/step - loss: 0.0825 - tp: 20082.0000 - fp: 1466.0000 - tn: 146534.0000 - fn: 9518.0000 - accuracy: 0.9382 - precision: 0.9320 - recall: 0.6784 - auc: 0.9813 - prc: 0.9242 - val_loss: 0.0660 - val_tp: 2715.0000 - val_fp: 149.0000 - val_tn: 18351.0000 - val_fn: 985.0000 - val_accuracy: 0.9489 - val_precision: 0.9480 - val_recall: 0.7338 - val_auc: 0.9885 - val_prc: 0.9506\n",
      "Epoch 41/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0844 - tp: 19673.0000 - fp: 1427.0000 - tn: 145933.0000 - fn: 9799.0000 - accuracy: 0.9365 - precision: 0.9324 - recall: 0.6675 - auc: 0.9806 - prc: 0.9207\n",
      "Epoch 41: val_loss improved from 0.06601 to 0.06519, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0845 - tp: 19760.0000 - fp: 1433.0000 - tn: 146567.0000 - fn: 9840.0000 - accuracy: 0.9365 - precision: 0.9324 - recall: 0.6676 - auc: 0.9806 - prc: 0.9207 - val_loss: 0.0652 - val_tp: 2738.0000 - val_fp: 147.0000 - val_tn: 18353.0000 - val_fn: 962.0000 - val_accuracy: 0.9500 - val_precision: 0.9490 - val_recall: 0.7400 - val_auc: 0.9887 - val_prc: 0.9522\n",
      "Epoch 42/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0831 - tp: 19931.0000 - fp: 1507.0000 - tn: 146333.0000 - fn: 9637.0000 - accuracy: 0.9372 - precision: 0.9297 - recall: 0.6741 - auc: 0.9812 - prc: 0.9228\n",
      "Epoch 42: val_loss did not improve from 0.06519\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0831 - tp: 19953.0000 - fp: 1509.0000 - tn: 146491.0000 - fn: 9647.0000 - accuracy: 0.9372 - precision: 0.9297 - recall: 0.6741 - auc: 0.9812 - prc: 0.9228 - val_loss: 0.0654 - val_tp: 2634.0000 - val_fp: 113.0000 - val_tn: 18387.0000 - val_fn: 1066.0000 - val_accuracy: 0.9469 - val_precision: 0.9589 - val_recall: 0.7119 - val_auc: 0.9886 - val_prc: 0.9518\n",
      "Epoch 43/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0840 - tp: 19831.0000 - fp: 1447.0000 - tn: 146313.0000 - fn: 9721.0000 - accuracy: 0.9370 - precision: 0.9320 - recall: 0.6711 - auc: 0.9806 - prc: 0.9220\n",
      "Epoch 43: val_loss did not improve from 0.06519\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0841 - tp: 19863.0000 - fp: 1449.0000 - tn: 146551.0000 - fn: 9737.0000 - accuracy: 0.9370 - precision: 0.9320 - recall: 0.6710 - auc: 0.9806 - prc: 0.9219 - val_loss: 0.0655 - val_tp: 2640.0000 - val_fp: 111.0000 - val_tn: 18389.0000 - val_fn: 1060.0000 - val_accuracy: 0.9473 - val_precision: 0.9597 - val_recall: 0.7135 - val_auc: 0.9888 - val_prc: 0.9528\n",
      "Epoch 44/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0830 - tp: 19988.0000 - fp: 1429.0000 - tn: 146491.0000 - fn: 9596.0000 - accuracy: 0.9379 - precision: 0.9333 - recall: 0.6756 - auc: 0.9812 - prc: 0.9235\n",
      "Epoch 44: val_loss improved from 0.06519 to 0.06364, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0830 - tp: 20000.0000 - fp: 1430.0000 - tn: 146570.0000 - fn: 9600.0000 - accuracy: 0.9379 - precision: 0.9333 - recall: 0.6757 - auc: 0.9812 - prc: 0.9235 - val_loss: 0.0636 - val_tp: 2739.0000 - val_fp: 144.0000 - val_tn: 18356.0000 - val_fn: 961.0000 - val_accuracy: 0.9502 - val_precision: 0.9501 - val_recall: 0.7403 - val_auc: 0.9892 - val_prc: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0821 - tp: 20136.0000 - fp: 1485.0000 - tn: 145955.0000 - fn: 9352.0000 - accuracy: 0.9387 - precision: 0.9313 - recall: 0.6829 - auc: 0.9817 - prc: 0.9248\n",
      "Epoch 45: val_loss did not improve from 0.06364\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0820 - tp: 20222.0000 - fp: 1488.0000 - tn: 146512.0000 - fn: 9378.0000 - accuracy: 0.9388 - precision: 0.9315 - recall: 0.6832 - auc: 0.9817 - prc: 0.9250 - val_loss: 0.0640 - val_tp: 2714.0000 - val_fp: 133.0000 - val_tn: 18367.0000 - val_fn: 986.0000 - val_accuracy: 0.9496 - val_precision: 0.9533 - val_recall: 0.7335 - val_auc: 0.9891 - val_prc: 0.9537\n",
      "Epoch 46/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0827 - tp: 19955.0000 - fp: 1429.0000 - tn: 145931.0000 - fn: 9517.0000 - accuracy: 0.9381 - precision: 0.9332 - recall: 0.6771 - auc: 0.9814 - prc: 0.9241\n",
      "Epoch 46: val_loss did not improve from 0.06364\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0827 - tp: 20043.0000 - fp: 1435.0000 - tn: 146565.0000 - fn: 9557.0000 - accuracy: 0.9381 - precision: 0.9332 - recall: 0.6771 - auc: 0.9814 - prc: 0.9241 - val_loss: 0.0639 - val_tp: 2648.0000 - val_fp: 103.0000 - val_tn: 18397.0000 - val_fn: 1052.0000 - val_accuracy: 0.9480 - val_precision: 0.9626 - val_recall: 0.7157 - val_auc: 0.9892 - val_prc: 0.9543\n",
      "Epoch 47/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0827 - tp: 20019.0000 - fp: 1442.0000 - tn: 146158.0000 - fn: 9501.0000 - accuracy: 0.9382 - precision: 0.9328 - recall: 0.6782 - auc: 0.9813 - prc: 0.9242\n",
      "Epoch 47: val_loss did not improve from 0.06364\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0828 - tp: 20071.0000 - fp: 1447.0000 - tn: 146553.0000 - fn: 9529.0000 - accuracy: 0.9382 - precision: 0.9328 - recall: 0.6781 - auc: 0.9813 - prc: 0.9242 - val_loss: 0.0642 - val_tp: 2588.0000 - val_fp: 93.0000 - val_tn: 18407.0000 - val_fn: 1112.0000 - val_accuracy: 0.9457 - val_precision: 0.9653 - val_recall: 0.6995 - val_auc: 0.9893 - val_prc: 0.9548\n",
      "Epoch 48/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0816 - tp: 20019.0000 - fp: 1406.0000 - tn: 146034.0000 - fn: 9469.0000 - accuracy: 0.9385 - precision: 0.9344 - recall: 0.6789 - auc: 0.9818 - prc: 0.9257\n",
      "Epoch 48: val_loss improved from 0.06364 to 0.06361, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0815 - tp: 20103.0000 - fp: 1411.0000 - tn: 146589.0000 - fn: 9497.0000 - accuracy: 0.9386 - precision: 0.9344 - recall: 0.6792 - auc: 0.9818 - prc: 0.9258 - val_loss: 0.0636 - val_tp: 2736.0000 - val_fp: 133.0000 - val_tn: 18367.0000 - val_fn: 964.0000 - val_accuracy: 0.9506 - val_precision: 0.9536 - val_recall: 0.7395 - val_auc: 0.9892 - val_prc: 0.9543\n",
      "Epoch 49/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0809 - tp: 20207.0000 - fp: 1444.0000 - tn: 145676.0000 - fn: 9217.0000 - accuracy: 0.9396 - precision: 0.9333 - recall: 0.6868 - auc: 0.9822 - prc: 0.9271\n",
      "Epoch 49: val_loss did not improve from 0.06361\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0809 - tp: 20329.0000 - fp: 1453.0000 - tn: 146547.0000 - fn: 9271.0000 - accuracy: 0.9396 - precision: 0.9333 - recall: 0.6868 - auc: 0.9822 - prc: 0.9271 - val_loss: 0.0638 - val_tp: 2721.0000 - val_fp: 127.0000 - val_tn: 18373.0000 - val_fn: 979.0000 - val_accuracy: 0.9502 - val_precision: 0.9554 - val_recall: 0.7354 - val_auc: 0.9891 - val_prc: 0.9539\n",
      "Epoch 50/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0810 - tp: 20245.0000 - fp: 1463.0000 - tn: 146057.0000 - fn: 9259.0000 - accuracy: 0.9394 - precision: 0.9326 - recall: 0.6862 - auc: 0.9823 - prc: 0.9272\n",
      "Epoch 50: val_loss improved from 0.06361 to 0.06331, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0809 - tp: 20314.0000 - fp: 1466.0000 - tn: 146534.0000 - fn: 9286.0000 - accuracy: 0.9395 - precision: 0.9327 - recall: 0.6863 - auc: 0.9823 - prc: 0.9273 - val_loss: 0.0633 - val_tp: 2746.0000 - val_fp: 134.0000 - val_tn: 18366.0000 - val_fn: 954.0000 - val_accuracy: 0.9510 - val_precision: 0.9535 - val_recall: 0.7422 - val_auc: 0.9893 - val_prc: 0.9544\n",
      "Epoch 51/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0810 - tp: 20270.0000 - fp: 1434.0000 - tn: 146486.0000 - fn: 9314.0000 - accuracy: 0.9394 - precision: 0.9339 - recall: 0.6852 - auc: 0.9822 - prc: 0.9270\n",
      "Epoch 51: val_loss improved from 0.06331 to 0.06266, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.0810 - tp: 20278.0000 - fp: 1434.0000 - tn: 146566.0000 - fn: 9322.0000 - accuracy: 0.9394 - precision: 0.9340 - recall: 0.6851 - auc: 0.9822 - prc: 0.9270 - val_loss: 0.0627 - val_tp: 2723.0000 - val_fp: 118.0000 - val_tn: 18382.0000 - val_fn: 977.0000 - val_accuracy: 0.9507 - val_precision: 0.9585 - val_recall: 0.7359 - val_auc: 0.9896 - val_prc: 0.9561\n",
      "Epoch 52/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0820 - tp: 20082.0000 - fp: 1424.0000 - tn: 146096.0000 - fn: 9422.0000 - accuracy: 0.9387 - precision: 0.9338 - recall: 0.6807 - auc: 0.9818 - prc: 0.9254\n",
      "Epoch 52: val_loss did not improve from 0.06266\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.0820 - tp: 20137.0000 - fp: 1429.0000 - tn: 146571.0000 - fn: 9463.0000 - accuracy: 0.9387 - precision: 0.9337 - recall: 0.6803 - auc: 0.9817 - prc: 0.9253 - val_loss: 0.0637 - val_tp: 2681.0000 - val_fp: 112.0000 - val_tn: 18388.0000 - val_fn: 1019.0000 - val_accuracy: 0.9491 - val_precision: 0.9599 - val_recall: 0.7246 - val_auc: 0.9893 - val_prc: 0.9548\n",
      "Epoch 53/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0803 - tp: 20276.0000 - fp: 1433.0000 - tn: 146487.0000 - fn: 9308.0000 - accuracy: 0.9395 - precision: 0.9340 - recall: 0.6854 - auc: 0.9824 - prc: 0.9278\n",
      "Epoch 53: val_loss improved from 0.06266 to 0.06248, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 7ms/step - loss: 0.0803 - tp: 20285.0000 - fp: 1434.0000 - tn: 146566.0000 - fn: 9315.0000 - accuracy: 0.9395 - precision: 0.9340 - recall: 0.6853 - auc: 0.9824 - prc: 0.9278 - val_loss: 0.0625 - val_tp: 2720.0000 - val_fp: 129.0000 - val_tn: 18371.0000 - val_fn: 980.0000 - val_accuracy: 0.9500 - val_precision: 0.9547 - val_recall: 0.7351 - val_auc: 0.9897 - val_prc: 0.9558\n",
      "Epoch 54/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0792 - tp: 20442.0000 - fp: 1456.0000 - tn: 146304.0000 - fn: 9110.0000 - accuracy: 0.9404 - precision: 0.9335 - recall: 0.6917 - auc: 0.9829 - prc: 0.9300\n",
      "Epoch 54: val_loss did not improve from 0.06248\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0792 - tp: 20471.0000 - fp: 1459.0000 - tn: 146541.0000 - fn: 9129.0000 - accuracy: 0.9404 - precision: 0.9335 - recall: 0.6916 - auc: 0.9829 - prc: 0.9300 - val_loss: 0.0638 - val_tp: 2823.0000 - val_fp: 162.0000 - val_tn: 18338.0000 - val_fn: 877.0000 - val_accuracy: 0.9532 - val_precision: 0.9457 - val_recall: 0.7630 - val_auc: 0.9890 - val_prc: 0.9543\n",
      "Epoch 55/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0818 - tp: 20084.0000 - fp: 1466.0000 - tn: 146294.0000 - fn: 9468.0000 - accuracy: 0.9383 - precision: 0.9320 - recall: 0.6796 - auc: 0.9819 - prc: 0.9259\n",
      "Epoch 55: val_loss did not improve from 0.06248\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0818 - tp: 20116.0000 - fp: 1469.0000 - tn: 146531.0000 - fn: 9484.0000 - accuracy: 0.9383 - precision: 0.9319 - recall: 0.6796 - auc: 0.9819 - prc: 0.9259 - val_loss: 0.0627 - val_tp: 2749.0000 - val_fp: 132.0000 - val_tn: 18368.0000 - val_fn: 951.0000 - val_accuracy: 0.9512 - val_precision: 0.9542 - val_recall: 0.7430 - val_auc: 0.9896 - val_prc: 0.9558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0807 - tp: 20413.0000 - fp: 1444.0000 - tn: 146156.0000 - fn: 9107.0000 - accuracy: 0.9404 - precision: 0.9339 - recall: 0.6915 - auc: 0.9824 - prc: 0.9278\n",
      "Epoch 56: val_loss did not improve from 0.06248\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0807 - tp: 20465.0000 - fp: 1448.0000 - tn: 146552.0000 - fn: 9135.0000 - accuracy: 0.9404 - precision: 0.9339 - recall: 0.6914 - auc: 0.9824 - prc: 0.9278 - val_loss: 0.0642 - val_tp: 2678.0000 - val_fp: 117.0000 - val_tn: 18383.0000 - val_fn: 1022.0000 - val_accuracy: 0.9487 - val_precision: 0.9581 - val_recall: 0.7238 - val_auc: 0.9892 - val_prc: 0.9541\n",
      "Epoch 57/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0809 - tp: 20255.0000 - fp: 1419.0000 - tn: 146101.0000 - fn: 9249.0000 - accuracy: 0.9397 - precision: 0.9345 - recall: 0.6865 - auc: 0.9822 - prc: 0.9272\n",
      "Epoch 57: val_loss improved from 0.06248 to 0.06068, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0809 - tp: 20318.0000 - fp: 1424.0000 - tn: 146576.0000 - fn: 9282.0000 - accuracy: 0.9397 - precision: 0.9345 - recall: 0.6864 - auc: 0.9822 - prc: 0.9272 - val_loss: 0.0607 - val_tp: 2761.0000 - val_fp: 107.0000 - val_tn: 18393.0000 - val_fn: 939.0000 - val_accuracy: 0.9529 - val_precision: 0.9627 - val_recall: 0.7462 - val_auc: 0.9904 - val_prc: 0.9592\n",
      "Epoch 58/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0794 - tp: 20377.0000 - fp: 1426.0000 - tn: 145694.0000 - fn: 9047.0000 - accuracy: 0.9407 - precision: 0.9346 - recall: 0.6925 - auc: 0.9828 - prc: 0.9297\n",
      "Epoch 58: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0793 - tp: 20507.0000 - fp: 1436.0000 - tn: 146564.0000 - fn: 9093.0000 - accuracy: 0.9407 - precision: 0.9346 - recall: 0.6928 - auc: 0.9828 - prc: 0.9297 - val_loss: 0.0623 - val_tp: 2745.0000 - val_fp: 136.0000 - val_tn: 18364.0000 - val_fn: 955.0000 - val_accuracy: 0.9509 - val_precision: 0.9528 - val_recall: 0.7419 - val_auc: 0.9896 - val_prc: 0.9567\n",
      "Epoch 59/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0793 - tp: 20478.0000 - fp: 1463.0000 - tn: 145977.0000 - fn: 9010.0000 - accuracy: 0.9408 - precision: 0.9333 - recall: 0.6945 - auc: 0.9829 - prc: 0.9305\n",
      "Epoch 59: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0794 - tp: 20552.0000 - fp: 1470.0000 - tn: 146530.0000 - fn: 9048.0000 - accuracy: 0.9408 - precision: 0.9332 - recall: 0.6943 - auc: 0.9829 - prc: 0.9303 - val_loss: 0.0629 - val_tp: 2756.0000 - val_fp: 135.0000 - val_tn: 18365.0000 - val_fn: 944.0000 - val_accuracy: 0.9514 - val_precision: 0.9533 - val_recall: 0.7449 - val_auc: 0.9895 - val_prc: 0.9553\n",
      "Epoch 60/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0788 - tp: 20519.0000 - fp: 1445.0000 - tn: 145995.0000 - fn: 8969.0000 - accuracy: 0.9411 - precision: 0.9342 - recall: 0.6958 - auc: 0.9832 - prc: 0.9309\n",
      "Epoch 60: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0788 - tp: 20599.0000 - fp: 1449.0000 - tn: 146551.0000 - fn: 9001.0000 - accuracy: 0.9412 - precision: 0.9343 - recall: 0.6959 - auc: 0.9832 - prc: 0.9309 - val_loss: 0.0615 - val_tp: 2851.0000 - val_fp: 163.0000 - val_tn: 18337.0000 - val_fn: 849.0000 - val_accuracy: 0.9544 - val_precision: 0.9459 - val_recall: 0.7705 - val_auc: 0.9900 - val_prc: 0.9574\n",
      "Epoch 61/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0796 - tp: 20404.0000 - fp: 1414.0000 - tn: 145706.0000 - fn: 9020.0000 - accuracy: 0.9409 - precision: 0.9352 - recall: 0.6934 - auc: 0.9829 - prc: 0.9300\n",
      "Epoch 61: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0797 - tp: 20511.0000 - fp: 1430.0000 - tn: 146570.0000 - fn: 9089.0000 - accuracy: 0.9408 - precision: 0.9348 - recall: 0.6929 - auc: 0.9828 - prc: 0.9297 - val_loss: 0.0609 - val_tp: 2749.0000 - val_fp: 124.0000 - val_tn: 18376.0000 - val_fn: 951.0000 - val_accuracy: 0.9516 - val_precision: 0.9568 - val_recall: 0.7430 - val_auc: 0.9903 - val_prc: 0.9585\n",
      "Epoch 62/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0785 - tp: 20603.0000 - fp: 1395.0000 - tn: 146365.0000 - fn: 8949.0000 - accuracy: 0.9417 - precision: 0.9366 - recall: 0.6972 - auc: 0.9833 - prc: 0.9316\n",
      "Epoch 62: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0785 - tp: 20637.0000 - fp: 1399.0000 - tn: 146601.0000 - fn: 8963.0000 - accuracy: 0.9417 - precision: 0.9365 - recall: 0.6972 - auc: 0.9833 - prc: 0.9316 - val_loss: 0.0618 - val_tp: 2794.0000 - val_fp: 149.0000 - val_tn: 18351.0000 - val_fn: 906.0000 - val_accuracy: 0.9525 - val_precision: 0.9494 - val_recall: 0.7551 - val_auc: 0.9898 - val_prc: 0.9567\n",
      "Epoch 63/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0792 - tp: 20444.0000 - fp: 1416.0000 - tn: 146184.0000 - fn: 9076.0000 - accuracy: 0.9408 - precision: 0.9352 - recall: 0.6925 - auc: 0.9831 - prc: 0.9304\n",
      "Epoch 63: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0792 - tp: 20497.0000 - fp: 1419.0000 - tn: 146581.0000 - fn: 9103.0000 - accuracy: 0.9408 - precision: 0.9353 - recall: 0.6925 - auc: 0.9831 - prc: 0.9304 - val_loss: 0.0619 - val_tp: 2691.0000 - val_fp: 98.0000 - val_tn: 18402.0000 - val_fn: 1009.0000 - val_accuracy: 0.9501 - val_precision: 0.9649 - val_recall: 0.7273 - val_auc: 0.9901 - val_prc: 0.9576\n",
      "Epoch 64/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0789 - tp: 20486.0000 - fp: 1419.0000 - tn: 146021.0000 - fn: 9002.0000 - accuracy: 0.9411 - precision: 0.9352 - recall: 0.6947 - auc: 0.9831 - prc: 0.9310\n",
      "Epoch 64: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0789 - tp: 20554.0000 - fp: 1426.0000 - tn: 146574.0000 - fn: 9046.0000 - accuracy: 0.9410 - precision: 0.9351 - recall: 0.6944 - auc: 0.9830 - prc: 0.9309 - val_loss: 0.0613 - val_tp: 2675.0000 - val_fp: 118.0000 - val_tn: 18382.0000 - val_fn: 1025.0000 - val_accuracy: 0.9485 - val_precision: 0.9578 - val_recall: 0.7230 - val_auc: 0.9903 - val_prc: 0.9580\n",
      "Epoch 65/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0783 - tp: 20611.0000 - fp: 1415.0000 - tn: 145785.0000 - fn: 8829.0000 - accuracy: 0.9420 - precision: 0.9358 - recall: 0.7001 - auc: 0.9834 - prc: 0.9323\n",
      "Epoch 65: val_loss did not improve from 0.06068\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0782 - tp: 20720.0000 - fp: 1420.0000 - tn: 146580.0000 - fn: 8880.0000 - accuracy: 0.9420 - precision: 0.9359 - recall: 0.7000 - auc: 0.9834 - prc: 0.9323 - val_loss: 0.0616 - val_tp: 2722.0000 - val_fp: 133.0000 - val_tn: 18367.0000 - val_fn: 978.0000 - val_accuracy: 0.9500 - val_precision: 0.9534 - val_recall: 0.7357 - val_auc: 0.9899 - val_prc: 0.9570\n",
      "Epoch 66/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0783 - tp: 20611.0000 - fp: 1372.0000 - tn: 146228.0000 - fn: 8909.0000 - accuracy: 0.9420 - precision: 0.9376 - recall: 0.6982 - auc: 0.9835 - prc: 0.9323\n",
      "Epoch 66: val_loss improved from 0.06068 to 0.05964, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0783 - tp: 20668.0000 - fp: 1377.0000 - tn: 146623.0000 - fn: 8932.0000 - accuracy: 0.9420 - precision: 0.9375 - recall: 0.6982 - auc: 0.9835 - prc: 0.9323 - val_loss: 0.0596 - val_tp: 2797.0000 - val_fp: 120.0000 - val_tn: 18380.0000 - val_fn: 903.0000 - val_accuracy: 0.9539 - val_precision: 0.9589 - val_recall: 0.7559 - val_auc: 0.9906 - val_prc: 0.9603\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0786 - tp: 20595.0000 - fp: 1387.0000 - tn: 146053.0000 - fn: 8893.0000 - accuracy: 0.9419 - precision: 0.9369 - recall: 0.6984 - auc: 0.9833 - prc: 0.9316\n",
      "Epoch 67: val_loss did not improve from 0.05964\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0785 - tp: 20675.0000 - fp: 1391.0000 - tn: 146609.0000 - fn: 8925.0000 - accuracy: 0.9419 - precision: 0.9370 - recall: 0.6985 - auc: 0.9833 - prc: 0.9316 - val_loss: 0.0624 - val_tp: 2706.0000 - val_fp: 118.0000 - val_tn: 18382.0000 - val_fn: 994.0000 - val_accuracy: 0.9499 - val_precision: 0.9582 - val_recall: 0.7314 - val_auc: 0.9899 - val_prc: 0.9567\n",
      "Epoch 68/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0786 - tp: 20526.0000 - fp: 1374.0000 - tn: 145906.0000 - fn: 8930.0000 - accuracy: 0.9417 - precision: 0.9373 - recall: 0.6968 - auc: 0.9833 - prc: 0.9314\n",
      "Epoch 68: val_loss did not improve from 0.05964\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0786 - tp: 20628.0000 - fp: 1381.0000 - tn: 146619.0000 - fn: 8972.0000 - accuracy: 0.9417 - precision: 0.9373 - recall: 0.6969 - auc: 0.9833 - prc: 0.9314 - val_loss: 0.0624 - val_tp: 2706.0000 - val_fp: 107.0000 - val_tn: 18393.0000 - val_fn: 994.0000 - val_accuracy: 0.9504 - val_precision: 0.9620 - val_recall: 0.7314 - val_auc: 0.9899 - val_prc: 0.9571\n",
      "Epoch 69/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0794 - tp: 20474.0000 - fp: 1405.0000 - tn: 145875.0000 - fn: 8982.0000 - accuracy: 0.9412 - precision: 0.9358 - recall: 0.6951 - auc: 0.9830 - prc: 0.9302\n",
      "Epoch 69: val_loss improved from 0.05964 to 0.05813, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 13s 7ms/step - loss: 0.0794 - tp: 20576.0000 - fp: 1411.0000 - tn: 146589.0000 - fn: 9024.0000 - accuracy: 0.9412 - precision: 0.9358 - recall: 0.6951 - auc: 0.9830 - prc: 0.9303 - val_loss: 0.0581 - val_tp: 2811.0000 - val_fp: 113.0000 - val_tn: 18387.0000 - val_fn: 889.0000 - val_accuracy: 0.9549 - val_precision: 0.9614 - val_recall: 0.7597 - val_auc: 0.9912 - val_prc: 0.9626\n",
      "Epoch 70/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0773 - tp: 20718.0000 - fp: 1374.0000 - tn: 146146.0000 - fn: 8786.0000 - accuracy: 0.9426 - precision: 0.9378 - recall: 0.7022 - auc: 0.9839 - prc: 0.9335\n",
      "Epoch 70: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0774 - tp: 20772.0000 - fp: 1378.0000 - tn: 146622.0000 - fn: 8828.0000 - accuracy: 0.9425 - precision: 0.9378 - recall: 0.7018 - auc: 0.9838 - prc: 0.9333 - val_loss: 0.0583 - val_tp: 2834.0000 - val_fp: 132.0000 - val_tn: 18368.0000 - val_fn: 866.0000 - val_accuracy: 0.9550 - val_precision: 0.9555 - val_recall: 0.7659 - val_auc: 0.9910 - val_prc: 0.9618\n",
      "Epoch 71/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0778 - tp: 20727.0000 - fp: 1380.0000 - tn: 146140.0000 - fn: 8777.0000 - accuracy: 0.9426 - precision: 0.9376 - recall: 0.7025 - auc: 0.9836 - prc: 0.9330\n",
      "Epoch 71: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0779 - tp: 20796.0000 - fp: 1387.0000 - tn: 146613.0000 - fn: 8804.0000 - accuracy: 0.9426 - precision: 0.9375 - recall: 0.7026 - auc: 0.9836 - prc: 0.9329 - val_loss: 0.0583 - val_tp: 2822.0000 - val_fp: 128.0000 - val_tn: 18372.0000 - val_fn: 878.0000 - val_accuracy: 0.9547 - val_precision: 0.9566 - val_recall: 0.7627 - val_auc: 0.9912 - val_prc: 0.9616\n",
      "Epoch 72/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0778 - tp: 20654.0000 - fp: 1347.0000 - tn: 145773.0000 - fn: 8770.0000 - accuracy: 0.9427 - precision: 0.9388 - recall: 0.7019 - auc: 0.9836 - prc: 0.9332\n",
      "Epoch 72: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0778 - tp: 20781.0000 - fp: 1352.0000 - tn: 146648.0000 - fn: 8819.0000 - accuracy: 0.9427 - precision: 0.9389 - recall: 0.7021 - auc: 0.9836 - prc: 0.9333 - val_loss: 0.0599 - val_tp: 2765.0000 - val_fp: 123.0000 - val_tn: 18377.0000 - val_fn: 935.0000 - val_accuracy: 0.9523 - val_precision: 0.9574 - val_recall: 0.7473 - val_auc: 0.9907 - val_prc: 0.9601\n",
      "Epoch 73/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0786 - tp: 20745.0000 - fp: 1408.0000 - tn: 146272.0000 - fn: 8791.0000 - accuracy: 0.9424 - precision: 0.9364 - recall: 0.7024 - auc: 0.9834 - prc: 0.9325\n",
      "Epoch 73: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0785 - tp: 20785.0000 - fp: 1409.0000 - tn: 146591.0000 - fn: 8815.0000 - accuracy: 0.9424 - precision: 0.9365 - recall: 0.7022 - auc: 0.9834 - prc: 0.9325 - val_loss: 0.0594 - val_tp: 2754.0000 - val_fp: 119.0000 - val_tn: 18381.0000 - val_fn: 946.0000 - val_accuracy: 0.9520 - val_precision: 0.9586 - val_recall: 0.7443 - val_auc: 0.9907 - val_prc: 0.9600\n",
      "Epoch 74/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0785 - tp: 20604.0000 - fp: 1382.0000 - tn: 146378.0000 - fn: 8948.0000 - accuracy: 0.9417 - precision: 0.9371 - recall: 0.6972 - auc: 0.9833 - prc: 0.9319\n",
      "Epoch 74: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0784 - tp: 20636.0000 - fp: 1383.0000 - tn: 146617.0000 - fn: 8964.0000 - accuracy: 0.9417 - precision: 0.9372 - recall: 0.6972 - auc: 0.9833 - prc: 0.9320 - val_loss: 0.0615 - val_tp: 2749.0000 - val_fp: 95.0000 - val_tn: 18405.0000 - val_fn: 951.0000 - val_accuracy: 0.9529 - val_precision: 0.9666 - val_recall: 0.7430 - val_auc: 0.9900 - val_prc: 0.9588\n",
      "Epoch 75/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0769 - tp: 20718.0000 - fp: 1351.0000 - tn: 145769.0000 - fn: 8706.0000 - accuracy: 0.9430 - precision: 0.9388 - recall: 0.7041 - auc: 0.9840 - prc: 0.9343\n",
      "Epoch 75: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0769 - tp: 20840.0000 - fp: 1361.0000 - tn: 146639.0000 - fn: 8760.0000 - accuracy: 0.9430 - precision: 0.9387 - recall: 0.7041 - auc: 0.9840 - prc: 0.9344 - val_loss: 0.0605 - val_tp: 2750.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 950.0000 - val_accuracy: 0.9523 - val_precision: 0.9622 - val_recall: 0.7432 - val_auc: 0.9905 - val_prc: 0.9593\n",
      "Epoch 76/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0772 - tp: 20858.0000 - fp: 1365.0000 - tn: 145835.0000 - fn: 8582.0000 - accuracy: 0.9437 - precision: 0.9386 - recall: 0.7085 - auc: 0.9839 - prc: 0.9347\n",
      "Epoch 76: val_loss did not improve from 0.05813\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0772 - tp: 20979.0000 - fp: 1375.0000 - tn: 146625.0000 - fn: 8621.0000 - accuracy: 0.9437 - precision: 0.9385 - recall: 0.7088 - auc: 0.9839 - prc: 0.9346 - val_loss: 0.0594 - val_tp: 2807.0000 - val_fp: 129.0000 - val_tn: 18371.0000 - val_fn: 893.0000 - val_accuracy: 0.9540 - val_precision: 0.9561 - val_recall: 0.7586 - val_auc: 0.9908 - val_prc: 0.9602\n",
      "Epoch 77/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0764 - tp: 20773.0000 - fp: 1389.0000 - tn: 145731.0000 - fn: 8651.0000 - accuracy: 0.9431 - precision: 0.9373 - recall: 0.7060 - auc: 0.9842 - prc: 0.9351\n",
      "Epoch 77: val_loss improved from 0.05813 to 0.05796, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 7ms/step - loss: 0.0764 - tp: 20887.0000 - fp: 1397.0000 - tn: 146603.0000 - fn: 8713.0000 - accuracy: 0.9431 - precision: 0.9373 - recall: 0.7056 - auc: 0.9842 - prc: 0.9351 - val_loss: 0.0580 - val_tp: 2745.0000 - val_fp: 105.0000 - val_tn: 18395.0000 - val_fn: 955.0000 - val_accuracy: 0.9523 - val_precision: 0.9632 - val_recall: 0.7419 - val_auc: 0.9913 - val_prc: 0.9627\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0777 - tp: 20772.0000 - fp: 1348.0000 - tn: 146172.0000 - fn: 8732.0000 - accuracy: 0.9431 - precision: 0.9391 - recall: 0.7040 - auc: 0.9838 - prc: 0.9333\n",
      "Epoch 78: val_loss did not improve from 0.05796\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0777 - tp: 20839.0000 - fp: 1351.0000 - tn: 146649.0000 - fn: 8761.0000 - accuracy: 0.9431 - precision: 0.9391 - recall: 0.7040 - auc: 0.9838 - prc: 0.9334 - val_loss: 0.0590 - val_tp: 2743.0000 - val_fp: 103.0000 - val_tn: 18397.0000 - val_fn: 957.0000 - val_accuracy: 0.9523 - val_precision: 0.9638 - val_recall: 0.7414 - val_auc: 0.9912 - val_prc: 0.9623\n",
      "Epoch 79/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0770 - tp: 20811.0000 - fp: 1421.0000 - tn: 146499.0000 - fn: 8773.0000 - accuracy: 0.9426 - precision: 0.9361 - recall: 0.7035 - auc: 0.9840 - prc: 0.9342\n",
      "Epoch 79: val_loss did not improve from 0.05796\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0769 - tp: 20825.0000 - fp: 1421.0000 - tn: 146579.0000 - fn: 8775.0000 - accuracy: 0.9426 - precision: 0.9361 - recall: 0.7035 - auc: 0.9840 - prc: 0.9342 - val_loss: 0.0601 - val_tp: 2727.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 973.0000 - val_accuracy: 0.9513 - val_precision: 0.9619 - val_recall: 0.7370 - val_auc: 0.9907 - val_prc: 0.9599\n",
      "Epoch 80/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0767 - tp: 20803.0000 - fp: 1391.0000 - tn: 146209.0000 - fn: 8717.0000 - accuracy: 0.9429 - precision: 0.9373 - recall: 0.7047 - auc: 0.9842 - prc: 0.9349\n",
      "Epoch 80: val_loss did not improve from 0.05796\n",
      "1850/1850 [==============================] - 7s 4ms/step - loss: 0.0767 - tp: 20856.0000 - fp: 1397.0000 - tn: 146603.0000 - fn: 8744.0000 - accuracy: 0.9429 - precision: 0.9372 - recall: 0.7046 - auc: 0.9842 - prc: 0.9349 - val_loss: 0.0582 - val_tp: 2810.0000 - val_fp: 114.0000 - val_tn: 18386.0000 - val_fn: 890.0000 - val_accuracy: 0.9548 - val_precision: 0.9610 - val_recall: 0.7595 - val_auc: 0.9914 - val_prc: 0.9627\n",
      "Epoch 81/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0763 - tp: 21002.0000 - fp: 1371.0000 - tn: 146629.0000 - fn: 8598.0000 - accuracy: 0.9439 - precision: 0.9387 - recall: 0.7095 - auc: 0.9844 - prc: 0.9358\n",
      "Epoch 81: val_loss did not improve from 0.05796\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0763 - tp: 21002.0000 - fp: 1371.0000 - tn: 146629.0000 - fn: 8598.0000 - accuracy: 0.9439 - precision: 0.9387 - recall: 0.7095 - auc: 0.9844 - prc: 0.9358 - val_loss: 0.0607 - val_tp: 2802.0000 - val_fp: 133.0000 - val_tn: 18367.0000 - val_fn: 898.0000 - val_accuracy: 0.9536 - val_precision: 0.9547 - val_recall: 0.7573 - val_auc: 0.9902 - val_prc: 0.9582\n",
      "Epoch 82/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0775 - tp: 20787.0000 - fp: 1381.0000 - tn: 146139.0000 - fn: 8717.0000 - accuracy: 0.9430 - precision: 0.9377 - recall: 0.7045 - auc: 0.9839 - prc: 0.9337\n",
      "Epoch 82: val_loss did not improve from 0.05796\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0776 - tp: 20854.0000 - fp: 1386.0000 - tn: 146614.0000 - fn: 8746.0000 - accuracy: 0.9430 - precision: 0.9377 - recall: 0.7045 - auc: 0.9838 - prc: 0.9336 - val_loss: 0.0587 - val_tp: 2733.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 967.0000 - val_accuracy: 0.9521 - val_precision: 0.9657 - val_recall: 0.7386 - val_auc: 0.9913 - val_prc: 0.9630\n",
      "Epoch 83/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0769 - tp: 20883.0000 - fp: 1399.0000 - tn: 146121.0000 - fn: 8621.0000 - accuracy: 0.9434 - precision: 0.9372 - recall: 0.7078 - auc: 0.9841 - prc: 0.9351\n",
      "Epoch 83: val_loss did not improve from 0.05796\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0769 - tp: 20949.0000 - fp: 1404.0000 - tn: 146596.0000 - fn: 8651.0000 - accuracy: 0.9434 - precision: 0.9372 - recall: 0.7077 - auc: 0.9841 - prc: 0.9351 - val_loss: 0.0592 - val_tp: 2767.0000 - val_fp: 110.0000 - val_tn: 18390.0000 - val_fn: 933.0000 - val_accuracy: 0.9530 - val_precision: 0.9618 - val_recall: 0.7478 - val_auc: 0.9911 - val_prc: 0.9614\n",
      "Epoch 84/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0770 - tp: 20912.0000 - fp: 1371.0000 - tn: 146549.0000 - fn: 8672.0000 - accuracy: 0.9434 - precision: 0.9385 - recall: 0.7069 - auc: 0.9840 - prc: 0.9350\n",
      "Epoch 84: val_loss improved from 0.05796 to 0.05638, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0770 - tp: 20924.0000 - fp: 1371.0000 - tn: 146629.0000 - fn: 8676.0000 - accuracy: 0.9434 - precision: 0.9385 - recall: 0.7069 - auc: 0.9840 - prc: 0.9350 - val_loss: 0.0564 - val_tp: 2899.0000 - val_fp: 124.0000 - val_tn: 18376.0000 - val_fn: 801.0000 - val_accuracy: 0.9583 - val_precision: 0.9590 - val_recall: 0.7835 - val_auc: 0.9916 - val_prc: 0.9642\n",
      "Epoch 85/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0768 - tp: 20840.0000 - fp: 1420.0000 - tn: 145860.0000 - fn: 8616.0000 - accuracy: 0.9432 - precision: 0.9362 - recall: 0.7075 - auc: 0.9841 - prc: 0.9345\n",
      "Epoch 85: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0767 - tp: 20946.0000 - fp: 1423.0000 - tn: 146577.0000 - fn: 8654.0000 - accuracy: 0.9433 - precision: 0.9364 - recall: 0.7076 - auc: 0.9841 - prc: 0.9346 - val_loss: 0.0591 - val_tp: 2822.0000 - val_fp: 127.0000 - val_tn: 18373.0000 - val_fn: 878.0000 - val_accuracy: 0.9547 - val_precision: 0.9569 - val_recall: 0.7627 - val_auc: 0.9907 - val_prc: 0.9604\n",
      "Epoch 86/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0760 - tp: 20902.0000 - fp: 1371.0000 - tn: 145909.0000 - fn: 8554.0000 - accuracy: 0.9438 - precision: 0.9384 - recall: 0.7096 - auc: 0.9844 - prc: 0.9359\n",
      "Epoch 86: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0760 - tp: 21005.0000 - fp: 1377.0000 - tn: 146623.0000 - fn: 8595.0000 - accuracy: 0.9438 - precision: 0.9385 - recall: 0.7096 - auc: 0.9844 - prc: 0.9359 - val_loss: 0.0589 - val_tp: 2773.0000 - val_fp: 120.0000 - val_tn: 18380.0000 - val_fn: 927.0000 - val_accuracy: 0.9528 - val_precision: 0.9585 - val_recall: 0.7495 - val_auc: 0.9910 - val_prc: 0.9610\n",
      "Epoch 87/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0764 - tp: 21023.0000 - fp: 1372.0000 - tn: 146308.0000 - fn: 8513.0000 - accuracy: 0.9442 - precision: 0.9387 - recall: 0.7118 - auc: 0.9844 - prc: 0.9357\n",
      "Epoch 87: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0764 - tp: 21064.0000 - fp: 1375.0000 - tn: 146625.0000 - fn: 8536.0000 - accuracy: 0.9442 - precision: 0.9387 - recall: 0.7116 - auc: 0.9843 - prc: 0.9357 - val_loss: 0.0575 - val_tp: 2782.0000 - val_fp: 89.0000 - val_tn: 18411.0000 - val_fn: 918.0000 - val_accuracy: 0.9546 - val_precision: 0.9690 - val_recall: 0.7519 - val_auc: 0.9916 - val_prc: 0.9641\n",
      "Epoch 88/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0765 - tp: 20891.0000 - fp: 1350.0000 - tn: 146250.0000 - fn: 8629.0000 - accuracy: 0.9437 - precision: 0.9393 - recall: 0.7077 - auc: 0.9843 - prc: 0.9353\n",
      "Epoch 88: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0765 - tp: 20944.0000 - fp: 1352.0000 - tn: 146648.0000 - fn: 8656.0000 - accuracy: 0.9436 - precision: 0.9394 - recall: 0.7076 - auc: 0.9843 - prc: 0.9353 - val_loss: 0.0579 - val_tp: 2844.0000 - val_fp: 110.0000 - val_tn: 18390.0000 - val_fn: 856.0000 - val_accuracy: 0.9565 - val_precision: 0.9628 - val_recall: 0.7686 - val_auc: 0.9914 - val_prc: 0.9630\n",
      "Epoch 89/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0749 - tp: 21203.0000 - fp: 1376.0000 - tn: 145824.0000 - fn: 8237.0000 - accuracy: 0.9456 - precision: 0.9391 - recall: 0.7202 - auc: 0.9850 - prc: 0.9383\n",
      "Epoch 89: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0750 - tp: 21310.0000 - fp: 1384.0000 - tn: 146616.0000 - fn: 8290.0000 - accuracy: 0.9455 - precision: 0.9390 - recall: 0.7199 - auc: 0.9850 - prc: 0.9382 - val_loss: 0.0576 - val_tp: 2820.0000 - val_fp: 109.0000 - val_tn: 18391.0000 - val_fn: 880.0000 - val_accuracy: 0.9555 - val_precision: 0.9628 - val_recall: 0.7622 - val_auc: 0.9913 - val_prc: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0769 - tp: 20967.0000 - fp: 1360.0000 - tn: 146160.0000 - fn: 8537.0000 - accuracy: 0.9441 - precision: 0.9391 - recall: 0.7106 - auc: 0.9842 - prc: 0.9351\n",
      "Epoch 90: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0768 - tp: 21031.0000 - fp: 1362.0000 - tn: 146638.0000 - fn: 8569.0000 - accuracy: 0.9441 - precision: 0.9392 - recall: 0.7105 - auc: 0.9843 - prc: 0.9352 - val_loss: 0.0582 - val_tp: 2766.0000 - val_fp: 107.0000 - val_tn: 18393.0000 - val_fn: 934.0000 - val_accuracy: 0.9531 - val_precision: 0.9628 - val_recall: 0.7476 - val_auc: 0.9914 - val_prc: 0.9634\n",
      "Epoch 91/200\n",
      "1833/1850 [============================>.] - ETA: 0s - loss: 0.0766 - tp: 20869.0000 - fp: 1355.0000 - tn: 145285.0000 - fn: 8459.0000 - accuracy: 0.9442 - precision: 0.9390 - recall: 0.7116 - auc: 0.9842 - prc: 0.9355\n",
      "Epoch 91: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0766 - tp: 21060.0000 - fp: 1366.0000 - tn: 146634.0000 - fn: 8540.0000 - accuracy: 0.9442 - precision: 0.9391 - recall: 0.7115 - auc: 0.9842 - prc: 0.9356 - val_loss: 0.0572 - val_tp: 2808.0000 - val_fp: 114.0000 - val_tn: 18386.0000 - val_fn: 892.0000 - val_accuracy: 0.9547 - val_precision: 0.9610 - val_recall: 0.7589 - val_auc: 0.9917 - val_prc: 0.9640\n",
      "Epoch 92/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0750 - tp: 21135.0000 - fp: 1357.0000 - tn: 146163.0000 - fn: 8369.0000 - accuracy: 0.9451 - precision: 0.9397 - recall: 0.7163 - auc: 0.9848 - prc: 0.9376\n",
      "Epoch 92: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0749 - tp: 21210.0000 - fp: 1361.0000 - tn: 146639.0000 - fn: 8390.0000 - accuracy: 0.9451 - precision: 0.9397 - recall: 0.7166 - auc: 0.9848 - prc: 0.9376 - val_loss: 0.0570 - val_tp: 2851.0000 - val_fp: 124.0000 - val_tn: 18376.0000 - val_fn: 849.0000 - val_accuracy: 0.9562 - val_precision: 0.9583 - val_recall: 0.7705 - val_auc: 0.9916 - val_prc: 0.9640\n",
      "Epoch 93/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0763 - tp: 21120.0000 - fp: 1367.0000 - tn: 146553.0000 - fn: 8464.0000 - accuracy: 0.9446 - precision: 0.9392 - recall: 0.7139 - auc: 0.9844 - prc: 0.9360\n",
      "Epoch 93: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0763 - tp: 21130.0000 - fp: 1368.0000 - tn: 146632.0000 - fn: 8470.0000 - accuracy: 0.9446 - precision: 0.9392 - recall: 0.7139 - auc: 0.9844 - prc: 0.9360 - val_loss: 0.0600 - val_tp: 2687.0000 - val_fp: 89.0000 - val_tn: 18411.0000 - val_fn: 1013.0000 - val_accuracy: 0.9504 - val_precision: 0.9679 - val_recall: 0.7262 - val_auc: 0.9909 - val_prc: 0.9622\n",
      "Epoch 94/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0746 - tp: 21079.0000 - fp: 1369.0000 - tn: 146311.0000 - fn: 8457.0000 - accuracy: 0.9446 - precision: 0.9390 - recall: 0.7137 - auc: 0.9849 - prc: 0.9382\n",
      "Epoch 94: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0746 - tp: 21125.0000 - fp: 1375.0000 - tn: 146625.0000 - fn: 8475.0000 - accuracy: 0.9445 - precision: 0.9389 - recall: 0.7137 - auc: 0.9849 - prc: 0.9382 - val_loss: 0.0568 - val_tp: 2807.0000 - val_fp: 107.0000 - val_tn: 18393.0000 - val_fn: 893.0000 - val_accuracy: 0.9550 - val_precision: 0.9633 - val_recall: 0.7586 - val_auc: 0.9915 - val_prc: 0.9641\n",
      "Epoch 95/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0750 - tp: 21093.0000 - fp: 1340.0000 - tn: 146180.0000 - fn: 8411.0000 - accuracy: 0.9449 - precision: 0.9403 - recall: 0.7149 - auc: 0.9848 - prc: 0.9381\n",
      "Epoch 95: val_loss did not improve from 0.05638\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0750 - tp: 21162.0000 - fp: 1344.0000 - tn: 146656.0000 - fn: 8438.0000 - accuracy: 0.9449 - precision: 0.9403 - recall: 0.7149 - auc: 0.9848 - prc: 0.9381 - val_loss: 0.0582 - val_tp: 2780.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 920.0000 - val_accuracy: 0.9542 - val_precision: 0.9663 - val_recall: 0.7514 - val_auc: 0.9914 - val_prc: 0.9632\n",
      "Epoch 96/200\n",
      "1834/1850 [============================>.] - ETA: 0s - loss: 0.0752 - tp: 21102.0000 - fp: 1303.0000 - tn: 145417.0000 - fn: 8242.0000 - accuracy: 0.9458 - precision: 0.9418 - recall: 0.7191 - auc: 0.9848 - prc: 0.9380\n",
      "Epoch 96: val_loss improved from 0.05638 to 0.05632, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.0753 - tp: 21277.0000 - fp: 1313.0000 - tn: 146687.0000 - fn: 8323.0000 - accuracy: 0.9457 - precision: 0.9419 - recall: 0.7188 - auc: 0.9848 - prc: 0.9380 - val_loss: 0.0563 - val_tp: 2764.0000 - val_fp: 86.0000 - val_tn: 18414.0000 - val_fn: 936.0000 - val_accuracy: 0.9540 - val_precision: 0.9698 - val_recall: 0.7470 - val_auc: 0.9921 - val_prc: 0.9660\n",
      "Epoch 97/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 21152.0000 - fp: 1374.0000 - tn: 146066.0000 - fn: 8336.0000 - accuracy: 0.9451 - precision: 0.9390 - recall: 0.7173 - auc: 0.9852 - prc: 0.9391\n",
      "Epoch 97: val_loss did not improve from 0.05632\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0742 - tp: 21230.0000 - fp: 1382.0000 - tn: 146618.0000 - fn: 8370.0000 - accuracy: 0.9451 - precision: 0.9389 - recall: 0.7172 - auc: 0.9851 - prc: 0.9390 - val_loss: 0.0576 - val_tp: 2828.0000 - val_fp: 117.0000 - val_tn: 18383.0000 - val_fn: 872.0000 - val_accuracy: 0.9555 - val_precision: 0.9603 - val_recall: 0.7643 - val_auc: 0.9913 - val_prc: 0.9631\n",
      "Epoch 98/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0764 - tp: 21061.0000 - fp: 1401.0000 - tn: 146199.0000 - fn: 8459.0000 - accuracy: 0.9443 - precision: 0.9376 - recall: 0.7134 - auc: 0.9843 - prc: 0.9359\n",
      "Epoch 98: val_loss did not improve from 0.05632\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0764 - tp: 21122.0000 - fp: 1408.0000 - tn: 146592.0000 - fn: 8478.0000 - accuracy: 0.9443 - precision: 0.9375 - recall: 0.7136 - auc: 0.9843 - prc: 0.9358 - val_loss: 0.0571 - val_tp: 2796.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 904.0000 - val_accuracy: 0.9544 - val_precision: 0.9628 - val_recall: 0.7557 - val_auc: 0.9917 - val_prc: 0.9645\n",
      "Epoch 99/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0748 - tp: 21078.0000 - fp: 1326.0000 - tn: 146194.0000 - fn: 8426.0000 - accuracy: 0.9449 - precision: 0.9408 - recall: 0.7144 - auc: 0.9850 - prc: 0.9383\n",
      "Epoch 99: val_loss did not improve from 0.05632\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0747 - tp: 21150.0000 - fp: 1331.0000 - tn: 146669.0000 - fn: 8450.0000 - accuracy: 0.9449 - precision: 0.9408 - recall: 0.7145 - auc: 0.9850 - prc: 0.9384 - val_loss: 0.0573 - val_tp: 2800.0000 - val_fp: 98.0000 - val_tn: 18402.0000 - val_fn: 900.0000 - val_accuracy: 0.9550 - val_precision: 0.9662 - val_recall: 0.7568 - val_auc: 0.9917 - val_prc: 0.9644\n",
      "Epoch 100/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0756 - tp: 21253.0000 - fp: 1408.0000 - tn: 146592.0000 - fn: 8347.0000 - accuracy: 0.9451 - precision: 0.9379 - recall: 0.7180 - auc: 0.9846 - prc: 0.9370\n",
      "Epoch 100: val_loss did not improve from 0.05632\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0756 - tp: 21253.0000 - fp: 1408.0000 - tn: 146592.0000 - fn: 8347.0000 - accuracy: 0.9451 - precision: 0.9379 - recall: 0.7180 - auc: 0.9846 - prc: 0.9370 - val_loss: 0.0581 - val_tp: 2849.0000 - val_fp: 132.0000 - val_tn: 18368.0000 - val_fn: 851.0000 - val_accuracy: 0.9557 - val_precision: 0.9557 - val_recall: 0.7700 - val_auc: 0.9912 - val_prc: 0.9622\n",
      "Epoch 101/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0756 - tp: 20950.0000 - fp: 1356.0000 - tn: 146164.0000 - fn: 8554.0000 - accuracy: 0.9440 - precision: 0.9392 - recall: 0.7101 - auc: 0.9847 - prc: 0.9369\n",
      "Epoch 101: val_loss did not improve from 0.05632\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0757 - tp: 21019.0000 - fp: 1360.0000 - tn: 146640.0000 - fn: 8581.0000 - accuracy: 0.9440 - precision: 0.9392 - recall: 0.7101 - auc: 0.9847 - prc: 0.9369 - val_loss: 0.0589 - val_tp: 2776.0000 - val_fp: 101.0000 - val_tn: 18399.0000 - val_fn: 924.0000 - val_accuracy: 0.9538 - val_precision: 0.9649 - val_recall: 0.7503 - val_auc: 0.9912 - val_prc: 0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0765 - tp: 21035.0000 - fp: 1384.0000 - tn: 146376.0000 - fn: 8517.0000 - accuracy: 0.9442 - precision: 0.9383 - recall: 0.7118 - auc: 0.9844 - prc: 0.9364\n",
      "Epoch 102: val_loss did not improve from 0.05632\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0765 - tp: 21071.0000 - fp: 1386.0000 - tn: 146614.0000 - fn: 8529.0000 - accuracy: 0.9442 - precision: 0.9383 - recall: 0.7119 - auc: 0.9844 - prc: 0.9364 - val_loss: 0.0602 - val_tp: 2746.0000 - val_fp: 95.0000 - val_tn: 18405.0000 - val_fn: 954.0000 - val_accuracy: 0.9527 - val_precision: 0.9666 - val_recall: 0.7422 - val_auc: 0.9907 - val_prc: 0.9609\n",
      "Epoch 103/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0745 - tp: 21167.0000 - fp: 1323.0000 - tn: 146277.0000 - fn: 8353.0000 - accuracy: 0.9454 - precision: 0.9412 - recall: 0.7170 - auc: 0.9849 - prc: 0.9386\n",
      "Epoch 103: val_loss improved from 0.05632 to 0.05598, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.0745 - tp: 21225.0000 - fp: 1327.0000 - tn: 146673.0000 - fn: 8375.0000 - accuracy: 0.9454 - precision: 0.9412 - recall: 0.7171 - auc: 0.9849 - prc: 0.9386 - val_loss: 0.0560 - val_tp: 2861.0000 - val_fp: 126.0000 - val_tn: 18374.0000 - val_fn: 839.0000 - val_accuracy: 0.9565 - val_precision: 0.9578 - val_recall: 0.7732 - val_auc: 0.9919 - val_prc: 0.9655\n",
      "Epoch 104/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0758 - tp: 21121.0000 - fp: 1363.0000 - tn: 146397.0000 - fn: 8431.0000 - accuracy: 0.9448 - precision: 0.9394 - recall: 0.7147 - auc: 0.9847 - prc: 0.9371\n",
      "Epoch 104: val_loss did not improve from 0.05598\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0758 - tp: 21154.0000 - fp: 1366.0000 - tn: 146634.0000 - fn: 8446.0000 - accuracy: 0.9448 - precision: 0.9393 - recall: 0.7147 - auc: 0.9847 - prc: 0.9371 - val_loss: 0.0568 - val_tp: 2806.0000 - val_fp: 111.0000 - val_tn: 18389.0000 - val_fn: 894.0000 - val_accuracy: 0.9547 - val_precision: 0.9619 - val_recall: 0.7584 - val_auc: 0.9917 - val_prc: 0.9646\n",
      "Epoch 105/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0748 - tp: 21342.0000 - fp: 1370.0000 - tn: 146630.0000 - fn: 8258.0000 - accuracy: 0.9458 - precision: 0.9397 - recall: 0.7210 - auc: 0.9851 - prc: 0.9388\n",
      "Epoch 105: val_loss did not improve from 0.05598\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0748 - tp: 21342.0000 - fp: 1370.0000 - tn: 146630.0000 - fn: 8258.0000 - accuracy: 0.9458 - precision: 0.9397 - recall: 0.7210 - auc: 0.9851 - prc: 0.9388 - val_loss: 0.0590 - val_tp: 2841.0000 - val_fp: 143.0000 - val_tn: 18357.0000 - val_fn: 859.0000 - val_accuracy: 0.9549 - val_precision: 0.9521 - val_recall: 0.7678 - val_auc: 0.9909 - val_prc: 0.9607\n",
      "Epoch 106/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 21249.0000 - fp: 1397.0000 - tn: 145963.0000 - fn: 8223.0000 - accuracy: 0.9456 - precision: 0.9383 - recall: 0.7210 - auc: 0.9853 - prc: 0.9392\n",
      "Epoch 106: val_loss did not improve from 0.05598\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0742 - tp: 21338.0000 - fp: 1405.0000 - tn: 146595.0000 - fn: 8262.0000 - accuracy: 0.9456 - precision: 0.9382 - recall: 0.7209 - auc: 0.9853 - prc: 0.9391 - val_loss: 0.0568 - val_tp: 2880.0000 - val_fp: 147.0000 - val_tn: 18353.0000 - val_fn: 820.0000 - val_accuracy: 0.9564 - val_precision: 0.9514 - val_recall: 0.7784 - val_auc: 0.9916 - val_prc: 0.9636\n",
      "Epoch 107/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0749 - tp: 21283.0000 - fp: 1371.0000 - tn: 145909.0000 - fn: 8173.0000 - accuracy: 0.9460 - precision: 0.9395 - recall: 0.7225 - auc: 0.9851 - prc: 0.9391\n",
      "Epoch 107: val_loss improved from 0.05598 to 0.05542, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0748 - tp: 21387.0000 - fp: 1377.0000 - tn: 146623.0000 - fn: 8213.0000 - accuracy: 0.9460 - precision: 0.9395 - recall: 0.7225 - auc: 0.9851 - prc: 0.9391 - val_loss: 0.0554 - val_tp: 2847.0000 - val_fp: 114.0000 - val_tn: 18386.0000 - val_fn: 853.0000 - val_accuracy: 0.9564 - val_precision: 0.9615 - val_recall: 0.7695 - val_auc: 0.9922 - val_prc: 0.9662\n",
      "Epoch 108/200\n",
      "1837/1850 [============================>.] - ETA: 0s - loss: 0.0753 - tp: 21057.0000 - fp: 1322.0000 - tn: 145638.0000 - fn: 8335.0000 - accuracy: 0.9452 - precision: 0.9409 - recall: 0.7164 - auc: 0.9850 - prc: 0.9380\n",
      "Epoch 108: val_loss improved from 0.05542 to 0.05533, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0753 - tp: 21207.0000 - fp: 1332.0000 - tn: 146668.0000 - fn: 8393.0000 - accuracy: 0.9452 - precision: 0.9409 - recall: 0.7165 - auc: 0.9850 - prc: 0.9380 - val_loss: 0.0553 - val_tp: 2900.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 800.0000 - val_accuracy: 0.9591 - val_precision: 0.9641 - val_recall: 0.7838 - val_auc: 0.9921 - val_prc: 0.9661\n",
      "Epoch 109/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0740 - tp: 21417.0000 - fp: 1384.0000 - tn: 146616.0000 - fn: 8183.0000 - accuracy: 0.9461 - precision: 0.9393 - recall: 0.7235 - auc: 0.9853 - prc: 0.9396\n",
      "Epoch 109: val_loss improved from 0.05533 to 0.05445, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0740 - tp: 21417.0000 - fp: 1384.0000 - tn: 146616.0000 - fn: 8183.0000 - accuracy: 0.9461 - precision: 0.9393 - recall: 0.7235 - auc: 0.9853 - prc: 0.9396 - val_loss: 0.0545 - val_tp: 2894.0000 - val_fp: 106.0000 - val_tn: 18394.0000 - val_fn: 806.0000 - val_accuracy: 0.9589 - val_precision: 0.9647 - val_recall: 0.7822 - val_auc: 0.9924 - val_prc: 0.9678\n",
      "Epoch 110/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 21226.0000 - fp: 1380.0000 - tn: 145660.0000 - fn: 8182.0000 - accuracy: 0.9458 - precision: 0.9390 - recall: 0.7218 - auc: 0.9852 - prc: 0.9396\n",
      "Epoch 110: val_loss did not improve from 0.05445\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0741 - tp: 21367.0000 - fp: 1386.0000 - tn: 146614.0000 - fn: 8233.0000 - accuracy: 0.9458 - precision: 0.9391 - recall: 0.7219 - auc: 0.9852 - prc: 0.9396 - val_loss: 0.0564 - val_tp: 2817.0000 - val_fp: 84.0000 - val_tn: 18416.0000 - val_fn: 883.0000 - val_accuracy: 0.9564 - val_precision: 0.9710 - val_recall: 0.7614 - val_auc: 0.9921 - val_prc: 0.9669\n",
      "Epoch 111/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0739 - tp: 21361.0000 - fp: 1340.0000 - tn: 146580.0000 - fn: 8223.0000 - accuracy: 0.9461 - precision: 0.9410 - recall: 0.7220 - auc: 0.9853 - prc: 0.9399\n",
      "Epoch 111: val_loss did not improve from 0.05445\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0739 - tp: 21375.0000 - fp: 1341.0000 - tn: 146659.0000 - fn: 8225.0000 - accuracy: 0.9461 - precision: 0.9410 - recall: 0.7221 - auc: 0.9854 - prc: 0.9399 - val_loss: 0.0554 - val_tp: 2857.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 843.0000 - val_accuracy: 0.9577 - val_precision: 0.9672 - val_recall: 0.7722 - val_auc: 0.9922 - val_prc: 0.9665\n",
      "Epoch 112/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0752 - tp: 21164.0000 - fp: 1347.0000 - tn: 145773.0000 - fn: 8260.0000 - accuracy: 0.9456 - precision: 0.9402 - recall: 0.7193 - auc: 0.9849 - prc: 0.9385\n",
      "Epoch 112: val_loss did not improve from 0.05445\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0752 - tp: 21291.0000 - fp: 1358.0000 - tn: 146642.0000 - fn: 8309.0000 - accuracy: 0.9456 - precision: 0.9400 - recall: 0.7193 - auc: 0.9849 - prc: 0.9384 - val_loss: 0.0575 - val_tp: 2826.0000 - val_fp: 115.0000 - val_tn: 18385.0000 - val_fn: 874.0000 - val_accuracy: 0.9555 - val_precision: 0.9609 - val_recall: 0.7638 - val_auc: 0.9915 - val_prc: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 21393.0000 - fp: 1347.0000 - tn: 146413.0000 - fn: 8159.0000 - accuracy: 0.9464 - precision: 0.9408 - recall: 0.7239 - auc: 0.9854 - prc: 0.9399\n",
      "Epoch 113: val_loss did not improve from 0.05445\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0740 - tp: 21433.0000 - fp: 1348.0000 - tn: 146652.0000 - fn: 8167.0000 - accuracy: 0.9464 - precision: 0.9408 - recall: 0.7241 - auc: 0.9854 - prc: 0.9400 - val_loss: 0.0560 - val_tp: 2857.0000 - val_fp: 117.0000 - val_tn: 18383.0000 - val_fn: 843.0000 - val_accuracy: 0.9568 - val_precision: 0.9607 - val_recall: 0.7722 - val_auc: 0.9918 - val_prc: 0.9648\n",
      "Epoch 114/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 21369.0000 - fp: 1318.0000 - tn: 146362.0000 - fn: 8167.0000 - accuracy: 0.9465 - precision: 0.9419 - recall: 0.7235 - auc: 0.9853 - prc: 0.9400\n",
      "Epoch 114: val_loss did not improve from 0.05445\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0741 - tp: 21412.0000 - fp: 1323.0000 - tn: 146677.0000 - fn: 8188.0000 - accuracy: 0.9464 - precision: 0.9418 - recall: 0.7234 - auc: 0.9853 - prc: 0.9400 - val_loss: 0.0548 - val_tp: 2857.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 843.0000 - val_accuracy: 0.9574 - val_precision: 0.9655 - val_recall: 0.7722 - val_auc: 0.9922 - val_prc: 0.9671\n",
      "Epoch 115/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0747 - tp: 21243.0000 - fp: 1359.0000 - tn: 146401.0000 - fn: 8309.0000 - accuracy: 0.9455 - precision: 0.9399 - recall: 0.7188 - auc: 0.9851 - prc: 0.9388\n",
      "Epoch 115: val_loss improved from 0.05445 to 0.05424, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0747 - tp: 21276.0000 - fp: 1361.0000 - tn: 146639.0000 - fn: 8324.0000 - accuracy: 0.9455 - precision: 0.9399 - recall: 0.7188 - auc: 0.9851 - prc: 0.9389 - val_loss: 0.0542 - val_tp: 2928.0000 - val_fp: 113.0000 - val_tn: 18387.0000 - val_fn: 772.0000 - val_accuracy: 0.9601 - val_precision: 0.9628 - val_recall: 0.7914 - val_auc: 0.9923 - val_prc: 0.9675\n",
      "Epoch 116/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0748 - tp: 21137.0000 - fp: 1369.0000 - tn: 145671.0000 - fn: 8271.0000 - accuracy: 0.9454 - precision: 0.9392 - recall: 0.7188 - auc: 0.9851 - prc: 0.9387\n",
      "Epoch 116: val_loss did not improve from 0.05424\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0747 - tp: 21277.0000 - fp: 1374.0000 - tn: 146626.0000 - fn: 8323.0000 - accuracy: 0.9454 - precision: 0.9393 - recall: 0.7188 - auc: 0.9851 - prc: 0.9388 - val_loss: 0.0557 - val_tp: 2921.0000 - val_fp: 127.0000 - val_tn: 18373.0000 - val_fn: 779.0000 - val_accuracy: 0.9592 - val_precision: 0.9583 - val_recall: 0.7895 - val_auc: 0.9920 - val_prc: 0.9657\n",
      "Epoch 117/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 21242.0000 - fp: 1318.0000 - tn: 146202.0000 - fn: 8262.0000 - accuracy: 0.9459 - precision: 0.9416 - recall: 0.7200 - auc: 0.9853 - prc: 0.9398\n",
      "Epoch 117: val_loss improved from 0.05424 to 0.05346, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 13s 7ms/step - loss: 0.0742 - tp: 21313.0000 - fp: 1325.0000 - tn: 146675.0000 - fn: 8287.0000 - accuracy: 0.9459 - precision: 0.9415 - recall: 0.7200 - auc: 0.9853 - prc: 0.9397 - val_loss: 0.0535 - val_tp: 2954.0000 - val_fp: 103.0000 - val_tn: 18397.0000 - val_fn: 746.0000 - val_accuracy: 0.9618 - val_precision: 0.9663 - val_recall: 0.7984 - val_auc: 0.9925 - val_prc: 0.9687\n",
      "Epoch 118/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0738 - tp: 21361.0000 - fp: 1343.0000 - tn: 145777.0000 - fn: 8063.0000 - accuracy: 0.9467 - precision: 0.9408 - recall: 0.7260 - auc: 0.9854 - prc: 0.9405\n",
      "Epoch 118: val_loss did not improve from 0.05346\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0738 - tp: 21483.0000 - fp: 1347.0000 - tn: 146653.0000 - fn: 8117.0000 - accuracy: 0.9467 - precision: 0.9410 - recall: 0.7258 - auc: 0.9854 - prc: 0.9405 - val_loss: 0.0541 - val_tp: 2853.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 847.0000 - val_accuracy: 0.9573 - val_precision: 0.9655 - val_recall: 0.7711 - val_auc: 0.9925 - val_prc: 0.9680\n",
      "Epoch 119/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 21345.0000 - fp: 1360.0000 - tn: 146320.0000 - fn: 8191.0000 - accuracy: 0.9461 - precision: 0.9401 - recall: 0.7227 - auc: 0.9852 - prc: 0.9397\n",
      "Epoch 119: val_loss did not improve from 0.05346\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0741 - tp: 21394.0000 - fp: 1361.0000 - tn: 146639.0000 - fn: 8206.0000 - accuracy: 0.9461 - precision: 0.9402 - recall: 0.7228 - auc: 0.9852 - prc: 0.9398 - val_loss: 0.0561 - val_tp: 2834.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 866.0000 - val_accuracy: 0.9566 - val_precision: 0.9669 - val_recall: 0.7659 - val_auc: 0.9920 - val_prc: 0.9655\n",
      "Epoch 120/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0731 - tp: 21384.0000 - fp: 1356.0000 - tn: 145844.0000 - fn: 8056.0000 - accuracy: 0.9467 - precision: 0.9404 - recall: 0.7264 - auc: 0.9856 - prc: 0.9412\n",
      "Epoch 120: val_loss improved from 0.05346 to 0.05280, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 7ms/step - loss: 0.0732 - tp: 21491.0000 - fp: 1367.0000 - tn: 146633.0000 - fn: 8109.0000 - accuracy: 0.9466 - precision: 0.9402 - recall: 0.7260 - auc: 0.9856 - prc: 0.9410 - val_loss: 0.0528 - val_tp: 2895.0000 - val_fp: 110.0000 - val_tn: 18390.0000 - val_fn: 805.0000 - val_accuracy: 0.9588 - val_precision: 0.9634 - val_recall: 0.7824 - val_auc: 0.9928 - val_prc: 0.9693\n",
      "Epoch 121/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0730 - tp: 21415.0000 - fp: 1327.0000 - tn: 145953.0000 - fn: 8041.0000 - accuracy: 0.9470 - precision: 0.9416 - recall: 0.7270 - auc: 0.9858 - prc: 0.9414\n",
      "Epoch 121: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0730 - tp: 21511.0000 - fp: 1332.0000 - tn: 146668.0000 - fn: 8089.0000 - accuracy: 0.9470 - precision: 0.9417 - recall: 0.7267 - auc: 0.9857 - prc: 0.9413 - val_loss: 0.0562 - val_tp: 2840.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 860.0000 - val_accuracy: 0.9567 - val_precision: 0.9653 - val_recall: 0.7676 - val_auc: 0.9920 - val_prc: 0.9655\n",
      "Epoch 122/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0738 - tp: 21370.0000 - fp: 1309.0000 - tn: 146531.0000 - fn: 8198.0000 - accuracy: 0.9464 - precision: 0.9423 - recall: 0.7227 - auc: 0.9854 - prc: 0.9402\n",
      "Epoch 122: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0738 - tp: 21396.0000 - fp: 1309.0000 - tn: 146691.0000 - fn: 8204.0000 - accuracy: 0.9464 - precision: 0.9423 - recall: 0.7228 - auc: 0.9854 - prc: 0.9403 - val_loss: 0.0530 - val_tp: 2938.0000 - val_fp: 125.0000 - val_tn: 18375.0000 - val_fn: 762.0000 - val_accuracy: 0.9600 - val_precision: 0.9592 - val_recall: 0.7941 - val_auc: 0.9926 - val_prc: 0.9688\n",
      "Epoch 123/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0726 - tp: 21515.0000 - fp: 1325.0000 - tn: 145795.0000 - fn: 7909.0000 - accuracy: 0.9477 - precision: 0.9420 - recall: 0.7312 - auc: 0.9859 - prc: 0.9422\n",
      "Epoch 123: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0727 - tp: 21634.0000 - fp: 1333.0000 - tn: 146667.0000 - fn: 7966.0000 - accuracy: 0.9476 - precision: 0.9420 - recall: 0.7309 - auc: 0.9859 - prc: 0.9421 - val_loss: 0.0557 - val_tp: 2881.0000 - val_fp: 113.0000 - val_tn: 18387.0000 - val_fn: 819.0000 - val_accuracy: 0.9580 - val_precision: 0.9623 - val_recall: 0.7786 - val_auc: 0.9920 - val_prc: 0.9661\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0724 - tp: 21533.0000 - fp: 1334.0000 - tn: 146266.0000 - fn: 7987.0000 - accuracy: 0.9474 - precision: 0.9417 - recall: 0.7294 - auc: 0.9858 - prc: 0.9423\n",
      "Epoch 124: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0725 - tp: 21587.0000 - fp: 1340.0000 - tn: 146660.0000 - fn: 8013.0000 - accuracy: 0.9473 - precision: 0.9416 - recall: 0.7293 - auc: 0.9858 - prc: 0.9422 - val_loss: 0.0540 - val_tp: 2907.0000 - val_fp: 126.0000 - val_tn: 18374.0000 - val_fn: 793.0000 - val_accuracy: 0.9586 - val_precision: 0.9585 - val_recall: 0.7857 - val_auc: 0.9925 - val_prc: 0.9677\n",
      "Epoch 125/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0726 - tp: 21580.0000 - fp: 1343.0000 - tn: 146417.0000 - fn: 7972.0000 - accuracy: 0.9475 - precision: 0.9414 - recall: 0.7302 - auc: 0.9858 - prc: 0.9419\n",
      "Epoch 125: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0726 - tp: 21610.0000 - fp: 1346.0000 - tn: 146654.0000 - fn: 7990.0000 - accuracy: 0.9474 - precision: 0.9414 - recall: 0.7301 - auc: 0.9858 - prc: 0.9419 - val_loss: 0.0552 - val_tp: 2877.0000 - val_fp: 127.0000 - val_tn: 18373.0000 - val_fn: 823.0000 - val_accuracy: 0.9572 - val_precision: 0.9577 - val_recall: 0.7776 - val_auc: 0.9922 - val_prc: 0.9661\n",
      "Epoch 126/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0734 - tp: 21401.0000 - fp: 1341.0000 - tn: 146259.0000 - fn: 8119.0000 - accuracy: 0.9466 - precision: 0.9410 - recall: 0.7250 - auc: 0.9855 - prc: 0.9408\n",
      "Epoch 126: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0735 - tp: 21458.0000 - fp: 1347.0000 - tn: 146653.0000 - fn: 8142.0000 - accuracy: 0.9466 - precision: 0.9409 - recall: 0.7249 - auc: 0.9855 - prc: 0.9407 - val_loss: 0.0548 - val_tp: 2878.0000 - val_fp: 116.0000 - val_tn: 18384.0000 - val_fn: 822.0000 - val_accuracy: 0.9577 - val_precision: 0.9613 - val_recall: 0.7778 - val_auc: 0.9923 - val_prc: 0.9670\n",
      "Epoch 127/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0740 - tp: 21383.0000 - fp: 1356.0000 - tn: 146004.0000 - fn: 8089.0000 - accuracy: 0.9466 - precision: 0.9404 - recall: 0.7255 - auc: 0.9854 - prc: 0.9403\n",
      "Epoch 127: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0740 - tp: 21477.0000 - fp: 1364.0000 - tn: 146636.0000 - fn: 8123.0000 - accuracy: 0.9466 - precision: 0.9403 - recall: 0.7256 - auc: 0.9854 - prc: 0.9404 - val_loss: 0.0568 - val_tp: 2851.0000 - val_fp: 117.0000 - val_tn: 18383.0000 - val_fn: 849.0000 - val_accuracy: 0.9565 - val_precision: 0.9606 - val_recall: 0.7705 - val_auc: 0.9916 - val_prc: 0.9641\n",
      "Epoch 128/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0726 - tp: 21543.0000 - fp: 1335.0000 - tn: 146665.0000 - fn: 8057.0000 - accuracy: 0.9471 - precision: 0.9416 - recall: 0.7278 - auc: 0.9858 - prc: 0.9419\n",
      "Epoch 128: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0726 - tp: 21543.0000 - fp: 1335.0000 - tn: 146665.0000 - fn: 8057.0000 - accuracy: 0.9471 - precision: 0.9416 - recall: 0.7278 - auc: 0.9858 - prc: 0.9419 - val_loss: 0.0531 - val_tp: 2894.0000 - val_fp: 114.0000 - val_tn: 18386.0000 - val_fn: 806.0000 - val_accuracy: 0.9586 - val_precision: 0.9621 - val_recall: 0.7822 - val_auc: 0.9927 - val_prc: 0.9689\n",
      "Epoch 129/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0723 - tp: 21545.0000 - fp: 1351.0000 - tn: 146409.0000 - fn: 8007.0000 - accuracy: 0.9472 - precision: 0.9410 - recall: 0.7291 - auc: 0.9859 - prc: 0.9422\n",
      "Epoch 129: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0723 - tp: 21575.0000 - fp: 1354.0000 - tn: 146646.0000 - fn: 8025.0000 - accuracy: 0.9472 - precision: 0.9409 - recall: 0.7289 - auc: 0.9859 - prc: 0.9422 - val_loss: 0.0535 - val_tp: 2912.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 788.0000 - val_accuracy: 0.9596 - val_precision: 0.9642 - val_recall: 0.7870 - val_auc: 0.9927 - val_prc: 0.9686\n",
      "Epoch 130/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0728 - tp: 21536.0000 - fp: 1333.0000 - tn: 146507.0000 - fn: 8032.0000 - accuracy: 0.9472 - precision: 0.9417 - recall: 0.7284 - auc: 0.9858 - prc: 0.9419\n",
      "Epoch 130: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0728 - tp: 21555.0000 - fp: 1335.0000 - tn: 146665.0000 - fn: 8045.0000 - accuracy: 0.9472 - precision: 0.9417 - recall: 0.7282 - auc: 0.9858 - prc: 0.9419 - val_loss: 0.0537 - val_tp: 2864.0000 - val_fp: 106.0000 - val_tn: 18394.0000 - val_fn: 836.0000 - val_accuracy: 0.9576 - val_precision: 0.9643 - val_recall: 0.7741 - val_auc: 0.9927 - val_prc: 0.9687\n",
      "Epoch 131/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0729 - tp: 21538.0000 - fp: 1342.0000 - tn: 146658.0000 - fn: 8062.0000 - accuracy: 0.9470 - precision: 0.9413 - recall: 0.7276 - auc: 0.9857 - prc: 0.9417\n",
      "Epoch 131: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.0729 - tp: 21538.0000 - fp: 1342.0000 - tn: 146658.0000 - fn: 8062.0000 - accuracy: 0.9470 - precision: 0.9413 - recall: 0.7276 - auc: 0.9857 - prc: 0.9417 - val_loss: 0.0544 - val_tp: 2893.0000 - val_fp: 105.0000 - val_tn: 18395.0000 - val_fn: 807.0000 - val_accuracy: 0.9589 - val_precision: 0.9650 - val_recall: 0.7819 - val_auc: 0.9925 - val_prc: 0.9674\n",
      "Epoch 132/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 21525.0000 - fp: 1355.0000 - tn: 146085.0000 - fn: 7963.0000 - accuracy: 0.9473 - precision: 0.9408 - recall: 0.7300 - auc: 0.9861 - prc: 0.9424\n",
      "Epoch 132: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0725 - tp: 21606.0000 - fp: 1361.0000 - tn: 146639.0000 - fn: 7994.0000 - accuracy: 0.9473 - precision: 0.9407 - recall: 0.7299 - auc: 0.9861 - prc: 0.9424 - val_loss: 0.0547 - val_tp: 2843.0000 - val_fp: 90.0000 - val_tn: 18410.0000 - val_fn: 857.0000 - val_accuracy: 0.9573 - val_precision: 0.9693 - val_recall: 0.7684 - val_auc: 0.9925 - val_prc: 0.9683\n",
      "Epoch 133/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0730 - tp: 21510.0000 - fp: 1330.0000 - tn: 146670.0000 - fn: 8090.0000 - accuracy: 0.9470 - precision: 0.9418 - recall: 0.7267 - auc: 0.9857 - prc: 0.9416\n",
      "Epoch 133: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0730 - tp: 21510.0000 - fp: 1330.0000 - tn: 146670.0000 - fn: 8090.0000 - accuracy: 0.9470 - precision: 0.9418 - recall: 0.7267 - auc: 0.9857 - prc: 0.9416 - val_loss: 0.0537 - val_tp: 2883.0000 - val_fp: 85.0000 - val_tn: 18415.0000 - val_fn: 817.0000 - val_accuracy: 0.9594 - val_precision: 0.9714 - val_recall: 0.7792 - val_auc: 0.9926 - val_prc: 0.9685\n",
      "Epoch 134/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0730 - tp: 21423.0000 - fp: 1370.0000 - tn: 146310.0000 - fn: 8113.0000 - accuracy: 0.9465 - precision: 0.9399 - recall: 0.7253 - auc: 0.9858 - prc: 0.9415\n",
      "Epoch 134: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0730 - tp: 21468.0000 - fp: 1373.0000 - tn: 146627.0000 - fn: 8132.0000 - accuracy: 0.9465 - precision: 0.9399 - recall: 0.7253 - auc: 0.9858 - prc: 0.9414 - val_loss: 0.0540 - val_tp: 2848.0000 - val_fp: 109.0000 - val_tn: 18391.0000 - val_fn: 852.0000 - val_accuracy: 0.9567 - val_precision: 0.9631 - val_recall: 0.7697 - val_auc: 0.9924 - val_prc: 0.9683\n",
      "Epoch 135/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 21263.0000 - fp: 1316.0000 - tn: 145884.0000 - fn: 8177.0000 - accuracy: 0.9463 - precision: 0.9417 - recall: 0.7222 - auc: 0.9854 - prc: 0.9404\n",
      "Epoch 135: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0741 - tp: 21376.0000 - fp: 1323.0000 - tn: 146677.0000 - fn: 8224.0000 - accuracy: 0.9462 - precision: 0.9417 - recall: 0.7222 - auc: 0.9855 - prc: 0.9405 - val_loss: 0.0556 - val_tp: 2876.0000 - val_fp: 120.0000 - val_tn: 18380.0000 - val_fn: 824.0000 - val_accuracy: 0.9575 - val_precision: 0.9599 - val_recall: 0.7773 - val_auc: 0.9920 - val_prc: 0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 21479.0000 - fp: 1349.0000 - tn: 145691.0000 - fn: 7929.0000 - accuracy: 0.9474 - precision: 0.9409 - recall: 0.7304 - auc: 0.9859 - prc: 0.9426\n",
      "Epoch 136: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0722 - tp: 21612.0000 - fp: 1358.0000 - tn: 146642.0000 - fn: 7988.0000 - accuracy: 0.9474 - precision: 0.9409 - recall: 0.7301 - auc: 0.9859 - prc: 0.9426 - val_loss: 0.0537 - val_tp: 2906.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 794.0000 - val_accuracy: 0.9594 - val_precision: 0.9642 - val_recall: 0.7854 - val_auc: 0.9926 - val_prc: 0.9685\n",
      "Epoch 137/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 21629.0000 - fp: 1311.0000 - tn: 146289.0000 - fn: 7891.0000 - accuracy: 0.9480 - precision: 0.9429 - recall: 0.7327 - auc: 0.9861 - prc: 0.9433\n",
      "Epoch 137: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0722 - tp: 21692.0000 - fp: 1318.0000 - tn: 146682.0000 - fn: 7908.0000 - accuracy: 0.9481 - precision: 0.9427 - recall: 0.7328 - auc: 0.9861 - prc: 0.9433 - val_loss: 0.0530 - val_tp: 2945.0000 - val_fp: 115.0000 - val_tn: 18385.0000 - val_fn: 755.0000 - val_accuracy: 0.9608 - val_precision: 0.9624 - val_recall: 0.7959 - val_auc: 0.9928 - val_prc: 0.9693\n",
      "Epoch 138/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 21660.0000 - fp: 1292.0000 - tn: 146628.0000 - fn: 7924.0000 - accuracy: 0.9481 - precision: 0.9437 - recall: 0.7322 - auc: 0.9861 - prc: 0.9434\n",
      "Epoch 138: val_loss did not improve from 0.05280\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0719 - tp: 21671.0000 - fp: 1293.0000 - tn: 146707.0000 - fn: 7929.0000 - accuracy: 0.9481 - precision: 0.9437 - recall: 0.7321 - auc: 0.9861 - prc: 0.9434 - val_loss: 0.0535 - val_tp: 2881.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 819.0000 - val_accuracy: 0.9582 - val_precision: 0.9639 - val_recall: 0.7786 - val_auc: 0.9928 - val_prc: 0.9692\n",
      "Epoch 139/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 21530.0000 - fp: 1306.0000 - tn: 146214.0000 - fn: 7974.0000 - accuracy: 0.9476 - precision: 0.9428 - recall: 0.7297 - auc: 0.9862 - prc: 0.9430\n",
      "Epoch 139: val_loss improved from 0.05280 to 0.05225, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0719 - tp: 21600.0000 - fp: 1308.0000 - tn: 146692.0000 - fn: 8000.0000 - accuracy: 0.9476 - precision: 0.9429 - recall: 0.7297 - auc: 0.9862 - prc: 0.9430 - val_loss: 0.0523 - val_tp: 2953.0000 - val_fp: 112.0000 - val_tn: 18388.0000 - val_fn: 747.0000 - val_accuracy: 0.9613 - val_precision: 0.9635 - val_recall: 0.7981 - val_auc: 0.9929 - val_prc: 0.9699\n",
      "Epoch 140/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 21532.0000 - fp: 1288.0000 - tn: 145992.0000 - fn: 7924.0000 - accuracy: 0.9479 - precision: 0.9436 - recall: 0.7310 - auc: 0.9862 - prc: 0.9437\n",
      "Epoch 140: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0719 - tp: 21632.0000 - fp: 1292.0000 - tn: 146708.0000 - fn: 7968.0000 - accuracy: 0.9479 - precision: 0.9436 - recall: 0.7308 - auc: 0.9862 - prc: 0.9437 - val_loss: 0.0537 - val_tp: 2901.0000 - val_fp: 98.0000 - val_tn: 18402.0000 - val_fn: 799.0000 - val_accuracy: 0.9596 - val_precision: 0.9673 - val_recall: 0.7841 - val_auc: 0.9926 - val_prc: 0.9687\n",
      "Epoch 141/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0729 - tp: 21510.0000 - fp: 1350.0000 - tn: 146010.0000 - fn: 7962.0000 - accuracy: 0.9473 - precision: 0.9409 - recall: 0.7298 - auc: 0.9859 - prc: 0.9423\n",
      "Epoch 141: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0729 - tp: 21611.0000 - fp: 1355.0000 - tn: 146645.0000 - fn: 7989.0000 - accuracy: 0.9474 - precision: 0.9410 - recall: 0.7301 - auc: 0.9860 - prc: 0.9423 - val_loss: 0.0538 - val_tp: 2937.0000 - val_fp: 111.0000 - val_tn: 18389.0000 - val_fn: 763.0000 - val_accuracy: 0.9606 - val_precision: 0.9636 - val_recall: 0.7938 - val_auc: 0.9925 - val_prc: 0.9684\n",
      "Epoch 142/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0720 - tp: 21582.0000 - fp: 1329.0000 - tn: 146351.0000 - fn: 7954.0000 - accuracy: 0.9476 - precision: 0.9420 - recall: 0.7307 - auc: 0.9861 - prc: 0.9431\n",
      "Epoch 142: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0720 - tp: 21623.0000 - fp: 1333.0000 - tn: 146667.0000 - fn: 7977.0000 - accuracy: 0.9476 - precision: 0.9419 - recall: 0.7305 - auc: 0.9860 - prc: 0.9430 - val_loss: 0.0540 - val_tp: 2875.0000 - val_fp: 107.0000 - val_tn: 18393.0000 - val_fn: 825.0000 - val_accuracy: 0.9580 - val_precision: 0.9641 - val_recall: 0.7770 - val_auc: 0.9925 - val_prc: 0.9682\n",
      "Epoch 143/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 21619.0000 - fp: 1309.0000 - tn: 145971.0000 - fn: 7837.0000 - accuracy: 0.9483 - precision: 0.9429 - recall: 0.7339 - auc: 0.9862 - prc: 0.9433\n",
      "Epoch 143: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0719 - tp: 21726.0000 - fp: 1317.0000 - tn: 146683.0000 - fn: 7874.0000 - accuracy: 0.9482 - precision: 0.9428 - recall: 0.7340 - auc: 0.9861 - prc: 0.9432 - val_loss: 0.0534 - val_tp: 2843.0000 - val_fp: 87.0000 - val_tn: 18413.0000 - val_fn: 857.0000 - val_accuracy: 0.9575 - val_precision: 0.9703 - val_recall: 0.7684 - val_auc: 0.9928 - val_prc: 0.9692\n",
      "Epoch 144/200\n",
      "1836/1850 [============================>.] - ETA: 0s - loss: 0.0728 - tp: 21468.0000 - fp: 1274.0000 - tn: 145606.0000 - fn: 7908.0000 - accuracy: 0.9479 - precision: 0.9440 - recall: 0.7308 - auc: 0.9860 - prc: 0.9425\n",
      "Epoch 144: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0728 - tp: 21638.0000 - fp: 1283.0000 - tn: 146717.0000 - fn: 7962.0000 - accuracy: 0.9479 - precision: 0.9440 - recall: 0.7310 - auc: 0.9860 - prc: 0.9425 - val_loss: 0.0547 - val_tp: 2875.0000 - val_fp: 121.0000 - val_tn: 18379.0000 - val_fn: 825.0000 - val_accuracy: 0.9574 - val_precision: 0.9596 - val_recall: 0.7770 - val_auc: 0.9923 - val_prc: 0.9670\n",
      "Epoch 145/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 21544.0000 - fp: 1253.0000 - tn: 146107.0000 - fn: 7928.0000 - accuracy: 0.9481 - precision: 0.9450 - recall: 0.7310 - auc: 0.9861 - prc: 0.9433\n",
      "Epoch 145: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0723 - tp: 21637.0000 - fp: 1259.0000 - tn: 146741.0000 - fn: 7963.0000 - accuracy: 0.9481 - precision: 0.9450 - recall: 0.7310 - auc: 0.9861 - prc: 0.9432 - val_loss: 0.0526 - val_tp: 2961.0000 - val_fp: 111.0000 - val_tn: 18389.0000 - val_fn: 739.0000 - val_accuracy: 0.9617 - val_precision: 0.9639 - val_recall: 0.8003 - val_auc: 0.9928 - val_prc: 0.9695\n",
      "Epoch 146/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 21616.0000 - fp: 1327.0000 - tn: 145953.0000 - fn: 7840.0000 - accuracy: 0.9481 - precision: 0.9422 - recall: 0.7338 - auc: 0.9862 - prc: 0.9431\n",
      "Epoch 146: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0722 - tp: 21720.0000 - fp: 1330.0000 - tn: 146670.0000 - fn: 7880.0000 - accuracy: 0.9481 - precision: 0.9423 - recall: 0.7338 - auc: 0.9862 - prc: 0.9431 - val_loss: 0.0526 - val_tp: 2908.0000 - val_fp: 94.0000 - val_tn: 18406.0000 - val_fn: 792.0000 - val_accuracy: 0.9601 - val_precision: 0.9687 - val_recall: 0.7859 - val_auc: 0.9930 - val_prc: 0.9705\n",
      "Epoch 147/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 21751.0000 - fp: 1325.0000 - tn: 146275.0000 - fn: 7769.0000 - accuracy: 0.9487 - precision: 0.9426 - recall: 0.7368 - auc: 0.9863 - prc: 0.9438\n",
      "Epoch 147: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0716 - tp: 21804.0000 - fp: 1332.0000 - tn: 146668.0000 - fn: 7796.0000 - accuracy: 0.9486 - precision: 0.9424 - recall: 0.7366 - auc: 0.9863 - prc: 0.9437 - val_loss: 0.0527 - val_tp: 2891.0000 - val_fp: 105.0000 - val_tn: 18395.0000 - val_fn: 809.0000 - val_accuracy: 0.9588 - val_precision: 0.9650 - val_recall: 0.7814 - val_auc: 0.9930 - val_prc: 0.9701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0718 - tp: 21680.0000 - fp: 1276.0000 - tn: 146324.0000 - fn: 7840.0000 - accuracy: 0.9485 - precision: 0.9444 - recall: 0.7344 - auc: 0.9862 - prc: 0.9437\n",
      "Epoch 148: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0719 - tp: 21735.0000 - fp: 1282.0000 - tn: 146718.0000 - fn: 7865.0000 - accuracy: 0.9485 - precision: 0.9443 - recall: 0.7343 - auc: 0.9862 - prc: 0.9437 - val_loss: 0.0546 - val_tp: 2861.0000 - val_fp: 107.0000 - val_tn: 18393.0000 - val_fn: 839.0000 - val_accuracy: 0.9574 - val_precision: 0.9639 - val_recall: 0.7732 - val_auc: 0.9922 - val_prc: 0.9669\n",
      "Epoch 149/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 21627.0000 - fp: 1256.0000 - tn: 145944.0000 - fn: 7813.0000 - accuracy: 0.9487 - precision: 0.9451 - recall: 0.7346 - auc: 0.9862 - prc: 0.9439\n",
      "Epoch 149: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0720 - tp: 21737.0000 - fp: 1266.0000 - tn: 146734.0000 - fn: 7863.0000 - accuracy: 0.9486 - precision: 0.9450 - recall: 0.7344 - auc: 0.9862 - prc: 0.9438 - val_loss: 0.0540 - val_tp: 2894.0000 - val_fp: 115.0000 - val_tn: 18385.0000 - val_fn: 806.0000 - val_accuracy: 0.9585 - val_precision: 0.9618 - val_recall: 0.7822 - val_auc: 0.9926 - val_prc: 0.9680\n",
      "Epoch 150/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0725 - tp: 21655.0000 - fp: 1341.0000 - tn: 146659.0000 - fn: 7945.0000 - accuracy: 0.9477 - precision: 0.9417 - recall: 0.7316 - auc: 0.9861 - prc: 0.9429\n",
      "Epoch 150: val_loss did not improve from 0.05225\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0725 - tp: 21655.0000 - fp: 1341.0000 - tn: 146659.0000 - fn: 7945.0000 - accuracy: 0.9477 - precision: 0.9417 - recall: 0.7316 - auc: 0.9861 - prc: 0.9429 - val_loss: 0.0531 - val_tp: 2914.0000 - val_fp: 106.0000 - val_tn: 18394.0000 - val_fn: 786.0000 - val_accuracy: 0.9598 - val_precision: 0.9649 - val_recall: 0.7876 - val_auc: 0.9928 - val_prc: 0.9693\n",
      "Epoch 151/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0727 - tp: 21434.0000 - fp: 1297.0000 - tn: 146063.0000 - fn: 8038.0000 - accuracy: 0.9472 - precision: 0.9429 - recall: 0.7273 - auc: 0.9859 - prc: 0.9419\n",
      "Epoch 151: val_loss improved from 0.05225 to 0.05154, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0727 - tp: 21529.0000 - fp: 1301.0000 - tn: 146699.0000 - fn: 8071.0000 - accuracy: 0.9472 - precision: 0.9430 - recall: 0.7273 - auc: 0.9860 - prc: 0.9420 - val_loss: 0.0515 - val_tp: 2959.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 741.0000 - val_accuracy: 0.9623 - val_precision: 0.9683 - val_recall: 0.7997 - val_auc: 0.9933 - val_prc: 0.9715\n",
      "Epoch 152/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0715 - tp: 21747.0000 - fp: 1354.0000 - tn: 146646.0000 - fn: 7853.0000 - accuracy: 0.9482 - precision: 0.9414 - recall: 0.7347 - auc: 0.9863 - prc: 0.9438\n",
      "Epoch 152: val_loss did not improve from 0.05154\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0715 - tp: 21747.0000 - fp: 1354.0000 - tn: 146646.0000 - fn: 7853.0000 - accuracy: 0.9482 - precision: 0.9414 - recall: 0.7347 - auc: 0.9863 - prc: 0.9438 - val_loss: 0.0524 - val_tp: 2919.0000 - val_fp: 91.0000 - val_tn: 18409.0000 - val_fn: 781.0000 - val_accuracy: 0.9607 - val_precision: 0.9698 - val_recall: 0.7889 - val_auc: 0.9930 - val_prc: 0.9702\n",
      "Epoch 153/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0723 - tp: 21599.0000 - fp: 1297.0000 - tn: 145743.0000 - fn: 7809.0000 - accuracy: 0.9484 - precision: 0.9434 - recall: 0.7345 - auc: 0.9862 - prc: 0.9432\n",
      "Epoch 153: val_loss did not improve from 0.05154\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0724 - tp: 21739.0000 - fp: 1308.0000 - tn: 146692.0000 - fn: 7861.0000 - accuracy: 0.9484 - precision: 0.9432 - recall: 0.7344 - auc: 0.9861 - prc: 0.9431 - val_loss: 0.0528 - val_tp: 2909.0000 - val_fp: 127.0000 - val_tn: 18373.0000 - val_fn: 791.0000 - val_accuracy: 0.9586 - val_precision: 0.9582 - val_recall: 0.7862 - val_auc: 0.9928 - val_prc: 0.9694\n",
      "Epoch 154/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0720 - tp: 21599.0000 - fp: 1299.0000 - tn: 145981.0000 - fn: 7857.0000 - accuracy: 0.9482 - precision: 0.9433 - recall: 0.7333 - auc: 0.9862 - prc: 0.9435\n",
      "Epoch 154: val_loss did not improve from 0.05154\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0720 - tp: 21700.0000 - fp: 1306.0000 - tn: 146694.0000 - fn: 7900.0000 - accuracy: 0.9482 - precision: 0.9432 - recall: 0.7331 - auc: 0.9862 - prc: 0.9435 - val_loss: 0.0527 - val_tp: 2954.0000 - val_fp: 116.0000 - val_tn: 18384.0000 - val_fn: 746.0000 - val_accuracy: 0.9612 - val_precision: 0.9622 - val_recall: 0.7984 - val_auc: 0.9928 - val_prc: 0.9695\n",
      "Epoch 155/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 21922.0000 - fp: 1351.0000 - tn: 146409.0000 - fn: 7630.0000 - accuracy: 0.9493 - precision: 0.9419 - recall: 0.7418 - auc: 0.9869 - prc: 0.9461\n",
      "Epoch 155: val_loss improved from 0.05154 to 0.05092, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0702 - tp: 21953.0000 - fp: 1353.0000 - tn: 146647.0000 - fn: 7647.0000 - accuracy: 0.9493 - precision: 0.9419 - recall: 0.7417 - auc: 0.9869 - prc: 0.9460 - val_loss: 0.0509 - val_tp: 2920.0000 - val_fp: 95.0000 - val_tn: 18405.0000 - val_fn: 780.0000 - val_accuracy: 0.9606 - val_precision: 0.9685 - val_recall: 0.7892 - val_auc: 0.9934 - val_prc: 0.9719\n",
      "Epoch 156/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 21627.0000 - fp: 1299.0000 - tn: 146301.0000 - fn: 7893.0000 - accuracy: 0.9481 - precision: 0.9433 - recall: 0.7326 - auc: 0.9864 - prc: 0.9441\n",
      "Epoch 156: val_loss did not improve from 0.05092\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0716 - tp: 21683.0000 - fp: 1307.0000 - tn: 146693.0000 - fn: 7917.0000 - accuracy: 0.9481 - precision: 0.9431 - recall: 0.7325 - auc: 0.9864 - prc: 0.9441 - val_loss: 0.0538 - val_tp: 2949.0000 - val_fp: 121.0000 - val_tn: 18379.0000 - val_fn: 751.0000 - val_accuracy: 0.9607 - val_precision: 0.9606 - val_recall: 0.7970 - val_auc: 0.9925 - val_prc: 0.9681\n",
      "Epoch 157/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0717 - tp: 21688.0000 - fp: 1343.0000 - tn: 145937.0000 - fn: 7768.0000 - accuracy: 0.9484 - precision: 0.9417 - recall: 0.7363 - auc: 0.9863 - prc: 0.9434\n",
      "Epoch 157: val_loss did not improve from 0.05092\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0717 - tp: 21791.0000 - fp: 1353.0000 - tn: 146647.0000 - fn: 7809.0000 - accuracy: 0.9484 - precision: 0.9415 - recall: 0.7362 - auc: 0.9863 - prc: 0.9434 - val_loss: 0.0534 - val_tp: 2888.0000 - val_fp: 93.0000 - val_tn: 18407.0000 - val_fn: 812.0000 - val_accuracy: 0.9592 - val_precision: 0.9688 - val_recall: 0.7805 - val_auc: 0.9927 - val_prc: 0.9691\n",
      "Epoch 158/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 21764.0000 - fp: 1260.0000 - tn: 146580.0000 - fn: 7804.0000 - accuracy: 0.9489 - precision: 0.9453 - recall: 0.7361 - auc: 0.9864 - prc: 0.9445\n",
      "Epoch 158: val_loss did not improve from 0.05092\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.0715 - tp: 21785.0000 - fp: 1261.0000 - tn: 146739.0000 - fn: 7815.0000 - accuracy: 0.9489 - precision: 0.9453 - recall: 0.7360 - auc: 0.9864 - prc: 0.9445 - val_loss: 0.0523 - val_tp: 2911.0000 - val_fp: 100.0000 - val_tn: 18400.0000 - val_fn: 789.0000 - val_accuracy: 0.9600 - val_precision: 0.9668 - val_recall: 0.7868 - val_auc: 0.9930 - val_prc: 0.9704\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0712 - tp: 21703.0000 - fp: 1302.0000 - tn: 146298.0000 - fn: 7817.0000 - accuracy: 0.9485 - precision: 0.9434 - recall: 0.7352 - auc: 0.9863 - prc: 0.9442\n",
      "Epoch 159: val_loss did not improve from 0.05092\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0712 - tp: 21767.0000 - fp: 1303.0000 - tn: 146697.0000 - fn: 7833.0000 - accuracy: 0.9486 - precision: 0.9435 - recall: 0.7354 - auc: 0.9863 - prc: 0.9442 - val_loss: 0.0532 - val_tp: 2930.0000 - val_fp: 133.0000 - val_tn: 18367.0000 - val_fn: 770.0000 - val_accuracy: 0.9593 - val_precision: 0.9566 - val_recall: 0.7919 - val_auc: 0.9928 - val_prc: 0.9684\n",
      "Epoch 160/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0717 - tp: 21596.0000 - fp: 1284.0000 - tn: 145916.0000 - fn: 7844.0000 - accuracy: 0.9483 - precision: 0.9439 - recall: 0.7336 - auc: 0.9864 - prc: 0.9439\n",
      "Epoch 160: val_loss did not improve from 0.05092\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0716 - tp: 21719.0000 - fp: 1290.0000 - tn: 146710.0000 - fn: 7881.0000 - accuracy: 0.9484 - precision: 0.9439 - recall: 0.7337 - auc: 0.9864 - prc: 0.9440 - val_loss: 0.0517 - val_tp: 2964.0000 - val_fp: 115.0000 - val_tn: 18385.0000 - val_fn: 736.0000 - val_accuracy: 0.9617 - val_precision: 0.9627 - val_recall: 0.8011 - val_auc: 0.9931 - val_prc: 0.9705\n",
      "Epoch 161/200\n",
      "1834/1850 [============================>.] - ETA: 0s - loss: 0.0700 - tp: 21701.0000 - fp: 1268.0000 - tn: 145452.0000 - fn: 7643.0000 - accuracy: 0.9494 - precision: 0.9448 - recall: 0.7395 - auc: 0.9869 - prc: 0.9464\n",
      "Epoch 161: val_loss did not improve from 0.05092\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0700 - tp: 21893.0000 - fp: 1279.0000 - tn: 146721.0000 - fn: 7707.0000 - accuracy: 0.9494 - precision: 0.9448 - recall: 0.7396 - auc: 0.9869 - prc: 0.9465 - val_loss: 0.0518 - val_tp: 2925.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 775.0000 - val_accuracy: 0.9607 - val_precision: 0.9679 - val_recall: 0.7905 - val_auc: 0.9933 - val_prc: 0.9711\n",
      "Epoch 162/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 21867.0000 - fp: 1321.0000 - tn: 145959.0000 - fn: 7589.0000 - accuracy: 0.9496 - precision: 0.9430 - recall: 0.7424 - auc: 0.9869 - prc: 0.9461\n",
      "Epoch 162: val_loss improved from 0.05092 to 0.05025, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0701 - tp: 21971.0000 - fp: 1328.0000 - tn: 146672.0000 - fn: 7629.0000 - accuracy: 0.9496 - precision: 0.9430 - recall: 0.7423 - auc: 0.9869 - prc: 0.9462 - val_loss: 0.0503 - val_tp: 2980.0000 - val_fp: 109.0000 - val_tn: 18391.0000 - val_fn: 720.0000 - val_accuracy: 0.9627 - val_precision: 0.9647 - val_recall: 0.8054 - val_auc: 0.9935 - val_prc: 0.9724\n",
      "Epoch 163/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0691 - tp: 22064.0000 - fp: 1258.0000 - tn: 146742.0000 - fn: 7536.0000 - accuracy: 0.9505 - precision: 0.9461 - recall: 0.7454 - auc: 0.9872 - prc: 0.9477\n",
      "Epoch 163: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0691 - tp: 22064.0000 - fp: 1258.0000 - tn: 146742.0000 - fn: 7536.0000 - accuracy: 0.9505 - precision: 0.9461 - recall: 0.7454 - auc: 0.9872 - prc: 0.9477 - val_loss: 0.0508 - val_tp: 2946.0000 - val_fp: 99.0000 - val_tn: 18401.0000 - val_fn: 754.0000 - val_accuracy: 0.9616 - val_precision: 0.9675 - val_recall: 0.7962 - val_auc: 0.9934 - val_prc: 0.9719\n",
      "Epoch 164/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0718 - tp: 21556.0000 - fp: 1275.0000 - tn: 145845.0000 - fn: 7868.0000 - accuracy: 0.9482 - precision: 0.9442 - recall: 0.7326 - auc: 0.9863 - prc: 0.9439\n",
      "Epoch 164: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0719 - tp: 21690.0000 - fp: 1287.0000 - tn: 146713.0000 - fn: 7910.0000 - accuracy: 0.9482 - precision: 0.9440 - recall: 0.7328 - auc: 0.9863 - prc: 0.9438 - val_loss: 0.0534 - val_tp: 2928.0000 - val_fp: 129.0000 - val_tn: 18371.0000 - val_fn: 772.0000 - val_accuracy: 0.9594 - val_precision: 0.9578 - val_recall: 0.7914 - val_auc: 0.9927 - val_prc: 0.9683\n",
      "Epoch 165/200\n",
      "1837/1850 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 21772.0000 - fp: 1322.0000 - tn: 145638.0000 - fn: 7620.0000 - accuracy: 0.9493 - precision: 0.9428 - recall: 0.7407 - auc: 0.9869 - prc: 0.9465\n",
      "Epoch 165: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 10s 5ms/step - loss: 0.0698 - tp: 21917.0000 - fp: 1333.0000 - tn: 146667.0000 - fn: 7683.0000 - accuracy: 0.9492 - precision: 0.9427 - recall: 0.7404 - auc: 0.9869 - prc: 0.9464 - val_loss: 0.0514 - val_tp: 2884.0000 - val_fp: 80.0000 - val_tn: 18420.0000 - val_fn: 816.0000 - val_accuracy: 0.9596 - val_precision: 0.9730 - val_recall: 0.7795 - val_auc: 0.9933 - val_prc: 0.9718\n",
      "Epoch 166/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 21940.0000 - fp: 1298.0000 - tn: 146222.0000 - fn: 7564.0000 - accuracy: 0.9499 - precision: 0.9441 - recall: 0.7436 - auc: 0.9871 - prc: 0.9471\n",
      "Epoch 166: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0694 - tp: 22006.0000 - fp: 1307.0000 - tn: 146693.0000 - fn: 7594.0000 - accuracy: 0.9499 - precision: 0.9439 - recall: 0.7434 - auc: 0.9870 - prc: 0.9469 - val_loss: 0.0506 - val_tp: 3043.0000 - val_fp: 124.0000 - val_tn: 18376.0000 - val_fn: 657.0000 - val_accuracy: 0.9648 - val_precision: 0.9608 - val_recall: 0.8224 - val_auc: 0.9933 - val_prc: 0.9717\n",
      "Epoch 167/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0712 - tp: 21784.0000 - fp: 1291.0000 - tn: 146149.0000 - fn: 7704.0000 - accuracy: 0.9492 - precision: 0.9441 - recall: 0.7387 - auc: 0.9866 - prc: 0.9451\n",
      "Epoch 167: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0712 - tp: 21867.0000 - fp: 1295.0000 - tn: 146705.0000 - fn: 7733.0000 - accuracy: 0.9492 - precision: 0.9441 - recall: 0.7387 - auc: 0.9866 - prc: 0.9450 - val_loss: 0.0514 - val_tp: 2920.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 780.0000 - val_accuracy: 0.9605 - val_precision: 0.9678 - val_recall: 0.7892 - val_auc: 0.9933 - val_prc: 0.9716\n",
      "Epoch 168/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0705 - tp: 21935.0000 - fp: 1316.0000 - tn: 146684.0000 - fn: 7665.0000 - accuracy: 0.9494 - precision: 0.9434 - recall: 0.7410 - auc: 0.9867 - prc: 0.9455\n",
      "Epoch 168: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0705 - tp: 21935.0000 - fp: 1316.0000 - tn: 146684.0000 - fn: 7665.0000 - accuracy: 0.9494 - precision: 0.9434 - recall: 0.7410 - auc: 0.9867 - prc: 0.9455 - val_loss: 0.0525 - val_tp: 2897.0000 - val_fp: 111.0000 - val_tn: 18389.0000 - val_fn: 803.0000 - val_accuracy: 0.9588 - val_precision: 0.9631 - val_recall: 0.7830 - val_auc: 0.9930 - val_prc: 0.9701\n",
      "Epoch 169/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0717 - tp: 21744.0000 - fp: 1279.0000 - tn: 146481.0000 - fn: 7808.0000 - accuracy: 0.9488 - precision: 0.9444 - recall: 0.7358 - auc: 0.9864 - prc: 0.9441\n",
      "Epoch 169: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0717 - tp: 21779.0000 - fp: 1280.0000 - tn: 146720.0000 - fn: 7821.0000 - accuracy: 0.9488 - precision: 0.9445 - recall: 0.7358 - auc: 0.9864 - prc: 0.9441 - val_loss: 0.0507 - val_tp: 2961.0000 - val_fp: 98.0000 - val_tn: 18402.0000 - val_fn: 739.0000 - val_accuracy: 0.9623 - val_precision: 0.9680 - val_recall: 0.8003 - val_auc: 0.9935 - val_prc: 0.9722\n",
      "Epoch 170/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 21978.0000 - fp: 1280.0000 - tn: 146480.0000 - fn: 7574.0000 - accuracy: 0.9501 - precision: 0.9450 - recall: 0.7437 - auc: 0.9869 - prc: 0.9465\n",
      "Epoch 170: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 5ms/step - loss: 0.0701 - tp: 22014.0000 - fp: 1281.0000 - tn: 146719.0000 - fn: 7586.0000 - accuracy: 0.9501 - precision: 0.9450 - recall: 0.7437 - auc: 0.9869 - prc: 0.9465 - val_loss: 0.0504 - val_tp: 3032.0000 - val_fp: 132.0000 - val_tn: 18368.0000 - val_fn: 668.0000 - val_accuracy: 0.9640 - val_precision: 0.9583 - val_recall: 0.8195 - val_auc: 0.9934 - val_prc: 0.9720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0705 - tp: 22025.0000 - fp: 1306.0000 - tn: 146694.0000 - fn: 7575.0000 - accuracy: 0.9500 - precision: 0.9440 - recall: 0.7441 - auc: 0.9868 - prc: 0.9461\n",
      "Epoch 171: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0705 - tp: 22025.0000 - fp: 1306.0000 - tn: 146694.0000 - fn: 7575.0000 - accuracy: 0.9500 - precision: 0.9440 - recall: 0.7441 - auc: 0.9868 - prc: 0.9461 - val_loss: 0.0506 - val_tp: 3000.0000 - val_fp: 108.0000 - val_tn: 18392.0000 - val_fn: 700.0000 - val_accuracy: 0.9636 - val_precision: 0.9653 - val_recall: 0.8108 - val_auc: 0.9934 - val_prc: 0.9719\n",
      "Epoch 172/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0702 - tp: 21990.0000 - fp: 1341.0000 - tn: 146179.0000 - fn: 7514.0000 - accuracy: 0.9500 - precision: 0.9425 - recall: 0.7453 - auc: 0.9869 - prc: 0.9464\n",
      "Epoch 172: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0702 - tp: 22068.0000 - fp: 1344.0000 - tn: 146656.0000 - fn: 7532.0000 - accuracy: 0.9500 - precision: 0.9426 - recall: 0.7455 - auc: 0.9869 - prc: 0.9464 - val_loss: 0.0514 - val_tp: 2958.0000 - val_fp: 115.0000 - val_tn: 18385.0000 - val_fn: 742.0000 - val_accuracy: 0.9614 - val_precision: 0.9626 - val_recall: 0.7995 - val_auc: 0.9932 - val_prc: 0.9709\n",
      "Epoch 173/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 21905.0000 - fp: 1330.0000 - tn: 146350.0000 - fn: 7631.0000 - accuracy: 0.9494 - precision: 0.9428 - recall: 0.7416 - auc: 0.9869 - prc: 0.9458\n",
      "Epoch 173: val_loss did not improve from 0.05025\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0701 - tp: 21953.0000 - fp: 1332.0000 - tn: 146668.0000 - fn: 7647.0000 - accuracy: 0.9494 - precision: 0.9428 - recall: 0.7417 - auc: 0.9869 - prc: 0.9457 - val_loss: 0.0510 - val_tp: 2927.0000 - val_fp: 99.0000 - val_tn: 18401.0000 - val_fn: 773.0000 - val_accuracy: 0.9607 - val_precision: 0.9673 - val_recall: 0.7911 - val_auc: 0.9934 - val_prc: 0.9718\n",
      "Epoch 174/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0716 - tp: 21749.0000 - fp: 1297.0000 - tn: 146143.0000 - fn: 7739.0000 - accuracy: 0.9489 - precision: 0.9437 - recall: 0.7376 - auc: 0.9863 - prc: 0.9442\n",
      "Epoch 174: val_loss improved from 0.05025 to 0.04923, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.0715 - tp: 21841.0000 - fp: 1300.0000 - tn: 146700.0000 - fn: 7759.0000 - accuracy: 0.9490 - precision: 0.9438 - recall: 0.7379 - auc: 0.9864 - prc: 0.9444 - val_loss: 0.0492 - val_tp: 2992.0000 - val_fp: 98.0000 - val_tn: 18402.0000 - val_fn: 708.0000 - val_accuracy: 0.9637 - val_precision: 0.9683 - val_recall: 0.8086 - val_auc: 0.9937 - val_prc: 0.9737\n",
      "Epoch 175/200\n",
      "1847/1850 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 21968.0000 - fp: 1296.0000 - tn: 146464.0000 - fn: 7584.0000 - accuracy: 0.9499 - precision: 0.9443 - recall: 0.7434 - auc: 0.9870 - prc: 0.9468\n",
      "Epoch 175: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0699 - tp: 22010.0000 - fp: 1297.0000 - tn: 146703.0000 - fn: 7590.0000 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.7436 - auc: 0.9870 - prc: 0.9468 - val_loss: 0.0523 - val_tp: 2901.0000 - val_fp: 84.0000 - val_tn: 18416.0000 - val_fn: 799.0000 - val_accuracy: 0.9602 - val_precision: 0.9719 - val_recall: 0.7841 - val_auc: 0.9930 - val_prc: 0.9707\n",
      "Epoch 176/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 21961.0000 - fp: 1268.0000 - tn: 145772.0000 - fn: 7447.0000 - accuracy: 0.9506 - precision: 0.9454 - recall: 0.7468 - auc: 0.9872 - prc: 0.9475\n",
      "Epoch 176: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0692 - tp: 22100.0000 - fp: 1271.0000 - tn: 146729.0000 - fn: 7500.0000 - accuracy: 0.9506 - precision: 0.9456 - recall: 0.7466 - auc: 0.9872 - prc: 0.9476 - val_loss: 0.0503 - val_tp: 2938.0000 - val_fp: 90.0000 - val_tn: 18410.0000 - val_fn: 762.0000 - val_accuracy: 0.9616 - val_precision: 0.9703 - val_recall: 0.7941 - val_auc: 0.9937 - val_prc: 0.9730\n",
      "Epoch 177/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 21765.0000 - fp: 1313.0000 - tn: 146367.0000 - fn: 7771.0000 - accuracy: 0.9487 - precision: 0.9431 - recall: 0.7369 - auc: 0.9865 - prc: 0.9450\n",
      "Epoch 177: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 7s 4ms/step - loss: 0.0712 - tp: 21813.0000 - fp: 1316.0000 - tn: 146684.0000 - fn: 7787.0000 - accuracy: 0.9487 - precision: 0.9431 - recall: 0.7369 - auc: 0.9865 - prc: 0.9450 - val_loss: 0.0508 - val_tp: 2924.0000 - val_fp: 97.0000 - val_tn: 18403.0000 - val_fn: 776.0000 - val_accuracy: 0.9607 - val_precision: 0.9679 - val_recall: 0.7903 - val_auc: 0.9934 - val_prc: 0.9721\n",
      "Epoch 178/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 21726.0000 - fp: 1304.0000 - tn: 146296.0000 - fn: 7794.0000 - accuracy: 0.9486 - precision: 0.9434 - recall: 0.7360 - auc: 0.9864 - prc: 0.9442\n",
      "Epoch 178: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0715 - tp: 21786.0000 - fp: 1309.0000 - tn: 146691.0000 - fn: 7814.0000 - accuracy: 0.9486 - precision: 0.9433 - recall: 0.7360 - auc: 0.9864 - prc: 0.9442 - val_loss: 0.0497 - val_tp: 2943.0000 - val_fp: 87.0000 - val_tn: 18413.0000 - val_fn: 757.0000 - val_accuracy: 0.9620 - val_precision: 0.9713 - val_recall: 0.7954 - val_auc: 0.9938 - val_prc: 0.9734\n",
      "Epoch 179/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0705 - tp: 21910.0000 - fp: 1308.0000 - tn: 146612.0000 - fn: 7674.0000 - accuracy: 0.9494 - precision: 0.9437 - recall: 0.7406 - auc: 0.9868 - prc: 0.9456\n",
      "Epoch 179: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0705 - tp: 21924.0000 - fp: 1308.0000 - tn: 146692.0000 - fn: 7676.0000 - accuracy: 0.9494 - precision: 0.9437 - recall: 0.7407 - auc: 0.9868 - prc: 0.9456 - val_loss: 0.0504 - val_tp: 3001.0000 - val_fp: 106.0000 - val_tn: 18394.0000 - val_fn: 699.0000 - val_accuracy: 0.9637 - val_precision: 0.9659 - val_recall: 0.8111 - val_auc: 0.9935 - val_prc: 0.9724\n",
      "Epoch 180/200\n",
      "1845/1850 [============================>.] - ETA: 0s - loss: 0.0701 - tp: 21980.0000 - fp: 1297.0000 - tn: 146303.0000 - fn: 7540.0000 - accuracy: 0.9501 - precision: 0.9443 - recall: 0.7446 - auc: 0.9871 - prc: 0.9466\n",
      "Epoch 180: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0701 - tp: 22037.0000 - fp: 1304.0000 - tn: 146696.0000 - fn: 7563.0000 - accuracy: 0.9501 - precision: 0.9441 - recall: 0.7445 - auc: 0.9870 - prc: 0.9465 - val_loss: 0.0495 - val_tp: 3010.0000 - val_fp: 113.0000 - val_tn: 18387.0000 - val_fn: 690.0000 - val_accuracy: 0.9638 - val_precision: 0.9638 - val_recall: 0.8135 - val_auc: 0.9938 - val_prc: 0.9732\n",
      "Epoch 181/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0705 - tp: 21862.0000 - fp: 1291.0000 - tn: 145749.0000 - fn: 7546.0000 - accuracy: 0.9499 - precision: 0.9442 - recall: 0.7434 - auc: 0.9869 - prc: 0.9463\n",
      "Epoch 181: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0705 - tp: 22005.0000 - fp: 1298.0000 - tn: 146702.0000 - fn: 7595.0000 - accuracy: 0.9499 - precision: 0.9443 - recall: 0.7434 - auc: 0.9869 - prc: 0.9463 - val_loss: 0.0495 - val_tp: 2908.0000 - val_fp: 85.0000 - val_tn: 18415.0000 - val_fn: 792.0000 - val_accuracy: 0.9605 - val_precision: 0.9716 - val_recall: 0.7859 - val_auc: 0.9939 - val_prc: 0.9742\n",
      "Epoch 182/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 21960.0000 - fp: 1270.0000 - tn: 146170.0000 - fn: 7528.0000 - accuracy: 0.9503 - precision: 0.9453 - recall: 0.7447 - auc: 0.9871 - prc: 0.9467\n",
      "Epoch 182: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0699 - tp: 22042.0000 - fp: 1277.0000 - tn: 146723.0000 - fn: 7558.0000 - accuracy: 0.9503 - precision: 0.9452 - recall: 0.7447 - auc: 0.9870 - prc: 0.9466 - val_loss: 0.0506 - val_tp: 2964.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 736.0000 - val_accuracy: 0.9623 - val_precision: 0.9667 - val_recall: 0.8011 - val_auc: 0.9935 - val_prc: 0.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0704 - tp: 21939.0000 - fp: 1303.0000 - tn: 146537.0000 - fn: 7629.0000 - accuracy: 0.9497 - precision: 0.9439 - recall: 0.7420 - auc: 0.9869 - prc: 0.9460\n",
      "Epoch 183: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 7s 4ms/step - loss: 0.0705 - tp: 21960.0000 - fp: 1303.0000 - tn: 146697.0000 - fn: 7640.0000 - accuracy: 0.9496 - precision: 0.9440 - recall: 0.7419 - auc: 0.9869 - prc: 0.9459 - val_loss: 0.0527 - val_tp: 2950.0000 - val_fp: 129.0000 - val_tn: 18371.0000 - val_fn: 750.0000 - val_accuracy: 0.9604 - val_precision: 0.9581 - val_recall: 0.7973 - val_auc: 0.9927 - val_prc: 0.9690\n",
      "Epoch 184/200\n",
      "1840/1850 [============================>.] - ETA: 0s - loss: 0.0695 - tp: 21955.0000 - fp: 1283.0000 - tn: 145917.0000 - fn: 7485.0000 - accuracy: 0.9504 - precision: 0.9448 - recall: 0.7458 - auc: 0.9872 - prc: 0.9471\n",
      "Epoch 184: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0696 - tp: 22080.0000 - fp: 1293.0000 - tn: 146707.0000 - fn: 7520.0000 - accuracy: 0.9504 - precision: 0.9447 - recall: 0.7459 - auc: 0.9871 - prc: 0.9470 - val_loss: 0.0515 - val_tp: 2956.0000 - val_fp: 99.0000 - val_tn: 18401.0000 - val_fn: 744.0000 - val_accuracy: 0.9620 - val_precision: 0.9676 - val_recall: 0.7989 - val_auc: 0.9933 - val_prc: 0.9711\n",
      "Epoch 185/200\n",
      "1841/1850 [============================>.] - ETA: 0s - loss: 0.0711 - tp: 21789.0000 - fp: 1274.0000 - tn: 146006.0000 - fn: 7667.0000 - accuracy: 0.9494 - precision: 0.9448 - recall: 0.7397 - auc: 0.9868 - prc: 0.9454\n",
      "Epoch 185: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0712 - tp: 21881.0000 - fp: 1281.0000 - tn: 146719.0000 - fn: 7719.0000 - accuracy: 0.9493 - precision: 0.9447 - recall: 0.7392 - auc: 0.9868 - prc: 0.9453 - val_loss: 0.0525 - val_tp: 2902.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 798.0000 - val_accuracy: 0.9595 - val_precision: 0.9660 - val_recall: 0.7843 - val_auc: 0.9930 - val_prc: 0.9701\n",
      "Epoch 186/200\n",
      "1838/1850 [============================>.] - ETA: 0s - loss: 0.0696 - tp: 21821.0000 - fp: 1246.0000 - tn: 145794.0000 - fn: 7587.0000 - accuracy: 0.9499 - precision: 0.9460 - recall: 0.7420 - auc: 0.9871 - prc: 0.9469\n",
      "Epoch 186: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0697 - tp: 21949.0000 - fp: 1257.0000 - tn: 146743.0000 - fn: 7651.0000 - accuracy: 0.9498 - precision: 0.9458 - recall: 0.7415 - auc: 0.9870 - prc: 0.9468 - val_loss: 0.0529 - val_tp: 2873.0000 - val_fp: 82.0000 - val_tn: 18418.0000 - val_fn: 827.0000 - val_accuracy: 0.9591 - val_precision: 0.9723 - val_recall: 0.7765 - val_auc: 0.9929 - val_prc: 0.9702\n",
      "Epoch 187/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0696 - tp: 21995.0000 - fp: 1278.0000 - tn: 146242.0000 - fn: 7509.0000 - accuracy: 0.9504 - precision: 0.9451 - recall: 0.7455 - auc: 0.9871 - prc: 0.9469\n",
      "Epoch 187: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0697 - tp: 22066.0000 - fp: 1287.0000 - tn: 146713.0000 - fn: 7534.0000 - accuracy: 0.9503 - precision: 0.9449 - recall: 0.7455 - auc: 0.9870 - prc: 0.9468 - val_loss: 0.0509 - val_tp: 2916.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 784.0000 - val_accuracy: 0.9601 - val_precision: 0.9662 - val_recall: 0.7881 - val_auc: 0.9934 - val_prc: 0.9719\n",
      "Epoch 188/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0696 - tp: 21956.0000 - fp: 1306.0000 - tn: 146374.0000 - fn: 7580.0000 - accuracy: 0.9499 - precision: 0.9439 - recall: 0.7434 - auc: 0.9871 - prc: 0.9472\n",
      "Epoch 188: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0696 - tp: 22000.0000 - fp: 1309.0000 - tn: 146691.0000 - fn: 7600.0000 - accuracy: 0.9498 - precision: 0.9438 - recall: 0.7432 - auc: 0.9871 - prc: 0.9472 - val_loss: 0.0529 - val_tp: 2964.0000 - val_fp: 128.0000 - val_tn: 18372.0000 - val_fn: 736.0000 - val_accuracy: 0.9611 - val_precision: 0.9586 - val_recall: 0.8011 - val_auc: 0.9928 - val_prc: 0.9687\n",
      "Epoch 189/200\n",
      "1836/1850 [============================>.] - ETA: 0s - loss: 0.0705 - tp: 21768.0000 - fp: 1296.0000 - tn: 145584.0000 - fn: 7608.0000 - accuracy: 0.9495 - precision: 0.9438 - recall: 0.7410 - auc: 0.9867 - prc: 0.9458\n",
      "Epoch 189: val_loss did not improve from 0.04923\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0706 - tp: 21934.0000 - fp: 1309.0000 - tn: 146691.0000 - fn: 7666.0000 - accuracy: 0.9495 - precision: 0.9437 - recall: 0.7410 - auc: 0.9867 - prc: 0.9457 - val_loss: 0.0505 - val_tp: 2935.0000 - val_fp: 100.0000 - val_tn: 18400.0000 - val_fn: 765.0000 - val_accuracy: 0.9610 - val_precision: 0.9671 - val_recall: 0.7932 - val_auc: 0.9934 - val_prc: 0.9721\n",
      "Epoch 190/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0694 - tp: 22022.0000 - fp: 1295.0000 - tn: 146145.0000 - fn: 7466.0000 - accuracy: 0.9505 - precision: 0.9445 - recall: 0.7468 - auc: 0.9872 - prc: 0.9474\n",
      "Epoch 190: val_loss improved from 0.04923 to 0.04907, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.0694 - tp: 22101.0000 - fp: 1305.0000 - tn: 146695.0000 - fn: 7499.0000 - accuracy: 0.9504 - precision: 0.9442 - recall: 0.7467 - auc: 0.9872 - prc: 0.9473 - val_loss: 0.0491 - val_tp: 2963.0000 - val_fp: 87.0000 - val_tn: 18413.0000 - val_fn: 737.0000 - val_accuracy: 0.9629 - val_precision: 0.9715 - val_recall: 0.8008 - val_auc: 0.9939 - val_prc: 0.9742\n",
      "Epoch 191/200\n",
      "1846/1850 [============================>.] - ETA: 0s - loss: 0.0706 - tp: 21963.0000 - fp: 1307.0000 - tn: 146373.0000 - fn: 7573.0000 - accuracy: 0.9499 - precision: 0.9438 - recall: 0.7436 - auc: 0.9867 - prc: 0.9460\n",
      "Epoch 191: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0706 - tp: 22008.0000 - fp: 1308.0000 - tn: 146692.0000 - fn: 7592.0000 - accuracy: 0.9499 - precision: 0.9439 - recall: 0.7435 - auc: 0.9867 - prc: 0.9460 - val_loss: 0.0499 - val_tp: 3012.0000 - val_fp: 119.0000 - val_tn: 18381.0000 - val_fn: 688.0000 - val_accuracy: 0.9636 - val_precision: 0.9620 - val_recall: 0.8141 - val_auc: 0.9935 - val_prc: 0.9724\n",
      "Epoch 192/200\n",
      "1849/1850 [============================>.] - ETA: 0s - loss: 0.0684 - tp: 22150.0000 - fp: 1268.0000 - tn: 146652.0000 - fn: 7434.0000 - accuracy: 0.9510 - precision: 0.9459 - recall: 0.7487 - auc: 0.9875 - prc: 0.9487\n",
      "Epoch 192: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0684 - tp: 22161.0000 - fp: 1270.0000 - tn: 146730.0000 - fn: 7439.0000 - accuracy: 0.9510 - precision: 0.9458 - recall: 0.7487 - auc: 0.9875 - prc: 0.9487 - val_loss: 0.0503 - val_tp: 2955.0000 - val_fp: 102.0000 - val_tn: 18398.0000 - val_fn: 745.0000 - val_accuracy: 0.9618 - val_precision: 0.9666 - val_recall: 0.7986 - val_auc: 0.9935 - val_prc: 0.9722\n",
      "Epoch 193/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0704 - tp: 21965.0000 - fp: 1323.0000 - tn: 146677.0000 - fn: 7635.0000 - accuracy: 0.9496 - precision: 0.9432 - recall: 0.7421 - auc: 0.9869 - prc: 0.9460\n",
      "Epoch 193: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0704 - tp: 21965.0000 - fp: 1323.0000 - tn: 146677.0000 - fn: 7635.0000 - accuracy: 0.9496 - precision: 0.9432 - recall: 0.7421 - auc: 0.9869 - prc: 0.9460 - val_loss: 0.0501 - val_tp: 3015.0000 - val_fp: 117.0000 - val_tn: 18383.0000 - val_fn: 685.0000 - val_accuracy: 0.9639 - val_precision: 0.9626 - val_recall: 0.8149 - val_auc: 0.9935 - val_prc: 0.9724\n",
      "Epoch 194/200\n",
      "1839/1850 [============================>.] - ETA: 0s - loss: 0.0696 - tp: 21957.0000 - fp: 1282.0000 - tn: 145838.0000 - fn: 7467.0000 - accuracy: 0.9504 - precision: 0.9448 - recall: 0.7462 - auc: 0.9872 - prc: 0.9473\n",
      "Epoch 194: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 9s 5ms/step - loss: 0.0696 - tp: 22084.0000 - fp: 1285.0000 - tn: 146715.0000 - fn: 7516.0000 - accuracy: 0.9504 - precision: 0.9450 - recall: 0.7461 - auc: 0.9872 - prc: 0.9473 - val_loss: 0.0496 - val_tp: 2962.0000 - val_fp: 84.0000 - val_tn: 18416.0000 - val_fn: 738.0000 - val_accuracy: 0.9630 - val_precision: 0.9724 - val_recall: 0.8005 - val_auc: 0.9938 - val_prc: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "1842/1850 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 21918.0000 - fp: 1267.0000 - tn: 146093.0000 - fn: 7554.0000 - accuracy: 0.9501 - precision: 0.9454 - recall: 0.7437 - auc: 0.9872 - prc: 0.9474\n",
      "Epoch 195: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0692 - tp: 22013.0000 - fp: 1274.0000 - tn: 146726.0000 - fn: 7587.0000 - accuracy: 0.9501 - precision: 0.9453 - recall: 0.7437 - auc: 0.9872 - prc: 0.9474 - val_loss: 0.0492 - val_tp: 2990.0000 - val_fp: 104.0000 - val_tn: 18396.0000 - val_fn: 710.0000 - val_accuracy: 0.9633 - val_precision: 0.9664 - val_recall: 0.8081 - val_auc: 0.9938 - val_prc: 0.9736\n",
      "Epoch 196/200\n",
      "1844/1850 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 21923.0000 - fp: 1244.0000 - tn: 146276.0000 - fn: 7581.0000 - accuracy: 0.9501 - precision: 0.9463 - recall: 0.7431 - auc: 0.9870 - prc: 0.9467\n",
      "Epoch 196: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0698 - tp: 22000.0000 - fp: 1249.0000 - tn: 146751.0000 - fn: 7600.0000 - accuracy: 0.9502 - precision: 0.9463 - recall: 0.7432 - auc: 0.9871 - prc: 0.9468 - val_loss: 0.0499 - val_tp: 2972.0000 - val_fp: 114.0000 - val_tn: 18386.0000 - val_fn: 728.0000 - val_accuracy: 0.9621 - val_precision: 0.9631 - val_recall: 0.8032 - val_auc: 0.9937 - val_prc: 0.9730\n",
      "Epoch 197/200\n",
      "1843/1850 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 21975.0000 - fp: 1268.0000 - tn: 146172.0000 - fn: 7513.0000 - accuracy: 0.9504 - precision: 0.9454 - recall: 0.7452 - auc: 0.9871 - prc: 0.9474\n",
      "Epoch 197: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0696 - tp: 22063.0000 - fp: 1271.0000 - tn: 146729.0000 - fn: 7537.0000 - accuracy: 0.9504 - precision: 0.9455 - recall: 0.7454 - auc: 0.9871 - prc: 0.9475 - val_loss: 0.0502 - val_tp: 2941.0000 - val_fp: 112.0000 - val_tn: 18388.0000 - val_fn: 759.0000 - val_accuracy: 0.9608 - val_precision: 0.9633 - val_recall: 0.7949 - val_auc: 0.9936 - val_prc: 0.9725\n",
      "Epoch 198/200\n",
      "1850/1850 [==============================] - ETA: 0s - loss: 0.0690 - tp: 22009.0000 - fp: 1289.0000 - tn: 146711.0000 - fn: 7591.0000 - accuracy: 0.9500 - precision: 0.9447 - recall: 0.7435 - auc: 0.9874 - prc: 0.9479\n",
      "Epoch 198: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0690 - tp: 22009.0000 - fp: 1289.0000 - tn: 146711.0000 - fn: 7591.0000 - accuracy: 0.9500 - precision: 0.9447 - recall: 0.7435 - auc: 0.9874 - prc: 0.9479 - val_loss: 0.0512 - val_tp: 2928.0000 - val_fp: 95.0000 - val_tn: 18405.0000 - val_fn: 772.0000 - val_accuracy: 0.9609 - val_precision: 0.9686 - val_recall: 0.7914 - val_auc: 0.9933 - val_prc: 0.9716\n",
      "Epoch 199/200\n",
      "1848/1850 [============================>.] - ETA: 0s - loss: 0.0695 - tp: 22042.0000 - fp: 1305.0000 - tn: 146535.0000 - fn: 7526.0000 - accuracy: 0.9502 - precision: 0.9441 - recall: 0.7455 - auc: 0.9872 - prc: 0.9471\n",
      "Epoch 199: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 7s 4ms/step - loss: 0.0695 - tp: 22063.0000 - fp: 1305.0000 - tn: 146695.0000 - fn: 7537.0000 - accuracy: 0.9502 - precision: 0.9442 - recall: 0.7454 - auc: 0.9872 - prc: 0.9472 - val_loss: 0.0508 - val_tp: 2918.0000 - val_fp: 101.0000 - val_tn: 18399.0000 - val_fn: 782.0000 - val_accuracy: 0.9602 - val_precision: 0.9665 - val_recall: 0.7886 - val_auc: 0.9935 - val_prc: 0.9723\n",
      "Epoch 200/200\n",
      "1836/1850 [============================>.] - ETA: 0s - loss: 0.0683 - tp: 22027.0000 - fp: 1246.0000 - tn: 145634.0000 - fn: 7349.0000 - accuracy: 0.9512 - precision: 0.9465 - recall: 0.7498 - auc: 0.9876 - prc: 0.9491\n",
      "Epoch 200: val_loss did not improve from 0.04907\n",
      "1850/1850 [==============================] - 8s 4ms/step - loss: 0.0682 - tp: 22202.0000 - fp: 1252.0000 - tn: 146748.0000 - fn: 7398.0000 - accuracy: 0.9513 - precision: 0.9466 - recall: 0.7501 - auc: 0.9876 - prc: 0.9492 - val_loss: 0.0500 - val_tp: 2973.0000 - val_fp: 112.0000 - val_tn: 18388.0000 - val_fn: 727.0000 - val_accuracy: 0.9622 - val_precision: 0.9637 - val_recall: 0.8035 - val_auc: 0.9936 - val_prc: 0.9724\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),#'categorical_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "#checkpoint_path = \"weights.best.hdf5\"\n",
    "\n",
    "checkpoint_path = \"weights.best.onlyfocalloss\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f913d8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9108db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1cf93ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 0.0770 - tp: 2391.0000 - fp: 83.0000 - tn: 18417.0000 - fn: 1309.0000 - accuracy: 0.9373 - precision: 0.9665 - recall: 0.6462 - auc: 0.9829 - prc: 0.9353\n"
     ]
    }
   ],
   "source": [
    "loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b7826a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.73      0.82       532\n",
      "           1       0.84      0.83      0.83       854\n",
      "           2       0.78      0.88      0.83       484\n",
      "           3       0.81      0.85      0.83       812\n",
      "           4       0.86      0.88      0.87       504\n",
      "           5       0.94      1.00      0.97       514\n",
      "\n",
      "    accuracy                           0.86      3700\n",
      "   macro avg       0.87      0.86      0.86      3700\n",
      "weighted avg       0.86      0.86      0.86      3700\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
    "y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names,normalize=True,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e8526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes 3, 4 Need to be weighted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30c05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
