{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5491b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import tqdm\n",
    "\n",
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16fcb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 21:35:11.567400: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-30 21:35:11.567484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cs229-vm-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-05-30 21:35:11.569480: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947d0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
    "sys.path.append(pose_sample_rpi_path)\n",
    "\n",
    "# Load MoveNet Thunder model\n",
    "import utils\n",
    "from data import BodyPart\n",
    "from ml import Movenet\n",
    "movenet = Movenet('movenet_thunder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e4b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/shellygoel2324/data_clean.csv'\n",
    "labels_path = '/home/shellygoel2324/processedLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d37956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pose_landmarks(csv_path, labels_path):\n",
    "    \"\"\"Loads a CSV created by MoveNetPreprocessor.\n",
    "    Returns:\n",
    "        X: Detected landmark coordinates and scores of shape (N, 17 * 3)\n",
    "        y: Ground truth labels of shape (N, label_count)\n",
    "        classes: The list of all class names found in the dataset\n",
    "        dataframe: The CSV loaded as a Pandas dataframe features (X) and ground\n",
    "        truth labels (y) to use later to train a pose classification model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    labels = pd.read_csv(labels_path, header=None)\n",
    "    df_to_process = dataframe.copy()\n",
    "\n",
    "    # Drop the file_name columns as you don't need it during training.\n",
    "    df_to_process.drop(columns=['file_name'], inplace=True)\n",
    "\n",
    "    # Extract the list of class names\n",
    "    df_to_process.pop('class_name')\n",
    "    df_to_process.pop('class_no')\n",
    "\n",
    "    # Extract the labels\n",
    "    y = labels\n",
    "    classes = range(8)\n",
    "\n",
    "    # Convert the input features and labels into the correct format for training.\n",
    "    X = df_to_process.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "    \n",
    "    return X, y, classes, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93bd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10255, 51)\n"
     ]
    }
   ],
   "source": [
    "# Load the train data\n",
    "X, y, class_names, _ = load_pose_landmarks(data_path, labels_path)\n",
    "\n",
    "# 80/10/10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4835b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DISTRIBUTION\n",
      "1: 0.50931253047294\n",
      "2: 0.24280838615309605\n",
      "3: 0.11038517796196977\n",
      "4: 0.04475865431496831\n",
      "5: 0.02340321794246709\n",
      "6: 0.008776206728425159\n",
      "7: 0.060555826426133594\n",
      "\n",
      "TEST DISTRIBUTION\n",
      "0: 0.0\n",
      "1: 0.5195007800312013\n",
      "2: 0.24726989079563183\n",
      "3: 0.09750390015600624\n",
      "4: 0.039781591263650544\n",
      "5: 0.0358814352574103\n",
      "6: 0.0062402496099844\n",
      "7: 0.05382215288611544\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DISTRIBUTION\")\n",
    "\n",
    "sample_dist = []\n",
    "\n",
    "\n",
    "for i in range(1,8):\n",
    "    \n",
    "    num_i = 0\n",
    "    for ind, sample in enumerate(y_train):\n",
    "            if tf.argmax(sample) == i:\n",
    "                if i ==0:\n",
    "                    print(\"HERE\")\n",
    "                \n",
    "                num_i+=1\n",
    "    dist = num_i/len(y_train)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    sample_dist.append(dist)\n",
    "\n",
    "    \n",
    "print(\"\\nTEST DISTRIBUTION\")\n",
    "for i in range(0,8):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_test:\n",
    "            if tf.argmax(sample) == i:\n",
    "                if i ==0:\n",
    "                    print(sample)\n",
    "                num_i+=1\n",
    "\n",
    "    dist = num_i/len(y_test)\n",
    "    print(f\"{i}: {dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74657710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_dist = sample_dist/np.linalg.norm(sample_dist)\n",
    "weight_balanced= [1/s for s in sample_dist]\n",
    "\n",
    "sample_weights = weight_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    \n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center\n",
    "\n",
    "\n",
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "\n",
    "        It is the maximum of two values:\n",
    "        * Torso size multiplied by `torso_size_multiplier`\n",
    "        * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "    return pose_size\n",
    "\n",
    "\n",
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "        scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "    # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def no_normalization(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    landmarks = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Flatten the landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks[:, :, :2])\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cea2f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e2eea",
   "metadata": {},
   "source": [
    "## No normalizing at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ffd45da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 51)]              0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 17, 3)             0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_1   (None, 17, 2)            0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 34)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               4480      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,256\n",
      "Trainable params: 13,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = no_normalization(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa8df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9634309783649244, 4.118473895582329, 9.059187279151944, 22.342047930283222, 42.729166666666664, 113.94444444444444, 16.513687600644122]\n",
      "[0.01567794 0.03288589 0.07233735 0.1784006  0.34119116 0.90984309\n",
      " 0.13186132]\n"
     ]
    }
   ],
   "source": [
    "print(sample_weights)\n",
    "\n",
    "\n",
    "sample_weights = sample_weights/np.linalg.norm(sample_weights)\n",
    "\n",
    "print(sample_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "117a48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "class_weights[0] = 0\n",
    "for i in range(1,8):\n",
    "    class_weights[i] = sample_weights[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf0903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0.01567793943728298, 2: 0.032885894650975495, 3: 0.07233734777467225, 4: 0.17840060496934418, 5: 0.34119115700387076, 6: 0.9098430853436554, 7: 0.1318613167164718}\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ef925c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#USING FOCAL LOSS\n",
    "\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3343445",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0920 - tp: 967.0000 - fp: 4886.0000 - tn: 65450.0000 - fn: 9081.0000 - accuracy: 0.8262 - precision: 0.1652 - recall: 0.0962 - auc: 0.5282 - prc: 0.1406\n",
      "Epoch 1: val_loss improved from -inf to 0.41194, saving model to weights.SigmoidFocalCrossEntropyWithClassWeightsNoNorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 21:43:50.894613: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights.SigmoidFocalCrossEntropyWithClassWeightsNoNorm/assets\n",
      "641/641 [==============================] - 6s 6ms/step - loss: 0.0907 - tp: 968.0000 - fp: 4897.0000 - tn: 66888.0000 - fn: 9287.0000 - accuracy: 0.8271 - precision: 0.1650 - recall: 0.0944 - auc: 0.5282 - prc: 0.1406 - val_loss: 0.4119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4245 - val_prc: 0.1354\n",
      "Epoch 2/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0241 - tp: 28.0000 - fp: 158.0000 - tn: 71410.0000 - fn: 10196.0000 - accuracy: 0.8734 - precision: 0.1505 - recall: 0.0027 - auc: 0.4973 - prc: 0.1311\n",
      "Epoch 2: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0241 - tp: 28.0000 - fp: 159.0000 - tn: 71626.0000 - fn: 10227.0000 - accuracy: 0.8734 - precision: 0.1497 - recall: 0.0027 - auc: 0.4973 - prc: 0.1311 - val_loss: 0.4111 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3540 - val_prc: 0.0898\n",
      "Epoch 3/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0223 - tp: 6.0000 - fp: 35.0000 - tn: 69965.0000 - fn: 9994.0000 - accuracy: 0.8746 - precision: 0.1463 - recall: 6.0000e-04 - auc: 0.4809 - prc: 0.1227\n",
      "Epoch 3: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0224 - tp: 6.0000 - fp: 36.0000 - tn: 71749.0000 - fn: 10249.0000 - accuracy: 0.8746 - precision: 0.1429 - recall: 5.8508e-04 - auc: 0.4802 - prc: 0.1224 - val_loss: 0.4005 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3290 - val_prc: 0.0890\n",
      "Epoch 4/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0219 - tp: 2.0000 - fp: 18.0000 - tn: 69982.0000 - fn: 9998.0000 - accuracy: 0.8748 - precision: 0.1000 - recall: 2.0000e-04 - auc: 0.4655 - prc: 0.1181\n",
      "Epoch 4: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0219 - tp: 2.0000 - fp: 18.0000 - tn: 71767.0000 - fn: 10253.0000 - accuracy: 0.8748 - precision: 0.1000 - recall: 1.9503e-04 - auc: 0.4666 - prc: 0.1182 - val_loss: 0.3898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4523 - val_prc: 0.1045\n",
      "Epoch 5/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0213 - tp: 4.0000 - fp: 6.0000 - tn: 71002.0000 - fn: 10140.0000 - accuracy: 0.8750 - precision: 0.4000 - recall: 3.9432e-04 - auc: 0.5523 - prc: 0.1382\n",
      "Epoch 5: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0214 - tp: 4.0000 - fp: 6.0000 - tn: 71779.0000 - fn: 10251.0000 - accuracy: 0.8750 - precision: 0.4000 - recall: 3.9005e-04 - auc: 0.5534 - prc: 0.1385 - val_loss: 0.3789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5560 - val_prc: 0.1241\n",
      "Epoch 6/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0214 - tp: 1.0000 - fp: 3.0000 - tn: 69773.0000 - fn: 9967.0000 - accuracy: 0.8750 - precision: 0.2500 - recall: 1.0032e-04 - auc: 0.6246 - prc: 0.1537\n",
      "Epoch 6: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0213 - tp: 1.0000 - fp: 3.0000 - tn: 71782.0000 - fn: 10254.0000 - accuracy: 0.8750 - precision: 0.2500 - recall: 9.7513e-05 - auc: 0.6235 - prc: 0.1535 - val_loss: 0.3734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6884 - val_prc: 0.1885\n",
      "Epoch 7/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0212 - tp: 1.0000 - fp: 5.0000 - tn: 71003.0000 - fn: 10143.0000 - accuracy: 0.8750 - precision: 0.1667 - recall: 9.8580e-05 - auc: 0.6051 - prc: 0.1578\n",
      "Epoch 7: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 3s 4ms/step - loss: 0.0211 - tp: 1.0000 - fp: 5.0000 - tn: 71780.0000 - fn: 10254.0000 - accuracy: 0.8750 - precision: 0.1667 - recall: 9.7513e-05 - auc: 0.6050 - prc: 0.1577 - val_loss: 0.3615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6878 - val_prc: 0.1696\n",
      "Epoch 8/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.0210 - tp: 0.0000e+00 - fp: 5.0000 - tn: 70107.0000 - fn: 10016.0000 - accuracy: 0.8749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5912 - prc: 0.1474\n",
      "Epoch 8: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0210 - tp: 0.0000e+00 - fp: 5.0000 - tn: 71780.0000 - fn: 10255.0000 - accuracy: 0.8749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5915 - prc: 0.1475 - val_loss: 0.3635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6063 - val_prc: 0.1400\n",
      "Epoch 9/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0209 - tp: 2.0000 - fp: 7.0000 - tn: 71673.0000 - fn: 10238.0000 - accuracy: 0.8749 - precision: 0.2222 - recall: 1.9531e-04 - auc: 0.5769 - prc: 0.1415\n",
      "Epoch 9: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0209 - tp: 2.0000 - fp: 7.0000 - tn: 71778.0000 - fn: 10253.0000 - accuracy: 0.8749 - precision: 0.2222 - recall: 1.9503e-04 - auc: 0.5767 - prc: 0.1414 - val_loss: 0.3638 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4664 - val_prc: 0.1054\n",
      "Epoch 10/200\n",
      "624/641 [============================>.] - ETA: 0s - loss: 0.0203 - tp: 2.0000 - fp: 5.0000 - tn: 69883.0000 - fn: 9982.0000 - accuracy: 0.8750 - precision: 0.2857 - recall: 2.0032e-04 - auc: 0.6186 - prc: 0.1542\n",
      "Epoch 10: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0204 - tp: 2.0000 - fp: 5.0000 - tn: 71780.0000 - fn: 10253.0000 - accuracy: 0.8750 - precision: 0.2857 - recall: 1.9503e-04 - auc: 0.6190 - prc: 0.1543 - val_loss: 0.3484 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6986 - val_prc: 0.1755\n",
      "Epoch 11/200\n",
      "627/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 8.0000 - fp: 40.0000 - tn: 70184.0000 - fn: 10024.0000 - accuracy: 0.8746 - precision: 0.1667 - recall: 7.9745e-04 - auc: 0.5928 - prc: 0.1427\n",
      "Epoch 11: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 8.0000 - fp: 40.0000 - tn: 71745.0000 - fn: 10247.0000 - accuracy: 0.8746 - precision: 0.1667 - recall: 7.8011e-04 - auc: 0.5945 - prc: 0.1434 - val_loss: 0.3534 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7728 - val_prc: 0.2534\n",
      "Epoch 12/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0199 - tp: 11.0000 - fp: 35.0000 - tn: 70637.0000 - fn: 10085.0000 - accuracy: 0.8747 - precision: 0.2391 - recall: 0.0011 - auc: 0.6131 - prc: 0.1520\n",
      "Epoch 12: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 11.0000 - fp: 35.0000 - tn: 71750.0000 - fn: 10244.0000 - accuracy: 0.8747 - precision: 0.2391 - recall: 0.0011 - auc: 0.6136 - prc: 0.1522 - val_loss: 0.3490 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6571 - val_prc: 0.1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0204 - tp: 1.0000 - fp: 11.0000 - tn: 71669.0000 - fn: 10239.0000 - accuracy: 0.8749 - precision: 0.0833 - recall: 9.7656e-05 - auc: 0.6134 - prc: 0.1542\n",
      "Epoch 13: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0204 - tp: 1.0000 - fp: 11.0000 - tn: 71774.0000 - fn: 10254.0000 - accuracy: 0.8749 - precision: 0.0833 - recall: 9.7513e-05 - auc: 0.6133 - prc: 0.1542 - val_loss: 0.3618 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4951 - val_prc: 0.1119\n",
      "Epoch 14/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0203 - tp: 3.0000 - fp: 24.0000 - tn: 69752.0000 - fn: 9965.0000 - accuracy: 0.8747 - precision: 0.1111 - recall: 3.0096e-04 - auc: 0.5949 - prc: 0.1447\n",
      "Epoch 14: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 3.0000 - fp: 26.0000 - tn: 71759.0000 - fn: 10252.0000 - accuracy: 0.8747 - precision: 0.1034 - recall: 2.9254e-04 - auc: 0.5955 - prc: 0.1445 - val_loss: 0.3519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5716 - val_prc: 0.1305\n",
      "Epoch 15/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0200 - tp: 9.0000 - fp: 54.0000 - tn: 71066.0000 - fn: 10151.0000 - accuracy: 0.8744 - precision: 0.1429 - recall: 8.8583e-04 - auc: 0.6162 - prc: 0.1467\n",
      "Epoch 15: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 9.0000 - fp: 54.0000 - tn: 71731.0000 - fn: 10246.0000 - accuracy: 0.8745 - precision: 0.1429 - recall: 8.7762e-04 - auc: 0.6158 - prc: 0.1466 - val_loss: 0.3545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5083 - val_prc: 0.1140\n",
      "Epoch 16/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0210 - tp: 1.0000 - fp: 21.0000 - tn: 70427.0000 - fn: 10063.0000 - accuracy: 0.8748 - precision: 0.0455 - recall: 9.9364e-05 - auc: 0.5893 - prc: 0.1404\n",
      "Epoch 16: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0209 - tp: 1.0000 - fp: 21.0000 - tn: 71764.0000 - fn: 10254.0000 - accuracy: 0.8748 - precision: 0.0455 - recall: 9.7513e-05 - auc: 0.5875 - prc: 0.1397 - val_loss: 0.3681 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5016 - val_prc: 0.1125\n",
      "Epoch 17/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.0205 - tp: 0.0000e+00 - fp: 5.0000 - tn: 69659.0000 - fn: 9952.0000 - accuracy: 0.8749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5736 - prc: 0.1331\n",
      "Epoch 17: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0205 - tp: 0.0000e+00 - fp: 5.0000 - tn: 71780.0000 - fn: 10255.0000 - accuracy: 0.8749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5745 - prc: 0.1334 - val_loss: 0.3528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6263 - val_prc: 0.1454\n",
      "Epoch 18/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0204 - tp: 3.0000 - fp: 9.0000 - tn: 70327.0000 - fn: 10045.0000 - accuracy: 0.8749 - precision: 0.2500 - recall: 2.9857e-04 - auc: 0.5777 - prc: 0.1349\n",
      "Epoch 18: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0204 - tp: 3.0000 - fp: 10.0000 - tn: 71775.0000 - fn: 10252.0000 - accuracy: 0.8749 - precision: 0.2308 - recall: 2.9254e-04 - auc: 0.5783 - prc: 0.1351 - val_loss: 0.3483 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6699 - val_prc: 0.1722\n",
      "Epoch 19/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 1.0000 - fp: 8.0000 - tn: 70888.0000 - fn: 10127.0000 - accuracy: 0.8749 - precision: 0.1111 - recall: 9.8736e-05 - auc: 0.5993 - prc: 0.1430\n",
      "Epoch 19: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 1.0000 - fp: 8.0000 - tn: 71777.0000 - fn: 10254.0000 - accuracy: 0.8749 - precision: 0.1111 - recall: 9.7513e-05 - auc: 0.5989 - prc: 0.1429 - val_loss: 0.3577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5180 - val_prc: 0.1210\n",
      "Epoch 20/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 4.0000 - fp: 23.0000 - tn: 70649.0000 - fn: 10092.0000 - accuracy: 0.8748 - precision: 0.1481 - recall: 3.9620e-04 - auc: 0.5864 - prc: 0.1374\n",
      "Epoch 20: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 4.0000 - fp: 23.0000 - tn: 71762.0000 - fn: 10251.0000 - accuracy: 0.8748 - precision: 0.1481 - recall: 3.9005e-04 - auc: 0.5881 - prc: 0.1384 - val_loss: 0.3442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7322 - val_prc: 0.2009\n",
      "Epoch 21/200\n",
      "624/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 13.0000 - fp: 43.0000 - tn: 69845.0000 - fn: 9971.0000 - accuracy: 0.8746 - precision: 0.2321 - recall: 0.0013 - auc: 0.5874 - prc: 0.1370\n",
      "Epoch 21: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0200 - tp: 13.0000 - fp: 43.0000 - tn: 71742.0000 - fn: 10242.0000 - accuracy: 0.8746 - precision: 0.2321 - recall: 0.0013 - auc: 0.5869 - prc: 0.1367 - val_loss: 0.3525 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6173 - val_prc: 0.1423\n",
      "Epoch 22/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0200 - tp: 15.0000 - fp: 43.0000 - tn: 71189.0000 - fn: 10161.0000 - accuracy: 0.8747 - precision: 0.2586 - recall: 0.0015 - auc: 0.6167 - prc: 0.1493\n",
      "Epoch 22: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0200 - tp: 15.0000 - fp: 43.0000 - tn: 71742.0000 - fn: 10240.0000 - accuracy: 0.8747 - precision: 0.2586 - recall: 0.0015 - auc: 0.6160 - prc: 0.1490 - val_loss: 0.3594 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5035 - val_prc: 0.1144\n",
      "Epoch 23/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 9.0000 - fp: 49.0000 - tn: 71295.0000 - fn: 10183.0000 - accuracy: 0.8745 - precision: 0.1552 - recall: 8.8305e-04 - auc: 0.6025 - prc: 0.1424\n",
      "Epoch 23: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 9.0000 - fp: 51.0000 - tn: 71734.0000 - fn: 10246.0000 - accuracy: 0.8745 - precision: 0.1500 - recall: 8.7762e-04 - auc: 0.6026 - prc: 0.1423 - val_loss: 0.3522 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6700 - val_prc: 0.1937\n",
      "Epoch 24/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0199 - tp: 10.0000 - fp: 35.0000 - tn: 71421.0000 - fn: 10198.0000 - accuracy: 0.8747 - precision: 0.2222 - recall: 9.7962e-04 - auc: 0.6097 - prc: 0.1473\n",
      "Epoch 24: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 10.0000 - fp: 35.0000 - tn: 71750.0000 - fn: 10245.0000 - accuracy: 0.8747 - precision: 0.2222 - recall: 9.7513e-04 - auc: 0.6094 - prc: 0.1471 - val_loss: 0.3637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5233 - val_prc: 0.1173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0196 - tp: 13.0000 - fp: 53.0000 - tn: 71515.0000 - fn: 10211.0000 - accuracy: 0.8745 - precision: 0.1970 - recall: 0.0013 - auc: 0.6032 - prc: 0.1468\n",
      "Epoch 25: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0196 - tp: 13.0000 - fp: 53.0000 - tn: 71732.0000 - fn: 10242.0000 - accuracy: 0.8745 - precision: 0.1970 - recall: 0.0013 - auc: 0.6028 - prc: 0.1467 - val_loss: 0.3599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4806 - val_prc: 0.1095\n",
      "Epoch 26/200\n",
      "624/641 [============================>.] - ETA: 0s - loss: 0.0195 - tp: 20.0000 - fp: 44.0000 - tn: 69844.0000 - fn: 9964.0000 - accuracy: 0.8747 - precision: 0.3125 - recall: 0.0020 - auc: 0.6191 - prc: 0.1516\n",
      "Epoch 26: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0196 - tp: 20.0000 - fp: 47.0000 - tn: 71738.0000 - fn: 10235.0000 - accuracy: 0.8747 - precision: 0.2985 - recall: 0.0020 - auc: 0.6176 - prc: 0.1508 - val_loss: 0.3590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5477 - val_prc: 0.1253\n",
      "Epoch 27/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0195 - tp: 15.0000 - fp: 33.0000 - tn: 70639.0000 - fn: 10081.0000 - accuracy: 0.8748 - precision: 0.3125 - recall: 0.0015 - auc: 0.6254 - prc: 0.1542\n",
      "Epoch 27: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0195 - tp: 15.0000 - fp: 33.0000 - tn: 71752.0000 - fn: 10240.0000 - accuracy: 0.8748 - precision: 0.3125 - recall: 0.0015 - auc: 0.6263 - prc: 0.1545 - val_loss: 0.3478 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1279.0000 - val_accuracy: 0.8753 - val_precision: 1.0000 - val_recall: 0.0023 - val_auc: 0.6695 - val_prc: 0.1631\n",
      "Epoch 28/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0210 - tp: 17.0000 - fp: 84.0000 - tn: 71596.0000 - fn: 10223.0000 - accuracy: 0.8742 - precision: 0.1683 - recall: 0.0017 - auc: 0.6217 - prc: 0.1509\n",
      "Epoch 28: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0210 - tp: 17.0000 - fp: 84.0000 - tn: 71701.0000 - fn: 10238.0000 - accuracy: 0.8742 - precision: 0.1683 - recall: 0.0017 - auc: 0.6217 - prc: 0.1509 - val_loss: 0.3536 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5837 - val_prc: 0.1360\n",
      "Epoch 29/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0201 - tp: 9.0000 - fp: 62.0000 - tn: 71723.0000 - fn: 10246.0000 - accuracy: 0.8744 - precision: 0.1268 - recall: 8.7762e-04 - auc: 0.6109 - prc: 0.1446\n",
      "Epoch 29: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 9.0000 - fp: 62.0000 - tn: 71723.0000 - fn: 10246.0000 - accuracy: 0.8744 - precision: 0.1268 - recall: 8.7762e-04 - auc: 0.6109 - prc: 0.1446 - val_loss: 0.3590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6100 - val_prc: 0.1396\n",
      "Epoch 30/200\n",
      "624/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 5.0000 - fp: 35.0000 - tn: 69853.0000 - fn: 9979.0000 - accuracy: 0.8746 - precision: 0.1250 - recall: 5.0080e-04 - auc: 0.6106 - prc: 0.1449\n",
      "Epoch 30: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 5.0000 - fp: 36.0000 - tn: 71749.0000 - fn: 10250.0000 - accuracy: 0.8746 - precision: 0.1220 - recall: 4.8757e-04 - auc: 0.6113 - prc: 0.1453 - val_loss: 0.3515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7520 - val_prc: 0.2419\n",
      "Epoch 31/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.0208 - tp: 2.0000 - fp: 38.0000 - tn: 70074.0000 - fn: 10014.0000 - accuracy: 0.8746 - precision: 0.0500 - recall: 1.9968e-04 - auc: 0.6090 - prc: 0.1493\n",
      "Epoch 31: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0207 - tp: 2.0000 - fp: 41.0000 - tn: 71744.0000 - fn: 10253.0000 - accuracy: 0.8745 - precision: 0.0465 - recall: 1.9503e-04 - auc: 0.6080 - prc: 0.1488 - val_loss: 0.3696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5663 - val_prc: 0.1273\n",
      "Epoch 32/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0206 - tp: 5.0000 - fp: 50.0000 - tn: 69726.0000 - fn: 9963.0000 - accuracy: 0.8744 - precision: 0.0909 - recall: 5.0161e-04 - auc: 0.5930 - prc: 0.1388\n",
      "Epoch 32: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0206 - tp: 5.0000 - fp: 50.0000 - tn: 71735.0000 - fn: 10250.0000 - accuracy: 0.8745 - precision: 0.0909 - recall: 4.8757e-04 - auc: 0.5936 - prc: 0.1391 - val_loss: 0.3520 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7035 - val_prc: 0.1805\n",
      "Epoch 33/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0203 - tp: 6.0000 - fp: 36.0000 - tn: 70300.0000 - fn: 10042.0000 - accuracy: 0.8746 - precision: 0.1429 - recall: 5.9713e-04 - auc: 0.6038 - prc: 0.1471\n",
      "Epoch 33: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0203 - tp: 6.0000 - fp: 37.0000 - tn: 71748.0000 - fn: 10249.0000 - accuracy: 0.8746 - precision: 0.1395 - recall: 5.8508e-04 - auc: 0.6037 - prc: 0.1470 - val_loss: 0.3553 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6084 - val_prc: 0.1419\n",
      "Epoch 34/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 6.0000 - fp: 40.0000 - tn: 69736.0000 - fn: 9962.0000 - accuracy: 0.8746 - precision: 0.1304 - recall: 6.0193e-04 - auc: 0.6029 - prc: 0.1419\n",
      "Epoch 34: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0200 - tp: 6.0000 - fp: 42.0000 - tn: 71743.0000 - fn: 10249.0000 - accuracy: 0.8746 - precision: 0.1250 - recall: 5.8508e-04 - auc: 0.6023 - prc: 0.1415 - val_loss: 0.3525 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6132 - val_prc: 0.1426\n",
      "Epoch 35/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0203 - tp: 2.0000 - fp: 9.0000 - tn: 71447.0000 - fn: 10206.0000 - accuracy: 0.8749 - precision: 0.1818 - recall: 1.9592e-04 - auc: 0.5923 - prc: 0.1380     \n",
      "Epoch 35: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0203 - tp: 2.0000 - fp: 9.0000 - tn: 71776.0000 - fn: 10253.0000 - accuracy: 0.8749 - precision: 0.1818 - recall: 1.9503e-04 - auc: 0.5924 - prc: 0.1380 - val_loss: 0.3580 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6548 - val_prc: 0.1571\n",
      "Epoch 36/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0201 - tp: 3.0000 - fp: 52.0000 - tn: 71733.0000 - fn: 10252.0000 - accuracy: 0.8744 - precision: 0.0545 - recall: 2.9254e-04 - auc: 0.6104 - prc: 0.1432\n",
      "Epoch 36: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 3.0000 - fp: 52.0000 - tn: 71733.0000 - fn: 10252.0000 - accuracy: 0.8744 - precision: 0.0545 - recall: 2.9254e-04 - auc: 0.6104 - prc: 0.1432 - val_loss: 0.3336 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8205 - val_prc: 0.4022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 1.0000 - fp: 50.0000 - tn: 70510.0000 - fn: 10079.0000 - accuracy: 0.8744 - precision: 0.0196 - recall: 9.9206e-05 - auc: 0.6085 - prc: 0.1435   \n",
      "Epoch 37: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0203 - tp: 1.0000 - fp: 50.0000 - tn: 71735.0000 - fn: 10254.0000 - accuracy: 0.8744 - precision: 0.0196 - recall: 9.7513e-05 - auc: 0.6073 - prc: 0.1431 - val_loss: 0.3666 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1158\n",
      "Epoch 38/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 4.0000 - fp: 44.0000 - tn: 69956.0000 - fn: 9996.0000 - accuracy: 0.8745 - precision: 0.0833 - recall: 4.0000e-04 - auc: 0.6013 - prc: 0.1393\n",
      "Epoch 38: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 4.0000 - fp: 46.0000 - tn: 71739.0000 - fn: 10251.0000 - accuracy: 0.8745 - precision: 0.0800 - recall: 3.9005e-04 - auc: 0.6020 - prc: 0.1397 - val_loss: 0.3495 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6800 - val_prc: 0.1740\n",
      "Epoch 39/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.0198 - tp: 8.0000 - fp: 55.0000 - tn: 69497.0000 - fn: 9928.0000 - accuracy: 0.8744 - precision: 0.1270 - recall: 8.0515e-04 - auc: 0.6217 - prc: 0.1506\n",
      "Epoch 39: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 8.0000 - fp: 59.0000 - tn: 71726.0000 - fn: 10247.0000 - accuracy: 0.8744 - precision: 0.1194 - recall: 7.8011e-04 - auc: 0.6201 - prc: 0.1498 - val_loss: 0.3592 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4878 - val_prc: 0.1113\n",
      "Epoch 40/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 3.0000 - fp: 40.0000 - tn: 71640.0000 - fn: 10237.0000 - accuracy: 0.8745 - precision: 0.0698 - recall: 2.9297e-04 - auc: 0.6184 - prc: 0.1521\n",
      "Epoch 40: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 3s 4ms/step - loss: 0.0201 - tp: 3.0000 - fp: 40.0000 - tn: 71745.0000 - fn: 10252.0000 - accuracy: 0.8745 - precision: 0.0698 - recall: 2.9254e-04 - auc: 0.6183 - prc: 0.1520 - val_loss: 0.3619 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4864 - val_prc: 0.1155\n",
      "Epoch 41/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0199 - tp: 7.0000 - fp: 43.0000 - tn: 71637.0000 - fn: 10233.0000 - accuracy: 0.8746 - precision: 0.1400 - recall: 6.8359e-04 - auc: 0.6083 - prc: 0.1440\n",
      "Epoch 41: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 7.0000 - fp: 45.0000 - tn: 71740.0000 - fn: 10248.0000 - accuracy: 0.8745 - precision: 0.1346 - recall: 6.8259e-04 - auc: 0.6083 - prc: 0.1439 - val_loss: 0.3528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6124 - val_prc: 0.1405\n",
      "Epoch 42/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0198 - tp: 6.0000 - fp: 56.0000 - tn: 69720.0000 - fn: 9962.0000 - accuracy: 0.8744 - precision: 0.0968 - recall: 6.0193e-04 - auc: 0.6142 - prc: 0.1468\n",
      "Epoch 42: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 6.0000 - fp: 56.0000 - tn: 71729.0000 - fn: 10249.0000 - accuracy: 0.8744 - precision: 0.0968 - recall: 5.8508e-04 - auc: 0.6145 - prc: 0.1470 - val_loss: 0.3513 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6267 - val_prc: 0.1793\n",
      "Epoch 43/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 5.0000 - fp: 64.0000 - tn: 71280.0000 - fn: 10187.0000 - accuracy: 0.8743 - precision: 0.0725 - recall: 4.9058e-04 - auc: 0.6290 - prc: 0.1542\n",
      "Epoch 43: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 5.0000 - fp: 64.0000 - tn: 71721.0000 - fn: 10250.0000 - accuracy: 0.8743 - precision: 0.0725 - recall: 4.8757e-04 - auc: 0.6294 - prc: 0.1544 - val_loss: 0.3439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7096 - val_prc: 0.1834\n",
      "Epoch 44/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0200 - tp: 1.0000 - fp: 31.0000 - tn: 70753.0000 - fn: 10111.0000 - accuracy: 0.8746 - precision: 0.0312 - recall: 9.8892e-05 - auc: 0.6331 - prc: 0.1606       \n",
      "Epoch 44: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0200 - tp: 1.0000 - fp: 34.0000 - tn: 71751.0000 - fn: 10254.0000 - accuracy: 0.8746 - precision: 0.0286 - recall: 9.7513e-05 - auc: 0.6320 - prc: 0.1599 - val_loss: 0.3603 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6340 - val_prc: 0.1483\n",
      "Epoch 45/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0200 - tp: 3.0000 - fp: 46.0000 - tn: 71298.0000 - fn: 10189.0000 - accuracy: 0.8745 - precision: 0.0612 - recall: 2.9435e-04 - auc: 0.6304 - prc: 0.1548\n",
      "Epoch 45: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 3.0000 - fp: 46.0000 - tn: 71739.0000 - fn: 10252.0000 - accuracy: 0.8745 - precision: 0.0612 - recall: 2.9254e-04 - auc: 0.6308 - prc: 0.1551 - val_loss: 0.3400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7154 - val_prc: 0.2137\n",
      "Epoch 46/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0199 - tp: 9.0000 - fp: 90.0000 - tn: 70358.0000 - fn: 10055.0000 - accuracy: 0.8740 - precision: 0.0909 - recall: 8.9428e-04 - auc: 0.6210 - prc: 0.1532\n",
      "Epoch 46: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 9.0000 - fp: 90.0000 - tn: 71695.0000 - fn: 10246.0000 - accuracy: 0.8740 - precision: 0.0909 - recall: 8.7762e-04 - auc: 0.6216 - prc: 0.1536 - val_loss: 0.3491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6908 - val_prc: 0.1758\n",
      "Epoch 47/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 6.0000 - fp: 47.0000 - tn: 69617.0000 - fn: 9946.0000 - accuracy: 0.8745 - precision: 0.1132 - recall: 6.0289e-04 - auc: 0.6184 - prc: 0.1531\n",
      "Epoch 47: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 6.0000 - fp: 47.0000 - tn: 71738.0000 - fn: 10249.0000 - accuracy: 0.8745 - precision: 0.1132 - recall: 5.8508e-04 - auc: 0.6195 - prc: 0.1532 - val_loss: 0.3555 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6285 - val_prc: 0.1465\n",
      "Epoch 48/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0201 - tp: 4.0000 - fp: 78.0000 - tn: 71707.0000 - fn: 10251.0000 - accuracy: 0.8741 - precision: 0.0488 - recall: 3.9005e-04 - auc: 0.6172 - prc: 0.1481\n",
      "Epoch 48: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 4.0000 - fp: 78.0000 - tn: 71707.0000 - fn: 10251.0000 - accuracy: 0.8741 - precision: 0.0488 - recall: 3.9005e-04 - auc: 0.6172 - prc: 0.1481 - val_loss: 0.3435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7908 - val_prc: 0.2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 12.0000 - fp: 96.0000 - tn: 71248.0000 - fn: 10180.0000 - accuracy: 0.8740 - precision: 0.1111 - recall: 0.0012 - auc: 0.6224 - prc: 0.1517\n",
      "Epoch 49: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0200 - tp: 12.0000 - fp: 96.0000 - tn: 71689.0000 - fn: 10243.0000 - accuracy: 0.8740 - precision: 0.1111 - recall: 0.0012 - auc: 0.6226 - prc: 0.1518 - val_loss: 0.3590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6725 - val_prc: 0.1767\n",
      "Epoch 50/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0201 - tp: 1.0000 - fp: 32.0000 - tn: 71088.0000 - fn: 10159.0000 - accuracy: 0.8746 - precision: 0.0303 - recall: 9.8425e-05 - auc: 0.6113 - prc: 0.1469       \n",
      "Epoch 50: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0201 - tp: 1.0000 - fp: 34.0000 - tn: 71751.0000 - fn: 10254.0000 - accuracy: 0.8746 - precision: 0.0286 - recall: 9.7513e-05 - auc: 0.6114 - prc: 0.1469 - val_loss: 0.3512 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6155 - val_prc: 0.1422\n",
      "Epoch 51/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0200 - tp: 3.0000 - fp: 73.0000 - tn: 71383.0000 - fn: 10205.0000 - accuracy: 0.8741 - precision: 0.0395 - recall: 2.9389e-04 - auc: 0.6313 - prc: 0.1543\n",
      "Epoch 51: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0200 - tp: 3.0000 - fp: 75.0000 - tn: 71710.0000 - fn: 10252.0000 - accuracy: 0.8741 - precision: 0.0385 - recall: 2.9254e-04 - auc: 0.6313 - prc: 0.1543 - val_loss: 0.3465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7230 - val_prc: 0.2152\n",
      "Epoch 52/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0202 - tp: 2.0000 - fp: 59.0000 - tn: 71397.0000 - fn: 10206.0000 - accuracy: 0.8743 - precision: 0.0328 - recall: 1.9592e-04 - auc: 0.6108 - prc: 0.1551\n",
      "Epoch 52: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0202 - tp: 2.0000 - fp: 59.0000 - tn: 71726.0000 - fn: 10253.0000 - accuracy: 0.8743 - precision: 0.0328 - recall: 1.9503e-04 - auc: 0.6112 - prc: 0.1554 - val_loss: 0.3347 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7861 - val_prc: 0.2608\n",
      "Epoch 53/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0200 - tp: 9.0000 - fp: 63.0000 - tn: 70385.0000 - fn: 10055.0000 - accuracy: 0.8743 - precision: 0.1250 - recall: 8.9428e-04 - auc: 0.5969 - prc: 0.1434\n",
      "Epoch 53: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 10.0000 - fp: 64.0000 - tn: 71721.0000 - fn: 10245.0000 - accuracy: 0.8743 - precision: 0.1351 - recall: 9.7513e-04 - auc: 0.5979 - prc: 0.1437 - val_loss: 0.3464 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7292 - val_prc: 0.1944\n",
      "Epoch 54/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0199 - tp: 15.0000 - fp: 81.0000 - tn: 70927.0000 - fn: 10129.0000 - accuracy: 0.8742 - precision: 0.1562 - recall: 0.0015 - auc: 0.6229 - prc: 0.1555\n",
      "Epoch 54: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0199 - tp: 15.0000 - fp: 81.0000 - tn: 71704.0000 - fn: 10240.0000 - accuracy: 0.8742 - precision: 0.1562 - recall: 0.0015 - auc: 0.6234 - prc: 0.1557 - val_loss: 0.3476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7834 - val_prc: 0.2696\n",
      "Epoch 55/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0205 - tp: 8.0000 - fp: 86.0000 - tn: 69914.0000 - fn: 9992.0000 - accuracy: 0.8740 - precision: 0.0851 - recall: 8.0000e-04 - auc: 0.6277 - prc: 0.1548\n",
      "Epoch 55: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0206 - tp: 8.0000 - fp: 86.0000 - tn: 71699.0000 - fn: 10247.0000 - accuracy: 0.8740 - precision: 0.0851 - recall: 7.8011e-04 - auc: 0.6239 - prc: 0.1535 - val_loss: 0.3852 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4624 - val_prc: 0.1073\n",
      "Epoch 56/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0203 - tp: 5.0000 - fp: 22.0000 - tn: 71546.0000 - fn: 10219.0000 - accuracy: 0.8748 - precision: 0.1852 - recall: 4.8905e-04 - auc: 0.5918 - prc: 0.1374\n",
      "Epoch 56: val_loss did not improve from 0.41194\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0203 - tp: 5.0000 - fp: 22.0000 - tn: 71763.0000 - fn: 10250.0000 - accuracy: 0.8748 - precision: 0.1852 - recall: 4.8757e-04 - auc: 0.5918 - prc: 0.1374 - val_loss: 0.3449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 8974.0000 - val_fn: 1282.0000 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7635 - val_prc: 0.2219\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "#checkpoint_path = \"weights.best.hdf5\"\n",
    "\n",
    "checkpoint_path = \"weights.SigmoidFocalCrossEntropyWithClassWeightsNoNorm\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "\n",
    "history = model.fit(X_train, y_train,class_weight= class_weights,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de5d2ebc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b6d6f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20634a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3443 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 8974.0000 - fn: 1282.0000 - accuracy: 0.8750 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7630 - prc: 0.2229\n"
     ]
    }
   ],
   "source": [
    "loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b06d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "\n",
      "Classification Report for No Normalization:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       666\n",
      "           2       0.00      0.00      0.00       317\n",
      "           3       0.10      1.00      0.18       125\n",
      "           4       0.00      0.00      0.00        51\n",
      "           5       0.00      0.00      0.00        46\n",
      "           6       0.27      0.75      0.40         8\n",
      "           7       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.10      1282\n",
      "   macro avg       0.05      0.25      0.08      1282\n",
      "weighted avg       0.01      0.10      0.02      1282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
    "y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report for No Normalization:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c23041",
   "metadata": {},
   "source": [
    "## Normalize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28566ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 51)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 17, 3)        0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 17, 2)       0           ['reshape_3[0][0]']              \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_9 (TFOpLam  (None, 2)           0           ['tf.__operators__.getitem_3[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_10 (TFOpLa  (None, 2)           0           ['tf.__operators__.getitem_3[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_9[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_10[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 2)           0           ['tf.math.multiply_9[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_10[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_2 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_3[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_2 (TFOp  ()                  0           ['tf.compat.v1.size_2[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.broadcast_to_2 (TFOpLambda)  (None, 17, 2)       0           ['tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 17, 2)       0           ['tf.__operators__.getitem_3[0][0\n",
      " )                                                               ]',                              \n",
      "                                                                  'tf.broadcast_to_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_15 (TFOpLa  (None, 2)           0           ['tf.math.subtract_3[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_16 (TFOpLa  (None, 2)           0           ['tf.math.subtract_3[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_15[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_16[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 2)           0           ['tf.math.multiply_15[0][0]',    \n",
      " mbda)                                                            'tf.math.multiply_16[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_3 (TFOpLambd  ()                  0           ['tf.math.subtract_3[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_13 (TFOpLa  (None, 2)           0           ['tf.math.subtract_3[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_14 (TFOpLa  (None, 2)           0           ['tf.math.subtract_3[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_11 (TFOpLa  (None, 2)           0           ['tf.math.subtract_3[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_12 (TFOpLa  (None, 2)           0           ['tf.math.subtract_3[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_3 (TFOp  ()                  0           ['tf.compat.v1.size_3[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_13[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_14[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_11[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_12[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.broadcast_to_3 (TFOpLambda)  (None, 17, 2)       0           ['tf.expand_dims_3[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 2)           0           ['tf.math.multiply_13[0][0]',    \n",
      " mbda)                                                            'tf.math.multiply_14[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 2)           0           ['tf.math.multiply_11[0][0]',    \n",
      " mbda)                                                            'tf.math.multiply_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.subtract_5 (TFOpLambda  (None, 17, 2)       0           ['tf.math.subtract_3[0][0]',     \n",
      " )                                                                'tf.broadcast_to_3[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_4 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_6[0][0]', \n",
      " )                                                                'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_17 (TFOpLa  (17, 2)             0           ['tf.math.subtract_5[0][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_2 (TFOpLambd  ()                  0           ['tf.math.subtract_4[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_3 (TFOpLambd  (2,)                0           ['tf.compat.v1.gather_17[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  ()                  0           ['tf.compat.v1.norm_2[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['tf.compat.v1.norm_3[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.maximum_1 (TFOpLambda)  ()                  0           ['tf.math.multiply_17[0][0]',    \n",
      "                                                                  'tf.math.reduce_max_1[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLambda)  (None, 17, 2)       0           ['tf.math.subtract_3[0][0]',     \n",
      "                                                                  'tf.math.maximum_1[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 34)           0           ['tf.math.truediv_1[0][0]']      \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          4480        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 128)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           8256        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 8)            520         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,256\n",
      "Trainable params: 13,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = landmarks_to_embedding(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9df7224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.6636\n",
      "Epoch 1: val_loss improved from -inf to 0.12713, saving model to weights.SigmoidFocalCrossEntropyWithClassWeightsAllNorm\n",
      "INFO:tensorflow:Assets written to: weights.SigmoidFocalCrossEntropyWithClassWeightsAllNorm/assets\n",
      "641/641 [==============================] - 4s 5ms/step - loss: 0.1958 - accuracy: 0.6642 - val_loss: 0.1271 - val_accuracy: 0.7730\n",
      "Epoch 2/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.7567\n",
      "Epoch 2: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1446 - accuracy: 0.7578 - val_loss: 0.1062 - val_accuracy: 0.8097\n",
      "Epoch 3/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.7799\n",
      "Epoch 3: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.7791 - val_loss: 0.1031 - val_accuracy: 0.8307\n",
      "Epoch 4/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.1236 - accuracy: 0.7891\n",
      "Epoch 4: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1236 - accuracy: 0.7895 - val_loss: 0.0940 - val_accuracy: 0.8339\n",
      "Epoch 5/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.7954\n",
      "Epoch 5: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.7945 - val_loss: 0.1014 - val_accuracy: 0.8151\n",
      "Epoch 6/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.8031\n",
      "Epoch 6: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.1146 - accuracy: 0.8032 - val_loss: 0.0891 - val_accuracy: 0.8471\n",
      "Epoch 7/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.8049\n",
      "Epoch 7: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.8040 - val_loss: 0.0861 - val_accuracy: 0.8432\n",
      "Epoch 8/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.8055\n",
      "Epoch 8: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.8057 - val_loss: 0.0846 - val_accuracy: 0.8432\n",
      "Epoch 9/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.8160\n",
      "Epoch 9: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.8160 - val_loss: 0.0819 - val_accuracy: 0.8518\n",
      "Epoch 10/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.8134\n",
      "Epoch 10: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.1061 - accuracy: 0.8135 - val_loss: 0.0813 - val_accuracy: 0.8619\n",
      "Epoch 11/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.1027 - accuracy: 0.8201\n",
      "Epoch 11: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.1024 - accuracy: 0.8201 - val_loss: 0.0804 - val_accuracy: 0.8534\n",
      "Epoch 12/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.8182\n",
      "Epoch 12: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.1036 - accuracy: 0.8178 - val_loss: 0.0791 - val_accuracy: 0.8658\n",
      "Epoch 13/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.1012 - accuracy: 0.8247\n",
      "Epoch 13: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.8255 - val_loss: 0.0773 - val_accuracy: 0.8674\n",
      "Epoch 14/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0995 - accuracy: 0.8265\n",
      "Epoch 14: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.8265 - val_loss: 0.0774 - val_accuracy: 0.8682\n",
      "Epoch 15/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.8335\n",
      "Epoch 15: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.8334 - val_loss: 0.0759 - val_accuracy: 0.8768\n",
      "Epoch 16/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.8299\n",
      "Epoch 16: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.8299 - val_loss: 0.0733 - val_accuracy: 0.8768\n",
      "Epoch 17/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.8325\n",
      "Epoch 17: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.8324 - val_loss: 0.0727 - val_accuracy: 0.8768\n",
      "Epoch 18/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 0.8346\n",
      "Epoch 18: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0952 - accuracy: 0.8344 - val_loss: 0.0728 - val_accuracy: 0.8838\n",
      "Epoch 19/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.8355\n",
      "Epoch 19: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.8368 - val_loss: 0.0715 - val_accuracy: 0.8846\n",
      "Epoch 20/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.8401\n",
      "Epoch 20: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0925 - accuracy: 0.8400 - val_loss: 0.0708 - val_accuracy: 0.8853\n",
      "Epoch 21/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.8395\n",
      "Epoch 21: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.8395 - val_loss: 0.0685 - val_accuracy: 0.8892\n",
      "Epoch 22/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.8443\n",
      "Epoch 22: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.8447 - val_loss: 0.0691 - val_accuracy: 0.8916\n",
      "Epoch 23/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.8423\n",
      "Epoch 23: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.8424 - val_loss: 0.0692 - val_accuracy: 0.8916\n",
      "Epoch 24/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0908 - accuracy: 0.8422\n",
      "Epoch 24: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.8423 - val_loss: 0.0678 - val_accuracy: 0.8939\n",
      "Epoch 25/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.8473\n",
      "Epoch 25: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.8471 - val_loss: 0.0681 - val_accuracy: 0.8924\n",
      "Epoch 26/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.8490\n",
      "Epoch 26: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.8490 - val_loss: 0.0662 - val_accuracy: 0.8994\n",
      "Epoch 27/200\n",
      "619/641 [===========================>..] - ETA: 0s - loss: 0.0877 - accuracy: 0.8536\n",
      "Epoch 27: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.8533 - val_loss: 0.0667 - val_accuracy: 0.8947\n",
      "Epoch 28/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.8522\n",
      "Epoch 28: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.8523 - val_loss: 0.0653 - val_accuracy: 0.9002\n",
      "Epoch 29/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.8472\n",
      "Epoch 29: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8471 - val_loss: 0.0683 - val_accuracy: 0.8978\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/641 [============================>.] - ETA: 0s - loss: 0.0869 - accuracy: 0.8516\n",
      "Epoch 30: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.8515 - val_loss: 0.0672 - val_accuracy: 0.8994\n",
      "Epoch 31/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 0.8502\n",
      "Epoch 31: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.8500 - val_loss: 0.0667 - val_accuracy: 0.8986\n",
      "Epoch 32/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.8523\n",
      "Epoch 32: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.8529 - val_loss: 0.0645 - val_accuracy: 0.9048\n",
      "Epoch 33/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.8580\n",
      "Epoch 33: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0833 - accuracy: 0.8584 - val_loss: 0.0627 - val_accuracy: 0.9033\n",
      "Epoch 34/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.8577\n",
      "Epoch 34: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0856 - accuracy: 0.8579 - val_loss: 0.0648 - val_accuracy: 0.9056\n",
      "Epoch 35/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.8550\n",
      "Epoch 35: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.8550 - val_loss: 0.0659 - val_accuracy: 0.8931\n",
      "Epoch 36/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 0.8551\n",
      "Epoch 36: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8552 - val_loss: 0.0617 - val_accuracy: 0.9017\n",
      "Epoch 37/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.8583\n",
      "Epoch 37: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.8589 - val_loss: 0.0633 - val_accuracy: 0.9056\n",
      "Epoch 38/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.8603\n",
      "Epoch 38: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8606 - val_loss: 0.0607 - val_accuracy: 0.9064\n",
      "Epoch 39/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 0.8601\n",
      "Epoch 39: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8603 - val_loss: 0.0616 - val_accuracy: 0.9064\n",
      "Epoch 40/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.0840 - accuracy: 0.8551\n",
      "Epoch 40: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8545 - val_loss: 0.0624 - val_accuracy: 0.9041\n",
      "Epoch 41/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.8596\n",
      "Epoch 41: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8601 - val_loss: 0.0625 - val_accuracy: 0.9056\n",
      "Epoch 42/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.8606\n",
      "Epoch 42: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8609 - val_loss: 0.0618 - val_accuracy: 0.9072\n",
      "Epoch 43/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0817 - accuracy: 0.8590\n",
      "Epoch 43: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0816 - accuracy: 0.8594 - val_loss: 0.0606 - val_accuracy: 0.9048\n",
      "Epoch 44/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0821 - accuracy: 0.8623\n",
      "Epoch 44: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8627 - val_loss: 0.0603 - val_accuracy: 0.9048\n",
      "Epoch 45/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.8604\n",
      "Epoch 45: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0818 - accuracy: 0.8596 - val_loss: 0.0604 - val_accuracy: 0.9017\n",
      "Epoch 46/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.8618\n",
      "Epoch 46: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.8618 - val_loss: 0.0602 - val_accuracy: 0.9048\n",
      "Epoch 47/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.8628\n",
      "Epoch 47: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.8628 - val_loss: 0.0601 - val_accuracy: 0.9041\n",
      "Epoch 48/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.8649\n",
      "Epoch 48: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.8647 - val_loss: 0.0628 - val_accuracy: 0.9002\n",
      "Epoch 49/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 0.8637\n",
      "Epoch 49: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.8630 - val_loss: 0.0617 - val_accuracy: 0.9064\n",
      "Epoch 50/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.8607\n",
      "Epoch 50: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.8610 - val_loss: 0.0613 - val_accuracy: 0.9080\n",
      "Epoch 51/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.8635\n",
      "Epoch 51: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.8630 - val_loss: 0.0606 - val_accuracy: 0.9072\n",
      "Epoch 52/200\n",
      "619/641 [===========================>..] - ETA: 0s - loss: 0.0801 - accuracy: 0.8629\n",
      "Epoch 52: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.8635 - val_loss: 0.0600 - val_accuracy: 0.9064\n",
      "Epoch 53/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.8641\n",
      "Epoch 53: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.8640 - val_loss: 0.0622 - val_accuracy: 0.9025\n",
      "Epoch 54/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.8655\n",
      "Epoch 54: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.8672 - val_loss: 0.0585 - val_accuracy: 0.9103\n",
      "Epoch 55/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0799 - accuracy: 0.8651\n",
      "Epoch 55: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0801 - accuracy: 0.8645 - val_loss: 0.0588 - val_accuracy: 0.9095\n",
      "Epoch 56/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.8637\n",
      "Epoch 56: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.8633 - val_loss: 0.0583 - val_accuracy: 0.9095\n",
      "Epoch 57/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 0.8659\n",
      "Epoch 57: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0786 - accuracy: 0.8659 - val_loss: 0.0581 - val_accuracy: 0.9087\n",
      "Epoch 58/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.8645\n",
      "Epoch 58: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.8645 - val_loss: 0.0622 - val_accuracy: 0.9072\n",
      "Epoch 59/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.8630\n",
      "Epoch 59: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.8630 - val_loss: 0.0581 - val_accuracy: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.8715\n",
      "Epoch 60: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.8715 - val_loss: 0.0596 - val_accuracy: 0.9111\n",
      "Epoch 61/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.8663\n",
      "Epoch 61: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8665 - val_loss: 0.0580 - val_accuracy: 0.9080\n",
      "Epoch 62/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 0.8714\n",
      "Epoch 62: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.8713 - val_loss: 0.0587 - val_accuracy: 0.9103\n",
      "Epoch 63/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0779 - accuracy: 0.8691\n",
      "Epoch 63: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.8693 - val_loss: 0.0583 - val_accuracy: 0.9134\n",
      "Epoch 64/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.8685\n",
      "Epoch 64: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.8685 - val_loss: 0.0578 - val_accuracy: 0.9080\n",
      "Epoch 65/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.8711\n",
      "Epoch 65: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.8715 - val_loss: 0.0570 - val_accuracy: 0.9126\n",
      "Epoch 66/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.8678\n",
      "Epoch 66: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.8686 - val_loss: 0.0589 - val_accuracy: 0.9165\n",
      "Epoch 67/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.8691\n",
      "Epoch 67: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.8691 - val_loss: 0.0574 - val_accuracy: 0.9103\n",
      "Epoch 68/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.8686\n",
      "Epoch 68: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8688 - val_loss: 0.0576 - val_accuracy: 0.9134\n",
      "Epoch 69/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.8686\n",
      "Epoch 69: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.8685 - val_loss: 0.0580 - val_accuracy: 0.9142\n",
      "Epoch 70/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.8704\n",
      "Epoch 70: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0762 - accuracy: 0.8702 - val_loss: 0.0584 - val_accuracy: 0.9080\n",
      "Epoch 71/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.8691\n",
      "Epoch 71: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8690 - val_loss: 0.0586 - val_accuracy: 0.9134\n",
      "Epoch 72/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0762 - accuracy: 0.8731\n",
      "Epoch 72: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0763 - accuracy: 0.8730 - val_loss: 0.0579 - val_accuracy: 0.9119\n",
      "Epoch 73/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.8672\n",
      "Epoch 73: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 3s 4ms/step - loss: 0.0775 - accuracy: 0.8681 - val_loss: 0.0575 - val_accuracy: 0.9150\n",
      "Epoch 74/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.8695\n",
      "Epoch 74: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8695 - val_loss: 0.0565 - val_accuracy: 0.9041\n",
      "Epoch 75/200\n",
      "627/641 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.8757\n",
      "Epoch 75: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8757 - val_loss: 0.0563 - val_accuracy: 0.9126\n",
      "Epoch 76/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.8705\n",
      "Epoch 76: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.8708 - val_loss: 0.0556 - val_accuracy: 0.9158\n",
      "Epoch 77/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.8727\n",
      "Epoch 77: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.8725 - val_loss: 0.0545 - val_accuracy: 0.9150\n",
      "Epoch 78/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.8699\n",
      "Epoch 78: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.8696 - val_loss: 0.0578 - val_accuracy: 0.9134\n",
      "Epoch 79/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.8726\n",
      "Epoch 79: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.8721 - val_loss: 0.0542 - val_accuracy: 0.9173\n",
      "Epoch 80/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.8763\n",
      "Epoch 80: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.8763 - val_loss: 0.0549 - val_accuracy: 0.9189\n",
      "Epoch 81/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0759 - accuracy: 0.8730\n",
      "Epoch 81: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0752 - accuracy: 0.8740 - val_loss: 0.0549 - val_accuracy: 0.9119\n",
      "Epoch 82/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0747 - accuracy: 0.8716\n",
      "Epoch 82: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8724 - val_loss: 0.0552 - val_accuracy: 0.9189\n",
      "Epoch 83/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.8740\n",
      "Epoch 83: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0757 - accuracy: 0.8738 - val_loss: 0.0553 - val_accuracy: 0.9165\n",
      "Epoch 84/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0739 - accuracy: 0.8765\n",
      "Epoch 84: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.8757 - val_loss: 0.0571 - val_accuracy: 0.9087\n",
      "Epoch 85/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.8653\n",
      "Epoch 85: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.8654 - val_loss: 0.0538 - val_accuracy: 0.9150\n",
      "Epoch 86/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.8761\n",
      "Epoch 86: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.8758 - val_loss: 0.0533 - val_accuracy: 0.9212\n",
      "Epoch 87/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.8764\n",
      "Epoch 87: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.8766 - val_loss: 0.0541 - val_accuracy: 0.9134\n",
      "Epoch 88/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.8724\n",
      "Epoch 88: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.8731 - val_loss: 0.0561 - val_accuracy: 0.9158\n",
      "Epoch 89/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.8702\n",
      "Epoch 89: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8698 - val_loss: 0.0560 - val_accuracy: 0.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.8729\n",
      "Epoch 90: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8731 - val_loss: 0.0545 - val_accuracy: 0.9150\n",
      "Epoch 91/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.8760\n",
      "Epoch 91: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.8757 - val_loss: 0.0561 - val_accuracy: 0.9173\n",
      "Epoch 92/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.8717\n",
      "Epoch 92: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.8718 - val_loss: 0.0561 - val_accuracy: 0.9119\n",
      "Epoch 93/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.8731\n",
      "Epoch 93: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0731 - accuracy: 0.8734 - val_loss: 0.0552 - val_accuracy: 0.9103\n",
      "Epoch 94/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.8760\n",
      "Epoch 94: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8762 - val_loss: 0.0547 - val_accuracy: 0.9173\n",
      "Epoch 95/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.8745\n",
      "Epoch 95: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.8745 - val_loss: 0.0555 - val_accuracy: 0.9134\n",
      "Epoch 96/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0742 - accuracy: 0.8750\n",
      "Epoch 96: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.8736 - val_loss: 0.0547 - val_accuracy: 0.9103\n",
      "Epoch 97/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.8767\n",
      "Epoch 97: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8769 - val_loss: 0.0539 - val_accuracy: 0.9189\n",
      "Epoch 98/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.8733\n",
      "Epoch 98: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.8743 - val_loss: 0.0534 - val_accuracy: 0.9189\n",
      "Epoch 99/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.8756\n",
      "Epoch 99: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.8758 - val_loss: 0.0541 - val_accuracy: 0.9173\n",
      "Epoch 100/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.8745\n",
      "Epoch 100: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.8745 - val_loss: 0.0531 - val_accuracy: 0.9181\n",
      "Epoch 101/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.8769\n",
      "Epoch 101: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.8767 - val_loss: 0.0564 - val_accuracy: 0.9126\n",
      "Epoch 102/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.8765\n",
      "Epoch 102: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.8760 - val_loss: 0.0516 - val_accuracy: 0.9212\n",
      "Epoch 103/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.8772\n",
      "Epoch 103: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8771 - val_loss: 0.0548 - val_accuracy: 0.9126\n",
      "Epoch 104/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.8800\n",
      "Epoch 104: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8801 - val_loss: 0.0548 - val_accuracy: 0.9165\n",
      "Epoch 105/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0747 - accuracy: 0.8750\n",
      "Epoch 105: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0747 - accuracy: 0.8750 - val_loss: 0.0550 - val_accuracy: 0.9173\n",
      "Epoch 106/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.8757\n",
      "Epoch 106: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.8763 - val_loss: 0.0549 - val_accuracy: 0.9150\n",
      "Epoch 107/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.8778\n",
      "Epoch 107: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.8773 - val_loss: 0.0553 - val_accuracy: 0.9197\n",
      "Epoch 108/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.8797\n",
      "Epoch 108: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.8803 - val_loss: 0.0544 - val_accuracy: 0.9204\n",
      "Epoch 109/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.8750\n",
      "Epoch 109: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8748 - val_loss: 0.0551 - val_accuracy: 0.9189\n",
      "Epoch 110/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.8800\n",
      "Epoch 110: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.8797 - val_loss: 0.0543 - val_accuracy: 0.9111\n",
      "Epoch 111/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.8817\n",
      "Epoch 111: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.8816 - val_loss: 0.0543 - val_accuracy: 0.9197\n",
      "Epoch 112/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.8746\n",
      "Epoch 112: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8751 - val_loss: 0.0530 - val_accuracy: 0.9212\n",
      "Epoch 113/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.8765\n",
      "Epoch 113: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 4ms/step - loss: 0.0741 - accuracy: 0.8763 - val_loss: 0.0541 - val_accuracy: 0.9212\n",
      "Epoch 114/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.8733\n",
      "Epoch 114: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.8728 - val_loss: 0.0524 - val_accuracy: 0.9181\n",
      "Epoch 115/200\n",
      "627/641 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.8772\n",
      "Epoch 115: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.8776 - val_loss: 0.0550 - val_accuracy: 0.9134\n",
      "Epoch 116/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.8751\n",
      "Epoch 116: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8761 - val_loss: 0.0537 - val_accuracy: 0.9189\n",
      "Epoch 117/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.8764\n",
      "Epoch 117: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.8757 - val_loss: 0.0532 - val_accuracy: 0.9282\n",
      "Epoch 118/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0719 - accuracy: 0.8787\n",
      "Epoch 118: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.8787 - val_loss: 0.0549 - val_accuracy: 0.9197\n",
      "Epoch 119/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.8776\n",
      "Epoch 119: val_loss did not improve from 0.12713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.8778 - val_loss: 0.0531 - val_accuracy: 0.9251\n",
      "Epoch 120/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.8814\n",
      "Epoch 120: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.8809 - val_loss: 0.0528 - val_accuracy: 0.9189\n",
      "Epoch 121/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.8780\n",
      "Epoch 121: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.8780 - val_loss: 0.0518 - val_accuracy: 0.9204\n",
      "Epoch 122/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.8792\n",
      "Epoch 122: val_loss did not improve from 0.12713\n",
      "641/641 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8796 - val_loss: 0.0551 - val_accuracy: 0.9158\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "#checkpoint_path = \"weights.best.hdf5\"\n",
    "\n",
    "checkpoint_path = \"weights.SigmoidFocalCrossEntropyWithClassWeightsAllNorm\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f913d8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABEnklEQVR4nO3dd3hUVfrA8e+bQgqEFkJLCKE3gQChKoogCjbEgmBFVOxdd9eyrrvq/nTtBQULFkRAxYINCyJgAem9BgIkAVKAhIT0Ob8/ziSZhAlMIMOQ5P08T56Z22beG8h97yn3HDHGoJRSSpXn5+sAlFJKnZo0QSillHJLE4RSSim3NEEopZRySxOEUkoptzRBKKWUcksThKr1RCRGRIyIBHiw73gR+e1kxKWUr2mCUNWKiCSISL6INCm3fpXzIh/jo9CUqnE0QajqaAcwrnhBRLoDIb4L59TgSQlIqcrQBKGqo2nAdS7L1wMfuu4gIg1E5EMRSRWRnSLymIj4Obf5i8jzIpImItuBC9wc+66I7BGRJBF5SkT8PQlMRD4Vkb0ikiEiC0Wkm8u2EBF5wRlPhoj8JiIhzm1niMgfInJQRHaLyHjn+l9F5CaXzyhTxeUsNd0hIluBrc51rzg/I1NElovIYJf9/UXkERGJF5FDzu2tRGSSiLxQ7ly+FpF7PTlvVTNpglDV0WKgvoh0cV64rwQ+KrfPa0ADoC1wFjah3ODcdjNwIdALiAMuL3fsB0Ah0N65z7nATXjme6AD0BRYAUx32fY80AcYBDQG/gY4RCTaedxrQAQQC6zy8PsALgH6A12dy0udn9EY+Bj4VESCndvux5a+zgfqAxOAw9hzHueSRJsAw4AZlYhD1TTGGP3Rn2rzAyQA5wCPAf8HjAB+AgIAA8QA/kAe0NXluFuAX53vfwFuddl2rvPYAKCZ89gQl+3jgPnO9+OB3zyMtaHzcxtgb8ZygJ5u9nsY+KKCz/gVuMllucz3Oz9/6DHiOFD8vcBmYFQF+20Ehjvf3wl85+t/b/3x7Y/WWarqahqwEGhDueoloAlQB9jpsm4nEOl83xLYXW5bsdZAILBHRIrX+ZXb3y1naeZp4ApsScDhEk8QEAzEuzm0VQXrPVUmNhF5AFviaYlNIPWdMRzruz4ArsEm3GuAV04gJlUDaBWTqpaMMTuxjdXnA5+X25wGFGAv9sWigSTn+z3YC6XrtmK7sSWIJsaYhs6f+saYbhzbVcAobAmnAbY0AyDOmHKBdm6O213BeoBsINRlubmbfUqGZHa2N/wdGAM0MsY0BDKcMRzruz4CRolIT6AL8GUF+6laQhOEqs5uxFavZLuuNMYUAZ8AT4tImIi0xta9F7dTfALcLSJRItII+IfLsXuAH4EXRKS+iPiJSDsROcuDeMKwySUde1H/r8vnOoCpwIsi0tLZWDxQRIKw7RTniMgYEQkQkXARiXUeugq4VERCRaS985yPFUMhkAoEiMjj2BJEsXeAJ0Wkg1g9RCTcGWMitv1iGjDbGJPjwTmrGkwThKq2jDHxxphlFWy+C3v3vR34DdtYO9W57W3gB2A1tiG5fAnkOmwV1QZs/f1nQAsPQvoQW12V5Dx2cbntDwJrsRfh/cCzgJ8xZhe2JPSAc/0qoKfzmJeAfGAftgpoOkf3A7bBe4szllzKVkG9iE2QPwKZwLuU7SL8AdAdmyRULSfG6IRBSilLRM7ElrRinKUeVYtpCUIpBYCIBAL3AO9oclCgCUIpBYhIF+AgtirtZZ8Go04ZWsWklFLKLS1BKKWUcqtGPSjXpEkTExMT4+swlFKq2li+fHmaMSbC3bYalSBiYmJYtqyiXo9KKaXKE5GdFW3TKiallFJuaYJQSinlliYIpZRSbmmCUEop5ZYmCKWUUm5pglBKKeWWJgillFJuaYJQSqlThaMIlr0HeYd8HQmgCUIppU4dm7+Hb+6FxZN9HQmgCUIppU4daz+xrys/BIfLiOu5mT4JRxOEUkqdCnIOwua50LgtHNwFO36163cthufa2aqnk0wThFJKnQo2zoGiPBj1BoQ0ghUfQlEBfHMfFOXD/KdPetuEJgillHekbS1bTXKqyUyGvCzvf8eORfYnaTkcbf6dNZ9AeHuIHgA9xsLGb+CXpyBlAwx+ALJT4c9J3o23HE0QSqmqt2MRvB4Hy6f6OhL3CnJh8mB7d14ZB3fbC/m3D8LC5+Hwfvf77VsPn98CL3eHDy60P28PhTl32Z5K7j43YRH0uBJEoPd14CiA31+GTufDsMehy8Xwx2uQlQK7l8I390PqlkqfemXUqOG+lVJV6MBO2PYTxF4NgSF2XWE+rJ5hL1r13E4hYO+Sf3rcvl88GfpMAD8v34se3A2rPgbjsBfYmDOg9en2vTsbv4bDabDhSxj5LIQ2PvZ3rJoBX94GGAisCwXZsOhF6DsBhv0L/APtfruWwHsjICAE+k2EjiNA/GDbz/aCn5sBl70DAUGln73uM/va/Qr72qwrRPW1iWbks3bdsMdh07cw+QzI2mfX7fwdJv5a+u9TxTRBKKXKSt0CC/8H6z4HU2SrYc64125b8QF89yD88iRc/Bp0Gnnk8Ru+guQV0OFc2PojxP8CHc459vdmpdqLdtMu7rfv2wCNWkOdukdu++UpWDOz7LrIPtD1EnuRTVoOcRNg4O2l5xHSCHIOwOqZpevBJrj0eMjaC9GDbHJL2wbfPgCtB9kLdtOukLoJfnvJ3tVHdIZe19jj/3oLgsLgrpVQN7z0c9sMhnrN4IeH4ZPrYezH9rNzDtiqo9ZnQOM2pftf+hYcPgANo+1ykw4w8A7bVnHe/0HDVjDrGvjxMbjghWP/fo+DVjEpdSrZsdBWHRQVePd7stPctw+kbYOp59r++ANus3fhf06Cghwb0++vQrPuUK85zBgL854se3xRAcz7D0R0gTEf2gviEpc+/dnp7uvh139hq6SmnGUvzuWlboHJp8NHl0NhXtltOQdtSSBuAjyRAY/uhQtetNU/P/0T4ufZksXPT9jPTo+31TkD77RJZMWHNiaHA77/BzzXHl7vA+9fANMvsyWp2TdCQB249G1o3h38/KFZN7vctJs9R2Psd26cY9sQXJNDsYG3w4hnYMv38NcUu27ef+BwOoz4b9l9G7eFqD5l1537JNyz2n5Ol4vsOSx9x/57eYGWIJQ6VexdCzPGQX6WvYvud/PxfY4xsPZTaNzuyAuMwwE/PAJL3oTgBhDVz5YCYq+C/MPw8RW2OuTWRfYCtWORrT9f+ZG9c8/YBRd8Am2HwJe32zvouAnQINJ+/ooPYX88jJtlqz3iboRf/2vv4ld9bJNNz7Fw8evgH2CrW757CNbMgpa97MX7uwfhms/LVg/99hL4BcCuP+CrO+yFuXj72k+hMBd6X2+XA0Og743QZ7ytiglrAYf2wut97We36Anib6vO6jaBr++BxKX2wr7kTeg6CtoNtUlx3n/g1V62JHXlR6XnWUwE+t8CX98Nu/6EPWtsj6Pe11X879P/Vti+wFbDBYbY7qsDbrNxVdawx2HHAvjqTps4gupV/jOOQszRWtWrmbi4OKNTjqpTXvwv0CK2bL13ZjK8Pcy+r9/C1qnfvdL+wR/eD8vfs/3hE5dB35tg6KOlx+7+C/zrQMtYmwB+fAwWT7J3xzf/UrpfUSHMudO2IfS8yt4RJ/wO6VshtAnUjYD92+H6ryG6vz3GGJh6no0vINj+3LrIXhgPJMArsbaHzbB/Qn62vZg2bgc3fGf3yUqBl7rZpFOYCzGD7d17p/PtRfzre+1nn/kgnPmQvVh+/xBcPhVOu8zGcGCn/dz+t9gL+rz/2H2HPmbjmzIYEBvX0SyZAt//zf6u2p8D42bYbqPPd4KwZvbc+94M5z9XmnzStsG399vkNfzf7j83/zC81NWeW/o2+zuaOP/osWSnw5uDbDVWWAu4c6mtljoeqVsgM9EmteMgIsuNMXHutmkJQqmTxRhbzfH7y9D2bLj2C3shKsi11TV5mTBhrl1+9xxY/Ia9s//wEnsRj+hs72B/fxl6X2vrptPj4f0Lbf/5NmdCSGNb3dK4na13z9xjEw7Yu9zVM+DsR+0FVsTGtPN3+O1l2D7f3pkXJwew+wx+AD4eY5cvf6/04tkoxl7ol79nP2/xG/aO/cqPSvep19TeTW/8Gi7+EDqeB0vesklg83c2zht/hCjn9anvjbBqOsx9BNoNg5CG8MerNsEMvBPqt4T9O2Dhczb2zhfYkpcndfB9b7KlmD2rSu/wg8LgtEth5TTocJ6t/nEtuTRpD9fPOfrn1gm1pZffX7bLF7587FjqhsPoybYt4vznjz85AER0tD9eoCUIpdwxBhyFpT1TjqUg1zbcZibZ5cbt4Ky/27t0sF0bv7nPNo62iLUXqcvehe6X23rvJW/CuJmljb6zroH4+bYhNTcTrpppG0gzkuC13tBtNFzyJkwbbRPBoLttXXTWXhjyiK2ffnMgXOisAspIhJdOs1UZI/7P/TkU5pXtWeP6u3jrLHunfMcSW/9ebMdC+OAiGP4fWPActD0Lxk4ve3xxW4drT6YNc2DPahh8/5GNzkkr4J1hNtn1GW8bgXuOhYtfPfJ3Wa+5raZ6cLOtMjuWlE02GZzzb1vFBfap5aXv2lLM8V6oD+6GV3rY0sMDmyG4vmfHFRWWxuEjRytBaIJQyp2v74GV0221TVS/0otPSCNo1dc21Bb/YTscthFz/ecQ3gEwtqqh/XDbUJtzAL66Hbb/CoMfhLMfsRfAzGQ477/22P63lnZnBPuQ2aT+thrqms+hRY/SbT89bhuLB98Pi16wd6D9brYX+P3bbfuFMfBqrI3nms/g12dtW8A9q+2df2Ud3m8vzOW7thpjq0pSNti7/NuXVM3d7K4lsOh52wtK/ODOZRDeruz3FpfGel4Fo9888e88UfOetFWCZ1Ty2Qof0wShVLH0eFsv3jK24r7jh/bZevOWsbYxM3mFbXh0FVgXelxh79xXfgS/vWjvSou7gy5/39avt+hh6+qLCmz1RR9nQ2rySvvglHHYXjA3/wKBwWW/Y+eftitjg6iy63MOwCs97Z1zy15w07yyd/XF5j4CS9+Gh7bBm6fbC+x1X1Xmt+WZ5e/bhNr7+tK7/Kqyb4Pt4dNmsPvt8b/Y30FIo6r93lpE2yDUqScrxXZPBFusL64nd5WyyV7g6kfCoLs8r+5xZ/dS2xNm87d22S/Q9hqJHgDRA+0FqLiUsPw9+xTr6Cn2ompMadfMQ8m2sTh+vn1wavkHgLFVIaffU/p9fcZDcEOYfZNNNMWfVaxlL+h/m724Xv7ukckBoPVA9+cS0giGPAw//ct253SXHAA6n28bq3/8J2TsttVA3tBznP33jLux6j+7Wdejbz/OhlnlGS1BqKpTmG/rhducCRGdjtx+IMFWdez6w74vITDoThj6T1sHvmuxbTTd8r3tcVKUDy172weHmnSofFzx82HaJfbC2m+iTQy7/7LfU1w6qB8JN/0MoeG2rr5lLFz96dE/99A+25c956CtHnKXwLLTbUOru4u4MbZh2pO6c3dyM49e111UCM+3tyWOkMbwwCb3bQyqVtMShKp6+dnwznDbS+X0e+wDUZ9PhH1rbT/yMR+W3f/wfph2qe3l0naI7VES5iw17FhoGyK3/WJLE7sX2wvakIdtt8Odv9nqmtfjbH002Kd0L3vX1vnmHIDPJkDqZmjVzw6z0Os620DscNg6+4bRcNsfpY2QnS+wr4V5tq//p9fDx1faO//sFNul8ljCmtl+6Efj7mGpYiLHnxzg2A2h/gG2Z86amfYuX5ODqiSvJggRGQG8AvgD7xhjnim3vREwFWgH5AITjDHrPDlW+djiNyBlvb2YTrsEEHv3HdnHPgTkKCq9ay7Mg5lX254018+x1Tquul9uL9hz7ob8QzDyOeh1dWnvlq6joFV/WDHNdufMOwR/vQ0fjoJRr8NnN9puoB3Ps1VJ67+AxOVwyRu24XjvGtt9010PlYAgOwzEFe/bBPHtA9Cko+1iWRP0GGO7vfYZ7+tIVDXktSomEfEHtgDDgURgKTDOGLPBZZ/ngCxjzL9FpDMwyRgzzJNj3dEqppMkO902krY9yz7QtHqm7bUz6G7bU+fzm+Dm+RDZ2+7/xW2w+uOyDz+5U/x/saIB1lxt+hY+vcEmjMC6MO5jWzIB+PUZ+PX/4My/2Rm66oTBLQuPPWDc0nftQ1EXvgxxNxw7huqiML+0u61S5fiqiqkfsM0Ys90ZxExgFOB6ke8K/B+AMWaTiMSISDOgrQfHKm8wxt51t4gt26jqatHzdiTLYY/bO/DinjlQepHe7kwQ6fE2OZx+z9GTA3iWGIp1vgCumW2TwfD/lB1S4qy/Ox+m+p9dvma2Z6OJ9r0R2g+Dhq09j6M60OSgjpM3E0QksNtlORHoX26f1cClwG8i0g9oDUR5eCwAIjIRmAgQHR1dJYHXGrkZ9oGsfhPtg1Vgn3j9bAIEhsJ5T9u661Uf2549QQ3shXjpO3bkSncN0fUi7DMC8fPtE7grp9l2g/63VX38bQa77/4oYrtb5h60jdyVqS46nmcElKqhvJkg3N0Olq/PegZ4RURWAWuBlUChh8falca8BbwFtorpeIOtlZa+axuIk1baESpDw2HuP2y//HpN7dOqcx+BwhxboijIhj9et0+LDnm44s9te5Yd8jg3wyaXDue578bqTQFBcNUsWyKqTMlEKVXCmwkiEWjlshwFJLvuYIzJBG4AEBEBdjh/Qo91rDpB+YftyJqRcfap3dk32yqhzCTbYBsZB8vetaNc9rrW9gwSsXMDFBy2CaQi7c6GP1+3T7pm7Tv6yJbepslBqePmzQSxFOggIm2AJGAscJXrDiLSEDhsjMkHbgIWGmMyReSYx6oTtOJDOznLldPskA+zb4TEv2xvl1b97D79bj5yyOmgesceUjh6kK3aWTbVjpXT4VyvnIJSyru8liCMMYUicifwA7ar6lRjzHoRudW5fTLQBfhQRIqwDdA3Hu1Yb8VaKyStsCNgNu9he+j88ap9grj1ILs94Tc7JeKwf534d9UJtV1Zdyy03VV9PBiZUur46JPUNVVBrh1/HwN/vQMLnrHPFeRm2PGFTBFcPbvsVJBFBSc2nIWrP163D6jdtcxOPKOUOiXpk9S1iaPIti388pR9RqBY9yvsRCiH9tmnlh0Ftkunq6pKDmCfRO40UpODUtWYJoiaJCMRPr/FDk3R6Xw7wxXY8Ys6DLfvQxrBJZO8H4t/YMXPUSilqgVNEDVFdhq8d74dGnnUJDvfrvbgUUqdAE0QNUFBjp2yMmsfjP+2dPpGpZQ6AR6MP6BOWQ6HnTNh9k12MvtL39LkoJSqMlqCqG6SV9lxjnYtht1L7FDXAOc+ZUc9VUqpKqIJojrZvgA+vNi+D+9gB6yLHmh/tEFYKVXFNEFUJwufs5Ps3LLoyMnjlVKnhM17D/HNmmQmntmWsOAq7DoOGGMoKDLUCTg5rQOaIKqLXUsgYRGc919NDkp5yR/xaUQ2DKF1eN0K9zHG8MXKJJrVD+b09k1K1h/Izueln7fw0eKdOJzTmD94npsRj49TZm4BN3+wjIT0bN69vi+nRdrZCB0OQ+KBHKLDQ6vsu4ppgqguFr1gR1vVmcGUqnLGGF6dt42Xft5CdONQ5t47mNA6R14eC4sc/PvrDUxbvJOw4ADmPXAWTcOCyS0oYsyUP4lPzeKaAa1JPpjD1N93cMPpMYTXO76pXnekZbN5byZxMY0xBq6f+hdbUw7RKLQOY6b8yUtXxnLwcD5TFmwnt6CIBX87m0D/qi1ZaIKoDvasga0/wNDHSqfhVEqVMMaQV+ggONC/0scezi/k8a/W89nyRM7sGMHCLan8b+5mnri4W5n9dqRl89Q3G5i3KYUr41rxxcoknv52I6+M7cWzczexNSWL92/oy5BOTdmWcohzX1rIlIXbeeT8Lm6/91BuAW/8Gs/gDk0Y2DYccXluadHWVG6dtpzs/CIA6gUFUOQwvHN9X7o0D2PCB0u5ZdpyALq1rM99wzvi54XnnjRBnGq+uhPWfFJ2naMQgupD35vdH6OUB3ILigj098Pfz7MLScbhAqb+voPLekcds/oiI6eABiFl69vXJWUwb2MKv8enEREWxHOX93B7V16ssMhBTkGR23r7wiIHM5bupmuLMPq0bnzEtr99tobv1+3lmcu6Myo2suR892TkEhMeioiQk1/Ecz9s5tu1yXRuXp/e0Y3YlprFzxv2kVNQxD3DOnDvOR3499cbeP+PBEae1pyWDUP4fEUS363dw+Z9h/D3E5685DSuHdCaZg2CeXXeVqIbh/Le7wmMHxTDkE52GPz2TcO4JDaSD/5I4PpBMWzZe4i/EvYz4fQ2RITZEsW/5qzn8xVJvPlrPD2jGnBZnyhaNQolOSOHf321nvZN6/HPC7uyOvEgm/ce4rqBMfRp3QiAWRMH8vai7cS1bszp7csml6qkg/WdSjL3wEvd7NwLLXuV3RZzRulwGUpVUn6hgwtfW0Sj0Dp8fPOAYyaJIodh/Ht/sWhrGqF1/PnHyM5c0781fuWO25GWzbPfb2Lu+r1MHR/H0M7NANiy7xAjX1mEwxi6NK/Ppr2ZDGwXzrvX93V7l5+Qls3t01eQdDCH2bcNpH3TsJJtB7LzuXPGCn7flg7A6e3DufWsdvRvE46fwH2frObr1cnEhIeSkH6Y8YNiqBcUwPQlOzlwuIAOTetxQY8WfLkyiYT0wwzt3JTd+w+zNSWLRqGBjOzegst6R5YknsP5hZz38kL2Z+WTnV+ECPRt3ZgRpzXnvNOaE9kwBLAJ6LyXF7Iz/TBtm9Tl27sHE1Kn9Nx2pmcz9IUFCFDosNfZjs3qMePmAfy5PZ07P17JbUPaEdUohLcXbich/XDJsQPaNuat6+KoX8WN3O4cbbA+TRCnkkUvwLz/wF0rtNuqOi4HD+fTMPTIOag/+COBf82xI+b/bUQnbh/S/qif88z3m5i8IJ6HzuvEkh37WbgllV7RDbn3nI6c2aEJW1OymPrbDj5bnkiQs0fN2Z2b8vpVvQF48cfNvD5/Gwv/djZRjUKZvTyRBz5dzdDOTZl8TZ8yvXC+XbOHv89eQ4C/4C9CaJA/X9x+Ok3qBbF8537um7WavRm5PHFxNw7nFzJ5wXbSsvIICfSnZcNg4lOzeXhkZyac0Yb/+24TU3/fgQic06UZA9qG8+2aZFbsOkhUoxD+d3kPBrWzDcuZuQWEBPq7rbdflrCfp77dyNDOTbm0dyRRjdyXoP7YlsY/Pl/Lq+N6Eduq4RHb31oYz4bkTC7o0ZKgAD8mTltG68Z12ZuZS0yTunx260AC/f1wOAwph/JIOpjDodwCBrYLJyig8tVlx0MTRHXgcMBrvaBBKxj/ja+jUSeZMeaEqwn+7/uNvLNoB9Mm9GOQS++aQ7kFnPXcr3RsVo/wukH8uGEvX91xBgH+wqvzttKsfjAPj+xMgPNC+eXKJO6dtYqr+0fz9OjuGGP4bHkiL/20heSMXCIbhpB0MIegAD/GxLXi7mEdeOnnLXy5MokV/xxOcKA/w19cQHi9OsycOLAkjulLdvLoF+sY3rUZk67qTZ0Av5LE1Su6Ia9f1ZvUQ3mMfetPOjULo35IIIu2ptE0LIg3r+lTUr2SW1DEgi2p/LEtjVWJGVzWO5LrBsaUfM+6pAzqBweWqRbbm5FLw9DA42qjqEq/b0tjwvtL8RPhu3sG06aJ79sUNUFUB8UPwV36NvQY4+to1AmYsiCeWct288Xtp5fUy89ensisZbu595wOJXewxdYlZXDLtOUMahfO06O7e9zH3eEwJVU+s5bu4u+z11LH34+IsCDm3ju4pC7/+R/s3fycO0+nVaNQzn15IUUOw4HD+QQF+JFb4OCsjhG8fGUsk+Zv453fdtAvpjEf3dS/TCz5hQ5mr0jk69XJnN6+CeP6RdO4ri2t/LY1jWveXcKUa/vQLqIu57y4kH9f3I3rB8WUifnDPxN4/Kv1DOvclP5tG/Pf7zaVSRgAc9ft5bbpy2kcWoeJZ7blmgGtqRtUc5pL1yVlUFDkoFd0I1+HAmiCqB4+uxG2/QQPbIbAEF9Ho45TYZGDQc/8QsqhPC7rHcULY3qyLeUQF7z6G0UOQ6HDMKJbc8afHkOv6IYsTzjAxGnLCfAXDh4uYGDbcCZf2wc/ga0pWQjQpF4QEWFBJXe/axIP8twPm/kjPp3T2zehf5vGvPTTFga2C+euoR0Y+9afXNm3Ff8d3Z2/duzn+vf+4tyuzXl1nG3XWrAllQc+Wc1lvSO59ax2zF2/l8e+XIe/n5Bf6OC6ga155PwulbrbLihy0O/pnzmrYwTtIurxwk9bWPzwMJo3CD5i348W7+SxL9cBMKJbc167qtcR1TzxqVm0aBB81EZtVTV0wqBTWWYy7PwDNs6xzzhocqjWftmUQsqhPPrFNGb2ikSGdWnKpPnbqBsUwFd3nM5Xq5KYND+euev3EhLoT6HDQdsm9Xh/Ql8Wb0/nb5+tYcB/55FTUHTEZzeuW4fwunVKGlfHxEWxaGsaC7ek0i6iLq9f1ZsGIYHcPLgtUxZuZ8XOg2zed4jwunV4yOWBrbM6RrDssdKZBMf1i6ZFg2Be/nkrtw9px7ndmlf6vAP9/Ti3a3O+XbuHDXsy6dO6kdvkAHDNgNbUCwpgw55MHjqvk9s2gHYRx5j3XJ0UWoLwhaICWPe5ndlt31q7LqQx3PijndxH+ZQxhjcXxBOfks2/Lu5aqZ4kE95fyvrkDH598GwuffMPNu/NxGHgrWv7lFx4M3MLWByfzh/x6eQVOvjHiM40CLXfsWR7Op+vSCI6PJROzcLw84O0Q/mkHMolOSOXfRm59IhqyIQzYggLDsQYw9qkDCIbhpQ8kJVbUMTlk/8gt8DB+EExXNo78qTcif+6OYXx7y0F4LELunDTYJ1NsDrQEsSpJCPRTuxzcCdEdLZDZ0QPhObdq3bKT3VcjDE8+c1Gpv6+A4BVuw/w9nVxtHW5o12XlMGzczfRvmk9xg+KKRmWIflgDr9uTuH2Ie0JqePPC1f05JI3fuey3lFl7srrBwdybrfmbu/U+7cNp3/bcI/jFRF6RDUssy440J+v7zzDa33jKzKoXRPqBweQmVvIecdRClGnHk0QJ9vaT21yuPIj6HQB+OmUHN6wfOd+/u+7TeQXObhraAfO6dK0wgumMYZ9mXnsSMtm9opEPlueyA2nxzC8azPu/Hgloyb9zg2DYrg4tiUrdh3ksS/XUS8ogD/j03n/jwSGdW7GhDNiWLJ9Pwa4sm8rALq2rM/ih4fRKPTkJ/6TnRwA6gT4Ma5fNFtTsmjVuOrHBVInn1YxnWwfXAzZqXD7n76OpNpalrCf4ED/ksHKiuUVFrF0xwE+WbabOauTaVY/iJBAfxLSDxPbqiGPXdCFuBj7MNSG5EymLIxn895D7Ew/XKbO/46z2/HguZ0QEXbvP8wjX6zlt21pFP+pDGoXzmvjelHoMHy0eCfTl+xif3Y+InBG+yZMu7H/SftdKHWitBeTr6RshK/vhTEfQlgzOzXoM62h700w4r++jq5ayMorJNBfSh4a+mZNMvfMXIW/nzDpqt4M79qMjMMFPDN3I3NWJZOdX0RQgB83D27LbUPaERTgx+wVibz001b2ZuYyKrYl9YICmPHXLsKCA+kd3ZA2TerRpkkoMU3q0i6iHi0bHtlRICUzl2/X7sFPhKv7R5c8MwC2zn/OqmS+XJXEved0pF+bxkccr9SpShOEr3z3N/hrih1k78yHYNs8+OhSuPqzWjtshjGGP+PTmbxwOwcP5xNetw4dm4dx//COJUngUG4BkxfEs2hrGuuSMmgUWofxg2KICAvikS/W0qd1I/KLDOuSMph4Zls+X5FIWlY+V/SJYnjXZgxsF35Eo+zh/ELe/DWeKQu3U+QwXDugNfed07GkcVip2kobqX3B4bBdVwFWTIMzHoDtv4J/HWg9yKehVbX8Qgdb9h0iqlGI22Eeim1PzeJvn61h2c4DNKsfROfm9dmXmcf8zak0DKnDbUPs8CJPfbORT5fvpk/rRtxxdnvWJmXwwk9bAOjXpjHvje+LAW6Ztow3f42nY7N6vHNdX7pHNajwu0PrBPDAuZ24dkBrCh3GbSlBKVWWJghvSfwLDu2BjiNhy/ewY4GdS7pV/xo3ZPd/vlnPR4t3AdAwNJAbBrXh7mHtyzSU7snI4Zp3lpBb6ODJUd24Iq5VyYNYN32wjNd+2cqlvSNJOpjDrGW7mXhm2zLDJG/ck8miralcM6B1Selg6vi+LNqSxuCOTTwet6Zpffd985VSR9IE4S3rvwT/IBj1OrweB7+9CHvXwtB/+jqyKrVy1wGmL9nFqNiWdI9swOLt6bz08xYS0rN59rIe1AnwI+NwAddP/YvM3EJmThxwROPyPy/swvAXF/Lf7zayLSWL5vWDuXtY2edBurSoT5cW9cusCwrw55yuzbx+jkrVVpogvMHhgA1fQfthULcJ9BgLS96029qd7dvYqlBhkYNHv1hHs7Bgnh7dnXpBAdx4Rhte/2UbL/y0hfXJGTQMrcPu/YdJz8rn/Ql9j0gOAK3D63LT4Da88Ws8AK9f1Yt6NWjsHaWqK+2E7w2JS+FQMnS9xC73vta+BjeEFrE+Curodu8/zJcrk9ifne/xMR/8uZMNezJ5/KKuJRd0EeGuYR14ZWwsIXUCEKBbywZMua7PEYPUubrj7PZENQphSKcILuje4kRPRylVBbx6myYiI4BXAH/gHWPMM+W2NwA+AqKdsTxvjHnPuS0BOAQUAYUVtbKfkjZ8aRujO42wy826Qbuh0LA1+Pl2uGF3MnIKuPbdJSSkH8ZPoH+bcJ64uBudmpdO2uI6cijATxv28dwPmzirYwQjTzvyqdlRsZElM3t5om5QAD/ceyZBAX4+echLKXUkryUIEfEHJgHDgURgqYjMMcZscNntDmCDMeYiEYkANovIdGNM8W3s2caYNG/F6BVFhbD+C2h/DgS7VKdc+4XvYjoKh8PwwCerSDyQw4tjerIjLZuPl+zizo9X8M3dZxAU4M/u/YcZ/cbvtGwYwg2nx3DwcAFPfrOB7pENeGFMzyq7oNekIZ2Vqgm8+RfZD9hmjNkOICIzgVGAa4IwQJjYK0w9YD9Q6MWYvG/bz7b3Uuzzvo7EI2/8uo2fN6bwxEVdubR3FAC9oxtxw/tLmTQ/ntuHtOO26cvJK3SQnVfIfbNWAzC8azNeGRurwzErVYN58687EtjtspwIlB+D4HVgDpAMhAFXGmMczm0G+FFEDDDFGPOWuy8RkYnARIDo6Oiqi/54rfgQ6jaFjuf5OpKjSjxwmP9+t5Hv1u5lVGzLMhO7nN25KaN7RfLG/G1sSM5gXVImb18Xx7DOTVm0LY2d6dlc3b/1Mec1VkpVb95spHZ39Sj/2PZ5wCqgJRALvC4ixX0ZTzfG9AZGAneIyJnuvsQY85YxJs4YExcREVElgR9Tykb45DrISim7/tBe2DIXYq86pUdm/XxFIsNeWMAvm1K4f3hH/nd5jyOqiR6/sCsNQgL5eWMKt5zVluFdm+HnJ5zVMYLrBsZoclCqFvBmCSIRaOWyHIUtKbi6AXjG2PE+tonIDqAz8JcxJhnAGJMiIl9gq6wWejFez8X/YruxZiTZ+aOLJ/lZNR1MEfS+zrfxHcW2lEM8/PlaerZqyMtXxlb4RHGjunV47apezNuYwkPndnK7j1KqZvNmCWIp0EFE2ohIHWAstjrJ1S5gGICINAM6AdtFpK6IhDnX1wXOBdZ5MdbKyUwG8YOk5fD5RPvcg8Nhh9SIGQzh7Xwa3u79hxn+4gJe+HEz+YWOkvX5hQ7umbmKukEBvH5Vr2MONzGoXRP+eWHXMgPTKaVqD6+VIIwxhSJyJ/ADtpvrVGPMehG51bl9MvAk8L6IrMVWSf3dGJMmIm2BL5zVHgHAx8aYud6KtdIO7YFGMRB3I/z4KLx8Gog/ZOyCsx/xaWjGGB7+fC070rJ57Zdt/LRhHw+c24lGoYF8s2YP65MzeevaPjQN0yEnlFJH59UuKMaY74Dvyq2b7PI+GVs6KH/cdqCnN2M7IZl7IKwFDLzDtjUkLbfrg0dC11E+De3TZYn8ti2NJy85jRb1g3nki7Xc/GHpCLdj+7Y6rjmHlVK1j/ZRPB6HkiEyDkSg/y0+DaWwyMG3a/cQFOBHeL0gnvx2A/3aNObqftH4+Qn92zZmfXIm+YUO/EQY0FbnKlBKeUYTRGUZY0sQXXw/HEReYRF3z1jJD+v3lawLCvDj2ct6lDz1HBYcyIBKzHGslFLFNEFUVs4BKMqDsJY+DSO3oIhbpi1nwZZUHrugCwPahrM9LZuWDYJp06RmDSeulPINTRCVlensqVvfdyWI7alZ3DdrFWuSMnjm0u6M7WcfEHQ3UqpSSh0vTRCVdWiPffVBCcLhMEz/axdPf7uB4EB/3ry6DyPcDJSnlFJVQRPEsaz51I7OevlUCAjyegniz/h08oscnNWx7FPhG/dk8s8v17Fs5wEGd2jC81f0pJnOjqaU8iJNEEezeDLM/bt9v28dRPaxw2kA1Kv6O/esvEJum76cjJwCXr4yllGxkeQXOnjp5y28tXA7DUIC+d9lPbgiLkqHxFZKeZ0miIosehHm/RuiB8GuP2DfemeCSIbQJhBQp8q/cvrinRw8XEDn5mHc/8lqMnIKmL08kdWJGYyJi+LhkV1oVLfqv1cppdzRMRTcKSqEX5+BjiPhuq8gsK5NEGC7uHqheim3oIi3F21ncIcmfHbbILpHNuDxr9aTkH6Yydf05n+X99TkoJQ6qbQE4c7BnbYra5cLbUmhWdfSBHEo2SsN1DP/2kVaVj53De1AvaAAPpjQjw//SODSPlFEHmPMJKWU8gYtQbiTtsW+NuloX5t1s20QxQ/JVXEJIiUzlykLt9OvTWP6tbFPOjcICeSuYR00OSilfEZLEO6kbravJQniNFj+PhxIgMNpVVaCmLdxH5Pmb2Pl7oMI8MKYU3f4KaVU7aMJwp20LVCvGYQ0tMvNutnX+Hn2tQpKENl5hdw7axWN69bh/nM6MrJ7c9o3DTvhz1VKqaqiCcKd1M2lpQeApl3t69af7WsVlCA+XbabQ7mFfDihH72iG53w5ymlVFXzqA1CRGaLyAUiUvPbLIyxJYgIl1nUQhpCg1awwzmh3QmWIIochvf+SKB3dENNDkqpU5anF/w3gauArSLyjIh09mJMvnVoL+Rlli1BgK1mKsi278MqnyDmb0rhpw121NV5G/exM/0wN57R9kSjVUopr/GoiskY8zPws4g0AMYBP4nIbuBt4CNjTIEXYzy50so1UBdr1g22zAX/IAip3F1/yqFcbpu+nNwCB+d3b86ejFwiG4ZwXrdmVRS0UkpVPY+rjEQkHBgP3ASsBF4BegM/eSUyX0nbal9dq5igtKG6fgs7UVAlTFmwnfxCBxPPbMvPG1JYuesg4wfF6FzPSqlTmkclCBH5HOgMTAMuMsY4hzRllogsq/jIaih1M9QJO7Iaqdlp9tWDBuqlCfup4+9Hz1YN2ZeZy0eLd3Jp7ygeOb8Ll/eJYs6qZK7qH+2F4JVSqup42ovpdWPML+42GGPiqjAe30vbDBEdjywlNG5nq5eO0UCdX+jgxveXkpVXyP3DO5JyKI9Ch+HuoR0A6NgsjAfP63TUz1BKqVOBpwmii4isMMYcBBCRRsA4Y8wbXovMV1K3QLuhR673D4CRz5R2ea3An9vTycwtpEdUA57/0T6RPbZvK6LDQ70RrVJKeY2nleA3FycHAGPMAeBmr0TkS7kZkLUXmnRwvz1uAkQPOOpHzF23h7p1/PnkloE8Pfo0ekQ14M6h7b0QrFJKeZenJQg/ERFjjAEQEX+g5g0tmuocg6l8A7WHCosc/LB+H0O7NCM40J+r+7fm6v6tqzBApZQ6eTxNED8An4jIZMAAtwJzvRaVr5QM0nd8CeKvhP3sz85npE4DqpSqATxNEH8HbgFuAwT4EXjHW0H5TMZu+9rw+HoYzV23l+BAP4Z0ijj2zkopdYrz9EE5B/Zp6je9G46PZaXYh+COY7Y4h8Mwd91ehnRsSmgdHeJKKVX9efocRAfg/4CuQHDxemNMzRorImufHcW1kvILHXz4ZwIph/IY2V2rl5RSNYOnt7rvAf8CXgLOBm7AVjXVLNmpUNez6qGCIgcbkjNZvD2dD//cSdLBHOJaN2J4Vx0+QylVM3iaIEKMMfOcPZl2Ak+IyCJs0qiQiIzADsnhD7xjjHmm3PYGwEdAtDOW540x73lyrFdk7YPIYz/3tzRhPze8Zx+GA+gd3ZCnR5/GWR0jkEoOw6GUUqcqTxNErnOo760icieQBDQ92gHOrrCTgOFAIrBUROYYYza47HYHsMEYc5GIRACbRWQ6UOTBsVUvKxXqHfW0AJj8azzBgf48e1kP4mIa0ax+8DGPUUqp6sbTB+XuBUKBu4E+wDXA9cc4ph+wzRiz3RiTD8wERpXbxwBhYm+76wH7gUIPj61aeVl2OO9jJIh9mbnM35zCFXFRXNCjhSYHpVSNdcwShLMkMMYY8xCQhW1/8EQksNtlORHoX26f14E5QDIQBlxpjHGIiCfHFsc3EZgIEB19AgPgZafY17pHTxCfLU/EYWBMXKvj/y6llKoGjlmCMMYUAX2k8pXr7vY35ZbPA1YBLYFY4HURqe/hscXxvWWMiTPGxEVEnMDzB1mp9vUovZiMMXy6bDf92jSmTZO6x/9dSilVDXjaBrES+EpEPgWyi1caYz4/yjGJgOttdhS2pODqBuAZ5xAe20RkB3ZYcU+OrVpZdrY36lWcZJbs2E9C+mHuHlbBWE1KKVWDeJogGgPpgOswpwY4WoJYCnQQkTbYRu2x2GlLXe0ChgGLRKQZ0AnYDhz04NiqVVzFdJQSxKyluwkLCmDkaSc2J7VSSlUHnj5J7Wm7g+sxhc4eTz9gu6pONcasF5FbndsnA08C74vIWmy10t+NMWkA7o6tbAyVkpViQwht4nbz+uQMvl6dzNX9owmp4+/VUJRS6lTg6ZPU7+GmDcAYM+FoxxljvgO+K7dussv7ZOBcT4/1qqwUCG1s530op6DIwYOfrqFhaB3uG97RzcFKKVXzeFrF9I3L+2BgNN5uEzjZslIqrF56Y348G/dkMuXaPjQMrXmjnCullDueVjHNdl0WkRnAz16JyFeyU9wOs7Fl3yFen7+Vi3u25LxuOs6SUqr28PRBufI6YIfHqDkqGKjvo8U78fcTnri4mw+CUkop3/G0DeIQZdsg9mLniKgZjHE7zIbrEN6N62rVklKqdvG0iinM24H4VN4hKMw5IkGs3H1Ah/BWStVaHlUxicho58irxcsNReQSr0V1smU7n6IuN8zGd2v3Usffj6Gdjz2An1JK1TSetkH8yxiTUbxgjDnIMYb6rlZKnqIuTQTG2OqlMzo0ISw40EeBKaWU73iaINztV3Pm1cwqfoq6NEGsTcog6WAOI07T6iWlVO3kaYJYJiIvikg7EWkrIi8By70Z2EmVdeQwG9+v20uAn3CuzhCnlKqlPE0QdwH5wCzgEyAHO9lPzZCdAuIHoeElq35Yv5eB7cL1wTilVK3laS+mbOAfXo7Fd7JS7BhMfnaMpey8QranZnNpr0gfB6aUUr7jaS+mn0SkoctyIxH5wWtRnWxZKWXaH7an2hHN2zet56uIlFLK5zytYmri7LkEgDHmAMeYk7payS6bIOJTswBoF6EJQilVe3maIBwiUjK0hojEUMEMb9VSVkqZZyDiU7Pw9xOiw0N9GJRSSvmWp11VHwV+E5EFzuUzcc4DXe0Zc0QVU3xqFtGNQwkK0HkflFK1l6eN1HNFJA6bFFYBX2F7MtUMtyyEoNLqpG0pWVq9pJSq9TwdrO8m4B7s3NCrgAHAn5SdgrR6EoGmnUsWC4scJKQd5mwdXkMpVct52gZxD9AX2GmMORvoBaR6LSofSjyQQ36RQ0sQSqlaz9MEkWuMyQUQkSBjzCagk/fC8p1tKbYHk3ZxVUrVdp42Uic6n4P4EvhJRA5Q06YcdSrp4tpEE4RSqnbztJF6tPPtEyIyH2gAzPVaVD4Un5pFk3pBNAjVEVyVUrVbpUdkNcYsOPZe1Vd8ajbtIur6OgyllPK5452TukYyxrAtJUvbH5RSCk0QZaRn55ORU6A9mJRSCk0QZcQ7ezC10xKEUkppgnAV7xzFVdsglFJKE0QZB3PyAWhSL8jHkSillO9pgnCRW+AAIChAfy1KKaVXQhe5BUUEB/ohIr4ORSmlfM6rCUJERojIZhHZJiJHTFkqIg+JyCrnzzoRKRKRxs5tCSKy1rltmTfjLGYThA7xrZRScBwPynlKRPyBScBwIBFYKiJzjDEbivcxxjwHPOfc/yLgPmPMfpePOdsYk+atGMvLLSgiWOeAUEopwLsliH7ANmPMdmNMPjATGHWU/ccBM7wYzzHlFjgIDtRaN6WUAu8miEhgt8tyonPdEUQkFBgBzHZZbYAfRWS5iFQ4e52ITBSRZSKyLDX1xEYg1yompZQq5c0E4a6lt6J5rC8Cfi9XvXS6MaY3MBK4Q0TOdHegMeYtY0ycMSYuIiLihALO0QShlFIlvJkgEoFWLstRVDxE+FjKVS8ZY5KdrynAF9gqK6/K0yompZQq4c2r4VKgg4i0EZE62CQwp/xOItIAOAs7z3XxuroiElb8HjgXWOfFWAHILdQShFJKFfNaLyZjTKGI3An8APgDU40x60XkVuf2yc5dRwM/GmOyXQ5vBnzhfB4hAPjYGOP1+Se0F5NSSpXyWoIAMMZ8B3xXbt3kcsvvA++XW7cd6OnN2NzRXkxKKVVKr4YucguKCKmjJQillAJNEGXkFBQRpFVMSikFaIIow/Zi0gShlFKgCaJEkcOQX6RtEEopVUyvhk55hUUAWoJQSiknTRBOxXNBhGiCUEopQBNEiZyC4hKE/kqUUgo0QZTILdAqJqWUcqUJwqk4QWg3V6WUsjRBOBW3QWgVk1JKWXo1dMpzliC0kVoppSxNEE452gahlFJlaIJwKq1i0gShlFKgCaJErnZzVUqpMvRq6JSrT1IrpVQZmiCcSqqYtJurUkoBmiBKlFQx1dFfiVJKgSaIErkFRYhAHX/9lSilFGiCKFE8H7VzHmyllKr1NEE46XzUSilVll4RnXILirQHk1JKudAE4ZRTUKTDbCillAtNEE65BQ6CNEEopVQJTRBOeYVF2gahlFIu9IroVNyLSSmllKUJwkl7MSmlVFl6RXTSXkxKKVWWJggn7cWklFJleTVBiMgIEdksIttE5B9utj8kIqucP+tEpEhEGntybFXTXkxKKVWW1xKEiPgDk4CRQFdgnIh0dd3HGPOcMSbWGBMLPAwsMMbs9+TYqpZXoL2YlFLKVYAXP7sfsM0Ysx1ARGYCo4ANFew/DphxnMeesNxCbYNQqiYrKCggMTGR3NxcX4fiE8HBwURFRREYGOjxMd5MEJHAbpflRKC/ux1FJBQYAdx5HMdOBCYCREdHH1eghUUOCoqMdnNVqgZLTEwkLCyMmJiYWjcopzGG9PR0EhMTadOmjcfHebNOxd2/gKlg34uA340x+yt7rDHmLWNMnDEmLiIi4jjChNxCO1lQiM4FoVSNlZubS3h4eK1LDgAiQnh4eKVLT968IiYCrVyWo4DkCvYdS2n1UmWPPWGl81FrCUKpmqw2Jodix3Pu3kwQS4EOItJGROpgk8Cc8juJSAPgLOCryh5bVUoShFYxKaVUCa8lCGNMIbZN4QdgI/CJMWa9iNwqIre67Doa+NEYk32sY70Va/F81EHai0kp5SXp6enExsYSGxtL8+bNiYyMLFkWEWJjYznttNO46KKLOHjwYJlje/bsybhx48qsGz9+PJ999hkAQ4YMIS4urmTbsmXLGDJkyAnH7NUrojHmO2NMR2NMO2PM0851k40xk132ed8YM9aTY71Fq5iUUt4WHh7OqlWrWLVqFbfeeiv33XdfyXLdunVZtWoV69ato3HjxkyaNKnkuI0bN+JwOFi4cCHZ2dkVfn5KSgrff/99lcbszV5M1YYmCKVql39/vZ4NyZlV+pldW9bnXxd1O+HPGThwIGvWrClZ/vjjj7n22mvZuHEjc+bMOaIkUeyhhx7iqaeeYuTIkSccQzGtU6G0ikmH2lBK+VJRURHz5s3j4osvLlk3a9YsrrzySsaNG8eMGTMqPHbgwIEEBQUxf/78KotHSxC4liA0XypVG1TFnX5VysnJITY2loSEBPr06cPw4cMBWLp0KREREbRu3ZqoqCgmTJjAgQMHaNSokdvPeeyxx3jqqad49tlnqyQuvSJin6IGrWJSSvlGSEgIq1atYufOneTn55e0QcyYMYNNmzYRExNDu3btyMzMZPbs2RV+ztChQ8nNzWXx4sVVEpcmCEqrmLSbq1LKlxo0aMCrr77K888/T15eHp9++ilr1qwhISGBhIQEvvrqq6NWMwE8+uij/O9//6uSeDRBYIf6Bq1iUkr5Xq9evejZsyeffPIJkZGRREZGlmw788wz2bBhA3v27Knw+PPPP5/jHVWiPDGmotEvqp+4uDizbNmySh/3zqLtPPXtRtY8cS71gz0fyEopVX1s3LiRLl26+DoMn3L3OxCR5caYOHf76y0z+iS1Ukq5owkC2wbhJxDoX3vHaVFKqfI0QVA6H3VtHshLKaXK0wSBbaTWLq5KKVWWJghsFVNwgP4qlFLKlV4VcU43WkdLEEop5UoTBJBXUKQ9mJRSXjVkyBB++OGHMutefvllbr/9dlJTUwkMDGTKlClltsfExJCWlnYywyxDEwTOKiZ9SE4p5UXjxo1j5syZZdbNnDmTcePG8emnnzJgwIBjPiV9sulgfZT2YlJK1RLf/wP2rq3az2zeHUY+U+Hmyy+/nMcee4y8vDyCgoJISEggOTmZM844g0ceeYQXXniBq666iqSkpDJPT/uS3jajvZiUUt4XHh5Ov379mDt3LmBLD1deeSWJiYns3buXfv36MWbMGGbNmuXjSEtpCQJbgtC5IJSqRY5yp+9NxdVMo0aNYubMmUydOpWZM2cyZswYAMaOHcuNN97I/fff75P4ytMEgW2D0PmolVLedskll3D//fezYsUKcnJy6N27NzfddBP79u1j+vTpACQnJ7N161Y6dOjg42i1igmAvEKtYlJKeV+9evUYMmQIEyZMYNy4cWzevJns7GySkpJKhvR++OGHj2jM9hVNEBQ/KKcJQinlfePGjWP16tWMHTuWGTNmMHr06DLbL7vssjK9mXr06EFUVBRRUVEnvepJq5iAc7o05bTI+r4OQylVC4wePZriaRaeeOKJI7b36NGDDRs2AJCQkHASIzuSJgjg5bG9fB2CUkqdcrSKSSmllFuaIJRStUZNmkGzso7n3DVBKKVqheDgYNLT02tlkjDGkJ6eTnBwcKWO0zYIpVStEBUVRWJiIqmpqb4OxSeCg4OJioqq1DGaIJRStUJgYCBt2rTxdRjVilYxKaWUcksThFJKKbc0QSillHJLalKLvoikAjuP8/AmgO+mbqo6eh6nnppyLnoep56qOJfWxpgIdxtqVII4ESKyzBgT5+s4TpSex6mnppyLnsepx9vnolVMSiml3NIEoZRSyi1NEKXe8nUAVUTP49RTU85Fz+PU49Vz0TYIpZRSbmkJQimllFuaIJRSSrlV6xOEiIwQkc0isk1E/uHreDwlIq1EZL6IbBSR9SJyj3N9YxH5SUS2Ol8b+TpWT4iIv4isFJFvnMvV9TwaishnIrLJ+W8zsDqei4jc5/x/tU5EZohIcHU5DxGZKiIpIrLOZV2FsYvIw86//80icp5voj5SBefxnPP/1hoR+UJEGrpsq/LzqNUJQkT8gUnASKArME5Euvo2Ko8VAg8YY7oAA4A7nLH/A5hnjOkAzHMuVwf3ABtdlqvrebwCzDXGdAZ6Ys+pWp2LiEQCdwNxxpjTAH9gLNXnPN4HRpRb5zZ259/MWKCb85g3nNeFU8H7HHkePwGnGWN6AFuAh8F751GrEwTQD9hmjNlujMkHZgKjfByTR4wxe4wxK5zvD2EvRJHY+D9w7vYBcIlPAqwEEYkCLgDecVldHc+jPnAm8C6AMSbfGHOQangu2JGeQ0QkAAgFkqkm52GMWQjsL7e6othHATONMXnGmB3ANux1wefcnYcx5kdjTKFzcTFQPH63V86jtieISGC3y3Kic121IiIxQC9gCdDMGLMHbBIBmvowNE+9DPwNcLisq47n0RZIBd5zVpe9IyJ1qWbnYoxJAp4HdgF7gAxjzI9Us/Mop6LYq/M1YALwvfO9V86jticIcbOuWvX7FZF6wGzgXmNMpq/jqSwRuRBIMcYs93UsVSAA6A28aYzpBWRz6lbDVMhZPz8KaAO0BOqKyDW+jcprquU1QEQexVYzTy9e5Wa3Ez6P2p4gEoFWLstR2KJ0tSAigdjkMN0Y87lz9T4RaeHc3gJI8VV8HjoduFhEErBVfENF5COq33mA/f+UaIxZ4lz+DJswqtu5nAPsMMakGmMKgM+BQVS/83BVUezV7hogItcDFwJXm9IH2bxyHrU9QSwFOohIGxGpg23kmePjmDwiIoKt695ojHnRZdMc4Hrn++uBr052bJVhjHnYGBNljInB/v5/McZcQzU7DwBjzF5gt4h0cq4aBmyg+p3LLmCAiIQ6/58Nw7ZxVbfzcFVR7HOAsSISJCJtgA7AXz6IzyMiMgL4O3CxMeawyybvnIcxplb/AOdjewPEA4/6Op5KxH0Gtgi5Bljl/DkfCMf20tjqfG3s61grcU5DgG+c76vleQCxwDLnv8uXQKPqeC7Av4FNwDpgGhBUXc4DmIFtOynA3lnfeLTYgUedf/+bgZG+jv8Y57EN29ZQ/Dc/2ZvnoUNtKKWUcqu2VzEppZSqgCYIpZRSbmmCUEop5ZYmCKWUUm5pglBKKeWWJgilTgEiMqR4JFulThWaIJRSSrmlCUKpShCRa0TkLxFZJSJTnPNYZInICyKyQkTmiUiEc99YEVnsMnZ/I+f69iLys4isdh7Tzvnx9VzmkpjufIpZKZ/RBKGUh0SkC3AlcLoxJhYoAq4G6gIrjDG9gQXAv5yHfAj83dix+9e6rJ8OTDLG9MSOcbTHub4XcC92bpK22HGqlPKZAF8HoFQ1MgzoAyx13tyHYAd9cwCznPt8BHwuIg2AhsaYBc71HwCfikgYEGmM+QLAGJML4Py8v4wxic7lVUAM8JvXz0qpCmiCUMpzAnxgjHm4zEqRf5bb72jj1xyt2ijP5X0R+vepfEyrmJTy3DzgchFpCiXzHLfG/h1d7tznKuA3Y0wGcEBEBjvXXwssMHbOjkQRucT5GUEiEnoyT0IpT+kdilIeMsZsEJHHgB9FxA87yuYd2ImBuonIciAD204Bdljpyc4EsB24wbn+WmCKiPzH+RlXnMTTUMpjOpqrUidIRLKMMfV8HYdSVU2rmJRSSrmlJQillFJuaQlCKaWUW5oglFJKuaUJQimllFuaIJRSSrmlCUIppZRb/w9R/sUh3xQ6+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3201e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1cf93ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.7083\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the TEST dataset\n",
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b7826a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "\n",
      "Classification Report for Normalization, Size and Position:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.66      0.79       666\n",
      "           2       0.57      0.92      0.71       317\n",
      "           3       0.64      0.79      0.71       125\n",
      "           4       0.55      0.33      0.41        51\n",
      "           5       0.73      0.52      0.61        46\n",
      "           6       0.26      1.00      0.41         8\n",
      "           7       0.40      0.46      0.43        69\n",
      "\n",
      "    accuracy                           0.71      1282\n",
      "   macro avg       0.59      0.67      0.58      1282\n",
      "weighted avg       0.78      0.71      0.72      1282\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
    "y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report for Normalization, Size and Position:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9c7d5",
   "metadata": {},
   "source": [
    "## No normalizing size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1cb5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pose_landmarks_norescale(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "        scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "    # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    return landmarks\n",
    "def landmarks_to_embedding_norescale(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks_norescale(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a575572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 51)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 17, 3)        0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 17, 2)       0           ['reshape_4[0][0]']              \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_18 (TFOpLa  (None, 2)           0           ['tf.__operators__.getitem_4[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_19 (TFOpLa  (None, 2)           0           ['tf.__operators__.getitem_4[0][0\n",
      " mbda)                                                           ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_18[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None, 2)           0           ['tf.compat.v1.gather_19[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 2)           0           ['tf.math.multiply_18[0][0]',    \n",
      " mbda)                                                            'tf.math.multiply_19[0][0]']    \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_4 (TFOpLambd  ()                  0           ['tf.__operators__.getitem_4[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_4 (TFOp  ()                  0           ['tf.compat.v1.size_4[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.broadcast_to_4 (TFOpLambda)  (None, 17, 2)       0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_4[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (None, 17, 2)       0           ['tf.__operators__.getitem_4[0][0\n",
      " )                                                               ]',                              \n",
      "                                                                  'tf.broadcast_to_4[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 34)           0           ['tf.math.subtract_6[0][0]']     \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          4480        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           8256        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 64)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 8)            520         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,256\n",
      "Trainable params: 13,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = landmarks_to_embedding_norescale(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model2 = keras.Model(inputs, outputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dd62899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.8481 - accuracy: 0.3889\n",
      "Epoch 1: val_loss improved from -inf to 0.22203, saving model to weights.SigmoidFocalCrossEntropyWithClassWeightsNormSize\n",
      "INFO:tensorflow:Assets written to: weights.SigmoidFocalCrossEntropyWithClassWeightsNormSize/assets\n",
      "641/641 [==============================] - 3s 4ms/step - loss: 0.8290 - accuracy: 0.3937 - val_loss: 0.2220 - val_accuracy: 0.5601\n",
      "Epoch 2/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.5502\n",
      "Epoch 2: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.5496 - val_loss: 0.1982 - val_accuracy: 0.5671\n",
      "Epoch 3/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.5788\n",
      "Epoch 3: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.2324 - accuracy: 0.5781 - val_loss: 0.1736 - val_accuracy: 0.6303\n",
      "Epoch 4/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.6382\n",
      "Epoch 4: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.6390 - val_loss: 0.1460 - val_accuracy: 0.7512\n",
      "Epoch 5/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.6822\n",
      "Epoch 5: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.6822 - val_loss: 0.1373 - val_accuracy: 0.7824\n",
      "Epoch 6/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.7090\n",
      "Epoch 6: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7091 - val_loss: 0.1260 - val_accuracy: 0.7730\n",
      "Epoch 7/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.1653 - accuracy: 0.7278\n",
      "Epoch 7: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1657 - accuracy: 0.7283 - val_loss: 0.1183 - val_accuracy: 0.7878\n",
      "Epoch 8/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.7387\n",
      "Epoch 8: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1571 - accuracy: 0.7378 - val_loss: 0.1110 - val_accuracy: 0.8011\n",
      "Epoch 9/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.7451\n",
      "Epoch 9: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1529 - accuracy: 0.7448 - val_loss: 0.1095 - val_accuracy: 0.7949\n",
      "Epoch 10/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.7457\n",
      "Epoch 10: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.7467 - val_loss: 0.1072 - val_accuracy: 0.7972\n",
      "Epoch 11/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.7558\n",
      "Epoch 11: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1471 - accuracy: 0.7562 - val_loss: 0.1095 - val_accuracy: 0.7956\n",
      "Epoch 12/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.7518\n",
      "Epoch 12: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1457 - accuracy: 0.7510 - val_loss: 0.1062 - val_accuracy: 0.7972\n",
      "Epoch 13/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.7602\n",
      "Epoch 13: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.7599 - val_loss: 0.1179 - val_accuracy: 0.7699\n",
      "Epoch 14/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.7615\n",
      "Epoch 14: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.7615 - val_loss: 0.1021 - val_accuracy: 0.8066\n",
      "Epoch 15/200\n",
      "624/641 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.7595\n",
      "Epoch 15: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.7599 - val_loss: 0.1005 - val_accuracy: 0.8128\n",
      "Epoch 16/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.7748\n",
      "Epoch 16: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1336 - accuracy: 0.7744 - val_loss: 0.0923 - val_accuracy: 0.8237\n",
      "Epoch 17/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.7729\n",
      "Epoch 17: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1336 - accuracy: 0.7727 - val_loss: 0.0951 - val_accuracy: 0.8167\n",
      "Epoch 18/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.7785\n",
      "Epoch 18: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.7784 - val_loss: 0.0940 - val_accuracy: 0.8198\n",
      "Epoch 19/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.7765\n",
      "Epoch 19: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.7762 - val_loss: 0.0942 - val_accuracy: 0.8151\n",
      "Epoch 20/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.7768\n",
      "Epoch 20: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.7768 - val_loss: 0.0915 - val_accuracy: 0.8362\n",
      "Epoch 21/200\n",
      "627/641 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.7854\n",
      "Epoch 21: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1291 - accuracy: 0.7850 - val_loss: 0.0895 - val_accuracy: 0.8432\n",
      "Epoch 22/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.7744\n",
      "Epoch 22: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1302 - accuracy: 0.7755 - val_loss: 0.0908 - val_accuracy: 0.8432\n",
      "Epoch 23/200\n",
      "627/641 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.7821\n",
      "Epoch 23: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1290 - accuracy: 0.7817 - val_loss: 0.0898 - val_accuracy: 0.8440\n",
      "Epoch 24/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.7875\n",
      "Epoch 24: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1263 - accuracy: 0.7871 - val_loss: 0.0950 - val_accuracy: 0.8541\n",
      "Epoch 25/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.7874\n",
      "Epoch 25: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1259 - accuracy: 0.7874 - val_loss: 0.0880 - val_accuracy: 0.8385\n",
      "Epoch 26/200\n",
      "616/641 [===========================>..] - ETA: 0s - loss: 0.1268 - accuracy: 0.7879\n",
      "Epoch 26: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1271 - accuracy: 0.7873 - val_loss: 0.0897 - val_accuracy: 0.8487\n",
      "Epoch 27/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.7891\n",
      "Epoch 27: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.7895 - val_loss: 0.0851 - val_accuracy: 0.8604\n",
      "Epoch 28/200\n",
      "619/641 [===========================>..] - ETA: 0s - loss: 0.1234 - accuracy: 0.7926\n",
      "Epoch 28: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1232 - accuracy: 0.7924 - val_loss: 0.0811 - val_accuracy: 0.8760\n",
      "Epoch 29/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.1222 - accuracy: 0.7926\n",
      "Epoch 29: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1224 - accuracy: 0.7925 - val_loss: 0.0838 - val_accuracy: 0.8619\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/641 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.7931\n",
      "Epoch 30: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.1240 - accuracy: 0.7930 - val_loss: 0.0876 - val_accuracy: 0.8534\n",
      "Epoch 31/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.7931\n",
      "Epoch 31: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.7922 - val_loss: 0.0804 - val_accuracy: 0.8877\n",
      "Epoch 32/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.8024\n",
      "Epoch 32: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 2s 4ms/step - loss: 0.1175 - accuracy: 0.8027 - val_loss: 0.0834 - val_accuracy: 0.8674\n",
      "Epoch 33/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.7978\n",
      "Epoch 33: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.7983 - val_loss: 0.0797 - val_accuracy: 0.8619\n",
      "Epoch 34/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.8003\n",
      "Epoch 34: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1188 - accuracy: 0.8001 - val_loss: 0.0861 - val_accuracy: 0.8604\n",
      "Epoch 35/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.8011\n",
      "Epoch 35: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.8012 - val_loss: 0.0790 - val_accuracy: 0.8705\n",
      "Epoch 36/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.8105\n",
      "Epoch 36: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1133 - accuracy: 0.8108 - val_loss: 0.0756 - val_accuracy: 0.8729\n",
      "Epoch 37/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.8078\n",
      "Epoch 37: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.8077 - val_loss: 0.0750 - val_accuracy: 0.8838\n",
      "Epoch 38/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.8080\n",
      "Epoch 38: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1124 - accuracy: 0.8081 - val_loss: 0.0762 - val_accuracy: 0.8752\n",
      "Epoch 39/200\n",
      "619/641 [===========================>..] - ETA: 0s - loss: 0.1151 - accuracy: 0.8100\n",
      "Epoch 39: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1150 - accuracy: 0.8099 - val_loss: 0.0784 - val_accuracy: 0.8799\n",
      "Epoch 40/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.8112\n",
      "Epoch 40: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1129 - accuracy: 0.8112 - val_loss: 0.0778 - val_accuracy: 0.8791\n",
      "Epoch 41/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.8058\n",
      "Epoch 41: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1134 - accuracy: 0.8060 - val_loss: 0.0787 - val_accuracy: 0.8853\n",
      "Epoch 42/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.1116 - accuracy: 0.8118\n",
      "Epoch 42: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.8123 - val_loss: 0.0739 - val_accuracy: 0.8830\n",
      "Epoch 43/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.8156\n",
      "Epoch 43: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1092 - accuracy: 0.8164 - val_loss: 0.0740 - val_accuracy: 0.8994\n",
      "Epoch 44/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.8141\n",
      "Epoch 44: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1123 - accuracy: 0.8141 - val_loss: 0.0782 - val_accuracy: 0.8838\n",
      "Epoch 45/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.1114 - accuracy: 0.8124\n",
      "Epoch 45: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1112 - accuracy: 0.8128 - val_loss: 0.0742 - val_accuracy: 0.8822\n",
      "Epoch 46/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.8131\n",
      "Epoch 46: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1121 - accuracy: 0.8128 - val_loss: 0.0763 - val_accuracy: 0.8775\n",
      "Epoch 47/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.8141\n",
      "Epoch 47: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.8138 - val_loss: 0.0775 - val_accuracy: 0.8768\n",
      "Epoch 48/200\n",
      "627/641 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.8143\n",
      "Epoch 48: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.8147 - val_loss: 0.0752 - val_accuracy: 0.8838\n",
      "Epoch 49/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.8183\n",
      "Epoch 49: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1096 - accuracy: 0.8193 - val_loss: 0.0753 - val_accuracy: 0.8924\n",
      "Epoch 50/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.1079 - accuracy: 0.8191\n",
      "Epoch 50: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1084 - accuracy: 0.8181 - val_loss: 0.0735 - val_accuracy: 0.8814\n",
      "Epoch 51/200\n",
      "623/641 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.8200\n",
      "Epoch 51: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1078 - accuracy: 0.8191 - val_loss: 0.0733 - val_accuracy: 0.8846\n",
      "Epoch 52/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.8193\n",
      "Epoch 52: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1065 - accuracy: 0.8202 - val_loss: 0.0721 - val_accuracy: 0.8916\n",
      "Epoch 53/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.1091 - accuracy: 0.8191\n",
      "Epoch 53: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1085 - accuracy: 0.8196 - val_loss: 0.0731 - val_accuracy: 0.8900\n",
      "Epoch 54/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.8231\n",
      "Epoch 54: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1073 - accuracy: 0.8226 - val_loss: 0.0711 - val_accuracy: 0.8916\n",
      "Epoch 55/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.8233\n",
      "Epoch 55: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1070 - accuracy: 0.8231 - val_loss: 0.0731 - val_accuracy: 0.8846\n",
      "Epoch 56/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.8249\n",
      "Epoch 56: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1061 - accuracy: 0.8257 - val_loss: 0.0708 - val_accuracy: 0.8908\n",
      "Epoch 57/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.8245\n",
      "Epoch 57: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1050 - accuracy: 0.8242 - val_loss: 0.0733 - val_accuracy: 0.8931\n",
      "Epoch 58/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.8265\n",
      "Epoch 58: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1053 - accuracy: 0.8263 - val_loss: 0.0767 - val_accuracy: 0.8947\n",
      "Epoch 59/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 0.8252\n",
      "Epoch 59: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1055 - accuracy: 0.8251 - val_loss: 0.0722 - val_accuracy: 0.8822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "619/641 [===========================>..] - ETA: 0s - loss: 0.1041 - accuracy: 0.8270\n",
      "Epoch 60: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.8264 - val_loss: 0.0697 - val_accuracy: 0.8877\n",
      "Epoch 61/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.8258\n",
      "Epoch 61: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.8257 - val_loss: 0.0723 - val_accuracy: 0.8846\n",
      "Epoch 62/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.1049 - accuracy: 0.8249\n",
      "Epoch 62: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.8240 - val_loss: 0.0713 - val_accuracy: 0.8924\n",
      "Epoch 63/200\n",
      "615/641 [===========================>..] - ETA: 0s - loss: 0.1043 - accuracy: 0.8310\n",
      "Epoch 63: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.8308 - val_loss: 0.0734 - val_accuracy: 0.8877\n",
      "Epoch 64/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.8290\n",
      "Epoch 64: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.8295 - val_loss: 0.0726 - val_accuracy: 0.8846\n",
      "Epoch 65/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.8241\n",
      "Epoch 65: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1070 - accuracy: 0.8239 - val_loss: 0.0723 - val_accuracy: 0.8900\n",
      "Epoch 66/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.8267\n",
      "Epoch 66: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.8270 - val_loss: 0.0720 - val_accuracy: 0.8931\n",
      "Epoch 67/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.8293\n",
      "Epoch 67: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.8293 - val_loss: 0.0714 - val_accuracy: 0.8892\n",
      "Epoch 68/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.1047 - accuracy: 0.8242\n",
      "Epoch 68: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1040 - accuracy: 0.8247 - val_loss: 0.0688 - val_accuracy: 0.8892\n",
      "Epoch 69/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.8287\n",
      "Epoch 69: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1035 - accuracy: 0.8295 - val_loss: 0.0662 - val_accuracy: 0.8861\n",
      "Epoch 70/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.8283\n",
      "Epoch 70: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.8283 - val_loss: 0.0682 - val_accuracy: 0.8908\n",
      "Epoch 71/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.8291\n",
      "Epoch 71: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1050 - accuracy: 0.8289 - val_loss: 0.0664 - val_accuracy: 0.9041\n",
      "Epoch 72/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.8283\n",
      "Epoch 72: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.8282 - val_loss: 0.0704 - val_accuracy: 0.8916\n",
      "Epoch 73/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.1044 - accuracy: 0.8336\n",
      "Epoch 73: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1043 - accuracy: 0.8339 - val_loss: 0.0687 - val_accuracy: 0.8978\n",
      "Epoch 74/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.8288\n",
      "Epoch 74: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.8286 - val_loss: 0.0691 - val_accuracy: 0.8955\n",
      "Epoch 75/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.8311\n",
      "Epoch 75: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 2s 4ms/step - loss: 0.1017 - accuracy: 0.8311 - val_loss: 0.0688 - val_accuracy: 0.8916\n",
      "Epoch 76/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.8270\n",
      "Epoch 76: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1028 - accuracy: 0.8270 - val_loss: 0.0700 - val_accuracy: 0.8908\n",
      "Epoch 77/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.8287\n",
      "Epoch 77: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1031 - accuracy: 0.8284 - val_loss: 0.0742 - val_accuracy: 0.8869\n",
      "Epoch 78/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.8348\n",
      "Epoch 78: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1029 - accuracy: 0.8348 - val_loss: 0.0688 - val_accuracy: 0.8924\n",
      "Epoch 79/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.8275\n",
      "Epoch 79: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.8276 - val_loss: 0.0684 - val_accuracy: 0.8931\n",
      "Epoch 80/200\n",
      "638/641 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.8341\n",
      "Epoch 80: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.8343 - val_loss: 0.0684 - val_accuracy: 0.8955\n",
      "Epoch 81/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.8341\n",
      "Epoch 81: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.8344 - val_loss: 0.0693 - val_accuracy: 0.8916\n",
      "Epoch 82/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.8380\n",
      "Epoch 82: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.8377 - val_loss: 0.0650 - val_accuracy: 0.8963\n",
      "Epoch 83/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.8430\n",
      "Epoch 83: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.8418 - val_loss: 0.0664 - val_accuracy: 0.8994\n",
      "Epoch 84/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.8341\n",
      "Epoch 84: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.8337 - val_loss: 0.0669 - val_accuracy: 0.8900\n",
      "Epoch 85/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.8370\n",
      "Epoch 85: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.8366 - val_loss: 0.0691 - val_accuracy: 0.8978\n",
      "Epoch 86/200\n",
      "619/641 [===========================>..] - ETA: 0s - loss: 0.0993 - accuracy: 0.8419\n",
      "Epoch 86: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.8418 - val_loss: 0.0665 - val_accuracy: 0.8986\n",
      "Epoch 87/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.8385\n",
      "Epoch 87: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.8378 - val_loss: 0.0682 - val_accuracy: 0.9009\n",
      "Epoch 88/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.8335\n",
      "Epoch 88: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.8334 - val_loss: 0.0700 - val_accuracy: 0.9009\n",
      "Epoch 89/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.8396\n",
      "Epoch 89: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.8396 - val_loss: 0.0688 - val_accuracy: 0.8978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.8410\n",
      "Epoch 90: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.8412 - val_loss: 0.0699 - val_accuracy: 0.8869\n",
      "Epoch 91/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.8389\n",
      "Epoch 91: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.8391 - val_loss: 0.0661 - val_accuracy: 0.9087\n",
      "Epoch 92/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.8396\n",
      "Epoch 92: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.8396 - val_loss: 0.0646 - val_accuracy: 0.9033\n",
      "Epoch 93/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.8420\n",
      "Epoch 93: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 2s 3ms/step - loss: 0.0982 - accuracy: 0.8424 - val_loss: 0.0664 - val_accuracy: 0.9017\n",
      "Epoch 94/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.8438\n",
      "Epoch 94: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.8441 - val_loss: 0.0650 - val_accuracy: 0.9041\n",
      "Epoch 95/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.8383\n",
      "Epoch 95: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.8383 - val_loss: 0.0688 - val_accuracy: 0.9017\n",
      "Epoch 96/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0988 - accuracy: 0.8384\n",
      "Epoch 96: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.8379 - val_loss: 0.0663 - val_accuracy: 0.8963\n",
      "Epoch 97/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.8404\n",
      "Epoch 97: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.8405 - val_loss: 0.0668 - val_accuracy: 0.8924\n",
      "Epoch 98/200\n",
      "628/641 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.8393\n",
      "Epoch 98: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.8396 - val_loss: 0.0642 - val_accuracy: 0.8970\n",
      "Epoch 99/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.8475\n",
      "Epoch 99: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.8469 - val_loss: 0.0689 - val_accuracy: 0.8947\n",
      "Epoch 100/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.8407\n",
      "Epoch 100: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.8407 - val_loss: 0.0654 - val_accuracy: 0.8963\n",
      "Epoch 101/200\n",
      "631/641 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.8400\n",
      "Epoch 101: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.8401 - val_loss: 0.0670 - val_accuracy: 0.8963\n",
      "Epoch 102/200\n",
      "621/641 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.8414\n",
      "Epoch 102: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.8424 - val_loss: 0.0682 - val_accuracy: 0.9025\n",
      "Epoch 103/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0968 - accuracy: 0.8405\n",
      "Epoch 103: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.8404 - val_loss: 0.0673 - val_accuracy: 0.9002\n",
      "Epoch 104/200\n",
      "629/641 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.8393\n",
      "Epoch 104: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.8401 - val_loss: 0.0643 - val_accuracy: 0.8963\n",
      "Epoch 105/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.8404\n",
      "Epoch 105: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.8409 - val_loss: 0.0667 - val_accuracy: 0.9041\n",
      "Epoch 106/200\n",
      "620/641 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.8403\n",
      "Epoch 106: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.8407 - val_loss: 0.0646 - val_accuracy: 0.9056\n",
      "Epoch 107/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.8432\n",
      "Epoch 107: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.8437 - val_loss: 0.0667 - val_accuracy: 0.8970\n",
      "Epoch 108/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.8412\n",
      "Epoch 108: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.8412 - val_loss: 0.0655 - val_accuracy: 0.9134\n",
      "Epoch 109/200\n",
      "615/641 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.8405\n",
      "Epoch 109: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.8402 - val_loss: 0.0680 - val_accuracy: 0.9017\n",
      "Epoch 110/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0963 - accuracy: 0.8426\n",
      "Epoch 110: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.8421 - val_loss: 0.0670 - val_accuracy: 0.8978\n",
      "Epoch 111/200\n",
      "637/641 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.8402\n",
      "Epoch 111: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.8402 - val_loss: 0.0664 - val_accuracy: 0.8970\n",
      "Epoch 112/200\n",
      "624/641 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.8420\n",
      "Epoch 112: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.8413 - val_loss: 0.0615 - val_accuracy: 0.9142\n",
      "Epoch 113/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.8421\n",
      "Epoch 113: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.8421 - val_loss: 0.0656 - val_accuracy: 0.8970\n",
      "Epoch 114/200\n",
      "641/641 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.8447\n",
      "Epoch 114: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.8447 - val_loss: 0.0672 - val_accuracy: 0.9025\n",
      "Epoch 115/200\n",
      "622/641 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.8407\n",
      "Epoch 115: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.8418 - val_loss: 0.0645 - val_accuracy: 0.9041\n",
      "Epoch 116/200\n",
      "618/641 [===========================>..] - ETA: 0s - loss: 0.0958 - accuracy: 0.8461\n",
      "Epoch 116: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.8454 - val_loss: 0.0644 - val_accuracy: 0.9126\n",
      "Epoch 117/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.8481\n",
      "Epoch 117: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.8477 - val_loss: 0.0640 - val_accuracy: 0.9017\n",
      "Epoch 118/200\n",
      "634/641 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.8507\n",
      "Epoch 118: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 2s 4ms/step - loss: 0.0941 - accuracy: 0.8501 - val_loss: 0.0654 - val_accuracy: 0.9048\n",
      "Epoch 119/200\n",
      "617/641 [===========================>..] - ETA: 0s - loss: 0.0958 - accuracy: 0.8469\n",
      "Epoch 119: val_loss did not improve from 0.22203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.8466 - val_loss: 0.0663 - val_accuracy: 0.8955\n",
      "Epoch 120/200\n",
      "636/641 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.8418\n",
      "Epoch 120: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.8420 - val_loss: 0.0641 - val_accuracy: 0.8986\n",
      "Epoch 121/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.8443\n",
      "Epoch 121: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.8435 - val_loss: 0.0748 - val_accuracy: 0.8947\n",
      "Epoch 122/200\n",
      "635/641 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.8412\n",
      "Epoch 122: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.8413 - val_loss: 0.0617 - val_accuracy: 0.9009\n",
      "Epoch 123/200\n",
      "640/641 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.8476\n",
      "Epoch 123: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.8475 - val_loss: 0.0634 - val_accuracy: 0.8978\n",
      "Epoch 124/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.8436\n",
      "Epoch 124: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.8440 - val_loss: 0.0676 - val_accuracy: 0.8963\n",
      "Epoch 125/200\n",
      "625/641 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.8459\n",
      "Epoch 125: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.8451 - val_loss: 0.0635 - val_accuracy: 0.8963\n",
      "Epoch 126/200\n",
      "626/641 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.8393\n",
      "Epoch 126: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.8396 - val_loss: 0.0633 - val_accuracy: 0.9048\n",
      "Epoch 127/200\n",
      "639/641 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.8436\n",
      "Epoch 127: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.8436 - val_loss: 0.0639 - val_accuracy: 0.9009\n",
      "Epoch 128/200\n",
      "616/641 [===========================>..] - ETA: 0s - loss: 0.0955 - accuracy: 0.8454\n",
      "Epoch 128: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.8445 - val_loss: 0.0648 - val_accuracy: 0.9056\n",
      "Epoch 129/200\n",
      "632/641 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.8391\n",
      "Epoch 129: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.8389 - val_loss: 0.0648 - val_accuracy: 0.8994\n",
      "Epoch 130/200\n",
      "633/641 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.8448\n",
      "Epoch 130: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.8451 - val_loss: 0.0657 - val_accuracy: 0.8963\n",
      "Epoch 131/200\n",
      "615/641 [===========================>..] - ETA: 0s - loss: 0.0927 - accuracy: 0.8483\n",
      "Epoch 131: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.8466 - val_loss: 0.0691 - val_accuracy: 0.8892\n",
      "Epoch 132/200\n",
      "630/641 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.8473\n",
      "Epoch 132: val_loss did not improve from 0.22203\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.8473 - val_loss: 0.0619 - val_accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "checkpoint_path = \"weights.SigmoidFocalCrossEntropyWithClassWeightsNormSize\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "# Start training\n",
    "history2 = model2.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b965e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5e02847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f22cf12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.8838\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bf5e9",
   "metadata": {},
   "source": [
    "## No normalizing position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pose_landmarks_noreposition(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "        scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "   # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "\n",
    "    return landmarks\n",
    "def landmarks_to_embedding_norescale(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks_noreposition(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = landmarks_to_embedding_norescale(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model2 = keras.Model(inputs, outputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "checkpoint_path = \"weights.SigmoidFocalCrossEntropyWithClassWeightsNoNormPos\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "history2 = model2.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99261110",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977451df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
    "y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bd7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354390fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
