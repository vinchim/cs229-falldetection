{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5491b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947d0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
    "sys.path.append(pose_sample_rpi_path)\n",
    "\n",
    "# Load MoveNet Thunder model\n",
    "import utils\n",
    "from data import BodyPart\n",
    "from ml import Movenet\n",
    "movenet = Movenet('movenet_thunder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e4b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/shellygoel2324/data_merged.csv'\n",
    "#labels_path = '/home/shellygoel2324/processedLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d37956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pose_landmarks(csv_path):\n",
    "    \"\"\"Loads a CSV created by MoveNetPreprocessor.\n",
    "    Returns:\n",
    "        X: Detected landmark coordinates and scores of shape (N, 17 * 3)\n",
    "        y: Ground truth labels of shape (N, label_count)\n",
    "        classes: The list of all class names found in the dataset\n",
    "        dataframe: The CSV loaded as a Pandas dataframe features (X) and ground\n",
    "        truth labels (y) to use later to train a pose classification model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    \n",
    "    dataframe[\"label\"] = dataframe[\"label\"] - 1\n",
    "  \n",
    "    print(dataframe[\"label\"].unique())\n",
    "    \n",
    "    \n",
    "    curr_num = dataframe.loc[dataframe['label'] == 0]\n",
    "    \n",
    "    dataFinal = curr_num.sample(n=5000)\n",
    "    #print(f\"{i}:{curr_num_sub.shape}\")\n",
    "    #dataFinal.append(curr_num_sub)\n",
    "    \n",
    "    print(f\"{0}:{dataFinal.shape}\")\n",
    "    \n",
    "    '''\n",
    "    0: 5000\n",
    "    1:2500*2\n",
    "        2: 1000*5\n",
    "            3:250*20\n",
    "                4: 250*20\n",
    "                    5: 50*100\n",
    "                \n",
    "    '''\n",
    "        \n",
    "    for i in range(1, 6):\n",
    "        \n",
    "        curr_num = dataframe.loc[dataframe['label'] == i]\n",
    "        \n",
    "        '''\n",
    "        num_s = 0\n",
    "        if i == 1:\n",
    "            num_s = 2\n",
    "        if i == 2:\n",
    "            num_s = 5\n",
    "        if i == 3:\n",
    "            num_s = 20\n",
    "        if i == 4:\n",
    "            num_s = 20     \n",
    "        if i == 5:\n",
    "            num_s = 100\n",
    "            '''\n",
    "        \n",
    "        if i in [1,2,3,4]:\n",
    "            sample_n = 7500\n",
    "        else:\n",
    "            sample_n = 5000\n",
    "        \n",
    "        curr_num_sub = curr_num.sample(n=sample_n, replace = True)\n",
    "        print(f\"{i}:{curr_num_sub.shape}\")\n",
    "        dataFinal = dataFinal.append(curr_num_sub, ignore_index=True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(dataFinal.shape)\n",
    "    \n",
    "    dataframe = dataFinal\n",
    "    labels = dataframe[\"label\"]#pd.read_csv(labels_path, header=None)\n",
    "    \n",
    "    print(labels.unique())\n",
    "    df_to_process = dataframe.copy()\n",
    "\n",
    "    # Drop the file_name columns as you don't need it during training.\n",
    "    df_to_process.drop(columns=['file_name'], inplace=True)\n",
    "\n",
    "    # Extract the list of class names\n",
    "    df_to_process.pop('class_name')\n",
    "    df_to_process.pop('class_no')\n",
    "    df_to_process.pop('label')\n",
    "\n",
    "    # Extract the labels\n",
    "    y = labels\n",
    "    classes = range(6)\n",
    "\n",
    "    # Convert the input features and labels into the correct format for training.\n",
    "    X = df_to_process.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "\n",
    "    return X, y, classes, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93bd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 1. 2. 4. 5.]\n",
      "0:(5000, 55)\n",
      "1:(7500, 55)\n",
      "2:(7500, 55)\n",
      "3:(7500, 55)\n",
      "4:(7500, 55)\n",
      "5:(5000, 55)\n",
      "(40000, 55)\n",
      "[0. 1. 2. 3. 4. 5.]\n",
      "(40000, 51) (40000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the train data\n",
    "X, y, class_names, _ = load_pose_landmarks(data_path)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Split training data (X, y) into (X_train, y_train) and (X_val, y_val)\n",
    "\n",
    "# 80/10/10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "#print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "#60/20/20\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ead317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DISTRIBUTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 04:39:23.722913: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-31 04:39:23.722979: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cs229-vm-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-05-31 04:39:23.727126: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.125125\n",
      "0: 4004\n",
      "1: 0.18603125\n",
      "1: 5953\n",
      "2: 0.1878125\n",
      "2: 6010\n",
      "3: 0.18796875\n",
      "3: 6015\n",
      "4: 0.18878125\n",
      "4: 6041\n",
      "5: 0.12428125\n",
      "5: 3977\n",
      "\n",
      "TEST DISTRIBUTION\n",
      "0: 0.1165\n",
      "1: 0.20125\n",
      "2: 0.19125\n",
      "3: 0.17975\n",
      "4: 0.19025\n",
      "5: 0.121\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DISTRIBUTION\")\n",
    "\n",
    "sample_dist = []\n",
    "for i in range(0,6):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_train:\n",
    "            if tf.argmax(sample) == i:\n",
    "                num_i+=1\n",
    "    dist = num_i/len(y_train)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    print(f\"{i}: {num_i}\")\n",
    "    sample_dist.append(dist)\n",
    "\n",
    "\n",
    "print(\"\\nTEST DISTRIBUTION\")\n",
    "for i in range(0,6):\n",
    "    \n",
    "    num_i = 0\n",
    "    for sample in y_test:\n",
    "            if tf.argmax(sample) == i:\n",
    "                num_i+=1\n",
    "\n",
    "    dist = num_i/len(y_test)\n",
    "    print(f\"{i}: {dist}\")\n",
    "    #sample_dist.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14b5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134c92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30174363 0.44862134 0.45291689 0.4532937  0.45525307 0.2997089 ]\n",
      "[3.314071570768693, 2.2290513303137653, 2.207910577264201, 2.2060752401259927, 2.196580461737766, 3.3365709251591262]\n"
     ]
    }
   ],
   "source": [
    "sample_dist = sample_dist/np.linalg.norm(sample_dist)\n",
    "weight_balanced= [1/s for s in sample_dist]\n",
    "\n",
    "print(sample_dist)\n",
    "print(weight_balanced)\n",
    "#weight_balanced = weight_balanced/np.linalg.norm(weight_balanced)\n",
    "#print(weight_balanced)\n",
    "#print(np.sum(weight_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f5e271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {}\n",
    "for i in range(6):\n",
    "    class_weights[i] = weight_balanced[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    \n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center\n",
    "\n",
    "\n",
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "\n",
    "        It is the maximum of two values:\n",
    "        * Torso size multiplied by `torso_size_multiplier`\n",
    "        * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "    return pose_size\n",
    "\n",
    "\n",
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "        scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "    # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def no_normalization(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    landmarks = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Flatten the landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks[:, :, :2])\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea2f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c23041",
   "metadata": {},
   "source": [
    "## Normalize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28566ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 51)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 17, 3)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 17, 2)       0           ['reshape[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpLambd  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " a)                                                              ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_1 (TFOpLam  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " bda)                                                            ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2)            0           ['tf.compat.v1.gather[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_1[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['tf.math.multiply[0][0]',       \n",
      " da)                                                              'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size (TFOpLambda)  ()                  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 2)         0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div (TFOpLa  ()                  0           ['tf.compat.v1.size[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.broadcast_to (TFOpLambda)   (None, 17, 2)        0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.compat.v1.floor_div[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 17, 2)        0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.broadcast_to[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_6 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_7 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_6[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_7[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 2)           0           ['tf.math.multiply_6[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_1 (TFOpLambd  ()                  0           ['tf.math.subtract[0][0]']       \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_4 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_5 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_2 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_3 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_1 (TFOp  ()                  0           ['tf.compat.v1.size_1[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_5[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_3[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.broadcast_to_1 (TFOpLambda)  (None, 17, 2)       0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 2)           0           ['tf.math.multiply_4[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 2)           0           ['tf.math.multiply_2[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 17, 2)       0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.broadcast_to_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_2[0][0]', \n",
      " )                                                                'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_8 (TFOpLam  (17, 2)             0           ['tf.math.subtract_2[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm (TFOpLambda)  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_1 (TFOpLambd  (2,)                0           ['tf.compat.v1.gather_8[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  ()                  0           ['tf.compat.v1.norm[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['tf.compat.v1.norm_1[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   ()                   0           ['tf.math.multiply_8[0][0]',     \n",
      "                                                                  'tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 17, 2)        0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.maximum[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 34)           0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          4480        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            390         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,126\n",
      "Trainable params: 13,126\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "inputs = tf.keras.Input(shape=(51))\n",
    "embedding = landmarks_to_embedding(inputs)\n",
    "\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(embedding)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebdb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df7224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 0.1803 - tp: 6783.0000 - fp: 1104.0000 - tn: 158736.0000 - fn: 25185.0000 - accuracy: 0.8629 - precision: 0.8600 - recall: 0.2122 - auc: 0.9041 - prc: 0.6763\n",
      "Epoch 1: val_loss improved from inf to 0.12109, saving model to weights.best.onlyfocalloss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 04:40:27.062751: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 19s 7ms/step - loss: 0.1803 - tp: 6794.0000 - fp: 1106.0000 - tn: 158894.0000 - fn: 25206.0000 - accuracy: 0.8630 - precision: 0.8600 - recall: 0.2123 - auc: 0.9041 - prc: 0.6763 - val_loss: 0.1211 - val_tp: 1623.0000 - val_fp: 131.0000 - val_tn: 19869.0000 - val_fn: 2377.0000 - val_accuracy: 0.8955 - val_precision: 0.9253 - val_recall: 0.4058 - val_auc: 0.9590 - val_prc: 0.8404\n",
      "Epoch 2/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.1318 - tp: 13087.0000 - fp: 1624.0000 - tn: 158056.0000 - fn: 18849.0000 - accuracy: 0.8932 - precision: 0.8896 - recall: 0.4098 - auc: 0.9500 - prc: 0.8061\n",
      "Epoch 2: val_loss improved from 0.12109 to 0.10200, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1318 - tp: 13112.0000 - fp: 1629.0000 - tn: 158371.0000 - fn: 18888.0000 - accuracy: 0.8931 - precision: 0.8895 - recall: 0.4098 - auc: 0.9499 - prc: 0.8061 - val_loss: 0.1020 - val_tp: 2185.0000 - val_fp: 176.0000 - val_tn: 19824.0000 - val_fn: 1815.0000 - val_accuracy: 0.9170 - val_precision: 0.9255 - val_recall: 0.5462 - val_auc: 0.9712 - val_prc: 0.8802\n",
      "Epoch 3/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.1217 - tp: 15098.0000 - fp: 1717.0000 - tn: 157963.0000 - fn: 16838.0000 - accuracy: 0.9032 - precision: 0.8979 - recall: 0.4728 - auc: 0.9578 - prc: 0.8323\n",
      "Epoch 3: val_loss improved from 0.10200 to 0.09672, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1217 - tp: 15129.0000 - fp: 1722.0000 - tn: 158278.0000 - fn: 16871.0000 - accuracy: 0.9032 - precision: 0.8978 - recall: 0.4728 - auc: 0.9578 - prc: 0.8323 - val_loss: 0.0967 - val_tp: 2312.0000 - val_fp: 181.0000 - val_tn: 19819.0000 - val_fn: 1688.0000 - val_accuracy: 0.9221 - val_precision: 0.9274 - val_recall: 0.5780 - val_auc: 0.9740 - val_prc: 0.8921\n",
      "Epoch 4/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.1142 - tp: 16489.0000 - fp: 1736.0000 - tn: 157464.0000 - fn: 15351.0000 - accuracy: 0.9106 - precision: 0.9047 - recall: 0.5179 - auc: 0.9630 - prc: 0.8519\n",
      "Epoch 4: val_loss improved from 0.09672 to 0.09173, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.1142 - tp: 16584.0000 - fp: 1746.0000 - tn: 158254.0000 - fn: 15416.0000 - accuracy: 0.9106 - precision: 0.9047 - recall: 0.5182 - auc: 0.9630 - prc: 0.8520 - val_loss: 0.0917 - val_tp: 2538.0000 - val_fp: 199.0000 - val_tn: 19801.0000 - val_fn: 1462.0000 - val_accuracy: 0.9308 - val_precision: 0.9273 - val_recall: 0.6345 - val_auc: 0.9765 - val_prc: 0.9027\n",
      "Epoch 5/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.1102 - tp: 17352.0000 - fp: 1817.0000 - tn: 157543.0000 - fn: 14520.0000 - accuracy: 0.9146 - precision: 0.9052 - recall: 0.5444 - auc: 0.9658 - prc: 0.8621\n",
      "Epoch 5: val_loss improved from 0.09173 to 0.08819, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.1102 - tp: 17423.0000 - fp: 1828.0000 - tn: 158172.0000 - fn: 14577.0000 - accuracy: 0.9146 - precision: 0.9050 - recall: 0.5445 - auc: 0.9657 - prc: 0.8621 - val_loss: 0.0882 - val_tp: 2580.0000 - val_fp: 184.0000 - val_tn: 19816.0000 - val_fn: 1420.0000 - val_accuracy: 0.9332 - val_precision: 0.9334 - val_recall: 0.6450 - val_auc: 0.9787 - val_prc: 0.9100\n",
      "Epoch 6/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.1071 - tp: 17953.0000 - fp: 1793.0000 - tn: 157727.0000 - fn: 13951.0000 - accuracy: 0.9178 - precision: 0.9092 - recall: 0.5627 - auc: 0.9676 - prc: 0.8706\n",
      "Epoch 6: val_loss improved from 0.08819 to 0.08516, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.1070 - tp: 18005.0000 - fp: 1796.0000 - tn: 158204.0000 - fn: 13995.0000 - accuracy: 0.9178 - precision: 0.9093 - recall: 0.5627 - auc: 0.9676 - prc: 0.8707 - val_loss: 0.0852 - val_tp: 2581.0000 - val_fp: 172.0000 - val_tn: 19828.0000 - val_fn: 1419.0000 - val_accuracy: 0.9337 - val_precision: 0.9375 - val_recall: 0.6453 - val_auc: 0.9803 - val_prc: 0.9167\n",
      "Epoch 7/200\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 0.1044 - tp: 18547.0000 - fp: 1844.0000 - tn: 157996.0000 - fn: 13421.0000 - accuracy: 0.9204 - precision: 0.9096 - recall: 0.5802 - auc: 0.9694 - prc: 0.8771\n",
      "Epoch 7: val_loss improved from 0.08516 to 0.08355, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.1044 - tp: 18566.0000 - fp: 1847.0000 - tn: 158153.0000 - fn: 13434.0000 - accuracy: 0.9204 - precision: 0.9095 - recall: 0.5802 - auc: 0.9694 - prc: 0.8771 - val_loss: 0.0835 - val_tp: 2578.0000 - val_fp: 153.0000 - val_tn: 19847.0000 - val_fn: 1422.0000 - val_accuracy: 0.9344 - val_precision: 0.9440 - val_recall: 0.6445 - val_auc: 0.9809 - val_prc: 0.9210\n",
      "Epoch 8/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1043 - tp: 18627.0000 - fp: 1811.0000 - tn: 158109.0000 - fn: 13357.0000 - accuracy: 0.9210 - precision: 0.9114 - recall: 0.5824 - auc: 0.9694 - prc: 0.8773\n",
      "Epoch 8: val_loss improved from 0.08355 to 0.08331, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.1043 - tp: 18637.0000 - fp: 1811.0000 - tn: 158189.0000 - fn: 13363.0000 - accuracy: 0.9210 - precision: 0.9114 - recall: 0.5824 - auc: 0.9694 - prc: 0.8773 - val_loss: 0.0833 - val_tp: 2638.0000 - val_fp: 171.0000 - val_tn: 19829.0000 - val_fn: 1362.0000 - val_accuracy: 0.9361 - val_precision: 0.9391 - val_recall: 0.6595 - val_auc: 0.9811 - val_prc: 0.9207\n",
      "Epoch 9/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1016 - tp: 19090.0000 - fp: 1834.0000 - tn: 158086.0000 - fn: 12894.0000 - accuracy: 0.9233 - precision: 0.9123 - recall: 0.5969 - auc: 0.9711 - prc: 0.8835\n",
      "Epoch 9: val_loss improved from 0.08331 to 0.07976, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1016 - tp: 19098.0000 - fp: 1835.0000 - tn: 158165.0000 - fn: 12902.0000 - accuracy: 0.9232 - precision: 0.9123 - recall: 0.5968 - auc: 0.9711 - prc: 0.8835 - val_loss: 0.0798 - val_tp: 2709.0000 - val_fp: 178.0000 - val_tn: 19822.0000 - val_fn: 1291.0000 - val_accuracy: 0.9388 - val_precision: 0.9383 - val_recall: 0.6773 - val_auc: 0.9828 - val_prc: 0.9272\n",
      "Epoch 10/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.1015 - tp: 19062.0000 - fp: 1802.0000 - tn: 157718.0000 - fn: 12842.0000 - accuracy: 0.9235 - precision: 0.9136 - recall: 0.5975 - auc: 0.9713 - prc: 0.8838\n",
      "Epoch 10: val_loss did not improve from 0.07976\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.1014 - tp: 19116.0000 - fp: 1809.0000 - tn: 158191.0000 - fn: 12884.0000 - accuracy: 0.9235 - precision: 0.9135 - recall: 0.5974 - auc: 0.9713 - prc: 0.8838 - val_loss: 0.0813 - val_tp: 2580.0000 - val_fp: 139.0000 - val_tn: 19861.0000 - val_fn: 1420.0000 - val_accuracy: 0.9350 - val_precision: 0.9489 - val_recall: 0.6450 - val_auc: 0.9822 - val_prc: 0.9264\n",
      "Epoch 11/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0984 - tp: 19406.0000 - fp: 1807.0000 - tn: 157313.0000 - fn: 12418.0000 - accuracy: 0.9255 - precision: 0.9148 - recall: 0.6098 - auc: 0.9730 - prc: 0.8907\n",
      "Epoch 11: val_loss improved from 0.07976 to 0.07804, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0985 - tp: 19510.0000 - fp: 1820.0000 - tn: 158180.0000 - fn: 12490.0000 - accuracy: 0.9255 - precision: 0.9147 - recall: 0.6097 - auc: 0.9730 - prc: 0.8906 - val_loss: 0.0780 - val_tp: 2680.0000 - val_fp: 176.0000 - val_tn: 19824.0000 - val_fn: 1320.0000 - val_accuracy: 0.9377 - val_precision: 0.9384 - val_recall: 0.6700 - val_auc: 0.9834 - val_prc: 0.9311\n",
      "Epoch 12/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.0983 - tp: 19477.0000 - fp: 1772.0000 - tn: 157428.0000 - fn: 12363.0000 - accuracy: 0.9260 - precision: 0.9166 - recall: 0.6117 - auc: 0.9732 - prc: 0.8912\n",
      "Epoch 12: val_loss improved from 0.07804 to 0.07680, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0982 - tp: 19578.0000 - fp: 1781.0000 - tn: 158219.0000 - fn: 12422.0000 - accuracy: 0.9260 - precision: 0.9166 - recall: 0.6118 - auc: 0.9732 - prc: 0.8914 - val_loss: 0.0768 - val_tp: 2718.0000 - val_fp: 179.0000 - val_tn: 19821.0000 - val_fn: 1282.0000 - val_accuracy: 0.9391 - val_precision: 0.9382 - val_recall: 0.6795 - val_auc: 0.9840 - val_prc: 0.9330\n",
      "Epoch 13/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0967 - tp: 19964.0000 - fp: 1804.0000 - tn: 158116.0000 - fn: 12020.0000 - accuracy: 0.9280 - precision: 0.9171 - recall: 0.6242 - auc: 0.9740 - prc: 0.8951\n",
      "Epoch 13: val_loss did not improve from 0.07680\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0967 - tp: 19972.0000 - fp: 1805.0000 - tn: 158195.0000 - fn: 12028.0000 - accuracy: 0.9280 - precision: 0.9171 - recall: 0.6241 - auc: 0.9740 - prc: 0.8951 - val_loss: 0.0780 - val_tp: 2683.0000 - val_fp: 158.0000 - val_tn: 19842.0000 - val_fn: 1317.0000 - val_accuracy: 0.9385 - val_precision: 0.9444 - val_recall: 0.6708 - val_auc: 0.9835 - val_prc: 0.9308\n",
      "Epoch 14/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0959 - tp: 19994.0000 - fp: 1766.0000 - tn: 157594.0000 - fn: 11878.0000 - accuracy: 0.9287 - precision: 0.9188 - recall: 0.6273 - auc: 0.9745 - prc: 0.8966\n",
      "Epoch 14: val_loss improved from 0.07680 to 0.07560, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0958 - tp: 20077.0000 - fp: 1770.0000 - tn: 158230.0000 - fn: 11923.0000 - accuracy: 0.9287 - precision: 0.9190 - recall: 0.6274 - auc: 0.9746 - prc: 0.8967 - val_loss: 0.0756 - val_tp: 2752.0000 - val_fp: 169.0000 - val_tn: 19831.0000 - val_fn: 1248.0000 - val_accuracy: 0.9410 - val_precision: 0.9421 - val_recall: 0.6880 - val_auc: 0.9845 - val_prc: 0.9362\n",
      "Epoch 15/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0944 - tp: 20189.0000 - fp: 1786.0000 - tn: 158134.0000 - fn: 11795.0000 - accuracy: 0.9292 - precision: 0.9187 - recall: 0.6312 - auc: 0.9753 - prc: 0.9000\n",
      "Epoch 15: val_loss improved from 0.07560 to 0.07248, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.0944 - tp: 20198.0000 - fp: 1788.0000 - tn: 158212.0000 - fn: 11802.0000 - accuracy: 0.9292 - precision: 0.9187 - recall: 0.6312 - auc: 0.9753 - prc: 0.9000 - val_loss: 0.0725 - val_tp: 2795.0000 - val_fp: 167.0000 - val_tn: 19833.0000 - val_fn: 1205.0000 - val_accuracy: 0.9428 - val_precision: 0.9436 - val_recall: 0.6988 - val_auc: 0.9860 - val_prc: 0.9407\n",
      "Epoch 16/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0942 - tp: 20305.0000 - fp: 1765.0000 - tn: 157915.0000 - fn: 11631.0000 - accuracy: 0.9301 - precision: 0.9200 - recall: 0.6358 - auc: 0.9755 - prc: 0.9009\n",
      "Epoch 16: val_loss did not improve from 0.07248\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0942 - tp: 20343.0000 - fp: 1766.0000 - tn: 158234.0000 - fn: 11657.0000 - accuracy: 0.9301 - precision: 0.9201 - recall: 0.6357 - auc: 0.9755 - prc: 0.9009 - val_loss: 0.0749 - val_tp: 2841.0000 - val_fp: 189.0000 - val_tn: 19811.0000 - val_fn: 1159.0000 - val_accuracy: 0.9438 - val_precision: 0.9376 - val_recall: 0.7103 - val_auc: 0.9849 - val_prc: 0.9361\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0935 - tp: 20173.0000 - fp: 1792.0000 - tn: 158208.0000 - fn: 11827.0000 - accuracy: 0.9291 - precision: 0.9184 - recall: 0.6304 - auc: 0.9758 - prc: 0.9010\n",
      "Epoch 17: val_loss improved from 0.07248 to 0.07161, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0935 - tp: 20173.0000 - fp: 1792.0000 - tn: 158208.0000 - fn: 11827.0000 - accuracy: 0.9291 - precision: 0.9184 - recall: 0.6304 - auc: 0.9758 - prc: 0.9010 - val_loss: 0.0716 - val_tp: 2814.0000 - val_fp: 167.0000 - val_tn: 19833.0000 - val_fn: 1186.0000 - val_accuracy: 0.9436 - val_precision: 0.9440 - val_recall: 0.7035 - val_auc: 0.9863 - val_prc: 0.9421\n",
      "Epoch 18/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0932 - tp: 20408.0000 - fp: 1773.0000 - tn: 157747.0000 - fn: 11496.0000 - accuracy: 0.9307 - precision: 0.9201 - recall: 0.6397 - auc: 0.9759 - prc: 0.9031\n",
      "Epoch 18: val_loss did not improve from 0.07161\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0932 - tp: 20469.0000 - fp: 1781.0000 - tn: 158219.0000 - fn: 11531.0000 - accuracy: 0.9307 - precision: 0.9200 - recall: 0.6397 - auc: 0.9759 - prc: 0.9031 - val_loss: 0.0719 - val_tp: 2794.0000 - val_fp: 156.0000 - val_tn: 19844.0000 - val_fn: 1206.0000 - val_accuracy: 0.9433 - val_precision: 0.9471 - val_recall: 0.6985 - val_auc: 0.9861 - val_prc: 0.9414\n",
      "Epoch 19/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0921 - tp: 20476.0000 - fp: 1706.0000 - tn: 157654.0000 - fn: 11396.0000 - accuracy: 0.9315 - precision: 0.9231 - recall: 0.6424 - auc: 0.9765 - prc: 0.9051\n",
      "Epoch 19: val_loss improved from 0.07161 to 0.07093, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0920 - tp: 20558.0000 - fp: 1710.0000 - tn: 158290.0000 - fn: 11442.0000 - accuracy: 0.9315 - precision: 0.9232 - recall: 0.6424 - auc: 0.9766 - prc: 0.9052 - val_loss: 0.0709 - val_tp: 2799.0000 - val_fp: 163.0000 - val_tn: 19837.0000 - val_fn: 1201.0000 - val_accuracy: 0.9432 - val_precision: 0.9450 - val_recall: 0.6998 - val_auc: 0.9867 - val_prc: 0.9430\n",
      "Epoch 20/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0910 - tp: 20728.0000 - fp: 1748.0000 - tn: 158012.0000 - fn: 11224.0000 - accuracy: 0.9323 - precision: 0.9222 - recall: 0.6487 - auc: 0.9770 - prc: 0.9076\n",
      "Epoch 20: val_loss improved from 0.07093 to 0.06990, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0910 - tp: 20757.0000 - fp: 1750.0000 - tn: 158250.0000 - fn: 11243.0000 - accuracy: 0.9323 - precision: 0.9222 - recall: 0.6487 - auc: 0.9770 - prc: 0.9076 - val_loss: 0.0699 - val_tp: 2784.0000 - val_fp: 145.0000 - val_tn: 19855.0000 - val_fn: 1216.0000 - val_accuracy: 0.9433 - val_precision: 0.9505 - val_recall: 0.6960 - val_auc: 0.9869 - val_prc: 0.9457\n",
      "Epoch 21/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0917 - tp: 20497.0000 - fp: 1741.0000 - tn: 157539.0000 - fn: 11359.0000 - accuracy: 0.9315 - precision: 0.9217 - recall: 0.6434 - auc: 0.9768 - prc: 0.9056\n",
      "Epoch 21: val_loss improved from 0.06990 to 0.06840, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0916 - tp: 20601.0000 - fp: 1747.0000 - tn: 158253.0000 - fn: 11399.0000 - accuracy: 0.9315 - precision: 0.9218 - recall: 0.6438 - auc: 0.9768 - prc: 0.9058 - val_loss: 0.0684 - val_tp: 2901.0000 - val_fp: 172.0000 - val_tn: 19828.0000 - val_fn: 1099.0000 - val_accuracy: 0.9470 - val_precision: 0.9440 - val_recall: 0.7253 - val_auc: 0.9875 - val_prc: 0.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0910 - tp: 20738.0000 - fp: 1723.0000 - tn: 157957.0000 - fn: 11198.0000 - accuracy: 0.9326 - precision: 0.9233 - recall: 0.6494 - auc: 0.9771 - prc: 0.9078\n",
      "Epoch 22: val_loss did not improve from 0.06840\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0910 - tp: 20779.0000 - fp: 1729.0000 - tn: 158271.0000 - fn: 11221.0000 - accuracy: 0.9326 - precision: 0.9232 - recall: 0.6493 - auc: 0.9771 - prc: 0.9078 - val_loss: 0.0689 - val_tp: 2918.0000 - val_fp: 183.0000 - val_tn: 19817.0000 - val_fn: 1082.0000 - val_accuracy: 0.9473 - val_precision: 0.9410 - val_recall: 0.7295 - val_auc: 0.9873 - val_prc: 0.9462\n",
      "Epoch 23/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0901 - tp: 20837.0000 - fp: 1741.0000 - tn: 157699.0000 - fn: 11051.0000 - accuracy: 0.9331 - precision: 0.9229 - recall: 0.6534 - auc: 0.9777 - prc: 0.9091\n",
      "Epoch 23: val_loss did not improve from 0.06840\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0901 - tp: 20907.0000 - fp: 1745.0000 - tn: 158255.0000 - fn: 11093.0000 - accuracy: 0.9331 - precision: 0.9230 - recall: 0.6533 - auc: 0.9777 - prc: 0.9091 - val_loss: 0.0689 - val_tp: 2780.0000 - val_fp: 106.0000 - val_tn: 19894.0000 - val_fn: 1220.0000 - val_accuracy: 0.9448 - val_precision: 0.9633 - val_recall: 0.6950 - val_auc: 0.9875 - val_prc: 0.9470\n",
      "Epoch 24/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0892 - tp: 20980.0000 - fp: 1697.0000 - tn: 157743.0000 - fn: 10908.0000 - accuracy: 0.9341 - precision: 0.9252 - recall: 0.6579 - auc: 0.9782 - prc: 0.9113\n",
      "Epoch 24: val_loss improved from 0.06840 to 0.06798, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0892 - tp: 21050.0000 - fp: 1701.0000 - tn: 158299.0000 - fn: 10950.0000 - accuracy: 0.9341 - precision: 0.9252 - recall: 0.6578 - auc: 0.9781 - prc: 0.9113 - val_loss: 0.0680 - val_tp: 2764.0000 - val_fp: 129.0000 - val_tn: 19871.0000 - val_fn: 1236.0000 - val_accuracy: 0.9431 - val_precision: 0.9554 - val_recall: 0.6910 - val_auc: 0.9876 - val_prc: 0.9483\n",
      "Epoch 25/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0888 - tp: 21035.0000 - fp: 1717.0000 - tn: 157803.0000 - fn: 10869.0000 - accuracy: 0.9343 - precision: 0.9245 - recall: 0.6593 - auc: 0.9785 - prc: 0.9123\n",
      "Epoch 25: val_loss did not improve from 0.06798\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0888 - tp: 21100.0000 - fp: 1720.0000 - tn: 158280.0000 - fn: 10900.0000 - accuracy: 0.9343 - precision: 0.9246 - recall: 0.6594 - auc: 0.9786 - prc: 0.9123 - val_loss: 0.0683 - val_tp: 2924.0000 - val_fp: 177.0000 - val_tn: 19823.0000 - val_fn: 1076.0000 - val_accuracy: 0.9478 - val_precision: 0.9429 - val_recall: 0.7310 - val_auc: 0.9872 - val_prc: 0.9467\n",
      "Epoch 26/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0899 - tp: 21027.0000 - fp: 1747.0000 - tn: 158173.0000 - fn: 10957.0000 - accuracy: 0.9338 - precision: 0.9233 - recall: 0.6574 - auc: 0.9778 - prc: 0.9103\n",
      "Epoch 26: val_loss improved from 0.06798 to 0.06436, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0899 - tp: 21039.0000 - fp: 1748.0000 - tn: 158252.0000 - fn: 10961.0000 - accuracy: 0.9338 - precision: 0.9233 - recall: 0.6575 - auc: 0.9778 - prc: 0.9103 - val_loss: 0.0644 - val_tp: 2868.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 1132.0000 - val_accuracy: 0.9475 - val_precision: 0.9573 - val_recall: 0.7170 - val_auc: 0.9892 - val_prc: 0.9543\n",
      "Epoch 27/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0886 - tp: 21014.0000 - fp: 1693.0000 - tn: 157427.0000 - fn: 10810.0000 - accuracy: 0.9345 - precision: 0.9254 - recall: 0.6603 - auc: 0.9785 - prc: 0.9126\n",
      "Epoch 27: val_loss did not improve from 0.06436\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0886 - tp: 21134.0000 - fp: 1700.0000 - tn: 158300.0000 - fn: 10866.0000 - accuracy: 0.9346 - precision: 0.9255 - recall: 0.6604 - auc: 0.9785 - prc: 0.9127 - val_loss: 0.0677 - val_tp: 2983.0000 - val_fp: 180.0000 - val_tn: 19820.0000 - val_fn: 1017.0000 - val_accuracy: 0.9501 - val_precision: 0.9431 - val_recall: 0.7458 - val_auc: 0.9878 - val_prc: 0.9477\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0869 - tp: 21340.0000 - fp: 1696.0000 - tn: 158304.0000 - fn: 10660.0000 - accuracy: 0.9356 - precision: 0.9264 - recall: 0.6669 - auc: 0.9793 - prc: 0.9155\n",
      "Epoch 28: val_loss did not improve from 0.06436\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0869 - tp: 21340.0000 - fp: 1696.0000 - tn: 158304.0000 - fn: 10660.0000 - accuracy: 0.9356 - precision: 0.9264 - recall: 0.6669 - auc: 0.9793 - prc: 0.9155 - val_loss: 0.0650 - val_tp: 3002.0000 - val_fp: 192.0000 - val_tn: 19808.0000 - val_fn: 998.0000 - val_accuracy: 0.9504 - val_precision: 0.9399 - val_recall: 0.7505 - val_auc: 0.9888 - val_prc: 0.9517\n",
      "Epoch 29/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0888 - tp: 21184.0000 - fp: 1729.0000 - tn: 157951.0000 - fn: 10752.0000 - accuracy: 0.9349 - precision: 0.9245 - recall: 0.6633 - auc: 0.9786 - prc: 0.9124\n",
      "Epoch 29: val_loss improved from 0.06436 to 0.06386, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0888 - tp: 21225.0000 - fp: 1735.0000 - tn: 158265.0000 - fn: 10775.0000 - accuracy: 0.9348 - precision: 0.9244 - recall: 0.6633 - auc: 0.9786 - prc: 0.9123 - val_loss: 0.0639 - val_tp: 2947.0000 - val_fp: 169.0000 - val_tn: 19831.0000 - val_fn: 1053.0000 - val_accuracy: 0.9491 - val_precision: 0.9458 - val_recall: 0.7368 - val_auc: 0.9892 - val_prc: 0.9535\n",
      "Epoch 30/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0867 - tp: 21290.0000 - fp: 1732.0000 - tn: 157788.0000 - fn: 10614.0000 - accuracy: 0.9355 - precision: 0.9248 - recall: 0.6673 - auc: 0.9794 - prc: 0.9160\n",
      "Epoch 30: val_loss did not improve from 0.06386\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0868 - tp: 21356.0000 - fp: 1742.0000 - tn: 158258.0000 - fn: 10644.0000 - accuracy: 0.9355 - precision: 0.9246 - recall: 0.6674 - auc: 0.9793 - prc: 0.9159 - val_loss: 0.0651 - val_tp: 2914.0000 - val_fp: 175.0000 - val_tn: 19825.0000 - val_fn: 1086.0000 - val_accuracy: 0.9475 - val_precision: 0.9433 - val_recall: 0.7285 - val_auc: 0.9888 - val_prc: 0.9516\n",
      "Epoch 31/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0873 - tp: 21303.0000 - fp: 1736.0000 - tn: 157624.0000 - fn: 10569.0000 - accuracy: 0.9357 - precision: 0.9246 - recall: 0.6684 - auc: 0.9793 - prc: 0.9149\n",
      "Epoch 31: val_loss did not improve from 0.06386\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0872 - tp: 21393.0000 - fp: 1743.0000 - tn: 158257.0000 - fn: 10607.0000 - accuracy: 0.9357 - precision: 0.9247 - recall: 0.6685 - auc: 0.9793 - prc: 0.9150 - val_loss: 0.0660 - val_tp: 2805.0000 - val_fp: 107.0000 - val_tn: 19893.0000 - val_fn: 1195.0000 - val_accuracy: 0.9458 - val_precision: 0.9633 - val_recall: 0.7013 - val_auc: 0.9889 - val_prc: 0.9524\n",
      "Epoch 32/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0862 - tp: 21498.0000 - fp: 1696.0000 - tn: 157824.0000 - fn: 10406.0000 - accuracy: 0.9368 - precision: 0.9269 - recall: 0.6738 - auc: 0.9796 - prc: 0.9178\n",
      "Epoch 32: val_loss improved from 0.06386 to 0.06204, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0861 - tp: 21565.0000 - fp: 1700.0000 - tn: 158300.0000 - fn: 10435.0000 - accuracy: 0.9368 - precision: 0.9269 - recall: 0.6739 - auc: 0.9797 - prc: 0.9178 - val_loss: 0.0620 - val_tp: 2962.0000 - val_fp: 154.0000 - val_tn: 19846.0000 - val_fn: 1038.0000 - val_accuracy: 0.9503 - val_precision: 0.9506 - val_recall: 0.7405 - val_auc: 0.9899 - val_prc: 0.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0877 - tp: 21217.0000 - fp: 1686.0000 - tn: 157834.0000 - fn: 10687.0000 - accuracy: 0.9354 - precision: 0.9264 - recall: 0.6650 - auc: 0.9790 - prc: 0.9141\n",
      "Epoch 33: val_loss did not improve from 0.06204\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0877 - tp: 21283.0000 - fp: 1693.0000 - tn: 158307.0000 - fn: 10717.0000 - accuracy: 0.9354 - precision: 0.9263 - recall: 0.6651 - auc: 0.9790 - prc: 0.9141 - val_loss: 0.0649 - val_tp: 2853.0000 - val_fp: 147.0000 - val_tn: 19853.0000 - val_fn: 1147.0000 - val_accuracy: 0.9461 - val_precision: 0.9510 - val_recall: 0.7132 - val_auc: 0.9889 - val_prc: 0.9526\n",
      "Epoch 34/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0871 - tp: 21196.0000 - fp: 1642.0000 - tn: 157478.0000 - fn: 10628.0000 - accuracy: 0.9357 - precision: 0.9281 - recall: 0.6660 - auc: 0.9794 - prc: 0.9155\n",
      "Epoch 34: val_loss did not improve from 0.06204\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0872 - tp: 21314.0000 - fp: 1654.0000 - tn: 158346.0000 - fn: 10686.0000 - accuracy: 0.9357 - precision: 0.9280 - recall: 0.6661 - auc: 0.9794 - prc: 0.9154 - val_loss: 0.0625 - val_tp: 3019.0000 - val_fp: 181.0000 - val_tn: 19819.0000 - val_fn: 981.0000 - val_accuracy: 0.9516 - val_precision: 0.9434 - val_recall: 0.7548 - val_auc: 0.9896 - val_prc: 0.9558\n",
      "Epoch 35/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0869 - tp: 21423.0000 - fp: 1683.0000 - tn: 157597.0000 - fn: 10433.0000 - accuracy: 0.9366 - precision: 0.9272 - recall: 0.6725 - auc: 0.9796 - prc: 0.9169\n",
      "Epoch 35: val_loss did not improve from 0.06204\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0870 - tp: 21516.0000 - fp: 1691.0000 - tn: 158309.0000 - fn: 10484.0000 - accuracy: 0.9366 - precision: 0.9271 - recall: 0.6724 - auc: 0.9795 - prc: 0.9168 - val_loss: 0.0650 - val_tp: 2929.0000 - val_fp: 156.0000 - val_tn: 19844.0000 - val_fn: 1071.0000 - val_accuracy: 0.9489 - val_precision: 0.9494 - val_recall: 0.7322 - val_auc: 0.9888 - val_prc: 0.9522\n",
      "Epoch 36/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0864 - tp: 21514.0000 - fp: 1686.0000 - tn: 158234.0000 - fn: 10470.0000 - accuracy: 0.9367 - precision: 0.9273 - recall: 0.6726 - auc: 0.9796 - prc: 0.9170\n",
      "Epoch 36: val_loss did not improve from 0.06204\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0864 - tp: 21522.0000 - fp: 1687.0000 - tn: 158313.0000 - fn: 10478.0000 - accuracy: 0.9366 - precision: 0.9273 - recall: 0.6726 - auc: 0.9796 - prc: 0.9170 - val_loss: 0.0632 - val_tp: 3058.0000 - val_fp: 179.0000 - val_tn: 19821.0000 - val_fn: 942.0000 - val_accuracy: 0.9533 - val_precision: 0.9447 - val_recall: 0.7645 - val_auc: 0.9894 - val_prc: 0.9547\n",
      "Epoch 37/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0854 - tp: 21594.0000 - fp: 1705.0000 - tn: 157335.0000 - fn: 10214.0000 - accuracy: 0.9375 - precision: 0.9268 - recall: 0.6789 - auc: 0.9802 - prc: 0.9191\n",
      "Epoch 37: val_loss improved from 0.06204 to 0.06080, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0856 - tp: 21726.0000 - fp: 1720.0000 - tn: 158280.0000 - fn: 10274.0000 - accuracy: 0.9375 - precision: 0.9266 - recall: 0.6789 - auc: 0.9801 - prc: 0.9188 - val_loss: 0.0608 - val_tp: 3101.0000 - val_fp: 205.0000 - val_tn: 19795.0000 - val_fn: 899.0000 - val_accuracy: 0.9540 - val_precision: 0.9380 - val_recall: 0.7753 - val_auc: 0.9903 - val_prc: 0.9580\n",
      "Epoch 38/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0844 - tp: 21774.0000 - fp: 1698.0000 - tn: 158222.0000 - fn: 10210.0000 - accuracy: 0.9379 - precision: 0.9277 - recall: 0.6808 - auc: 0.9806 - prc: 0.9209\n",
      "Epoch 38: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0844 - tp: 21786.0000 - fp: 1699.0000 - tn: 158301.0000 - fn: 10214.0000 - accuracy: 0.9380 - precision: 0.9277 - recall: 0.6808 - auc: 0.9806 - prc: 0.9208 - val_loss: 0.0617 - val_tp: 2952.0000 - val_fp: 154.0000 - val_tn: 19846.0000 - val_fn: 1048.0000 - val_accuracy: 0.9499 - val_precision: 0.9504 - val_recall: 0.7380 - val_auc: 0.9901 - val_prc: 0.9571\n",
      "Epoch 39/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0861 - tp: 21477.0000 - fp: 1674.0000 - tn: 157846.0000 - fn: 10427.0000 - accuracy: 0.9368 - precision: 0.9277 - recall: 0.6732 - auc: 0.9799 - prc: 0.9178\n",
      "Epoch 39: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0861 - tp: 21541.0000 - fp: 1683.0000 - tn: 158317.0000 - fn: 10459.0000 - accuracy: 0.9368 - precision: 0.9275 - recall: 0.6732 - auc: 0.9799 - prc: 0.9178 - val_loss: 0.0618 - val_tp: 2992.0000 - val_fp: 159.0000 - val_tn: 19841.0000 - val_fn: 1008.0000 - val_accuracy: 0.9514 - val_precision: 0.9495 - val_recall: 0.7480 - val_auc: 0.9900 - val_prc: 0.9563\n",
      "Epoch 40/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0846 - tp: 21596.0000 - fp: 1708.0000 - tn: 157972.0000 - fn: 10340.0000 - accuracy: 0.9371 - precision: 0.9267 - recall: 0.6762 - auc: 0.9805 - prc: 0.9201\n",
      "Epoch 40: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0847 - tp: 21634.0000 - fp: 1710.0000 - tn: 158290.0000 - fn: 10366.0000 - accuracy: 0.9371 - precision: 0.9267 - recall: 0.6761 - auc: 0.9805 - prc: 0.9200 - val_loss: 0.0614 - val_tp: 2938.0000 - val_fp: 137.0000 - val_tn: 19863.0000 - val_fn: 1062.0000 - val_accuracy: 0.9500 - val_precision: 0.9554 - val_recall: 0.7345 - val_auc: 0.9901 - val_prc: 0.9575\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0838 - tp: 21801.0000 - fp: 1703.0000 - tn: 158297.0000 - fn: 10199.0000 - accuracy: 0.9380 - precision: 0.9275 - recall: 0.6813 - auc: 0.9809 - prc: 0.9216\n",
      "Epoch 41: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0838 - tp: 21801.0000 - fp: 1703.0000 - tn: 158297.0000 - fn: 10199.0000 - accuracy: 0.9380 - precision: 0.9275 - recall: 0.6813 - auc: 0.9809 - prc: 0.9216 - val_loss: 0.0620 - val_tp: 2955.0000 - val_fp: 159.0000 - val_tn: 19841.0000 - val_fn: 1045.0000 - val_accuracy: 0.9498 - val_precision: 0.9489 - val_recall: 0.7387 - val_auc: 0.9898 - val_prc: 0.9560\n",
      "Epoch 42/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0834 - tp: 21987.0000 - fp: 1636.0000 - tn: 157964.0000 - fn: 9933.0000 - accuracy: 0.9396 - precision: 0.9307 - recall: 0.6888 - auc: 0.9810 - prc: 0.9229\n",
      "Epoch 42: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0834 - tp: 22049.0000 - fp: 1641.0000 - tn: 158359.0000 - fn: 9951.0000 - accuracy: 0.9396 - precision: 0.9307 - recall: 0.6890 - auc: 0.9810 - prc: 0.9229 - val_loss: 0.0611 - val_tp: 3009.0000 - val_fp: 144.0000 - val_tn: 19856.0000 - val_fn: 991.0000 - val_accuracy: 0.9527 - val_precision: 0.9543 - val_recall: 0.7523 - val_auc: 0.9901 - val_prc: 0.9573\n",
      "Epoch 43/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0842 - tp: 21685.0000 - fp: 1654.0000 - tn: 158266.0000 - fn: 10299.0000 - accuracy: 0.9377 - precision: 0.9291 - recall: 0.6780 - auc: 0.9807 - prc: 0.9214\n",
      "Epoch 43: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0842 - tp: 21697.0000 - fp: 1655.0000 - tn: 158345.0000 - fn: 10303.0000 - accuracy: 0.9377 - precision: 0.9291 - recall: 0.6780 - auc: 0.9807 - prc: 0.9214 - val_loss: 0.0615 - val_tp: 2973.0000 - val_fp: 152.0000 - val_tn: 19848.0000 - val_fn: 1027.0000 - val_accuracy: 0.9509 - val_precision: 0.9514 - val_recall: 0.7433 - val_auc: 0.9900 - val_prc: 0.9569\n",
      "Epoch 44/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0829 - tp: 22054.0000 - fp: 1633.0000 - tn: 158127.0000 - fn: 9898.0000 - accuracy: 0.9399 - precision: 0.9311 - recall: 0.6902 - auc: 0.9814 - prc: 0.9241\n",
      "Epoch 44: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0829 - tp: 22080.0000 - fp: 1638.0000 - tn: 158362.0000 - fn: 9920.0000 - accuracy: 0.9398 - precision: 0.9309 - recall: 0.6900 - auc: 0.9813 - prc: 0.9240 - val_loss: 0.0625 - val_tp: 2905.0000 - val_fp: 147.0000 - val_tn: 19853.0000 - val_fn: 1095.0000 - val_accuracy: 0.9482 - val_precision: 0.9518 - val_recall: 0.7262 - val_auc: 0.9896 - val_prc: 0.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0830 - tp: 21963.0000 - fp: 1677.0000 - tn: 157603.0000 - fn: 9893.0000 - accuracy: 0.9395 - precision: 0.9291 - recall: 0.6894 - auc: 0.9814 - prc: 0.9239\n",
      "Epoch 45: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0830 - tp: 22062.0000 - fp: 1683.0000 - tn: 158317.0000 - fn: 9938.0000 - accuracy: 0.9395 - precision: 0.9291 - recall: 0.6894 - auc: 0.9814 - prc: 0.9240 - val_loss: 0.0638 - val_tp: 2893.0000 - val_fp: 123.0000 - val_tn: 19877.0000 - val_fn: 1107.0000 - val_accuracy: 0.9487 - val_precision: 0.9592 - val_recall: 0.7232 - val_auc: 0.9896 - val_prc: 0.9557\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0826 - tp: 22168.0000 - fp: 1603.0000 - tn: 158397.0000 - fn: 9832.0000 - accuracy: 0.9404 - precision: 0.9326 - recall: 0.6927 - auc: 0.9815 - prc: 0.9247\n",
      "Epoch 46: val_loss did not improve from 0.06080\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0826 - tp: 22168.0000 - fp: 1603.0000 - tn: 158397.0000 - fn: 9832.0000 - accuracy: 0.9404 - precision: 0.9326 - recall: 0.6927 - auc: 0.9815 - prc: 0.9247 - val_loss: 0.0632 - val_tp: 2907.0000 - val_fp: 142.0000 - val_tn: 19858.0000 - val_fn: 1093.0000 - val_accuracy: 0.9485 - val_precision: 0.9534 - val_recall: 0.7268 - val_auc: 0.9895 - val_prc: 0.9546\n",
      "Epoch 47/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0827 - tp: 22034.0000 - fp: 1619.0000 - tn: 157901.0000 - fn: 9870.0000 - accuracy: 0.9400 - precision: 0.9316 - recall: 0.6906 - auc: 0.9813 - prc: 0.9245\n",
      "Epoch 47: val_loss improved from 0.06080 to 0.05905, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0826 - tp: 22101.0000 - fp: 1624.0000 - tn: 158376.0000 - fn: 9899.0000 - accuracy: 0.9400 - precision: 0.9315 - recall: 0.6907 - auc: 0.9814 - prc: 0.9246 - val_loss: 0.0591 - val_tp: 2996.0000 - val_fp: 123.0000 - val_tn: 19877.0000 - val_fn: 1004.0000 - val_accuracy: 0.9530 - val_precision: 0.9606 - val_recall: 0.7490 - val_auc: 0.9908 - val_prc: 0.9601\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0836 - tp: 22051.0000 - fp: 1711.0000 - tn: 158289.0000 - fn: 9949.0000 - accuracy: 0.9393 - precision: 0.9280 - recall: 0.6891 - auc: 0.9812 - prc: 0.9227\n",
      "Epoch 48: val_loss did not improve from 0.05905\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0836 - tp: 22051.0000 - fp: 1711.0000 - tn: 158289.0000 - fn: 9949.0000 - accuracy: 0.9393 - precision: 0.9280 - recall: 0.6891 - auc: 0.9812 - prc: 0.9227 - val_loss: 0.0602 - val_tp: 3033.0000 - val_fp: 160.0000 - val_tn: 19840.0000 - val_fn: 967.0000 - val_accuracy: 0.9530 - val_precision: 0.9499 - val_recall: 0.7582 - val_auc: 0.9905 - val_prc: 0.9590\n",
      "Epoch 49/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.0825 - tp: 22008.0000 - fp: 1644.0000 - tn: 157556.0000 - fn: 9832.0000 - accuracy: 0.9399 - precision: 0.9305 - recall: 0.6912 - auc: 0.9817 - prc: 0.9247\n",
      "Epoch 49: val_loss did not improve from 0.05905\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0824 - tp: 22115.0000 - fp: 1654.0000 - tn: 158346.0000 - fn: 9885.0000 - accuracy: 0.9399 - precision: 0.9304 - recall: 0.6911 - auc: 0.9817 - prc: 0.9247 - val_loss: 0.0606 - val_tp: 2948.0000 - val_fp: 129.0000 - val_tn: 19871.0000 - val_fn: 1052.0000 - val_accuracy: 0.9508 - val_precision: 0.9581 - val_recall: 0.7370 - val_auc: 0.9904 - val_prc: 0.9586\n",
      "Epoch 50/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0822 - tp: 22082.0000 - fp: 1602.0000 - tn: 158158.0000 - fn: 9870.0000 - accuracy: 0.9402 - precision: 0.9324 - recall: 0.6911 - auc: 0.9818 - prc: 0.9253\n",
      "Epoch 50: val_loss improved from 0.05905 to 0.05784, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0822 - tp: 22114.0000 - fp: 1604.0000 - tn: 158396.0000 - fn: 9886.0000 - accuracy: 0.9402 - precision: 0.9324 - recall: 0.6911 - auc: 0.9818 - prc: 0.9253 - val_loss: 0.0578 - val_tp: 3027.0000 - val_fp: 150.0000 - val_tn: 19850.0000 - val_fn: 973.0000 - val_accuracy: 0.9532 - val_precision: 0.9528 - val_recall: 0.7567 - val_auc: 0.9914 - val_prc: 0.9620\n",
      "Epoch 51/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0820 - tp: 21990.0000 - fp: 1674.0000 - tn: 157766.0000 - fn: 9898.0000 - accuracy: 0.9395 - precision: 0.9293 - recall: 0.6896 - auc: 0.9818 - prc: 0.9253\n",
      "Epoch 51: val_loss did not improve from 0.05784\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0819 - tp: 22075.0000 - fp: 1676.0000 - tn: 158324.0000 - fn: 9925.0000 - accuracy: 0.9396 - precision: 0.9294 - recall: 0.6898 - auc: 0.9818 - prc: 0.9254 - val_loss: 0.0607 - val_tp: 2993.0000 - val_fp: 147.0000 - val_tn: 19853.0000 - val_fn: 1007.0000 - val_accuracy: 0.9519 - val_precision: 0.9532 - val_recall: 0.7483 - val_auc: 0.9904 - val_prc: 0.9584\n",
      "Epoch 52/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0815 - tp: 22236.0000 - fp: 1665.0000 - tn: 158095.0000 - fn: 9716.0000 - accuracy: 0.9406 - precision: 0.9303 - recall: 0.6959 - auc: 0.9821 - prc: 0.9263\n",
      "Epoch 52: val_loss did not improve from 0.05784\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0815 - tp: 22270.0000 - fp: 1668.0000 - tn: 158332.0000 - fn: 9730.0000 - accuracy: 0.9406 - precision: 0.9303 - recall: 0.6959 - auc: 0.9821 - prc: 0.9263 - val_loss: 0.0583 - val_tp: 3036.0000 - val_fp: 125.0000 - val_tn: 19875.0000 - val_fn: 964.0000 - val_accuracy: 0.9546 - val_precision: 0.9605 - val_recall: 0.7590 - val_auc: 0.9913 - val_prc: 0.9623\n",
      "Epoch 53/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.0821 - tp: 22030.0000 - fp: 1624.0000 - tn: 157576.0000 - fn: 9810.0000 - accuracy: 0.9401 - precision: 0.9313 - recall: 0.6919 - auc: 0.9819 - prc: 0.9259\n",
      "Epoch 53: val_loss did not improve from 0.05784\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0822 - tp: 22146.0000 - fp: 1638.0000 - tn: 158362.0000 - fn: 9854.0000 - accuracy: 0.9401 - precision: 0.9311 - recall: 0.6921 - auc: 0.9819 - prc: 0.9258 - val_loss: 0.0593 - val_tp: 3007.0000 - val_fp: 163.0000 - val_tn: 19837.0000 - val_fn: 993.0000 - val_accuracy: 0.9518 - val_precision: 0.9486 - val_recall: 0.7517 - val_auc: 0.9908 - val_prc: 0.9599\n",
      "Epoch 54/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0811 - tp: 22198.0000 - fp: 1696.0000 - tn: 157984.0000 - fn: 9738.0000 - accuracy: 0.9403 - precision: 0.9290 - recall: 0.6951 - auc: 0.9823 - prc: 0.9269\n",
      "Epoch 54: val_loss did not improve from 0.05784\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0811 - tp: 22244.0000 - fp: 1701.0000 - tn: 158299.0000 - fn: 9756.0000 - accuracy: 0.9403 - precision: 0.9290 - recall: 0.6951 - auc: 0.9823 - prc: 0.9269 - val_loss: 0.0594 - val_tp: 2974.0000 - val_fp: 142.0000 - val_tn: 19858.0000 - val_fn: 1026.0000 - val_accuracy: 0.9513 - val_precision: 0.9544 - val_recall: 0.7435 - val_auc: 0.9908 - val_prc: 0.9599\n",
      "Epoch 55/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0807 - tp: 22251.0000 - fp: 1692.0000 - tn: 158228.0000 - fn: 9733.0000 - accuracy: 0.9405 - precision: 0.9293 - recall: 0.6957 - auc: 0.9824 - prc: 0.9276\n",
      "Epoch 55: val_loss improved from 0.05784 to 0.05727, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0807 - tp: 22265.0000 - fp: 1692.0000 - tn: 158308.0000 - fn: 9735.0000 - accuracy: 0.9405 - precision: 0.9294 - recall: 0.6958 - auc: 0.9824 - prc: 0.9276 - val_loss: 0.0573 - val_tp: 3044.0000 - val_fp: 151.0000 - val_tn: 19849.0000 - val_fn: 956.0000 - val_accuracy: 0.9539 - val_precision: 0.9527 - val_recall: 0.7610 - val_auc: 0.9914 - val_prc: 0.9625\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0814 - tp: 22208.0000 - fp: 1641.0000 - tn: 157399.0000 - fn: 9600.0000 - accuracy: 0.9411 - precision: 0.9312 - recall: 0.6982 - auc: 0.9821 - prc: 0.9270\n",
      "Epoch 56: val_loss did not improve from 0.05727\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0814 - tp: 22349.0000 - fp: 1648.0000 - tn: 158352.0000 - fn: 9651.0000 - accuracy: 0.9412 - precision: 0.9313 - recall: 0.6984 - auc: 0.9822 - prc: 0.9271 - val_loss: 0.0573 - val_tp: 3034.0000 - val_fp: 129.0000 - val_tn: 19871.0000 - val_fn: 966.0000 - val_accuracy: 0.9544 - val_precision: 0.9592 - val_recall: 0.7585 - val_auc: 0.9913 - val_prc: 0.9624\n",
      "Epoch 57/200\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 0.0809 - tp: 22190.0000 - fp: 1639.0000 - tn: 158201.0000 - fn: 9778.0000 - accuracy: 0.9405 - precision: 0.9312 - recall: 0.6941 - auc: 0.9823 - prc: 0.9277\n",
      "Epoch 57: val_loss did not improve from 0.05727\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0809 - tp: 22215.0000 - fp: 1641.0000 - tn: 158359.0000 - fn: 9785.0000 - accuracy: 0.9405 - precision: 0.9312 - recall: 0.6942 - auc: 0.9823 - prc: 0.9277 - val_loss: 0.0577 - val_tp: 3034.0000 - val_fp: 135.0000 - val_tn: 19865.0000 - val_fn: 966.0000 - val_accuracy: 0.9541 - val_precision: 0.9574 - val_recall: 0.7585 - val_auc: 0.9914 - val_prc: 0.9624\n",
      "Epoch 58/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0806 - tp: 22184.0000 - fp: 1663.0000 - tn: 157377.0000 - fn: 9624.0000 - accuracy: 0.9409 - precision: 0.9303 - recall: 0.6974 - auc: 0.9825 - prc: 0.9280\n",
      "Epoch 58: val_loss did not improve from 0.05727\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0805 - tp: 22326.0000 - fp: 1674.0000 - tn: 158326.0000 - fn: 9674.0000 - accuracy: 0.9409 - precision: 0.9302 - recall: 0.6977 - auc: 0.9826 - prc: 0.9281 - val_loss: 0.0610 - val_tp: 2928.0000 - val_fp: 140.0000 - val_tn: 19860.0000 - val_fn: 1072.0000 - val_accuracy: 0.9495 - val_precision: 0.9544 - val_recall: 0.7320 - val_auc: 0.9904 - val_prc: 0.9583\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0801 - tp: 22460.0000 - fp: 1571.0000 - tn: 158429.0000 - fn: 9540.0000 - accuracy: 0.9421 - precision: 0.9346 - recall: 0.7019 - auc: 0.9827 - prc: 0.9292\n",
      "Epoch 59: val_loss did not improve from 0.05727\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0801 - tp: 22460.0000 - fp: 1571.0000 - tn: 158429.0000 - fn: 9540.0000 - accuracy: 0.9421 - precision: 0.9346 - recall: 0.7019 - auc: 0.9827 - prc: 0.9292 - val_loss: 0.0579 - val_tp: 2890.0000 - val_fp: 90.0000 - val_tn: 19910.0000 - val_fn: 1110.0000 - val_accuracy: 0.9500 - val_precision: 0.9698 - val_recall: 0.7225 - val_auc: 0.9917 - val_prc: 0.9637\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0813 - tp: 22358.0000 - fp: 1664.0000 - tn: 158336.0000 - fn: 9642.0000 - accuracy: 0.9411 - precision: 0.9307 - recall: 0.6987 - auc: 0.9823 - prc: 0.9273\n",
      "Epoch 60: val_loss did not improve from 0.05727\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0813 - tp: 22358.0000 - fp: 1664.0000 - tn: 158336.0000 - fn: 9642.0000 - accuracy: 0.9411 - precision: 0.9307 - recall: 0.6987 - auc: 0.9823 - prc: 0.9273 - val_loss: 0.0605 - val_tp: 2883.0000 - val_fp: 101.0000 - val_tn: 19899.0000 - val_fn: 1117.0000 - val_accuracy: 0.9492 - val_precision: 0.9662 - val_recall: 0.7207 - val_auc: 0.9907 - val_prc: 0.9597\n",
      "Epoch 61/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0801 - tp: 22461.0000 - fp: 1618.0000 - tn: 158302.0000 - fn: 9523.0000 - accuracy: 0.9419 - precision: 0.9328 - recall: 0.7023 - auc: 0.9827 - prc: 0.9295\n",
      "Epoch 61: val_loss did not improve from 0.05727\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0801 - tp: 22473.0000 - fp: 1618.0000 - tn: 158382.0000 - fn: 9527.0000 - accuracy: 0.9420 - precision: 0.9328 - recall: 0.7023 - auc: 0.9827 - prc: 0.9295 - val_loss: 0.0582 - val_tp: 3054.0000 - val_fp: 146.0000 - val_tn: 19854.0000 - val_fn: 946.0000 - val_accuracy: 0.9545 - val_precision: 0.9544 - val_recall: 0.7635 - val_auc: 0.9913 - val_prc: 0.9616\n",
      "Epoch 62/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0800 - tp: 22422.0000 - fp: 1626.0000 - tn: 157894.0000 - fn: 9482.0000 - accuracy: 0.9420 - precision: 0.9324 - recall: 0.7028 - auc: 0.9827 - prc: 0.9293\n",
      "Epoch 62: val_loss improved from 0.05727 to 0.05672, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0800 - tp: 22489.0000 - fp: 1632.0000 - tn: 158368.0000 - fn: 9511.0000 - accuracy: 0.9420 - precision: 0.9323 - recall: 0.7028 - auc: 0.9827 - prc: 0.9293 - val_loss: 0.0567 - val_tp: 3028.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 972.0000 - val_accuracy: 0.9542 - val_precision: 0.9594 - val_recall: 0.7570 - val_auc: 0.9916 - val_prc: 0.9634\n",
      "Epoch 63/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0803 - tp: 22348.0000 - fp: 1588.0000 - tn: 157772.0000 - fn: 9524.0000 - accuracy: 0.9419 - precision: 0.9337 - recall: 0.7012 - auc: 0.9827 - prc: 0.9292\n",
      "Epoch 63: val_loss did not improve from 0.05672\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0804 - tp: 22438.0000 - fp: 1594.0000 - tn: 158406.0000 - fn: 9562.0000 - accuracy: 0.9419 - precision: 0.9337 - recall: 0.7012 - auc: 0.9827 - prc: 0.9291 - val_loss: 0.0569 - val_tp: 3103.0000 - val_fp: 161.0000 - val_tn: 19839.0000 - val_fn: 897.0000 - val_accuracy: 0.9559 - val_precision: 0.9507 - val_recall: 0.7757 - val_auc: 0.9916 - val_prc: 0.9635\n",
      "Epoch 64/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.0800 - tp: 22336.0000 - fp: 1602.0000 - tn: 157598.0000 - fn: 9504.0000 - accuracy: 0.9419 - precision: 0.9331 - recall: 0.7015 - auc: 0.9826 - prc: 0.9294\n",
      "Epoch 64: val_loss improved from 0.05672 to 0.05533, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0800 - tp: 22444.0000 - fp: 1614.0000 - tn: 158386.0000 - fn: 9556.0000 - accuracy: 0.9418 - precision: 0.9329 - recall: 0.7014 - auc: 0.9826 - prc: 0.9293 - val_loss: 0.0553 - val_tp: 3029.0000 - val_fp: 132.0000 - val_tn: 19868.0000 - val_fn: 971.0000 - val_accuracy: 0.9540 - val_precision: 0.9582 - val_recall: 0.7573 - val_auc: 0.9922 - val_prc: 0.9654\n",
      "Epoch 65/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0799 - tp: 22508.0000 - fp: 1596.0000 - tn: 157524.0000 - fn: 9316.0000 - accuracy: 0.9429 - precision: 0.9338 - recall: 0.7073 - auc: 0.9831 - prc: 0.9300\n",
      "Epoch 65: val_loss did not improve from 0.05533\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0799 - tp: 22634.0000 - fp: 1610.0000 - tn: 158390.0000 - fn: 9366.0000 - accuracy: 0.9428 - precision: 0.9336 - recall: 0.7073 - auc: 0.9831 - prc: 0.9300 - val_loss: 0.0569 - val_tp: 3057.0000 - val_fp: 149.0000 - val_tn: 19851.0000 - val_fn: 943.0000 - val_accuracy: 0.9545 - val_precision: 0.9535 - val_recall: 0.7642 - val_auc: 0.9917 - val_prc: 0.9633\n",
      "Epoch 66/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0796 - tp: 22464.0000 - fp: 1609.0000 - tn: 158311.0000 - fn: 9520.0000 - accuracy: 0.9420 - precision: 0.9332 - recall: 0.7024 - auc: 0.9830 - prc: 0.9298\n",
      "Epoch 66: val_loss did not improve from 0.05533\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0796 - tp: 22475.0000 - fp: 1609.0000 - tn: 158391.0000 - fn: 9525.0000 - accuracy: 0.9420 - precision: 0.9332 - recall: 0.7023 - auc: 0.9830 - prc: 0.9298 - val_loss: 0.0568 - val_tp: 3016.0000 - val_fp: 141.0000 - val_tn: 19859.0000 - val_fn: 984.0000 - val_accuracy: 0.9531 - val_precision: 0.9553 - val_recall: 0.7540 - val_auc: 0.9918 - val_prc: 0.9640\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0803 - tp: 22344.0000 - fp: 1589.0000 - tn: 158171.0000 - fn: 9608.0000 - accuracy: 0.9416 - precision: 0.9336 - recall: 0.6993 - auc: 0.9827 - prc: 0.9292\n",
      "Epoch 67: val_loss did not improve from 0.05533\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0803 - tp: 22376.0000 - fp: 1590.0000 - tn: 158410.0000 - fn: 9624.0000 - accuracy: 0.9416 - precision: 0.9337 - recall: 0.6992 - auc: 0.9827 - prc: 0.9292 - val_loss: 0.0565 - val_tp: 3033.0000 - val_fp: 137.0000 - val_tn: 19863.0000 - val_fn: 967.0000 - val_accuracy: 0.9540 - val_precision: 0.9568 - val_recall: 0.7582 - val_auc: 0.9918 - val_prc: 0.9639\n",
      "Epoch 68/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0790 - tp: 22433.0000 - fp: 1578.0000 - tn: 157702.0000 - fn: 9423.0000 - accuracy: 0.9424 - precision: 0.9343 - recall: 0.7042 - auc: 0.9831 - prc: 0.9313\n",
      "Epoch 68: val_loss did not improve from 0.05533\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0789 - tp: 22538.0000 - fp: 1583.0000 - tn: 158417.0000 - fn: 9462.0000 - accuracy: 0.9425 - precision: 0.9344 - recall: 0.7043 - auc: 0.9831 - prc: 0.9314 - val_loss: 0.0554 - val_tp: 3087.0000 - val_fp: 143.0000 - val_tn: 19857.0000 - val_fn: 913.0000 - val_accuracy: 0.9560 - val_precision: 0.9557 - val_recall: 0.7717 - val_auc: 0.9922 - val_prc: 0.9658\n",
      "Epoch 69/200\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 0.0787 - tp: 22703.0000 - fp: 1648.0000 - tn: 158192.0000 - fn: 9265.0000 - accuracy: 0.9431 - precision: 0.9323 - recall: 0.7102 - auc: 0.9832 - prc: 0.9320\n",
      "Epoch 69: val_loss did not improve from 0.05533\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0787 - tp: 22727.0000 - fp: 1649.0000 - tn: 158351.0000 - fn: 9273.0000 - accuracy: 0.9431 - precision: 0.9324 - recall: 0.7102 - auc: 0.9832 - prc: 0.9321 - val_loss: 0.0556 - val_tp: 3071.0000 - val_fp: 118.0000 - val_tn: 19882.0000 - val_fn: 929.0000 - val_accuracy: 0.9564 - val_precision: 0.9630 - val_recall: 0.7678 - val_auc: 0.9921 - val_prc: 0.9655\n",
      "Epoch 70/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0797 - tp: 22526.0000 - fp: 1590.0000 - tn: 158170.0000 - fn: 9426.0000 - accuracy: 0.9425 - precision: 0.9341 - recall: 0.7050 - auc: 0.9830 - prc: 0.9307\n",
      "Epoch 70: val_loss did not improve from 0.05533\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0797 - tp: 22558.0000 - fp: 1592.0000 - tn: 158408.0000 - fn: 9442.0000 - accuracy: 0.9425 - precision: 0.9341 - recall: 0.7049 - auc: 0.9830 - prc: 0.9306 - val_loss: 0.0575 - val_tp: 2917.0000 - val_fp: 100.0000 - val_tn: 19900.0000 - val_fn: 1083.0000 - val_accuracy: 0.9507 - val_precision: 0.9669 - val_recall: 0.7293 - val_auc: 0.9918 - val_prc: 0.9645\n",
      "Epoch 71/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0782 - tp: 22647.0000 - fp: 1597.0000 - tn: 158083.0000 - fn: 9289.0000 - accuracy: 0.9432 - precision: 0.9341 - recall: 0.7091 - auc: 0.9835 - prc: 0.9320\n",
      "Epoch 71: val_loss improved from 0.05533 to 0.05446, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0782 - tp: 22693.0000 - fp: 1600.0000 - tn: 158400.0000 - fn: 9307.0000 - accuracy: 0.9432 - precision: 0.9341 - recall: 0.7092 - auc: 0.9835 - prc: 0.9320 - val_loss: 0.0545 - val_tp: 3051.0000 - val_fp: 117.0000 - val_tn: 19883.0000 - val_fn: 949.0000 - val_accuracy: 0.9556 - val_precision: 0.9631 - val_recall: 0.7628 - val_auc: 0.9924 - val_prc: 0.9665\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0784 - tp: 22615.0000 - fp: 1627.0000 - tn: 158373.0000 - fn: 9385.0000 - accuracy: 0.9426 - precision: 0.9329 - recall: 0.7067 - auc: 0.9833 - prc: 0.9319\n",
      "Epoch 72: val_loss improved from 0.05446 to 0.05424, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0784 - tp: 22615.0000 - fp: 1627.0000 - tn: 158373.0000 - fn: 9385.0000 - accuracy: 0.9426 - precision: 0.9329 - recall: 0.7067 - auc: 0.9833 - prc: 0.9319 - val_loss: 0.0542 - val_tp: 3065.0000 - val_fp: 127.0000 - val_tn: 19873.0000 - val_fn: 935.0000 - val_accuracy: 0.9557 - val_precision: 0.9602 - val_recall: 0.7663 - val_auc: 0.9925 - val_prc: 0.9669\n",
      "Epoch 73/200\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 0.0790 - tp: 22696.0000 - fp: 1584.0000 - tn: 158256.0000 - fn: 9272.0000 - accuracy: 0.9434 - precision: 0.9348 - recall: 0.7100 - auc: 0.9833 - prc: 0.9316\n",
      "Epoch 73: val_loss did not improve from 0.05424\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0790 - tp: 22715.0000 - fp: 1586.0000 - tn: 158414.0000 - fn: 9285.0000 - accuracy: 0.9434 - precision: 0.9347 - recall: 0.7098 - auc: 0.9833 - prc: 0.9316 - val_loss: 0.0573 - val_tp: 3082.0000 - val_fp: 154.0000 - val_tn: 19846.0000 - val_fn: 918.0000 - val_accuracy: 0.9553 - val_precision: 0.9524 - val_recall: 0.7705 - val_auc: 0.9914 - val_prc: 0.9628\n",
      "Epoch 74/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0800 - tp: 22526.0000 - fp: 1619.0000 - tn: 157901.0000 - fn: 9378.0000 - accuracy: 0.9426 - precision: 0.9329 - recall: 0.7061 - auc: 0.9830 - prc: 0.9304\n",
      "Epoch 74: val_loss did not improve from 0.05424\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0799 - tp: 22591.0000 - fp: 1621.0000 - tn: 158379.0000 - fn: 9409.0000 - accuracy: 0.9426 - precision: 0.9330 - recall: 0.7060 - auc: 0.9830 - prc: 0.9305 - val_loss: 0.0586 - val_tp: 2931.0000 - val_fp: 120.0000 - val_tn: 19880.0000 - val_fn: 1069.0000 - val_accuracy: 0.9505 - val_precision: 0.9607 - val_recall: 0.7327 - val_auc: 0.9911 - val_prc: 0.9616\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0788 - tp: 22748.0000 - fp: 1568.0000 - tn: 158432.0000 - fn: 9252.0000 - accuracy: 0.9436 - precision: 0.9355 - recall: 0.7109 - auc: 0.9833 - prc: 0.9322\n",
      "Epoch 75: val_loss did not improve from 0.05424\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0788 - tp: 22748.0000 - fp: 1568.0000 - tn: 158432.0000 - fn: 9252.0000 - accuracy: 0.9436 - precision: 0.9355 - recall: 0.7109 - auc: 0.9833 - prc: 0.9322 - val_loss: 0.0557 - val_tp: 3023.0000 - val_fp: 123.0000 - val_tn: 19877.0000 - val_fn: 977.0000 - val_accuracy: 0.9542 - val_precision: 0.9609 - val_recall: 0.7558 - val_auc: 0.9920 - val_prc: 0.9650\n",
      "Epoch 76/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0780 - tp: 22743.0000 - fp: 1611.0000 - tn: 158069.0000 - fn: 9193.0000 - accuracy: 0.9436 - precision: 0.9339 - recall: 0.7121 - auc: 0.9837 - prc: 0.9332\n",
      "Epoch 76: val_loss improved from 0.05424 to 0.05409, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0780 - tp: 22789.0000 - fp: 1615.0000 - tn: 158385.0000 - fn: 9211.0000 - accuracy: 0.9436 - precision: 0.9338 - recall: 0.7122 - auc: 0.9837 - prc: 0.9332 - val_loss: 0.0541 - val_tp: 3089.0000 - val_fp: 138.0000 - val_tn: 19862.0000 - val_fn: 911.0000 - val_accuracy: 0.9563 - val_precision: 0.9572 - val_recall: 0.7722 - val_auc: 0.9924 - val_prc: 0.9670\n",
      "Epoch 77/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0774 - tp: 22589.0000 - fp: 1606.0000 - tn: 157834.0000 - fn: 9299.0000 - accuracy: 0.9430 - precision: 0.9336 - recall: 0.7084 - auc: 0.9837 - prc: 0.9336\n",
      "Epoch 77: val_loss improved from 0.05409 to 0.05391, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0773 - tp: 22669.0000 - fp: 1613.0000 - tn: 158387.0000 - fn: 9331.0000 - accuracy: 0.9430 - precision: 0.9336 - recall: 0.7084 - auc: 0.9837 - prc: 0.9336 - val_loss: 0.0539 - val_tp: 3199.0000 - val_fp: 169.0000 - val_tn: 19831.0000 - val_fn: 801.0000 - val_accuracy: 0.9596 - val_precision: 0.9498 - val_recall: 0.7997 - val_auc: 0.9925 - val_prc: 0.9670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0774 - tp: 22603.0000 - fp: 1588.0000 - tn: 157452.0000 - fn: 9205.0000 - accuracy: 0.9434 - precision: 0.9344 - recall: 0.7106 - auc: 0.9839 - prc: 0.9338\n",
      "Epoch 78: val_loss did not improve from 0.05391\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0774 - tp: 22743.0000 - fp: 1597.0000 - tn: 158403.0000 - fn: 9257.0000 - accuracy: 0.9435 - precision: 0.9344 - recall: 0.7107 - auc: 0.9839 - prc: 0.9339 - val_loss: 0.0548 - val_tp: 3092.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 908.0000 - val_accuracy: 0.9568 - val_precision: 0.9602 - val_recall: 0.7730 - val_auc: 0.9923 - val_prc: 0.9664\n",
      "Epoch 79/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0783 - tp: 22514.0000 - fp: 1573.0000 - tn: 157547.0000 - fn: 9310.0000 - accuracy: 0.9430 - precision: 0.9347 - recall: 0.7075 - auc: 0.9836 - prc: 0.9325\n",
      "Epoch 79: val_loss improved from 0.05391 to 0.05337, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0784 - tp: 22635.0000 - fp: 1585.0000 - tn: 158415.0000 - fn: 9365.0000 - accuracy: 0.9430 - precision: 0.9346 - recall: 0.7073 - auc: 0.9835 - prc: 0.9324 - val_loss: 0.0534 - val_tp: 3123.0000 - val_fp: 126.0000 - val_tn: 19874.0000 - val_fn: 877.0000 - val_accuracy: 0.9582 - val_precision: 0.9612 - val_recall: 0.7807 - val_auc: 0.9927 - val_prc: 0.9677\n",
      "Epoch 80/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0777 - tp: 22771.0000 - fp: 1639.0000 - tn: 157401.0000 - fn: 9037.0000 - accuracy: 0.9441 - precision: 0.9329 - recall: 0.7159 - auc: 0.9838 - prc: 0.9334\n",
      "Epoch 80: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0776 - tp: 22914.0000 - fp: 1648.0000 - tn: 158352.0000 - fn: 9086.0000 - accuracy: 0.9441 - precision: 0.9329 - recall: 0.7161 - auc: 0.9838 - prc: 0.9335 - val_loss: 0.0546 - val_tp: 3052.0000 - val_fp: 127.0000 - val_tn: 19873.0000 - val_fn: 948.0000 - val_accuracy: 0.9552 - val_precision: 0.9601 - val_recall: 0.7630 - val_auc: 0.9924 - val_prc: 0.9664\n",
      "Epoch 81/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0777 - tp: 22771.0000 - fp: 1613.0000 - tn: 157747.0000 - fn: 9101.0000 - accuracy: 0.9440 - precision: 0.9339 - recall: 0.7145 - auc: 0.9839 - prc: 0.9338\n",
      "Epoch 81: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0777 - tp: 22866.0000 - fp: 1616.0000 - tn: 158384.0000 - fn: 9134.0000 - accuracy: 0.9440 - precision: 0.9340 - recall: 0.7146 - auc: 0.9839 - prc: 0.9338 - val_loss: 0.0548 - val_tp: 3061.0000 - val_fp: 129.0000 - val_tn: 19871.0000 - val_fn: 939.0000 - val_accuracy: 0.9555 - val_precision: 0.9596 - val_recall: 0.7653 - val_auc: 0.9924 - val_prc: 0.9663\n",
      "Epoch 82/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0783 - tp: 22707.0000 - fp: 1602.0000 - tn: 157518.0000 - fn: 9117.0000 - accuracy: 0.9439 - precision: 0.9341 - recall: 0.7135 - auc: 0.9837 - prc: 0.9331\n",
      "Epoch 82: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0782 - tp: 22842.0000 - fp: 1609.0000 - tn: 158391.0000 - fn: 9158.0000 - accuracy: 0.9439 - precision: 0.9342 - recall: 0.7138 - auc: 0.9838 - prc: 0.9333 - val_loss: 0.0554 - val_tp: 3093.0000 - val_fp: 139.0000 - val_tn: 19861.0000 - val_fn: 907.0000 - val_accuracy: 0.9564 - val_precision: 0.9570 - val_recall: 0.7732 - val_auc: 0.9920 - val_prc: 0.9649\n",
      "Epoch 83/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0770 - tp: 23027.0000 - fp: 1577.0000 - tn: 157863.0000 - fn: 8861.0000 - accuracy: 0.9454 - precision: 0.9359 - recall: 0.7221 - auc: 0.9842 - prc: 0.9351\n",
      "Epoch 83: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0770 - tp: 23108.0000 - fp: 1582.0000 - tn: 158418.0000 - fn: 8892.0000 - accuracy: 0.9454 - precision: 0.9359 - recall: 0.7221 - auc: 0.9842 - prc: 0.9351 - val_loss: 0.0547 - val_tp: 3007.0000 - val_fp: 100.0000 - val_tn: 19900.0000 - val_fn: 993.0000 - val_accuracy: 0.9545 - val_precision: 0.9678 - val_recall: 0.7517 - val_auc: 0.9924 - val_prc: 0.9670\n",
      "Epoch 84/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0777 - tp: 22807.0000 - fp: 1525.0000 - tn: 157915.0000 - fn: 9081.0000 - accuracy: 0.9446 - precision: 0.9373 - recall: 0.7152 - auc: 0.9839 - prc: 0.9338\n",
      "Epoch 84: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0777 - tp: 22891.0000 - fp: 1531.0000 - tn: 158469.0000 - fn: 9109.0000 - accuracy: 0.9446 - precision: 0.9373 - recall: 0.7153 - auc: 0.9839 - prc: 0.9338 - val_loss: 0.0555 - val_tp: 2992.0000 - val_fp: 101.0000 - val_tn: 19899.0000 - val_fn: 1008.0000 - val_accuracy: 0.9538 - val_precision: 0.9673 - val_recall: 0.7480 - val_auc: 0.9924 - val_prc: 0.9667\n",
      "Epoch 85/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0769 - tp: 22784.0000 - fp: 1600.0000 - tn: 157760.0000 - fn: 9088.0000 - accuracy: 0.9441 - precision: 0.9344 - recall: 0.7149 - auc: 0.9841 - prc: 0.9345\n",
      "Epoch 85: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.0769 - tp: 22875.0000 - fp: 1607.0000 - tn: 158393.0000 - fn: 9125.0000 - accuracy: 0.9441 - precision: 0.9344 - recall: 0.7148 - auc: 0.9841 - prc: 0.9344 - val_loss: 0.0544 - val_tp: 3119.0000 - val_fp: 133.0000 - val_tn: 19867.0000 - val_fn: 881.0000 - val_accuracy: 0.9578 - val_precision: 0.9591 - val_recall: 0.7797 - val_auc: 0.9926 - val_prc: 0.9671\n",
      "Epoch 86/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0767 - tp: 22957.0000 - fp: 1571.0000 - tn: 157869.0000 - fn: 8931.0000 - accuracy: 0.9451 - precision: 0.9360 - recall: 0.7199 - auc: 0.9841 - prc: 0.9352\n",
      "Epoch 86: val_loss did not improve from 0.05337\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0766 - tp: 23044.0000 - fp: 1575.0000 - tn: 158425.0000 - fn: 8956.0000 - accuracy: 0.9452 - precision: 0.9360 - recall: 0.7201 - auc: 0.9841 - prc: 0.9353 - val_loss: 0.0552 - val_tp: 2999.0000 - val_fp: 115.0000 - val_tn: 19885.0000 - val_fn: 1001.0000 - val_accuracy: 0.9535 - val_precision: 0.9631 - val_recall: 0.7498 - val_auc: 0.9923 - val_prc: 0.9662\n",
      "Epoch 87/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0774 - tp: 22770.0000 - fp: 1541.0000 - tn: 157899.0000 - fn: 9118.0000 - accuracy: 0.9443 - precision: 0.9366 - recall: 0.7141 - auc: 0.9840 - prc: 0.9346\n",
      "Epoch 87: val_loss improved from 0.05337 to 0.05315, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 0.0775 - tp: 22852.0000 - fp: 1550.0000 - tn: 158450.0000 - fn: 9148.0000 - accuracy: 0.9443 - precision: 0.9365 - recall: 0.7141 - auc: 0.9840 - prc: 0.9346 - val_loss: 0.0532 - val_tp: 3095.0000 - val_fp: 129.0000 - val_tn: 19871.0000 - val_fn: 905.0000 - val_accuracy: 0.9569 - val_precision: 0.9600 - val_recall: 0.7738 - val_auc: 0.9929 - val_prc: 0.9685\n",
      "Epoch 88/200\n",
      "1992/2000 [============================>.] - ETA: 0s - loss: 0.0775 - tp: 22736.0000 - fp: 1575.0000 - tn: 157785.0000 - fn: 9136.0000 - accuracy: 0.9440 - precision: 0.9352 - recall: 0.7134 - auc: 0.9839 - prc: 0.9338\n",
      "Epoch 88: val_loss did not improve from 0.05315\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0775 - tp: 22824.0000 - fp: 1581.0000 - tn: 158419.0000 - fn: 9176.0000 - accuracy: 0.9440 - precision: 0.9352 - recall: 0.7132 - auc: 0.9839 - prc: 0.9338 - val_loss: 0.0554 - val_tp: 3064.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 936.0000 - val_accuracy: 0.9557 - val_precision: 0.9599 - val_recall: 0.7660 - val_auc: 0.9922 - val_prc: 0.9658\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0764 - tp: 23103.0000 - fp: 1542.0000 - tn: 158458.0000 - fn: 8897.0000 - accuracy: 0.9456 - precision: 0.9374 - recall: 0.7220 - auc: 0.9844 - prc: 0.9362\n",
      "Epoch 89: val_loss did not improve from 0.05315\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0764 - tp: 23103.0000 - fp: 1542.0000 - tn: 158458.0000 - fn: 8897.0000 - accuracy: 0.9456 - precision: 0.9374 - recall: 0.7220 - auc: 0.9844 - prc: 0.9362 - val_loss: 0.0549 - val_tp: 3091.0000 - val_fp: 141.0000 - val_tn: 19859.0000 - val_fn: 909.0000 - val_accuracy: 0.9563 - val_precision: 0.9564 - val_recall: 0.7728 - val_auc: 0.9922 - val_prc: 0.9657\n",
      "Epoch 90/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0771 - tp: 22856.0000 - fp: 1558.0000 - tn: 158362.0000 - fn: 9128.0000 - accuracy: 0.9443 - precision: 0.9362 - recall: 0.7146 - auc: 0.9841 - prc: 0.9348\n",
      "Epoch 90: val_loss improved from 0.05315 to 0.05275, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0771 - tp: 22866.0000 - fp: 1558.0000 - tn: 158442.0000 - fn: 9134.0000 - accuracy: 0.9443 - precision: 0.9362 - recall: 0.7146 - auc: 0.9841 - prc: 0.9349 - val_loss: 0.0528 - val_tp: 3088.0000 - val_fp: 108.0000 - val_tn: 19892.0000 - val_fn: 912.0000 - val_accuracy: 0.9575 - val_precision: 0.9662 - val_recall: 0.7720 - val_auc: 0.9929 - val_prc: 0.9693\n",
      "Epoch 91/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0770 - tp: 22827.0000 - fp: 1595.0000 - tn: 157925.0000 - fn: 9077.0000 - accuracy: 0.9442 - precision: 0.9347 - recall: 0.7155 - auc: 0.9841 - prc: 0.9348\n",
      "Epoch 91: val_loss did not improve from 0.05275\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0769 - tp: 22899.0000 - fp: 1600.0000 - tn: 158400.0000 - fn: 9101.0000 - accuracy: 0.9443 - precision: 0.9347 - recall: 0.7156 - auc: 0.9841 - prc: 0.9349 - val_loss: 0.0537 - val_tp: 3093.0000 - val_fp: 117.0000 - val_tn: 19883.0000 - val_fn: 907.0000 - val_accuracy: 0.9573 - val_precision: 0.9636 - val_recall: 0.7732 - val_auc: 0.9927 - val_prc: 0.9683\n",
      "Epoch 92/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0773 - tp: 22945.0000 - fp: 1591.0000 - tn: 158089.0000 - fn: 8991.0000 - accuracy: 0.9448 - precision: 0.9352 - recall: 0.7185 - auc: 0.9840 - prc: 0.9346\n",
      "Epoch 92: val_loss did not improve from 0.05275\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0773 - tp: 22989.0000 - fp: 1595.0000 - tn: 158405.0000 - fn: 9011.0000 - accuracy: 0.9448 - precision: 0.9351 - recall: 0.7184 - auc: 0.9840 - prc: 0.9346 - val_loss: 0.0543 - val_tp: 3091.0000 - val_fp: 143.0000 - val_tn: 19857.0000 - val_fn: 909.0000 - val_accuracy: 0.9562 - val_precision: 0.9558 - val_recall: 0.7728 - val_auc: 0.9924 - val_prc: 0.9663\n",
      "Epoch 93/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0769 - tp: 22858.0000 - fp: 1580.0000 - tn: 157540.0000 - fn: 8966.0000 - accuracy: 0.9448 - precision: 0.9353 - recall: 0.7183 - auc: 0.9843 - prc: 0.9349\n",
      "Epoch 93: val_loss improved from 0.05275 to 0.05273, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.0769 - tp: 22989.0000 - fp: 1587.0000 - tn: 158413.0000 - fn: 9011.0000 - accuracy: 0.9448 - precision: 0.9354 - recall: 0.7184 - auc: 0.9843 - prc: 0.9349 - val_loss: 0.0527 - val_tp: 3208.0000 - val_fp: 160.0000 - val_tn: 19840.0000 - val_fn: 792.0000 - val_accuracy: 0.9603 - val_precision: 0.9525 - val_recall: 0.8020 - val_auc: 0.9928 - val_prc: 0.9687\n",
      "Epoch 94/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0760 - tp: 23168.0000 - fp: 1597.0000 - tn: 157923.0000 - fn: 8736.0000 - accuracy: 0.9460 - precision: 0.9355 - recall: 0.7262 - auc: 0.9845 - prc: 0.9362\n",
      "Epoch 94: val_loss did not improve from 0.05273\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0760 - tp: 23239.0000 - fp: 1604.0000 - tn: 158396.0000 - fn: 8761.0000 - accuracy: 0.9460 - precision: 0.9354 - recall: 0.7262 - auc: 0.9845 - prc: 0.9363 - val_loss: 0.0530 - val_tp: 3112.0000 - val_fp: 117.0000 - val_tn: 19883.0000 - val_fn: 888.0000 - val_accuracy: 0.9581 - val_precision: 0.9638 - val_recall: 0.7780 - val_auc: 0.9929 - val_prc: 0.9688\n",
      "Epoch 95/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0757 - tp: 23086.0000 - fp: 1619.0000 - tn: 158141.0000 - fn: 8866.0000 - accuracy: 0.9453 - precision: 0.9345 - recall: 0.7225 - auc: 0.9846 - prc: 0.9367\n",
      "Epoch 95: val_loss did not improve from 0.05273\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0757 - tp: 23129.0000 - fp: 1619.0000 - tn: 158381.0000 - fn: 8871.0000 - accuracy: 0.9454 - precision: 0.9346 - recall: 0.7228 - auc: 0.9846 - prc: 0.9368 - val_loss: 0.0535 - val_tp: 3184.0000 - val_fp: 165.0000 - val_tn: 19835.0000 - val_fn: 816.0000 - val_accuracy: 0.9591 - val_precision: 0.9507 - val_recall: 0.7960 - val_auc: 0.9927 - val_prc: 0.9675\n",
      "Epoch 96/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0758 - tp: 23017.0000 - fp: 1640.0000 - tn: 158040.0000 - fn: 8919.0000 - accuracy: 0.9449 - precision: 0.9335 - recall: 0.7207 - auc: 0.9845 - prc: 0.9365\n",
      "Epoch 96: val_loss improved from 0.05273 to 0.05260, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0757 - tp: 23065.0000 - fp: 1643.0000 - tn: 158357.0000 - fn: 8935.0000 - accuracy: 0.9449 - precision: 0.9335 - recall: 0.7208 - auc: 0.9845 - prc: 0.9366 - val_loss: 0.0526 - val_tp: 3033.0000 - val_fp: 110.0000 - val_tn: 19890.0000 - val_fn: 967.0000 - val_accuracy: 0.9551 - val_precision: 0.9650 - val_recall: 0.7582 - val_auc: 0.9931 - val_prc: 0.9690\n",
      "Epoch 97/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0756 - tp: 23095.0000 - fp: 1522.0000 - tn: 158078.0000 - fn: 8825.0000 - accuracy: 0.9460 - precision: 0.9382 - recall: 0.7235 - auc: 0.9847 - prc: 0.9373\n",
      "Epoch 97: val_loss did not improve from 0.05260\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0756 - tp: 23154.0000 - fp: 1525.0000 - tn: 158475.0000 - fn: 8846.0000 - accuracy: 0.9460 - precision: 0.9382 - recall: 0.7236 - auc: 0.9847 - prc: 0.9373 - val_loss: 0.0554 - val_tp: 3083.0000 - val_fp: 124.0000 - val_tn: 19876.0000 - val_fn: 917.0000 - val_accuracy: 0.9566 - val_precision: 0.9613 - val_recall: 0.7707 - val_auc: 0.9923 - val_prc: 0.9660\n",
      "Epoch 98/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0766 - tp: 22918.0000 - fp: 1609.0000 - tn: 157831.0000 - fn: 8970.0000 - accuracy: 0.9447 - precision: 0.9344 - recall: 0.7187 - auc: 0.9843 - prc: 0.9352\n",
      "Epoch 98: val_loss did not improve from 0.05260\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 0.0767 - tp: 22988.0000 - fp: 1617.0000 - tn: 158383.0000 - fn: 9012.0000 - accuracy: 0.9446 - precision: 0.9343 - recall: 0.7184 - auc: 0.9843 - prc: 0.9351 - val_loss: 0.0540 - val_tp: 3074.0000 - val_fp: 108.0000 - val_tn: 19892.0000 - val_fn: 926.0000 - val_accuracy: 0.9569 - val_precision: 0.9661 - val_recall: 0.7685 - val_auc: 0.9928 - val_prc: 0.9683\n",
      "Epoch 99/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0766 - tp: 22938.0000 - fp: 1572.0000 - tn: 158028.0000 - fn: 8982.0000 - accuracy: 0.9449 - precision: 0.9359 - recall: 0.7186 - auc: 0.9844 - prc: 0.9356\n",
      "Epoch 99: val_loss did not improve from 0.05260\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.0765 - tp: 22997.0000 - fp: 1574.0000 - tn: 158426.0000 - fn: 9003.0000 - accuracy: 0.9449 - precision: 0.9359 - recall: 0.7187 - auc: 0.9844 - prc: 0.9357 - val_loss: 0.0532 - val_tp: 3150.0000 - val_fp: 141.0000 - val_tn: 19859.0000 - val_fn: 850.0000 - val_accuracy: 0.9587 - val_precision: 0.9572 - val_recall: 0.7875 - val_auc: 0.9928 - val_prc: 0.9680\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0766 - tp: 23147.0000 - fp: 1627.0000 - tn: 157973.0000 - fn: 8773.0000 - accuracy: 0.9457 - precision: 0.9343 - recall: 0.7252 - auc: 0.9845 - prc: 0.9365\n",
      "Epoch 100: val_loss did not improve from 0.05260\n",
      "2000/2000 [==============================] - 9s 5ms/step - loss: 0.0766 - tp: 23199.0000 - fp: 1630.0000 - tn: 158370.0000 - fn: 8801.0000 - accuracy: 0.9457 - precision: 0.9344 - recall: 0.7250 - auc: 0.9845 - prc: 0.9365 - val_loss: 0.0543 - val_tp: 3053.0000 - val_fp: 111.0000 - val_tn: 19889.0000 - val_fn: 947.0000 - val_accuracy: 0.9559 - val_precision: 0.9649 - val_recall: 0.7632 - val_auc: 0.9925 - val_prc: 0.9674\n",
      "Epoch 101/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.0766 - tp: 22896.0000 - fp: 1639.0000 - tn: 157561.0000 - fn: 8944.0000 - accuracy: 0.9446 - precision: 0.9332 - recall: 0.7191 - auc: 0.9844 - prc: 0.9350\n",
      "Epoch 101: val_loss improved from 0.05260 to 0.05203, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0766 - tp: 23019.0000 - fp: 1650.0000 - tn: 158350.0000 - fn: 8981.0000 - accuracy: 0.9446 - precision: 0.9331 - recall: 0.7193 - auc: 0.9844 - prc: 0.9351 - val_loss: 0.0520 - val_tp: 3150.0000 - val_fp: 126.0000 - val_tn: 19874.0000 - val_fn: 850.0000 - val_accuracy: 0.9593 - val_precision: 0.9615 - val_recall: 0.7875 - val_auc: 0.9932 - val_prc: 0.9699\n",
      "Epoch 102/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 23158.0000 - fp: 1581.0000 - tn: 158099.0000 - fn: 8778.0000 - accuracy: 0.9459 - precision: 0.9361 - recall: 0.7251 - auc: 0.9848 - prc: 0.9380\n",
      "Epoch 102: val_loss improved from 0.05203 to 0.05188, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.0753 - tp: 23206.0000 - fp: 1583.0000 - tn: 158417.0000 - fn: 8794.0000 - accuracy: 0.9460 - precision: 0.9361 - recall: 0.7252 - auc: 0.9848 - prc: 0.9380 - val_loss: 0.0519 - val_tp: 3131.0000 - val_fp: 125.0000 - val_tn: 19875.0000 - val_fn: 869.0000 - val_accuracy: 0.9586 - val_precision: 0.9616 - val_recall: 0.7828 - val_auc: 0.9932 - val_prc: 0.9701\n",
      "Epoch 103/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0759 - tp: 23044.0000 - fp: 1576.0000 - tn: 157864.0000 - fn: 8844.0000 - accuracy: 0.9455 - precision: 0.9360 - recall: 0.7227 - auc: 0.9847 - prc: 0.9369\n",
      "Epoch 103: val_loss did not improve from 0.05188\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0759 - tp: 23125.0000 - fp: 1582.0000 - tn: 158418.0000 - fn: 8875.0000 - accuracy: 0.9455 - precision: 0.9360 - recall: 0.7227 - auc: 0.9847 - prc: 0.9369 - val_loss: 0.0532 - val_tp: 3087.0000 - val_fp: 117.0000 - val_tn: 19883.0000 - val_fn: 913.0000 - val_accuracy: 0.9571 - val_precision: 0.9635 - val_recall: 0.7717 - val_auc: 0.9927 - val_prc: 0.9685\n",
      "Epoch 104/200\n",
      "1980/2000 [============================>.] - ETA: 0s - loss: 0.0755 - tp: 22944.0000 - fp: 1512.0000 - tn: 156888.0000 - fn: 8736.0000 - accuracy: 0.9461 - precision: 0.9382 - recall: 0.7242 - auc: 0.9848 - prc: 0.9374\n",
      "Epoch 104: val_loss did not improve from 0.05188\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0756 - tp: 23174.0000 - fp: 1533.0000 - tn: 158467.0000 - fn: 8826.0000 - accuracy: 0.9460 - precision: 0.9380 - recall: 0.7242 - auc: 0.9848 - prc: 0.9373 - val_loss: 0.0519 - val_tp: 3075.0000 - val_fp: 99.0000 - val_tn: 19901.0000 - val_fn: 925.0000 - val_accuracy: 0.9573 - val_precision: 0.9688 - val_recall: 0.7688 - val_auc: 0.9934 - val_prc: 0.9711\n",
      "Epoch 105/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0762 - tp: 23011.0000 - fp: 1568.0000 - tn: 157712.0000 - fn: 8845.0000 - accuracy: 0.9455 - precision: 0.9362 - recall: 0.7223 - auc: 0.9846 - prc: 0.9364\n",
      "Epoch 105: val_loss did not improve from 0.05188\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0761 - tp: 23114.0000 - fp: 1572.0000 - tn: 158428.0000 - fn: 8886.0000 - accuracy: 0.9455 - precision: 0.9363 - recall: 0.7223 - auc: 0.9847 - prc: 0.9365 - val_loss: 0.0532 - val_tp: 3139.0000 - val_fp: 134.0000 - val_tn: 19866.0000 - val_fn: 861.0000 - val_accuracy: 0.9585 - val_precision: 0.9591 - val_recall: 0.7847 - val_auc: 0.9928 - val_prc: 0.9689\n",
      "Epoch 106/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0752 - tp: 23227.0000 - fp: 1507.0000 - tn: 157613.0000 - fn: 8597.0000 - accuracy: 0.9471 - precision: 0.9391 - recall: 0.7299 - auc: 0.9850 - prc: 0.9386\n",
      "Epoch 106: val_loss improved from 0.05188 to 0.05127, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0752 - tp: 23356.0000 - fp: 1517.0000 - tn: 158483.0000 - fn: 8644.0000 - accuracy: 0.9471 - precision: 0.9390 - recall: 0.7299 - auc: 0.9850 - prc: 0.9386 - val_loss: 0.0513 - val_tp: 3235.0000 - val_fp: 151.0000 - val_tn: 19849.0000 - val_fn: 765.0000 - val_accuracy: 0.9618 - val_precision: 0.9554 - val_recall: 0.8087 - val_auc: 0.9934 - val_prc: 0.9710\n",
      "Epoch 107/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0759 - tp: 23169.0000 - fp: 1586.0000 - tn: 157454.0000 - fn: 8639.0000 - accuracy: 0.9464 - precision: 0.9359 - recall: 0.7284 - auc: 0.9847 - prc: 0.9372\n",
      "Epoch 107: val_loss did not improve from 0.05127\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0760 - tp: 23313.0000 - fp: 1598.0000 - tn: 158402.0000 - fn: 8687.0000 - accuracy: 0.9464 - precision: 0.9359 - recall: 0.7285 - auc: 0.9847 - prc: 0.9371 - val_loss: 0.0554 - val_tp: 3133.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 867.0000 - val_accuracy: 0.9585 - val_precision: 0.9607 - val_recall: 0.7832 - val_auc: 0.9920 - val_prc: 0.9663\n",
      "Epoch 108/200\n",
      "1982/2000 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 22970.0000 - fp: 1558.0000 - tn: 157002.0000 - fn: 8742.0000 - accuracy: 0.9459 - precision: 0.9365 - recall: 0.7243 - auc: 0.9848 - prc: 0.9378\n",
      "Epoch 108: val_loss did not improve from 0.05127\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0753 - tp: 23189.0000 - fp: 1567.0000 - tn: 158433.0000 - fn: 8811.0000 - accuracy: 0.9459 - precision: 0.9367 - recall: 0.7247 - auc: 0.9848 - prc: 0.9380 - val_loss: 0.0520 - val_tp: 3124.0000 - val_fp: 134.0000 - val_tn: 19866.0000 - val_fn: 876.0000 - val_accuracy: 0.9579 - val_precision: 0.9589 - val_recall: 0.7810 - val_auc: 0.9931 - val_prc: 0.9695\n",
      "Epoch 109/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0744 - tp: 23231.0000 - fp: 1581.0000 - tn: 157539.0000 - fn: 8593.0000 - accuracy: 0.9467 - precision: 0.9363 - recall: 0.7300 - auc: 0.9852 - prc: 0.9390\n",
      "Epoch 109: val_loss did not improve from 0.05127\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0745 - tp: 23366.0000 - fp: 1591.0000 - tn: 158409.0000 - fn: 8634.0000 - accuracy: 0.9467 - precision: 0.9363 - recall: 0.7302 - auc: 0.9852 - prc: 0.9390 - val_loss: 0.0523 - val_tp: 3070.0000 - val_fp: 101.0000 - val_tn: 19899.0000 - val_fn: 930.0000 - val_accuracy: 0.9570 - val_precision: 0.9681 - val_recall: 0.7675 - val_auc: 0.9931 - val_prc: 0.9698\n",
      "Epoch 110/200\n",
      "1981/2000 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 23181.0000 - fp: 1566.0000 - tn: 156914.0000 - fn: 8515.0000 - accuracy: 0.9470 - precision: 0.9367 - recall: 0.7314 - auc: 0.9852 - prc: 0.9396\n",
      "Epoch 110: val_loss improved from 0.05127 to 0.05039, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0742 - tp: 23403.0000 - fp: 1582.0000 - tn: 158418.0000 - fn: 8597.0000 - accuracy: 0.9470 - precision: 0.9367 - recall: 0.7313 - auc: 0.9853 - prc: 0.9396 - val_loss: 0.0504 - val_tp: 3213.0000 - val_fp: 127.0000 - val_tn: 19873.0000 - val_fn: 787.0000 - val_accuracy: 0.9619 - val_precision: 0.9620 - val_recall: 0.8033 - val_auc: 0.9936 - val_prc: 0.9717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0746 - tp: 23206.0000 - fp: 1539.0000 - tn: 157501.0000 - fn: 8602.0000 - accuracy: 0.9469 - precision: 0.9378 - recall: 0.7296 - auc: 0.9852 - prc: 0.9387\n",
      "Epoch 111: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0745 - tp: 23350.0000 - fp: 1543.0000 - tn: 158457.0000 - fn: 8650.0000 - accuracy: 0.9469 - precision: 0.9380 - recall: 0.7297 - auc: 0.9852 - prc: 0.9389 - val_loss: 0.0505 - val_tp: 3204.0000 - val_fp: 121.0000 - val_tn: 19879.0000 - val_fn: 796.0000 - val_accuracy: 0.9618 - val_precision: 0.9636 - val_recall: 0.8010 - val_auc: 0.9935 - val_prc: 0.9714\n",
      "Epoch 112/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 23431.0000 - fp: 1592.0000 - tn: 158088.0000 - fn: 8505.0000 - accuracy: 0.9473 - precision: 0.9364 - recall: 0.7337 - auc: 0.9853 - prc: 0.9396\n",
      "Epoch 112: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0742 - tp: 23479.0000 - fp: 1597.0000 - tn: 158403.0000 - fn: 8521.0000 - accuracy: 0.9473 - precision: 0.9363 - recall: 0.7337 - auc: 0.9853 - prc: 0.9396 - val_loss: 0.0521 - val_tp: 3230.0000 - val_fp: 162.0000 - val_tn: 19838.0000 - val_fn: 770.0000 - val_accuracy: 0.9612 - val_precision: 0.9522 - val_recall: 0.8075 - val_auc: 0.9930 - val_prc: 0.9693\n",
      "Epoch 113/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 23183.0000 - fp: 1628.0000 - tn: 157652.0000 - fn: 8673.0000 - accuracy: 0.9461 - precision: 0.9344 - recall: 0.7277 - auc: 0.9850 - prc: 0.9380\n",
      "Epoch 113: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0754 - tp: 23288.0000 - fp: 1634.0000 - tn: 158366.0000 - fn: 8712.0000 - accuracy: 0.9461 - precision: 0.9344 - recall: 0.7278 - auc: 0.9850 - prc: 0.9380 - val_loss: 0.0504 - val_tp: 3160.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 840.0000 - val_accuracy: 0.9597 - val_precision: 0.9611 - val_recall: 0.7900 - val_auc: 0.9937 - val_prc: 0.9718\n",
      "Epoch 114/200\n",
      "1982/2000 [============================>.] - ETA: 0s - loss: 0.0757 - tp: 23051.0000 - fp: 1569.0000 - tn: 156991.0000 - fn: 8661.0000 - accuracy: 0.9462 - precision: 0.9363 - recall: 0.7269 - auc: 0.9847 - prc: 0.9371\n",
      "Epoch 114: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0756 - tp: 23261.0000 - fp: 1582.0000 - tn: 158418.0000 - fn: 8739.0000 - accuracy: 0.9462 - precision: 0.9363 - recall: 0.7269 - auc: 0.9847 - prc: 0.9372 - val_loss: 0.0525 - val_tp: 3142.0000 - val_fp: 133.0000 - val_tn: 19867.0000 - val_fn: 858.0000 - val_accuracy: 0.9587 - val_precision: 0.9594 - val_recall: 0.7855 - val_auc: 0.9933 - val_prc: 0.9696\n",
      "Epoch 115/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0738 - tp: 23435.0000 - fp: 1595.0000 - tn: 157925.0000 - fn: 8469.0000 - accuracy: 0.9474 - precision: 0.9363 - recall: 0.7345 - auc: 0.9855 - prc: 0.9400\n",
      "Epoch 115: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0738 - tp: 23510.0000 - fp: 1598.0000 - tn: 158402.0000 - fn: 8490.0000 - accuracy: 0.9475 - precision: 0.9364 - recall: 0.7347 - auc: 0.9855 - prc: 0.9401 - val_loss: 0.0509 - val_tp: 3113.0000 - val_fp: 106.0000 - val_tn: 19894.0000 - val_fn: 887.0000 - val_accuracy: 0.9586 - val_precision: 0.9671 - val_recall: 0.7782 - val_auc: 0.9935 - val_prc: 0.9716\n",
      "Epoch 116/200\n",
      "1982/2000 [============================>.] - ETA: 0s - loss: 0.0746 - tp: 23258.0000 - fp: 1594.0000 - tn: 156966.0000 - fn: 8454.0000 - accuracy: 0.9472 - precision: 0.9359 - recall: 0.7334 - auc: 0.9851 - prc: 0.9389\n",
      "Epoch 116: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0746 - tp: 23468.0000 - fp: 1614.0000 - tn: 158386.0000 - fn: 8532.0000 - accuracy: 0.9472 - precision: 0.9357 - recall: 0.7334 - auc: 0.9851 - prc: 0.9389 - val_loss: 0.0507 - val_tp: 3177.0000 - val_fp: 127.0000 - val_tn: 19873.0000 - val_fn: 823.0000 - val_accuracy: 0.9604 - val_precision: 0.9616 - val_recall: 0.7943 - val_auc: 0.9936 - val_prc: 0.9717\n",
      "Epoch 117/200\n",
      "1982/2000 [============================>.] - ETA: 0s - loss: 0.0746 - tp: 23188.0000 - fp: 1593.0000 - tn: 156967.0000 - fn: 8524.0000 - accuracy: 0.9468 - precision: 0.9357 - recall: 0.7312 - auc: 0.9853 - prc: 0.9393\n",
      "Epoch 117: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0746 - tp: 23408.0000 - fp: 1611.0000 - tn: 158389.0000 - fn: 8592.0000 - accuracy: 0.9469 - precision: 0.9356 - recall: 0.7315 - auc: 0.9853 - prc: 0.9393 - val_loss: 0.0523 - val_tp: 3128.0000 - val_fp: 130.0000 - val_tn: 19870.0000 - val_fn: 872.0000 - val_accuracy: 0.9583 - val_precision: 0.9601 - val_recall: 0.7820 - val_auc: 0.9931 - val_prc: 0.9693\n",
      "Epoch 118/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 23210.0000 - fp: 1570.0000 - tn: 158110.0000 - fn: 8726.0000 - accuracy: 0.9463 - precision: 0.9366 - recall: 0.7268 - auc: 0.9850 - prc: 0.9378\n",
      "Epoch 118: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0753 - tp: 23262.0000 - fp: 1571.0000 - tn: 158429.0000 - fn: 8738.0000 - accuracy: 0.9463 - precision: 0.9367 - recall: 0.7269 - auc: 0.9850 - prc: 0.9379 - val_loss: 0.0516 - val_tp: 3142.0000 - val_fp: 142.0000 - val_tn: 19858.0000 - val_fn: 858.0000 - val_accuracy: 0.9583 - val_precision: 0.9568 - val_recall: 0.7855 - val_auc: 0.9932 - val_prc: 0.9702\n",
      "Epoch 119/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0732 - tp: 23552.0000 - fp: 1543.0000 - tn: 157977.0000 - fn: 8352.0000 - accuracy: 0.9483 - precision: 0.9385 - recall: 0.7382 - auc: 0.9859 - prc: 0.9412\n",
      "Epoch 119: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0732 - tp: 23621.0000 - fp: 1548.0000 - tn: 158452.0000 - fn: 8379.0000 - accuracy: 0.9483 - precision: 0.9385 - recall: 0.7382 - auc: 0.9858 - prc: 0.9412 - val_loss: 0.0512 - val_tp: 3239.0000 - val_fp: 166.0000 - val_tn: 19834.0000 - val_fn: 761.0000 - val_accuracy: 0.9614 - val_precision: 0.9512 - val_recall: 0.8098 - val_auc: 0.9933 - val_prc: 0.9706\n",
      "Epoch 120/200\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0751 - tp: 23238.0000 - fp: 1558.0000 - tn: 157162.0000 - fn: 8506.0000 - accuracy: 0.9472 - precision: 0.9372 - recall: 0.7320 - auc: 0.9850 - prc: 0.9382\n",
      "Epoch 120: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0752 - tp: 23421.0000 - fp: 1573.0000 - tn: 158427.0000 - fn: 8579.0000 - accuracy: 0.9471 - precision: 0.9371 - recall: 0.7319 - auc: 0.9850 - prc: 0.9380 - val_loss: 0.0515 - val_tp: 3199.0000 - val_fp: 126.0000 - val_tn: 19874.0000 - val_fn: 801.0000 - val_accuracy: 0.9614 - val_precision: 0.9621 - val_recall: 0.7997 - val_auc: 0.9933 - val_prc: 0.9705\n",
      "Epoch 121/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 23316.0000 - fp: 1538.0000 - tn: 157902.0000 - fn: 8572.0000 - accuracy: 0.9472 - precision: 0.9381 - recall: 0.7312 - auc: 0.9854 - prc: 0.9399\n",
      "Epoch 121: val_loss did not improve from 0.05039\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0741 - tp: 23389.0000 - fp: 1548.0000 - tn: 158452.0000 - fn: 8611.0000 - accuracy: 0.9471 - precision: 0.9379 - recall: 0.7309 - auc: 0.9853 - prc: 0.9399 - val_loss: 0.0511 - val_tp: 3137.0000 - val_fp: 116.0000 - val_tn: 19884.0000 - val_fn: 863.0000 - val_accuracy: 0.9592 - val_precision: 0.9643 - val_recall: 0.7843 - val_auc: 0.9936 - val_prc: 0.9716\n",
      "Epoch 122/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0733 - tp: 23381.0000 - fp: 1568.0000 - tn: 158032.0000 - fn: 8539.0000 - accuracy: 0.9472 - precision: 0.9372 - recall: 0.7325 - auc: 0.9856 - prc: 0.9410\n",
      "Epoch 122: val_loss improved from 0.05039 to 0.04910, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0733 - tp: 23431.0000 - fp: 1573.0000 - tn: 158427.0000 - fn: 8569.0000 - accuracy: 0.9472 - precision: 0.9371 - recall: 0.7322 - auc: 0.9856 - prc: 0.9409 - val_loss: 0.0491 - val_tp: 3212.0000 - val_fp: 129.0000 - val_tn: 19871.0000 - val_fn: 788.0000 - val_accuracy: 0.9618 - val_precision: 0.9614 - val_recall: 0.8030 - val_auc: 0.9939 - val_prc: 0.9728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "1980/2000 [============================>.] - ETA: 0s - loss: 0.0740 - tp: 23173.0000 - fp: 1560.0000 - tn: 156840.0000 - fn: 8507.0000 - accuracy: 0.9470 - precision: 0.9369 - recall: 0.7315 - auc: 0.9855 - prc: 0.9398\n",
      "Epoch 123: val_loss did not improve from 0.04910\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0740 - tp: 23401.0000 - fp: 1575.0000 - tn: 158425.0000 - fn: 8599.0000 - accuracy: 0.9470 - precision: 0.9369 - recall: 0.7313 - auc: 0.9855 - prc: 0.9398 - val_loss: 0.0507 - val_tp: 3185.0000 - val_fp: 130.0000 - val_tn: 19870.0000 - val_fn: 815.0000 - val_accuracy: 0.9606 - val_precision: 0.9608 - val_recall: 0.7962 - val_auc: 0.9934 - val_prc: 0.9712\n",
      "Epoch 124/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 23402.0000 - fp: 1567.0000 - tn: 158353.0000 - fn: 8582.0000 - accuracy: 0.9471 - precision: 0.9372 - recall: 0.7317 - auc: 0.9854 - prc: 0.9399\n",
      "Epoch 124: val_loss did not improve from 0.04910\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0741 - tp: 23415.0000 - fp: 1568.0000 - tn: 158432.0000 - fn: 8585.0000 - accuracy: 0.9471 - precision: 0.9372 - recall: 0.7317 - auc: 0.9854 - prc: 0.9399 - val_loss: 0.0513 - val_tp: 3136.0000 - val_fp: 108.0000 - val_tn: 19892.0000 - val_fn: 864.0000 - val_accuracy: 0.9595 - val_precision: 0.9667 - val_recall: 0.7840 - val_auc: 0.9935 - val_prc: 0.9713\n",
      "Epoch 125/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0746 - tp: 23444.0000 - fp: 1553.0000 - tn: 158047.0000 - fn: 8476.0000 - accuracy: 0.9476 - precision: 0.9379 - recall: 0.7345 - auc: 0.9852 - prc: 0.9391\n",
      "Epoch 125: val_loss did not improve from 0.04910\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0745 - tp: 23509.0000 - fp: 1554.0000 - tn: 158446.0000 - fn: 8491.0000 - accuracy: 0.9477 - precision: 0.9380 - recall: 0.7347 - auc: 0.9853 - prc: 0.9392 - val_loss: 0.0493 - val_tp: 3231.0000 - val_fp: 122.0000 - val_tn: 19878.0000 - val_fn: 769.0000 - val_accuracy: 0.9629 - val_precision: 0.9636 - val_recall: 0.8077 - val_auc: 0.9940 - val_prc: 0.9734\n",
      "Epoch 126/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0746 - tp: 23276.0000 - fp: 1570.0000 - tn: 157470.0000 - fn: 8532.0000 - accuracy: 0.9471 - precision: 0.9368 - recall: 0.7318 - auc: 0.9852 - prc: 0.9390\n",
      "Epoch 126: val_loss did not improve from 0.04910\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0747 - tp: 23411.0000 - fp: 1579.0000 - tn: 158421.0000 - fn: 8589.0000 - accuracy: 0.9470 - precision: 0.9368 - recall: 0.7316 - auc: 0.9852 - prc: 0.9389 - val_loss: 0.0501 - val_tp: 3228.0000 - val_fp: 131.0000 - val_tn: 19869.0000 - val_fn: 772.0000 - val_accuracy: 0.9624 - val_precision: 0.9610 - val_recall: 0.8070 - val_auc: 0.9937 - val_prc: 0.9721\n",
      "Epoch 127/200\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 0.0739 - tp: 23468.0000 - fp: 1589.0000 - tn: 157051.0000 - fn: 8260.0000 - accuracy: 0.9483 - precision: 0.9366 - recall: 0.7397 - auc: 0.9855 - prc: 0.9404\n",
      "Epoch 127: val_loss did not improve from 0.04910\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0738 - tp: 23668.0000 - fp: 1599.0000 - tn: 158401.0000 - fn: 8332.0000 - accuracy: 0.9483 - precision: 0.9367 - recall: 0.7396 - auc: 0.9855 - prc: 0.9405 - val_loss: 0.0503 - val_tp: 3247.0000 - val_fp: 126.0000 - val_tn: 19874.0000 - val_fn: 753.0000 - val_accuracy: 0.9634 - val_precision: 0.9626 - val_recall: 0.8117 - val_auc: 0.9936 - val_prc: 0.9719\n",
      "Epoch 128/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0728 - tp: 23570.0000 - fp: 1576.0000 - tn: 157464.0000 - fn: 8238.0000 - accuracy: 0.9486 - precision: 0.9373 - recall: 0.7410 - auc: 0.9857 - prc: 0.9418\n",
      "Epoch 128: val_loss improved from 0.04910 to 0.04870, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0727 - tp: 23716.0000 - fp: 1584.0000 - tn: 158416.0000 - fn: 8284.0000 - accuracy: 0.9486 - precision: 0.9374 - recall: 0.7411 - auc: 0.9858 - prc: 0.9419 - val_loss: 0.0487 - val_tp: 3322.0000 - val_fp: 160.0000 - val_tn: 19840.0000 - val_fn: 678.0000 - val_accuracy: 0.9651 - val_precision: 0.9540 - val_recall: 0.8305 - val_auc: 0.9939 - val_prc: 0.9733\n",
      "Epoch 129/200\n",
      "1986/2000 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 23413.0000 - fp: 1557.0000 - tn: 157323.0000 - fn: 8363.0000 - accuracy: 0.9480 - precision: 0.9376 - recall: 0.7368 - auc: 0.9854 - prc: 0.9399\n",
      "Epoch 129: val_loss did not improve from 0.04870\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0739 - tp: 23593.0000 - fp: 1565.0000 - tn: 158435.0000 - fn: 8407.0000 - accuracy: 0.9481 - precision: 0.9378 - recall: 0.7373 - auc: 0.9854 - prc: 0.9401 - val_loss: 0.0503 - val_tp: 3179.0000 - val_fp: 130.0000 - val_tn: 19870.0000 - val_fn: 821.0000 - val_accuracy: 0.9604 - val_precision: 0.9607 - val_recall: 0.7947 - val_auc: 0.9936 - val_prc: 0.9719\n",
      "Epoch 130/200\n",
      "1985/2000 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 23301.0000 - fp: 1582.0000 - tn: 157218.0000 - fn: 8459.0000 - accuracy: 0.9473 - precision: 0.9364 - recall: 0.7337 - auc: 0.9854 - prc: 0.9398\n",
      "Epoch 130: val_loss did not improve from 0.04870\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0741 - tp: 23478.0000 - fp: 1593.0000 - tn: 158407.0000 - fn: 8522.0000 - accuracy: 0.9473 - precision: 0.9365 - recall: 0.7337 - auc: 0.9854 - prc: 0.9399 - val_loss: 0.0498 - val_tp: 3113.0000 - val_fp: 105.0000 - val_tn: 19895.0000 - val_fn: 887.0000 - val_accuracy: 0.9587 - val_precision: 0.9674 - val_recall: 0.7782 - val_auc: 0.9941 - val_prc: 0.9735\n",
      "Epoch 131/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0729 - tp: 23445.0000 - fp: 1608.0000 - tn: 157432.0000 - fn: 8363.0000 - accuracy: 0.9478 - precision: 0.9358 - recall: 0.7371 - auc: 0.9858 - prc: 0.9412\n",
      "Epoch 131: val_loss did not improve from 0.04870\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0729 - tp: 23590.0000 - fp: 1618.0000 - tn: 158382.0000 - fn: 8410.0000 - accuracy: 0.9478 - precision: 0.9358 - recall: 0.7372 - auc: 0.9858 - prc: 0.9412 - val_loss: 0.0502 - val_tp: 3144.0000 - val_fp: 102.0000 - val_tn: 19898.0000 - val_fn: 856.0000 - val_accuracy: 0.9601 - val_precision: 0.9686 - val_recall: 0.7860 - val_auc: 0.9937 - val_prc: 0.9724\n",
      "Epoch 132/200\n",
      "1998/2000 [============================>.] - ETA: 0s - loss: 0.0747 - tp: 23502.0000 - fp: 1539.0000 - tn: 158301.0000 - fn: 8466.0000 - accuracy: 0.9478 - precision: 0.9385 - recall: 0.7352 - auc: 0.9853 - prc: 0.9393\n",
      "Epoch 132: val_loss did not improve from 0.04870\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0747 - tp: 23524.0000 - fp: 1540.0000 - tn: 158460.0000 - fn: 8476.0000 - accuracy: 0.9478 - precision: 0.9386 - recall: 0.7351 - auc: 0.9853 - prc: 0.9393 - val_loss: 0.0523 - val_tp: 3098.0000 - val_fp: 102.0000 - val_tn: 19898.0000 - val_fn: 902.0000 - val_accuracy: 0.9582 - val_precision: 0.9681 - val_recall: 0.7745 - val_auc: 0.9932 - val_prc: 0.9698\n",
      "Epoch 133/200\n",
      "1997/2000 [============================>.] - ETA: 0s - loss: 0.0732 - tp: 23541.0000 - fp: 1535.0000 - tn: 158225.0000 - fn: 8411.0000 - accuracy: 0.9481 - precision: 0.9388 - recall: 0.7368 - auc: 0.9857 - prc: 0.9409\n",
      "Epoch 133: val_loss did not improve from 0.04870\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0733 - tp: 23572.0000 - fp: 1541.0000 - tn: 158459.0000 - fn: 8428.0000 - accuracy: 0.9481 - precision: 0.9386 - recall: 0.7366 - auc: 0.9856 - prc: 0.9408 - val_loss: 0.0507 - val_tp: 3277.0000 - val_fp: 164.0000 - val_tn: 19836.0000 - val_fn: 723.0000 - val_accuracy: 0.9630 - val_precision: 0.9523 - val_recall: 0.8192 - val_auc: 0.9934 - val_prc: 0.9711\n",
      "Epoch 134/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0721 - tp: 23698.0000 - fp: 1513.0000 - tn: 157927.0000 - fn: 8190.0000 - accuracy: 0.9493 - precision: 0.9400 - recall: 0.7432 - auc: 0.9861 - prc: 0.9427\n",
      "Epoch 134: val_loss improved from 0.04870 to 0.04861, saving model to weights.best.onlyfocalloss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0722 - tp: 23781.0000 - fp: 1521.0000 - tn: 158479.0000 - fn: 8219.0000 - accuracy: 0.9493 - precision: 0.9399 - recall: 0.7432 - auc: 0.9861 - prc: 0.9427 - val_loss: 0.0486 - val_tp: 3230.0000 - val_fp: 117.0000 - val_tn: 19883.0000 - val_fn: 770.0000 - val_accuracy: 0.9630 - val_precision: 0.9650 - val_recall: 0.8075 - val_auc: 0.9940 - val_prc: 0.9735\n",
      "Epoch 135/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0742 - tp: 23569.0000 - fp: 1585.0000 - tn: 158015.0000 - fn: 8351.0000 - accuracy: 0.9481 - precision: 0.9370 - recall: 0.7384 - auc: 0.9855 - prc: 0.9403\n",
      "Epoch 135: val_loss did not improve from 0.04861\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0743 - tp: 23625.0000 - fp: 1591.0000 - tn: 158409.0000 - fn: 8375.0000 - accuracy: 0.9481 - precision: 0.9369 - recall: 0.7383 - auc: 0.9854 - prc: 0.9402 - val_loss: 0.0489 - val_tp: 3177.0000 - val_fp: 120.0000 - val_tn: 19880.0000 - val_fn: 823.0000 - val_accuracy: 0.9607 - val_precision: 0.9636 - val_recall: 0.7943 - val_auc: 0.9939 - val_prc: 0.9733\n",
      "Epoch 136/200\n",
      "1980/2000 [============================>.] - ETA: 0s - loss: 0.0736 - tp: 23366.0000 - fp: 1577.0000 - tn: 156823.0000 - fn: 8314.0000 - accuracy: 0.9480 - precision: 0.9368 - recall: 0.7376 - auc: 0.9856 - prc: 0.9407\n",
      "Epoch 136: val_loss did not improve from 0.04861\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0736 - tp: 23617.0000 - fp: 1593.0000 - tn: 158407.0000 - fn: 8383.0000 - accuracy: 0.9480 - precision: 0.9368 - recall: 0.7380 - auc: 0.9856 - prc: 0.9408 - val_loss: 0.0507 - val_tp: 3254.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 746.0000 - val_accuracy: 0.9636 - val_precision: 0.9622 - val_recall: 0.8135 - val_auc: 0.9935 - val_prc: 0.9718\n",
      "Epoch 137/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 23706.0000 - fp: 1556.0000 - tn: 158124.0000 - fn: 8230.0000 - accuracy: 0.9489 - precision: 0.9384 - recall: 0.7423 - auc: 0.9860 - prc: 0.9424\n",
      "Epoch 137: val_loss did not improve from 0.04861\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0723 - tp: 23751.0000 - fp: 1564.0000 - tn: 158436.0000 - fn: 8249.0000 - accuracy: 0.9489 - precision: 0.9382 - recall: 0.7422 - auc: 0.9860 - prc: 0.9423 - val_loss: 0.0499 - val_tp: 3251.0000 - val_fp: 157.0000 - val_tn: 19843.0000 - val_fn: 749.0000 - val_accuracy: 0.9623 - val_precision: 0.9539 - val_recall: 0.8127 - val_auc: 0.9936 - val_prc: 0.9718\n",
      "Epoch 138/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 23712.0000 - fp: 1548.0000 - tn: 158132.0000 - fn: 8224.0000 - accuracy: 0.9490 - precision: 0.9387 - recall: 0.7425 - auc: 0.9860 - prc: 0.9425\n",
      "Epoch 138: val_loss did not improve from 0.04861\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0725 - tp: 23764.0000 - fp: 1551.0000 - tn: 158449.0000 - fn: 8236.0000 - accuracy: 0.9490 - precision: 0.9387 - recall: 0.7426 - auc: 0.9860 - prc: 0.9425 - val_loss: 0.0521 - val_tp: 3171.0000 - val_fp: 135.0000 - val_tn: 19865.0000 - val_fn: 829.0000 - val_accuracy: 0.9598 - val_precision: 0.9592 - val_recall: 0.7928 - val_auc: 0.9931 - val_prc: 0.9693\n",
      "Epoch 139/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0739 - tp: 23501.0000 - fp: 1543.0000 - tn: 157897.0000 - fn: 8387.0000 - accuracy: 0.9481 - precision: 0.9384 - recall: 0.7370 - auc: 0.9855 - prc: 0.9404\n",
      "Epoch 139: val_loss did not improve from 0.04861\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0739 - tp: 23580.0000 - fp: 1549.0000 - tn: 158451.0000 - fn: 8420.0000 - accuracy: 0.9481 - precision: 0.9384 - recall: 0.7369 - auc: 0.9855 - prc: 0.9404 - val_loss: 0.0502 - val_tp: 3157.0000 - val_fp: 123.0000 - val_tn: 19877.0000 - val_fn: 843.0000 - val_accuracy: 0.9598 - val_precision: 0.9625 - val_recall: 0.7893 - val_auc: 0.9936 - val_prc: 0.9716\n",
      "Epoch 140/200\n",
      "1980/2000 [============================>.] - ETA: 0s - loss: 0.0727 - tp: 23310.0000 - fp: 1517.0000 - tn: 156883.0000 - fn: 8370.0000 - accuracy: 0.9480 - precision: 0.9389 - recall: 0.7358 - auc: 0.9860 - prc: 0.9420\n",
      "Epoch 140: val_loss did not improve from 0.04861\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0727 - tp: 23551.0000 - fp: 1528.0000 - tn: 158472.0000 - fn: 8449.0000 - accuracy: 0.9480 - precision: 0.9391 - recall: 0.7360 - auc: 0.9860 - prc: 0.9421 - val_loss: 0.0488 - val_tp: 3276.0000 - val_fp: 144.0000 - val_tn: 19856.0000 - val_fn: 724.0000 - val_accuracy: 0.9638 - val_precision: 0.9579 - val_recall: 0.8190 - val_auc: 0.9940 - val_prc: 0.9734\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0737 - tp: 23605.0000 - fp: 1579.0000 - tn: 158421.0000 - fn: 8395.0000 - accuracy: 0.9481 - precision: 0.9373 - recall: 0.7377 - auc: 0.9855 - prc: 0.9406\n",
      "Epoch 141: val_loss improved from 0.04861 to 0.04803, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0737 - tp: 23605.0000 - fp: 1579.0000 - tn: 158421.0000 - fn: 8395.0000 - accuracy: 0.9481 - precision: 0.9373 - recall: 0.7377 - auc: 0.9855 - prc: 0.9406 - val_loss: 0.0480 - val_tp: 3200.0000 - val_fp: 105.0000 - val_tn: 19895.0000 - val_fn: 800.0000 - val_accuracy: 0.9623 - val_precision: 0.9682 - val_recall: 0.8000 - val_auc: 0.9943 - val_prc: 0.9750\n",
      "Epoch 142/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0723 - tp: 23688.0000 - fp: 1575.0000 - tn: 158345.0000 - fn: 8296.0000 - accuracy: 0.9486 - precision: 0.9377 - recall: 0.7406 - auc: 0.9860 - prc: 0.9424\n",
      "Epoch 142: val_loss did not improve from 0.04803\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0722 - tp: 23702.0000 - fp: 1575.0000 - tn: 158425.0000 - fn: 8298.0000 - accuracy: 0.9486 - precision: 0.9377 - recall: 0.7407 - auc: 0.9860 - prc: 0.9425 - val_loss: 0.0501 - val_tp: 3245.0000 - val_fp: 151.0000 - val_tn: 19849.0000 - val_fn: 755.0000 - val_accuracy: 0.9623 - val_precision: 0.9555 - val_recall: 0.8112 - val_auc: 0.9935 - val_prc: 0.9712\n",
      "Epoch 143/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0741 - tp: 23431.0000 - fp: 1547.0000 - tn: 157573.0000 - fn: 8393.0000 - accuracy: 0.9479 - precision: 0.9381 - recall: 0.7363 - auc: 0.9855 - prc: 0.9404\n",
      "Epoch 143: val_loss did not improve from 0.04803\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0740 - tp: 23562.0000 - fp: 1555.0000 - tn: 158445.0000 - fn: 8438.0000 - accuracy: 0.9480 - precision: 0.9381 - recall: 0.7363 - auc: 0.9855 - prc: 0.9404 - val_loss: 0.0510 - val_tp: 3222.0000 - val_fp: 133.0000 - val_tn: 19867.0000 - val_fn: 778.0000 - val_accuracy: 0.9620 - val_precision: 0.9604 - val_recall: 0.8055 - val_auc: 0.9935 - val_prc: 0.9717\n",
      "Epoch 144/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0731 - tp: 23481.0000 - fp: 1573.0000 - tn: 157707.0000 - fn: 8375.0000 - accuracy: 0.9480 - precision: 0.9372 - recall: 0.7371 - auc: 0.9858 - prc: 0.9413\n",
      "Epoch 144: val_loss did not improve from 0.04803\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0731 - tp: 23594.0000 - fp: 1579.0000 - tn: 158421.0000 - fn: 8406.0000 - accuracy: 0.9480 - precision: 0.9373 - recall: 0.7373 - auc: 0.9858 - prc: 0.9413 - val_loss: 0.0484 - val_tp: 3200.0000 - val_fp: 108.0000 - val_tn: 19892.0000 - val_fn: 800.0000 - val_accuracy: 0.9622 - val_precision: 0.9674 - val_recall: 0.8000 - val_auc: 0.9942 - val_prc: 0.9743\n",
      "Epoch 145/200\n",
      "1985/2000 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 23652.0000 - fp: 1555.0000 - tn: 157245.0000 - fn: 8108.0000 - accuracy: 0.9493 - precision: 0.9383 - recall: 0.7447 - auc: 0.9863 - prc: 0.9436\n",
      "Epoch 145: val_loss did not improve from 0.04803\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0719 - tp: 23827.0000 - fp: 1566.0000 - tn: 158434.0000 - fn: 8173.0000 - accuracy: 0.9493 - precision: 0.9383 - recall: 0.7446 - auc: 0.9863 - prc: 0.9436 - val_loss: 0.0496 - val_tp: 3175.0000 - val_fp: 112.0000 - val_tn: 19888.0000 - val_fn: 825.0000 - val_accuracy: 0.9610 - val_precision: 0.9659 - val_recall: 0.7937 - val_auc: 0.9939 - val_prc: 0.9731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200\n",
      "1988/2000 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 23581.0000 - fp: 1508.0000 - tn: 157532.0000 - fn: 8227.0000 - accuracy: 0.9490 - precision: 0.9399 - recall: 0.7414 - auc: 0.9861 - prc: 0.9429\n",
      "Epoch 146: val_loss did not improve from 0.04803\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0725 - tp: 23713.0000 - fp: 1517.0000 - tn: 158483.0000 - fn: 8287.0000 - accuracy: 0.9489 - precision: 0.9399 - recall: 0.7410 - auc: 0.9861 - prc: 0.9428 - val_loss: 0.0507 - val_tp: 3171.0000 - val_fp: 114.0000 - val_tn: 19886.0000 - val_fn: 829.0000 - val_accuracy: 0.9607 - val_precision: 0.9653 - val_recall: 0.7928 - val_auc: 0.9936 - val_prc: 0.9720\n",
      "Epoch 147/200\n",
      "1987/2000 [============================>.] - ETA: 0s - loss: 0.0714 - tp: 23725.0000 - fp: 1543.0000 - tn: 157417.0000 - fn: 8067.0000 - accuracy: 0.9496 - precision: 0.9389 - recall: 0.7463 - auc: 0.9865 - prc: 0.9442\n",
      "Epoch 147: val_loss improved from 0.04803 to 0.04769, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0714 - tp: 23870.0000 - fp: 1552.0000 - tn: 158448.0000 - fn: 8130.0000 - accuracy: 0.9496 - precision: 0.9390 - recall: 0.7459 - auc: 0.9865 - prc: 0.9441 - val_loss: 0.0477 - val_tp: 3224.0000 - val_fp: 121.0000 - val_tn: 19879.0000 - val_fn: 776.0000 - val_accuracy: 0.9626 - val_precision: 0.9638 - val_recall: 0.8060 - val_auc: 0.9943 - val_prc: 0.9745\n",
      "Epoch 148/200\n",
      "1985/2000 [============================>.] - ETA: 0s - loss: 0.0734 - tp: 23398.0000 - fp: 1531.0000 - tn: 157269.0000 - fn: 8362.0000 - accuracy: 0.9481 - precision: 0.9386 - recall: 0.7367 - auc: 0.9856 - prc: 0.9408\n",
      "Epoch 148: val_loss did not improve from 0.04769\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0734 - tp: 23575.0000 - fp: 1541.0000 - tn: 158459.0000 - fn: 8425.0000 - accuracy: 0.9481 - precision: 0.9386 - recall: 0.7367 - auc: 0.9856 - prc: 0.9409 - val_loss: 0.0503 - val_tp: 3185.0000 - val_fp: 124.0000 - val_tn: 19876.0000 - val_fn: 815.0000 - val_accuracy: 0.9609 - val_precision: 0.9625 - val_recall: 0.7962 - val_auc: 0.9936 - val_prc: 0.9719\n",
      "Epoch 149/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 23498.0000 - fp: 1519.0000 - tn: 158001.0000 - fn: 8406.0000 - accuracy: 0.9482 - precision: 0.9393 - recall: 0.7365 - auc: 0.9860 - prc: 0.9421\n",
      "Epoch 149: val_loss did not improve from 0.04769\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0725 - tp: 23578.0000 - fp: 1522.0000 - tn: 158478.0000 - fn: 8422.0000 - accuracy: 0.9482 - precision: 0.9394 - recall: 0.7368 - auc: 0.9860 - prc: 0.9422 - val_loss: 0.0490 - val_tp: 3210.0000 - val_fp: 110.0000 - val_tn: 19890.0000 - val_fn: 790.0000 - val_accuracy: 0.9625 - val_precision: 0.9669 - val_recall: 0.8025 - val_auc: 0.9939 - val_prc: 0.9735\n",
      "Epoch 150/200\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 0.0728 - tp: 23337.0000 - fp: 1530.0000 - tn: 157110.0000 - fn: 8391.0000 - accuracy: 0.9479 - precision: 0.9385 - recall: 0.7355 - auc: 0.9860 - prc: 0.9421\n",
      "Epoch 150: val_loss did not improve from 0.04769\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0728 - tp: 23545.0000 - fp: 1544.0000 - tn: 158456.0000 - fn: 8455.0000 - accuracy: 0.9479 - precision: 0.9385 - recall: 0.7358 - auc: 0.9860 - prc: 0.9421 - val_loss: 0.0489 - val_tp: 3188.0000 - val_fp: 122.0000 - val_tn: 19878.0000 - val_fn: 812.0000 - val_accuracy: 0.9611 - val_precision: 0.9631 - val_recall: 0.7970 - val_auc: 0.9940 - val_prc: 0.9733\n",
      "Epoch 151/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0727 - tp: 23566.0000 - fp: 1487.0000 - tn: 158433.0000 - fn: 8418.0000 - accuracy: 0.9484 - precision: 0.9406 - recall: 0.7368 - auc: 0.9860 - prc: 0.9418\n",
      "Epoch 151: val_loss did not improve from 0.04769\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0727 - tp: 23578.0000 - fp: 1488.0000 - tn: 158512.0000 - fn: 8422.0000 - accuracy: 0.9484 - precision: 0.9406 - recall: 0.7368 - auc: 0.9860 - prc: 0.9418 - val_loss: 0.0492 - val_tp: 3237.0000 - val_fp: 139.0000 - val_tn: 19861.0000 - val_fn: 763.0000 - val_accuracy: 0.9624 - val_precision: 0.9588 - val_recall: 0.8092 - val_auc: 0.9938 - val_prc: 0.9726\n",
      "Epoch 152/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 23537.0000 - fp: 1540.0000 - tn: 157580.0000 - fn: 8287.0000 - accuracy: 0.9485 - precision: 0.9386 - recall: 0.7396 - auc: 0.9860 - prc: 0.9422\n",
      "Epoch 152: val_loss did not improve from 0.04769\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0726 - tp: 23659.0000 - fp: 1555.0000 - tn: 158445.0000 - fn: 8341.0000 - accuracy: 0.9485 - precision: 0.9383 - recall: 0.7393 - auc: 0.9860 - prc: 0.9420 - val_loss: 0.0489 - val_tp: 3282.0000 - val_fp: 135.0000 - val_tn: 19865.0000 - val_fn: 718.0000 - val_accuracy: 0.9645 - val_precision: 0.9605 - val_recall: 0.8205 - val_auc: 0.9941 - val_prc: 0.9738\n",
      "Epoch 153/200\n",
      "1985/2000 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 23657.0000 - fp: 1539.0000 - tn: 157261.0000 - fn: 8103.0000 - accuracy: 0.9494 - precision: 0.9389 - recall: 0.7449 - auc: 0.9861 - prc: 0.9423\n",
      "Epoch 153: val_loss improved from 0.04769 to 0.04729, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0725 - tp: 23836.0000 - fp: 1546.0000 - tn: 158454.0000 - fn: 8164.0000 - accuracy: 0.9494 - precision: 0.9391 - recall: 0.7449 - auc: 0.9861 - prc: 0.9423 - val_loss: 0.0473 - val_tp: 3314.0000 - val_fp: 123.0000 - val_tn: 19877.0000 - val_fn: 686.0000 - val_accuracy: 0.9663 - val_precision: 0.9642 - val_recall: 0.8285 - val_auc: 0.9944 - val_prc: 0.9750\n",
      "Epoch 154/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0725 - tp: 23701.0000 - fp: 1511.0000 - tn: 158009.0000 - fn: 8203.0000 - accuracy: 0.9493 - precision: 0.9401 - recall: 0.7429 - auc: 0.9862 - prc: 0.9427\n",
      "Epoch 154: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0725 - tp: 23771.0000 - fp: 1514.0000 - tn: 158486.0000 - fn: 8229.0000 - accuracy: 0.9493 - precision: 0.9401 - recall: 0.7428 - auc: 0.9862 - prc: 0.9426 - val_loss: 0.0480 - val_tp: 3213.0000 - val_fp: 111.0000 - val_tn: 19889.0000 - val_fn: 787.0000 - val_accuracy: 0.9626 - val_precision: 0.9666 - val_recall: 0.8033 - val_auc: 0.9944 - val_prc: 0.9753\n",
      "Epoch 155/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 23908.0000 - fp: 1526.0000 - tn: 158074.0000 - fn: 8012.0000 - accuracy: 0.9502 - precision: 0.9400 - recall: 0.7490 - auc: 0.9868 - prc: 0.9457\n",
      "Epoch 155: val_loss improved from 0.04729 to 0.04729, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0704 - tp: 23966.0000 - fp: 1531.0000 - tn: 158469.0000 - fn: 8034.0000 - accuracy: 0.9502 - precision: 0.9400 - recall: 0.7489 - auc: 0.9868 - prc: 0.9457 - val_loss: 0.0473 - val_tp: 3222.0000 - val_fp: 99.0000 - val_tn: 19901.0000 - val_fn: 778.0000 - val_accuracy: 0.9635 - val_precision: 0.9702 - val_recall: 0.8055 - val_auc: 0.9944 - val_prc: 0.9757\n",
      "Epoch 156/200\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 23567.0000 - fp: 1483.0000 - tn: 157157.0000 - fn: 8161.0000 - accuracy: 0.9493 - precision: 0.9408 - recall: 0.7428 - auc: 0.9865 - prc: 0.9441\n",
      "Epoch 156: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0714 - tp: 23776.0000 - fp: 1500.0000 - tn: 158500.0000 - fn: 8224.0000 - accuracy: 0.9494 - precision: 0.9407 - recall: 0.7430 - auc: 0.9864 - prc: 0.9439 - val_loss: 0.0497 - val_tp: 3243.0000 - val_fp: 143.0000 - val_tn: 19857.0000 - val_fn: 757.0000 - val_accuracy: 0.9625 - val_precision: 0.9578 - val_recall: 0.8108 - val_auc: 0.9938 - val_prc: 0.9725\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979/2000 [============================>.] - ETA: 0s - loss: 0.0726 - tp: 23447.0000 - fp: 1466.0000 - tn: 156854.0000 - fn: 8217.0000 - accuracy: 0.9490 - precision: 0.9412 - recall: 0.7405 - auc: 0.9861 - prc: 0.9427\n",
      "Epoch 157: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0727 - tp: 23680.0000 - fp: 1482.0000 - tn: 158518.0000 - fn: 8320.0000 - accuracy: 0.9489 - precision: 0.9411 - recall: 0.7400 - auc: 0.9861 - prc: 0.9426 - val_loss: 0.0493 - val_tp: 3204.0000 - val_fp: 106.0000 - val_tn: 19894.0000 - val_fn: 796.0000 - val_accuracy: 0.9624 - val_precision: 0.9680 - val_recall: 0.8010 - val_auc: 0.9939 - val_prc: 0.9732\n",
      "Epoch 158/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 23812.0000 - fp: 1521.0000 - tn: 157919.0000 - fn: 8076.0000 - accuracy: 0.9498 - precision: 0.9400 - recall: 0.7467 - auc: 0.9866 - prc: 0.9441\n",
      "Epoch 158: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0713 - tp: 23895.0000 - fp: 1525.0000 - tn: 158475.0000 - fn: 8105.0000 - accuracy: 0.9498 - precision: 0.9400 - recall: 0.7467 - auc: 0.9866 - prc: 0.9441 - val_loss: 0.0494 - val_tp: 3150.0000 - val_fp: 99.0000 - val_tn: 19901.0000 - val_fn: 850.0000 - val_accuracy: 0.9605 - val_precision: 0.9695 - val_recall: 0.7875 - val_auc: 0.9939 - val_prc: 0.9734\n",
      "Epoch 159/200\n",
      "1981/2000 [============================>.] - ETA: 0s - loss: 0.0727 - tp: 23624.0000 - fp: 1526.0000 - tn: 156954.0000 - fn: 8072.0000 - accuracy: 0.9495 - precision: 0.9393 - recall: 0.7453 - auc: 0.9860 - prc: 0.9427\n",
      "Epoch 159: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0727 - tp: 23846.0000 - fp: 1537.0000 - tn: 158463.0000 - fn: 8154.0000 - accuracy: 0.9495 - precision: 0.9394 - recall: 0.7452 - auc: 0.9860 - prc: 0.9427 - val_loss: 0.0485 - val_tp: 3253.0000 - val_fp: 122.0000 - val_tn: 19878.0000 - val_fn: 747.0000 - val_accuracy: 0.9638 - val_precision: 0.9639 - val_recall: 0.8133 - val_auc: 0.9942 - val_prc: 0.9741\n",
      "Epoch 160/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 23878.0000 - fp: 1514.0000 - tn: 157606.0000 - fn: 7946.0000 - accuracy: 0.9505 - precision: 0.9404 - recall: 0.7503 - auc: 0.9867 - prc: 0.9449\n",
      "Epoch 160: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0714 - tp: 24001.0000 - fp: 1523.0000 - tn: 158477.0000 - fn: 7999.0000 - accuracy: 0.9504 - precision: 0.9403 - recall: 0.7500 - auc: 0.9867 - prc: 0.9448 - val_loss: 0.0484 - val_tp: 3187.0000 - val_fp: 89.0000 - val_tn: 19911.0000 - val_fn: 813.0000 - val_accuracy: 0.9624 - val_precision: 0.9728 - val_recall: 0.7968 - val_auc: 0.9945 - val_prc: 0.9759\n",
      "Epoch 161/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0706 - tp: 23958.0000 - fp: 1515.0000 - tn: 158005.0000 - fn: 7946.0000 - accuracy: 0.9506 - precision: 0.9405 - recall: 0.7509 - auc: 0.9867 - prc: 0.9453\n",
      "Epoch 161: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0707 - tp: 24028.0000 - fp: 1521.0000 - tn: 158479.0000 - fn: 7972.0000 - accuracy: 0.9506 - precision: 0.9405 - recall: 0.7509 - auc: 0.9867 - prc: 0.9452 - val_loss: 0.0489 - val_tp: 3199.0000 - val_fp: 118.0000 - val_tn: 19882.0000 - val_fn: 801.0000 - val_accuracy: 0.9617 - val_precision: 0.9644 - val_recall: 0.7997 - val_auc: 0.9939 - val_prc: 0.9733\n",
      "Epoch 162/200\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0717 - tp: 23655.0000 - fp: 1552.0000 - tn: 157168.0000 - fn: 8089.0000 - accuracy: 0.9494 - precision: 0.9384 - recall: 0.7452 - auc: 0.9864 - prc: 0.9435\n",
      "Epoch 162: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0717 - tp: 23845.0000 - fp: 1562.0000 - tn: 158438.0000 - fn: 8155.0000 - accuracy: 0.9494 - precision: 0.9385 - recall: 0.7452 - auc: 0.9864 - prc: 0.9436 - val_loss: 0.0475 - val_tp: 3162.0000 - val_fp: 99.0000 - val_tn: 19901.0000 - val_fn: 838.0000 - val_accuracy: 0.9610 - val_precision: 0.9696 - val_recall: 0.7905 - val_auc: 0.9945 - val_prc: 0.9758\n",
      "Epoch 163/200\n",
      "1993/2000 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 23832.0000 - fp: 1487.0000 - tn: 157953.0000 - fn: 8056.0000 - accuracy: 0.9501 - precision: 0.9413 - recall: 0.7474 - auc: 0.9866 - prc: 0.9444\n",
      "Epoch 163: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0715 - tp: 23915.0000 - fp: 1489.0000 - tn: 158511.0000 - fn: 8085.0000 - accuracy: 0.9501 - precision: 0.9414 - recall: 0.7473 - auc: 0.9866 - prc: 0.9444 - val_loss: 0.0486 - val_tp: 3188.0000 - val_fp: 108.0000 - val_tn: 19892.0000 - val_fn: 812.0000 - val_accuracy: 0.9617 - val_precision: 0.9672 - val_recall: 0.7970 - val_auc: 0.9941 - val_prc: 0.9742\n",
      "Epoch 164/200\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 23624.0000 - fp: 1542.0000 - tn: 157098.0000 - fn: 8104.0000 - accuracy: 0.9493 - precision: 0.9387 - recall: 0.7446 - auc: 0.9862 - prc: 0.9431\n",
      "Epoch 164: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0723 - tp: 23824.0000 - fp: 1555.0000 - tn: 158445.0000 - fn: 8176.0000 - accuracy: 0.9493 - precision: 0.9387 - recall: 0.7445 - auc: 0.9862 - prc: 0.9430 - val_loss: 0.0485 - val_tp: 3244.0000 - val_fp: 116.0000 - val_tn: 19884.0000 - val_fn: 756.0000 - val_accuracy: 0.9637 - val_precision: 0.9655 - val_recall: 0.8110 - val_auc: 0.9941 - val_prc: 0.9740\n",
      "Epoch 165/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0709 - tp: 23933.0000 - fp: 1535.0000 - tn: 158385.0000 - fn: 8051.0000 - accuracy: 0.9500 - precision: 0.9397 - recall: 0.7483 - auc: 0.9866 - prc: 0.9444\n",
      "Epoch 165: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0709 - tp: 23944.0000 - fp: 1535.0000 - tn: 158465.0000 - fn: 8056.0000 - accuracy: 0.9500 - precision: 0.9398 - recall: 0.7483 - auc: 0.9866 - prc: 0.9444 - val_loss: 0.0477 - val_tp: 3226.0000 - val_fp: 112.0000 - val_tn: 19888.0000 - val_fn: 774.0000 - val_accuracy: 0.9631 - val_precision: 0.9664 - val_recall: 0.8065 - val_auc: 0.9943 - val_prc: 0.9748\n",
      "Epoch 166/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0710 - tp: 23881.0000 - fp: 1515.0000 - tn: 157765.0000 - fn: 7975.0000 - accuracy: 0.9503 - precision: 0.9403 - recall: 0.7497 - auc: 0.9867 - prc: 0.9452\n",
      "Epoch 166: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0709 - tp: 24000.0000 - fp: 1520.0000 - tn: 158480.0000 - fn: 8000.0000 - accuracy: 0.9504 - precision: 0.9404 - recall: 0.7500 - auc: 0.9867 - prc: 0.9453 - val_loss: 0.0474 - val_tp: 3279.0000 - val_fp: 128.0000 - val_tn: 19872.0000 - val_fn: 721.0000 - val_accuracy: 0.9646 - val_precision: 0.9624 - val_recall: 0.8198 - val_auc: 0.9941 - val_prc: 0.9745\n",
      "Epoch 167/200\n",
      "1978/2000 [============================>.] - ETA: 0s - loss: 0.0698 - tp: 23818.0000 - fp: 1506.0000 - tn: 156734.0000 - fn: 7830.0000 - accuracy: 0.9508 - precision: 0.9405 - recall: 0.7526 - auc: 0.9871 - prc: 0.9463\n",
      "Epoch 167: val_loss did not improve from 0.04729\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0698 - tp: 24081.0000 - fp: 1521.0000 - tn: 158479.0000 - fn: 7919.0000 - accuracy: 0.9508 - precision: 0.9406 - recall: 0.7525 - auc: 0.9870 - prc: 0.9463 - val_loss: 0.0473 - val_tp: 3255.0000 - val_fp: 108.0000 - val_tn: 19892.0000 - val_fn: 745.0000 - val_accuracy: 0.9645 - val_precision: 0.9679 - val_recall: 0.8138 - val_auc: 0.9944 - val_prc: 0.9759\n",
      "Epoch 168/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0722 - tp: 23716.0000 - fp: 1523.0000 - tn: 157597.0000 - fn: 8108.0000 - accuracy: 0.9496 - precision: 0.9397 - recall: 0.7452 - auc: 0.9863 - prc: 0.9433\n",
      "Epoch 168: val_loss improved from 0.04729 to 0.04663, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0722 - tp: 23842.0000 - fp: 1528.0000 - tn: 158472.0000 - fn: 8158.0000 - accuracy: 0.9496 - precision: 0.9398 - recall: 0.7451 - auc: 0.9863 - prc: 0.9433 - val_loss: 0.0466 - val_tp: 3302.0000 - val_fp: 127.0000 - val_tn: 19873.0000 - val_fn: 698.0000 - val_accuracy: 0.9656 - val_precision: 0.9630 - val_recall: 0.8255 - val_auc: 0.9945 - val_prc: 0.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0726 - tp: 23550.0000 - fp: 1560.0000 - tn: 157160.0000 - fn: 8194.0000 - accuracy: 0.9488 - precision: 0.9379 - recall: 0.7419 - auc: 0.9862 - prc: 0.9428\n",
      "Epoch 169: val_loss did not improve from 0.04663\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0725 - tp: 23747.0000 - fp: 1573.0000 - tn: 158427.0000 - fn: 8253.0000 - accuracy: 0.9488 - precision: 0.9379 - recall: 0.7421 - auc: 0.9862 - prc: 0.9429 - val_loss: 0.0470 - val_tp: 3238.0000 - val_fp: 121.0000 - val_tn: 19879.0000 - val_fn: 762.0000 - val_accuracy: 0.9632 - val_precision: 0.9640 - val_recall: 0.8095 - val_auc: 0.9945 - val_prc: 0.9756\n",
      "Epoch 170/200\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0716 - tp: 23747.0000 - fp: 1561.0000 - tn: 157159.0000 - fn: 7997.0000 - accuracy: 0.9498 - precision: 0.9383 - recall: 0.7481 - auc: 0.9865 - prc: 0.9441\n",
      "Epoch 170: val_loss did not improve from 0.04663\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0717 - tp: 23938.0000 - fp: 1575.0000 - tn: 158425.0000 - fn: 8062.0000 - accuracy: 0.9498 - precision: 0.9383 - recall: 0.7481 - auc: 0.9864 - prc: 0.9439 - val_loss: 0.0472 - val_tp: 3211.0000 - val_fp: 92.0000 - val_tn: 19908.0000 - val_fn: 789.0000 - val_accuracy: 0.9633 - val_precision: 0.9721 - val_recall: 0.8027 - val_auc: 0.9946 - val_prc: 0.9763\n",
      "Epoch 171/200\n",
      "1980/2000 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 23685.0000 - fp: 1477.0000 - tn: 156923.0000 - fn: 7995.0000 - accuracy: 0.9502 - precision: 0.9413 - recall: 0.7476 - auc: 0.9865 - prc: 0.9448\n",
      "Epoch 171: val_loss did not improve from 0.04663\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0713 - tp: 23916.0000 - fp: 1489.0000 - tn: 158511.0000 - fn: 8084.0000 - accuracy: 0.9501 - precision: 0.9414 - recall: 0.7474 - auc: 0.9865 - prc: 0.9448 - val_loss: 0.0488 - val_tp: 3195.0000 - val_fp: 98.0000 - val_tn: 19902.0000 - val_fn: 805.0000 - val_accuracy: 0.9624 - val_precision: 0.9702 - val_recall: 0.7987 - val_auc: 0.9941 - val_prc: 0.9745\n",
      "Epoch 172/200\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 0.0707 - tp: 23675.0000 - fp: 1492.0000 - tn: 157148.0000 - fn: 8053.0000 - accuracy: 0.9499 - precision: 0.9407 - recall: 0.7462 - auc: 0.9868 - prc: 0.9450\n",
      "Epoch 172: val_loss did not improve from 0.04663\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0705 - tp: 23898.0000 - fp: 1500.0000 - tn: 158500.0000 - fn: 8102.0000 - accuracy: 0.9500 - precision: 0.9409 - recall: 0.7468 - auc: 0.9869 - prc: 0.9453 - val_loss: 0.0474 - val_tp: 3300.0000 - val_fp: 148.0000 - val_tn: 19852.0000 - val_fn: 700.0000 - val_accuracy: 0.9647 - val_precision: 0.9571 - val_recall: 0.8250 - val_auc: 0.9943 - val_prc: 0.9748\n",
      "Epoch 173/200\n",
      "1981/2000 [============================>.] - ETA: 0s - loss: 0.0721 - tp: 23572.0000 - fp: 1530.0000 - tn: 156950.0000 - fn: 8124.0000 - accuracy: 0.9492 - precision: 0.9390 - recall: 0.7437 - auc: 0.9862 - prc: 0.9435\n",
      "Epoch 173: val_loss did not improve from 0.04663\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0721 - tp: 23794.0000 - fp: 1541.0000 - tn: 158459.0000 - fn: 8206.0000 - accuracy: 0.9492 - precision: 0.9392 - recall: 0.7436 - auc: 0.9862 - prc: 0.9435 - val_loss: 0.0486 - val_tp: 3190.0000 - val_fp: 109.0000 - val_tn: 19891.0000 - val_fn: 810.0000 - val_accuracy: 0.9617 - val_precision: 0.9670 - val_recall: 0.7975 - val_auc: 0.9942 - val_prc: 0.9743\n",
      "Epoch 174/200\n",
      "1979/2000 [============================>.] - ETA: 0s - loss: 0.0714 - tp: 23523.0000 - fp: 1509.0000 - tn: 156811.0000 - fn: 8141.0000 - accuracy: 0.9492 - precision: 0.9397 - recall: 0.7429 - auc: 0.9866 - prc: 0.9442\n",
      "Epoch 174: val_loss did not improve from 0.04663\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0714 - tp: 23769.0000 - fp: 1524.0000 - tn: 158476.0000 - fn: 8231.0000 - accuracy: 0.9492 - precision: 0.9397 - recall: 0.7428 - auc: 0.9866 - prc: 0.9441 - val_loss: 0.0483 - val_tp: 3186.0000 - val_fp: 101.0000 - val_tn: 19899.0000 - val_fn: 814.0000 - val_accuracy: 0.9619 - val_precision: 0.9693 - val_recall: 0.7965 - val_auc: 0.9943 - val_prc: 0.9749\n",
      "Epoch 175/200\n",
      "1991/2000 [============================>.] - ETA: 0s - loss: 0.0706 - tp: 23864.0000 - fp: 1478.0000 - tn: 157802.0000 - fn: 7992.0000 - accuracy: 0.9505 - precision: 0.9417 - recall: 0.7491 - auc: 0.9866 - prc: 0.9455\n",
      "Epoch 175: val_loss improved from 0.04663 to 0.04535, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0706 - tp: 23971.0000 - fp: 1483.0000 - tn: 158517.0000 - fn: 8029.0000 - accuracy: 0.9505 - precision: 0.9417 - recall: 0.7491 - auc: 0.9866 - prc: 0.9455 - val_loss: 0.0454 - val_tp: 3298.0000 - val_fp: 109.0000 - val_tn: 19891.0000 - val_fn: 702.0000 - val_accuracy: 0.9662 - val_precision: 0.9680 - val_recall: 0.8245 - val_auc: 0.9948 - val_prc: 0.9771\n",
      "Epoch 176/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0703 - tp: 23864.0000 - fp: 1518.0000 - tn: 157602.0000 - fn: 7960.0000 - accuracy: 0.9504 - precision: 0.9402 - recall: 0.7499 - auc: 0.9868 - prc: 0.9458\n",
      "Epoch 176: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0702 - tp: 24004.0000 - fp: 1526.0000 - tn: 158474.0000 - fn: 7996.0000 - accuracy: 0.9504 - precision: 0.9402 - recall: 0.7501 - auc: 0.9868 - prc: 0.9459 - val_loss: 0.0476 - val_tp: 3201.0000 - val_fp: 112.0000 - val_tn: 19888.0000 - val_fn: 799.0000 - val_accuracy: 0.9620 - val_precision: 0.9662 - val_recall: 0.8002 - val_auc: 0.9943 - val_prc: 0.9750\n",
      "Epoch 177/200\n",
      "1978/2000 [============================>.] - ETA: 0s - loss: 0.0715 - tp: 23656.0000 - fp: 1488.0000 - tn: 156752.0000 - fn: 7992.0000 - accuracy: 0.9501 - precision: 0.9408 - recall: 0.7475 - auc: 0.9865 - prc: 0.9444\n",
      "Epoch 177: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0715 - tp: 23915.0000 - fp: 1501.0000 - tn: 158499.0000 - fn: 8085.0000 - accuracy: 0.9501 - precision: 0.9409 - recall: 0.7473 - auc: 0.9865 - prc: 0.9445 - val_loss: 0.0480 - val_tp: 3231.0000 - val_fp: 100.0000 - val_tn: 19900.0000 - val_fn: 769.0000 - val_accuracy: 0.9638 - val_precision: 0.9700 - val_recall: 0.8077 - val_auc: 0.9943 - val_prc: 0.9755\n",
      "Epoch 178/200\n",
      "1990/2000 [============================>.] - ETA: 0s - loss: 0.0708 - tp: 23828.0000 - fp: 1497.0000 - tn: 157703.0000 - fn: 8012.0000 - accuracy: 0.9502 - precision: 0.9409 - recall: 0.7484 - auc: 0.9866 - prc: 0.9452\n",
      "Epoch 178: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0707 - tp: 23951.0000 - fp: 1503.0000 - tn: 158497.0000 - fn: 8049.0000 - accuracy: 0.9502 - precision: 0.9410 - recall: 0.7485 - auc: 0.9866 - prc: 0.9453 - val_loss: 0.0493 - val_tp: 3173.0000 - val_fp: 118.0000 - val_tn: 19882.0000 - val_fn: 827.0000 - val_accuracy: 0.9606 - val_precision: 0.9641 - val_recall: 0.7933 - val_auc: 0.9939 - val_prc: 0.9729\n",
      "Epoch 179/200\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0724 - tp: 23530.0000 - fp: 1529.0000 - tn: 157191.0000 - fn: 8214.0000 - accuracy: 0.9488 - precision: 0.9390 - recall: 0.7412 - auc: 0.9861 - prc: 0.9433\n",
      "Epoch 179: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0724 - tp: 23716.0000 - fp: 1545.0000 - tn: 158455.0000 - fn: 8284.0000 - accuracy: 0.9488 - precision: 0.9388 - recall: 0.7411 - auc: 0.9861 - prc: 0.9433 - val_loss: 0.0481 - val_tp: 3258.0000 - val_fp: 124.0000 - val_tn: 19876.0000 - val_fn: 742.0000 - val_accuracy: 0.9639 - val_precision: 0.9633 - val_recall: 0.8145 - val_auc: 0.9941 - val_prc: 0.9740\n",
      "Epoch 180/200\n",
      "1982/2000 [============================>.] - ETA: 0s - loss: 0.0705 - tp: 23706.0000 - fp: 1447.0000 - tn: 157113.0000 - fn: 8006.0000 - accuracy: 0.9503 - precision: 0.9425 - recall: 0.7475 - auc: 0.9870 - prc: 0.9461\n",
      "Epoch 180: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0705 - tp: 23915.0000 - fp: 1460.0000 - tn: 158540.0000 - fn: 8085.0000 - accuracy: 0.9503 - precision: 0.9425 - recall: 0.7473 - auc: 0.9870 - prc: 0.9460 - val_loss: 0.0490 - val_tp: 3228.0000 - val_fp: 110.0000 - val_tn: 19890.0000 - val_fn: 772.0000 - val_accuracy: 0.9633 - val_precision: 0.9670 - val_recall: 0.8070 - val_auc: 0.9940 - val_prc: 0.9735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0719 - tp: 23748.0000 - fp: 1525.0000 - tn: 158155.0000 - fn: 8188.0000 - accuracy: 0.9493 - precision: 0.9397 - recall: 0.7436 - auc: 0.9864 - prc: 0.9439\n",
      "Epoch 181: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0719 - tp: 23795.0000 - fp: 1526.0000 - tn: 158474.0000 - fn: 8205.0000 - accuracy: 0.9493 - precision: 0.9397 - recall: 0.7436 - auc: 0.9864 - prc: 0.9439 - val_loss: 0.0496 - val_tp: 3103.0000 - val_fp: 94.0000 - val_tn: 19906.0000 - val_fn: 897.0000 - val_accuracy: 0.9587 - val_precision: 0.9706 - val_recall: 0.7757 - val_auc: 0.9940 - val_prc: 0.9738\n",
      "Epoch 182/200\n",
      "1986/2000 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 23845.0000 - fp: 1465.0000 - tn: 157415.0000 - fn: 7931.0000 - accuracy: 0.9507 - precision: 0.9421 - recall: 0.7504 - auc: 0.9871 - prc: 0.9466\n",
      "Epoch 182: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0698 - tp: 24012.0000 - fp: 1474.0000 - tn: 158526.0000 - fn: 7988.0000 - accuracy: 0.9507 - precision: 0.9422 - recall: 0.7504 - auc: 0.9871 - prc: 0.9465 - val_loss: 0.0469 - val_tp: 3241.0000 - val_fp: 102.0000 - val_tn: 19898.0000 - val_fn: 759.0000 - val_accuracy: 0.9641 - val_precision: 0.9695 - val_recall: 0.8102 - val_auc: 0.9946 - val_prc: 0.9766\n",
      "Epoch 183/200\n",
      "1978/2000 [============================>.] - ETA: 0s - loss: 0.0708 - tp: 23664.0000 - fp: 1508.0000 - tn: 156732.0000 - fn: 7984.0000 - accuracy: 0.9500 - precision: 0.9401 - recall: 0.7477 - auc: 0.9865 - prc: 0.9452\n",
      "Epoch 183: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0708 - tp: 23932.0000 - fp: 1518.0000 - tn: 158482.0000 - fn: 8068.0000 - accuracy: 0.9501 - precision: 0.9404 - recall: 0.7479 - auc: 0.9865 - prc: 0.9452 - val_loss: 0.0462 - val_tp: 3254.0000 - val_fp: 112.0000 - val_tn: 19888.0000 - val_fn: 746.0000 - val_accuracy: 0.9642 - val_precision: 0.9667 - val_recall: 0.8135 - val_auc: 0.9947 - val_prc: 0.9765\n",
      "Epoch 184/200\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 24037.0000 - fp: 1465.0000 - tn: 158455.0000 - fn: 7947.0000 - accuracy: 0.9510 - precision: 0.9426 - recall: 0.7515 - auc: 0.9870 - prc: 0.9466\n",
      "Epoch 184: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0697 - tp: 24047.0000 - fp: 1467.0000 - tn: 158533.0000 - fn: 7953.0000 - accuracy: 0.9509 - precision: 0.9425 - recall: 0.7515 - auc: 0.9870 - prc: 0.9465 - val_loss: 0.0469 - val_tp: 3273.0000 - val_fp: 131.0000 - val_tn: 19869.0000 - val_fn: 727.0000 - val_accuracy: 0.9643 - val_precision: 0.9615 - val_recall: 0.8183 - val_auc: 0.9944 - val_prc: 0.9754\n",
      "Epoch 185/200\n",
      "1980/2000 [============================>.] - ETA: 0s - loss: 0.0707 - tp: 23753.0000 - fp: 1473.0000 - tn: 156927.0000 - fn: 7927.0000 - accuracy: 0.9505 - precision: 0.9416 - recall: 0.7498 - auc: 0.9869 - prc: 0.9459\n",
      "Epoch 185: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0707 - tp: 23997.0000 - fp: 1495.0000 - tn: 158505.0000 - fn: 8003.0000 - accuracy: 0.9505 - precision: 0.9414 - recall: 0.7499 - auc: 0.9869 - prc: 0.9459 - val_loss: 0.0473 - val_tp: 3212.0000 - val_fp: 111.0000 - val_tn: 19889.0000 - val_fn: 788.0000 - val_accuracy: 0.9625 - val_precision: 0.9666 - val_recall: 0.8030 - val_auc: 0.9943 - val_prc: 0.9750\n",
      "Epoch 186/200\n",
      "1995/2000 [============================>.] - ETA: 0s - loss: 0.0717 - tp: 23841.0000 - fp: 1566.0000 - tn: 158034.0000 - fn: 8079.0000 - accuracy: 0.9496 - precision: 0.9384 - recall: 0.7469 - auc: 0.9864 - prc: 0.9436\n",
      "Epoch 186: val_loss did not improve from 0.04535\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0716 - tp: 23900.0000 - fp: 1568.0000 - tn: 158432.0000 - fn: 8100.0000 - accuracy: 0.9496 - precision: 0.9384 - recall: 0.7469 - auc: 0.9864 - prc: 0.9437 - val_loss: 0.0459 - val_tp: 3266.0000 - val_fp: 122.0000 - val_tn: 19878.0000 - val_fn: 734.0000 - val_accuracy: 0.9643 - val_precision: 0.9640 - val_recall: 0.8165 - val_auc: 0.9948 - val_prc: 0.9773\n",
      "Epoch 187/200\n",
      "1987/2000 [============================>.] - ETA: 0s - loss: 0.0702 - tp: 24024.0000 - fp: 1479.0000 - tn: 157481.0000 - fn: 7768.0000 - accuracy: 0.9515 - precision: 0.9420 - recall: 0.7557 - auc: 0.9872 - prc: 0.9466\n",
      "Epoch 187: val_loss improved from 0.04535 to 0.04503, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0701 - tp: 24187.0000 - fp: 1481.0000 - tn: 158519.0000 - fn: 7813.0000 - accuracy: 0.9516 - precision: 0.9423 - recall: 0.7558 - auc: 0.9872 - prc: 0.9467 - val_loss: 0.0450 - val_tp: 3315.0000 - val_fp: 109.0000 - val_tn: 19891.0000 - val_fn: 685.0000 - val_accuracy: 0.9669 - val_precision: 0.9682 - val_recall: 0.8288 - val_auc: 0.9949 - val_prc: 0.9777\n",
      "Epoch 188/200\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 0.0693 - tp: 24038.0000 - fp: 1518.0000 - tn: 157122.0000 - fn: 7690.0000 - accuracy: 0.9516 - precision: 0.9406 - recall: 0.7576 - auc: 0.9874 - prc: 0.9478\n",
      "Epoch 188: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0693 - tp: 24244.0000 - fp: 1532.0000 - tn: 158468.0000 - fn: 7756.0000 - accuracy: 0.9516 - precision: 0.9406 - recall: 0.7576 - auc: 0.9874 - prc: 0.9478 - val_loss: 0.0461 - val_tp: 3290.0000 - val_fp: 120.0000 - val_tn: 19880.0000 - val_fn: 710.0000 - val_accuracy: 0.9654 - val_precision: 0.9648 - val_recall: 0.8225 - val_auc: 0.9948 - val_prc: 0.9769\n",
      "Epoch 189/200\n",
      "1996/2000 [============================>.] - ETA: 0s - loss: 0.0710 - tp: 23838.0000 - fp: 1485.0000 - tn: 158195.0000 - fn: 8098.0000 - accuracy: 0.9500 - precision: 0.9414 - recall: 0.7464 - auc: 0.9867 - prc: 0.9451\n",
      "Epoch 189: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0710 - tp: 23889.0000 - fp: 1487.0000 - tn: 158513.0000 - fn: 8111.0000 - accuracy: 0.9500 - precision: 0.9414 - recall: 0.7465 - auc: 0.9868 - prc: 0.9451 - val_loss: 0.0469 - val_tp: 3249.0000 - val_fp: 103.0000 - val_tn: 19897.0000 - val_fn: 751.0000 - val_accuracy: 0.9644 - val_precision: 0.9693 - val_recall: 0.8123 - val_auc: 0.9946 - val_prc: 0.9763\n",
      "Epoch 190/200\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0700 - tp: 23854.0000 - fp: 1442.0000 - tn: 157278.0000 - fn: 7890.0000 - accuracy: 0.9510 - precision: 0.9430 - recall: 0.7514 - auc: 0.9870 - prc: 0.9468\n",
      "Epoch 190: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0700 - tp: 24041.0000 - fp: 1452.0000 - tn: 158548.0000 - fn: 7959.0000 - accuracy: 0.9510 - precision: 0.9430 - recall: 0.7513 - auc: 0.9870 - prc: 0.9469 - val_loss: 0.0470 - val_tp: 3234.0000 - val_fp: 116.0000 - val_tn: 19884.0000 - val_fn: 766.0000 - val_accuracy: 0.9632 - val_precision: 0.9654 - val_recall: 0.8085 - val_auc: 0.9945 - val_prc: 0.9756\n",
      "Epoch 191/200\n",
      "1979/2000 [============================>.] - ETA: 0s - loss: 0.0713 - tp: 23706.0000 - fp: 1490.0000 - tn: 156830.0000 - fn: 7958.0000 - accuracy: 0.9503 - precision: 0.9409 - recall: 0.7487 - auc: 0.9866 - prc: 0.9447\n",
      "Epoch 191: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0714 - tp: 23946.0000 - fp: 1504.0000 - tn: 158496.0000 - fn: 8054.0000 - accuracy: 0.9502 - precision: 0.9409 - recall: 0.7483 - auc: 0.9866 - prc: 0.9446 - val_loss: 0.0476 - val_tp: 3203.0000 - val_fp: 104.0000 - val_tn: 19896.0000 - val_fn: 797.0000 - val_accuracy: 0.9625 - val_precision: 0.9686 - val_recall: 0.8008 - val_auc: 0.9944 - val_prc: 0.9755\n",
      "Epoch 192/200\n",
      "1987/2000 [============================>.] - ETA: 0s - loss: 0.0709 - tp: 23731.0000 - fp: 1473.0000 - tn: 157487.0000 - fn: 8061.0000 - accuracy: 0.9500 - precision: 0.9416 - recall: 0.7464 - auc: 0.9868 - prc: 0.9454\n",
      "Epoch 192: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0709 - tp: 23895.0000 - fp: 1481.0000 - tn: 158519.0000 - fn: 8105.0000 - accuracy: 0.9501 - precision: 0.9416 - recall: 0.7467 - auc: 0.9868 - prc: 0.9454 - val_loss: 0.0470 - val_tp: 3250.0000 - val_fp: 109.0000 - val_tn: 19891.0000 - val_fn: 750.0000 - val_accuracy: 0.9642 - val_precision: 0.9675 - val_recall: 0.8125 - val_auc: 0.9945 - val_prc: 0.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "1987/2000 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 23984.0000 - fp: 1534.0000 - tn: 157426.0000 - fn: 7808.0000 - accuracy: 0.9510 - precision: 0.9399 - recall: 0.7544 - auc: 0.9871 - prc: 0.9464\n",
      "Epoch 193: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0700 - tp: 24142.0000 - fp: 1545.0000 - tn: 158455.0000 - fn: 7858.0000 - accuracy: 0.9510 - precision: 0.9399 - recall: 0.7544 - auc: 0.9871 - prc: 0.9463 - val_loss: 0.0476 - val_tp: 3284.0000 - val_fp: 153.0000 - val_tn: 19847.0000 - val_fn: 716.0000 - val_accuracy: 0.9638 - val_precision: 0.9555 - val_recall: 0.8210 - val_auc: 0.9944 - val_prc: 0.9748\n",
      "Epoch 194/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0708 - tp: 23868.0000 - fp: 1517.0000 - tn: 157603.0000 - fn: 7956.0000 - accuracy: 0.9504 - precision: 0.9402 - recall: 0.7500 - auc: 0.9868 - prc: 0.9452\n",
      "Epoch 194: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0707 - tp: 23996.0000 - fp: 1523.0000 - tn: 158477.0000 - fn: 8004.0000 - accuracy: 0.9504 - precision: 0.9403 - recall: 0.7499 - auc: 0.9868 - prc: 0.9452 - val_loss: 0.0491 - val_tp: 3195.0000 - val_fp: 107.0000 - val_tn: 19893.0000 - val_fn: 805.0000 - val_accuracy: 0.9620 - val_precision: 0.9676 - val_recall: 0.7987 - val_auc: 0.9941 - val_prc: 0.9740\n",
      "Epoch 195/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0706 - tp: 23959.0000 - fp: 1469.0000 - tn: 157651.0000 - fn: 7865.0000 - accuracy: 0.9511 - precision: 0.9422 - recall: 0.7529 - auc: 0.9868 - prc: 0.9459\n",
      "Epoch 195: val_loss did not improve from 0.04503\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0707 - tp: 24093.0000 - fp: 1480.0000 - tn: 158520.0000 - fn: 7907.0000 - accuracy: 0.9511 - precision: 0.9421 - recall: 0.7529 - auc: 0.9868 - prc: 0.9459 - val_loss: 0.0463 - val_tp: 3289.0000 - val_fp: 123.0000 - val_tn: 19877.0000 - val_fn: 711.0000 - val_accuracy: 0.9652 - val_precision: 0.9640 - val_recall: 0.8223 - val_auc: 0.9947 - val_prc: 0.9764\n",
      "Epoch 196/200\n",
      "1978/2000 [============================>.] - ETA: 0s - loss: 0.0696 - tp: 23877.0000 - fp: 1518.0000 - tn: 156722.0000 - fn: 7771.0000 - accuracy: 0.9511 - precision: 0.9402 - recall: 0.7545 - auc: 0.9872 - prc: 0.9466\n",
      "Epoch 196: val_loss improved from 0.04503 to 0.04498, saving model to weights.best.onlyfocalloss\n",
      "INFO:tensorflow:Assets written to: weights.best.onlyfocalloss/assets\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0695 - tp: 24141.0000 - fp: 1531.0000 - tn: 158469.0000 - fn: 7859.0000 - accuracy: 0.9511 - precision: 0.9404 - recall: 0.7544 - auc: 0.9873 - prc: 0.9467 - val_loss: 0.0450 - val_tp: 3325.0000 - val_fp: 116.0000 - val_tn: 19884.0000 - val_fn: 675.0000 - val_accuracy: 0.9670 - val_precision: 0.9663 - val_recall: 0.8313 - val_auc: 0.9949 - val_prc: 0.9779\n",
      "Epoch 197/200\n",
      "1994/2000 [============================>.] - ETA: 0s - loss: 0.0699 - tp: 24114.0000 - fp: 1503.0000 - tn: 158017.0000 - fn: 7790.0000 - accuracy: 0.9515 - precision: 0.9413 - recall: 0.7558 - auc: 0.9870 - prc: 0.9466\n",
      "Epoch 197: val_loss did not improve from 0.04498\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0700 - tp: 24181.0000 - fp: 1509.0000 - tn: 158491.0000 - fn: 7819.0000 - accuracy: 0.9514 - precision: 0.9413 - recall: 0.7557 - auc: 0.9870 - prc: 0.9466 - val_loss: 0.0485 - val_tp: 3149.0000 - val_fp: 88.0000 - val_tn: 19912.0000 - val_fn: 851.0000 - val_accuracy: 0.9609 - val_precision: 0.9728 - val_recall: 0.7872 - val_auc: 0.9942 - val_prc: 0.9747\n",
      "Epoch 198/200\n",
      "1982/2000 [============================>.] - ETA: 0s - loss: 0.0708 - tp: 23920.0000 - fp: 1527.0000 - tn: 157033.0000 - fn: 7792.0000 - accuracy: 0.9510 - precision: 0.9400 - recall: 0.7543 - auc: 0.9869 - prc: 0.9462\n",
      "Epoch 198: val_loss did not improve from 0.04498\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0708 - tp: 24134.0000 - fp: 1540.0000 - tn: 158460.0000 - fn: 7866.0000 - accuracy: 0.9510 - precision: 0.9400 - recall: 0.7542 - auc: 0.9869 - prc: 0.9462 - val_loss: 0.0461 - val_tp: 3265.0000 - val_fp: 104.0000 - val_tn: 19896.0000 - val_fn: 735.0000 - val_accuracy: 0.9650 - val_precision: 0.9691 - val_recall: 0.8163 - val_auc: 0.9948 - val_prc: 0.9772\n",
      "Epoch 199/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0700 - tp: 23914.0000 - fp: 1494.0000 - tn: 157626.0000 - fn: 7910.0000 - accuracy: 0.9507 - precision: 0.9412 - recall: 0.7514 - auc: 0.9871 - prc: 0.9464\n",
      "Epoch 199: val_loss did not improve from 0.04498\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0699 - tp: 24057.0000 - fp: 1498.0000 - tn: 158502.0000 - fn: 7943.0000 - accuracy: 0.9508 - precision: 0.9414 - recall: 0.7518 - auc: 0.9871 - prc: 0.9465 - val_loss: 0.0477 - val_tp: 3294.0000 - val_fp: 151.0000 - val_tn: 19849.0000 - val_fn: 706.0000 - val_accuracy: 0.9643 - val_precision: 0.9562 - val_recall: 0.8235 - val_auc: 0.9942 - val_prc: 0.9744\n",
      "Epoch 200/200\n",
      "1989/2000 [============================>.] - ETA: 0s - loss: 0.0700 - tp: 23963.0000 - fp: 1494.0000 - tn: 157626.0000 - fn: 7861.0000 - accuracy: 0.9510 - precision: 0.9413 - recall: 0.7530 - auc: 0.9871 - prc: 0.9466\n",
      "Epoch 200: val_loss did not improve from 0.04498\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0701 - tp: 24082.0000 - fp: 1502.0000 - tn: 158498.0000 - fn: 7918.0000 - accuracy: 0.9509 - precision: 0.9413 - recall: 0.7526 - auc: 0.9871 - prc: 0.9465 - val_loss: 0.0464 - val_tp: 3281.0000 - val_fp: 136.0000 - val_tn: 19864.0000 - val_fn: 719.0000 - val_accuracy: 0.9644 - val_precision: 0.9602 - val_recall: 0.8202 - val_auc: 0.9947 - val_prc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tfa.losses.SigmoidFocalCrossEntropy(),#'categorical_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "#checkpoint_path = \"weights.best.hdf5\"\n",
    "\n",
    "checkpoint_path = \"weights.best.onlyfocalloss\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f913d8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABMK0lEQVR4nO3dd3hUVfrA8e+bHkISIIEACRB67xFBFLGLDRFFcG3YFntbu7uuvy2WtWFZu2sHu6AiFkQRBamhhhJ6QiAhkISE9Dm/P86dZBImkACTCeH9PE+embll5sxNct57uhhjUEoppaoL8HcClFJKNUwaIJRSSnmlAUIppZRXGiCUUkp5pQFCKaWUVxoglFJKeaUBQh3zRCRRRIyIBNXi2KtFZG59pEspf9MAoY4qIrJZREpEJLba9mQnk0/0U9KUanQ0QKij0SZggvuFiPQFwv2XnIahNiUgpepCA4Q6Gr0HXOnx+irgXc8DRCRaRN4VkSwR2SIiD4tIgLMvUESeEpFdIrIRONfLuW+KSIaIpIvIP0UksDYJE5FPRGSHiOSKyBwR6e2xL1xEnnbSkysic0Uk3Nl3ooj8LiI5IrJNRK52tv8sItd5vEeVKi6n1HSziKwH1jvbJjvvkScii0XkJI/jA0XkQRHZICJ7nf3tROQlEXm62nf5SkTuqM33Vo2TBgh1NJoPRIlITyfjvhR4v9oxLwDRQCfgZGxAmejsux44DxgIJAEXVzv3HaAM6OIccyZwHbXzLdAVaAUsAT7w2PcUMBg4AWgB3Au4RKS9c94LQEtgAJBcy88DuBA4HujlvF7ovEcL4EPgExEJc/bdhS19nQNEAdcA+7DfeYJHEI0FTgOm1CEdqrExxuiP/hw1P8Bm4HTgYeAx4GzgByAIMEAiEAgUA708zvsz8LPz/Cdgkse+M51zg4A459xwj/0TgNnO86uBubVMazPnfaOxN2OFQH8vxz0AfFHDe/wMXOfxusrnO+9/6kHSscf9ucBaYHQNx6UAZzjPbwFm+Pv3rT/+/dE6S3W0eg+YA3SkWvUSEAuEAFs8tm0B4p3nbYFt1fa5dQCCgQwRcW8LqHa8V05p5l/AJdiSgMsjPaFAGLDBy6ntatheW1XSJiJ3Y0s8bbEBJMpJw8E+6x3gcmzAvRyYfBhpUo2AVjGpo5IxZgu2sfoc4PNqu3cBpdjM3q09kO48z8BmlJ773LZhSxCxxphmzk+UMaY3B3cZMBpbwonGlmYAxElTEdDZy3nbatgOUAA08Xjd2ssxFVMyO+0N9wHjgObGmGZArpOGg33W+8BoEekP9AS+rOE4dYzQAKGOZtdiq1cKPDcaY8qBj4F/iUikiHTA1r272yk+Bm4TkQQRaQ7c73FuBvA98LSIRIlIgIh0FpGTa5GeSGxwycZm6v/2eF8X8BbwjIi0dRqLh4lIKLad4nQRGSciQSISIyIDnFOTgYtEpImIdHG+88HSUAZkAUEi8jdsCcLtDeAfItJVrH4iEuOkMQ3bfvEe8JkxprAW31k1Yhog1FHLGLPBGLOoht23Yu++NwJzsY21bzn7Xge+A5ZhG5Krl0CuxFZRrcbW338KtKlFkt7FVlelO+fOr7b/L8AKbCa8G3gCCDDGbMWWhO52ticD/Z1zngVKgJ3YKqAPOLDvsA3e65y0FFG1CuoZbID8HsgD3qRqF+F3gL7YIKGOcWKMLhiklLJEZAS2pJXolHrUMUxLEEopAEQkGLgdeEODgwINEEopQER6AjnYqrTn/JoY1WBoFZNSSimvtAShlFLKq0Y1UC42NtYkJib6OxlKKXXUWLx48S5jTEtv+xpVgEhMTGTRopp6PSqllKpORLbUtE+rmJRSSnmlAUIppZRXGiCUUkp5pQFCKaWUVxoglFJKeaUBQimllFcaIJRSSnmlAUIppepTaRFkH8ICgmmLYcu8I5+eA9AAoZRq2IwBV7m/U3HkzH0GXhoCu9bX/pzyUvj4CvjmLt+lywsNEEqphu2PV+Dp7vbO25++ugPmPnf477N6GrjKYNb/1f6cVV9CXjrs2WwDZj3RAKGUarjKSuC3yVCQBTtWHPn3X/kZfP7ng2e6rnJYNhVWfHp4n5e9AbLWQIvOkDId0moxNZAxMO8F+7x0HxTsOrw01IEGCKWU9cer8Nvz/k5FVaunwd4M+zz9CM+ztnsjTLsVlk+FjGUHPjZ7A5QVQlYKlBUf+meu+cY+jv8AmsbBF5OgKPfA56QvtunrNsq+3rMZ1v8Ac/7j86o3DRBKKcjPhB/+ZqtzGgpjYP5LENMVouIhbeGRed/fX4DnB8G7oyEgCCQQVn9Z9Zg1M2DyACjKs693OqUXVxlkrq5d2nPTIH2JzdzLy5z3/QZa94NWPeHi/8GeTfD5DeDyWMCvtMi2Obht/Nk+nnCrfczZAr8+Az/9Ez65Cpa8BwvfrONFqB0NEEopGxjKimw998HuaA+mtBDWzjz8uvLtS+3P8X+GhOMOHCBcLtg6v+bPdJXbY/IzYfa/AQOBoTD6Beg4wtbxe5674DWbeW/+1b72rN7KWA57ttgAALZn0aovK/cX5tg2k2d7w+unwKsjYO6zthSy7Q/oeb49LnE4nPUYrJtpP8/9Pd44HZ7rB4vftmnaPBda9YK2A+0xuzfZ9LToBClfwfRb6taeUQcaIJQ61hXmwII3oGlr+zpzTe3OWz0NXjtl/4CybApMudRmXodjyTsQ3AT6jYOEJMjZagPPjHuhOL/qsSnT4K2z7Gd78/Ud8ExP+PImW0V02Sdw6yLoNRp6j7HBYMHrNjPeuxM2/WLP2/CTfdyxAuL6QGiUrfJ55zz47Dq7b8Zf7J3813fZksLOVZC/E4bfDhOm2gA0/78w5ykIDIZBV1Wma8j10PUs+PERyFoL6761pZWgUPjqdttOse0PSDwRQprYaqmNs6FkL5x4J9y+HG5fBnevPbxrXQMNEEodi4ry4Jcn7Z3wlzdCST6c94zd560KpawYXj0Z/tMF3j7P3uku/QC2L4HZj1U9Nn2JfZz9r4PXkZeXee+dVJxvG4R7j4GwaFuCAJgyHha8Cl/8uWq1zKY59vHHv1dWC7nlZ0HyFCjcDak/wMA/QWyXyv09zoPAEPj2Hnj7XPjsWjAuiO3uESBWQuu+tnpo2VQbrLYtgJxtNiDEdIVFb8LaGZCdas9Juha6j4JTHrafvexD6DsOIuMqP1sELngBQiLgg0vg58egWXu4+Q+Ibg8z7rEN0x2G2+ObdYAtv9vnbfpD8w7QPBGCww58nQ+RBgiljkUrPrYZ+PMDbaZ29mPQ/RwIaQqZKfsfn7UGMpJtKWPzr7B5jn0MbmIz7CpVMMsgNNqeM+MeWPKuvTvOy7D7PKtypt1sq2Fc5fYO/qMrbMa/4hMbtNx32236Q0AwRLaBE++CNV/DS8fBFzdCyT5bzdO8o71z//GRqp+R/AG4SuHa7+HcZ+D0R6t+t4gYmDQXrp8NXU6336t1X0i6xjZkpy2G/B12W5v+UF4MQeFgym3VEQbO+Y9ty8hYZgNEYChEJ9j3b398ZQY/7Ob9r21kHPzpEyjKsddx2K22BDH0Rvt9oPL85h3s5wUEQ8uetftdH4ZGtaKcUkel/ExY9D846W4I9PiXLNhl7+6bxEC3s+zd9KFaPc3efbYdYF9vmQcRrWzVRVRbGHKDvZtt2cN7CSLLqcI471lbvTLzAXtnO+ZV+PZe2xV17Bu2pJGZAsNusnX1i7w0np77DBx3LeSm20BgyiH5Q5j1DyjOhYWv20bYtoOg3RB7TnA4jP8QYrvaO+amcZD6o70rj+1iexed9jfYtxvmvWgbk899FiTA1uW3P8HW4bvr8atr2d0+XvK2DVp9L7ElCIAZd9vHuD7QJNY+P+NR+O4hG/wCQ6H9MJu2zNWA2PaBgMDK9z/vOVvaiuvl/fPjB8NVX9sqsoGX222DroCfH4eoNtDUWRG0eaJ9bNUTgkK8v9cR5NMAISJnA5OBQOANY8zj1fY3B94COgNFwDXGmJXOvmbAG0AfwDj76necuVL1Ycm78PO/ocMJ0PGkyu0bf4b130N4C5txbJgN5zx18Ixh6x+2dGBcMPwOewf72XUQ3hxunAdNWsDWeTY4XPK/que26mkbTavLWmPvkNv0t8Fq9TRbLdPjPNjyG6z8wlYVZaXYu/W2A+2dekmBvQve8psNHqun2d5SXU6Hpe/bNDZtbdsIXGU2Y/32XkBgwoc2aLl1O7Py+dBJtvH6lRPh5yfstg7Dod3xtlQz50koyLbfdc8mOPXh2v0uQiNh3Lv2uTEQ281WL7UfZjPxgCAoL4H+E2DVF/Y6dhhuq3ha9bJdcYPCbbDw1LKb/TmQNv3sj2daLn7TXme3Zh0qj60HPqtiEpFA4CVgFNALmCAi1cPng0CyMaYfcCU2mLhNBmYaY3oA/QEv5V6lGoEtvzmPv1fdnrXW3gHfuco2SC55x94dH8yiN22Pn52rbOBJ/dFmavk74avbbP15XroNSNW16mkHpeVnVd2euQZiOtvg1Odiu639MAhtCr0utI2mG2ZVjidoM8Bm7qFN7XmDrrQNshf+FxBb17/gNeh6Joz4iw0O3c+FMU5vnsFX2wz5QERsNVB5sb2LbzvQbjv1IRtI186Ape/BiHuhz9iDXzdv7//nX+GBNLhmpv0uwWH2zj4wyDY+Q2X1T1xve213b4CYLjW/b110PQM6nVz52l2CaDPgyLz/QfiyDWIIkGqM2WiMKQGmAqOrHdMLmAVgjFkDJIpInIhEASOAN519JcaYHB+mVanaK8iGT662vV0OV3mZveMH2DK36r6sFHtHHdIETv87dDvbTvWwb3flMUV5tifR+h/ta2NsyaP7OXDSXbbHze8v2Gqq0x6xdfdf32mPbT90//S0cuq1dyx3HlfYNGatsdVPYDOtFp1t7yKwGWV4c9vVc3uybVR2Z2TVNWsP49+3d9iuMhh+m61SGTwRzvg/aHcc3LLIZvC10W+cbTdJOM7W27sNuR4u/xQufd8GDM+SSF0Eh9XcANz1TEBsaQhsgAD7vY5UgKguIck2fveqnpX6hi+rmOKBbR6v04Djqx2zDLgImCsiQ4AOQAJQDmQB/xOR/sBi4HZjTIEP06sai9w0+09aUyZ1uFJ/tNULrXrByfce3ntlLIPSAohuB9sW2qkl3FVIWWsrM2WwdewvD4dfn4az/mW3LXnH1m3PewG6nm4z8vyd0GmkzcB+eMQGiQF/stVNG36yd/qh0Tb91SUcZzP4xW/bOvR3R8Opf7XVNO678OBwuG1J5TmBwbaqacUnEBRmq6EOlCF3Gml/PJ3/XOXz6tUzBxIaCROm2Gq46twZt68kJME9qRDhtEu4AwT4LkAEh1f2NqsHvixBePsLqT6K5XGguYgkA7cCS4EybOAaBLxsjBkIFAD3e/0QkRtEZJGILMrKyvJ2iDrWfP5n+PBS372/uxpl2VSboSd/aAeH1cRVDh9faXvpVOcuNZx4h53KYftS+7qsxA6s8gwQcb3t3fa8l2Ddd3a07fxXbNvAxl9sYHSPuu000vaO6XKafd3jXAgIgDGv2ACQOLxqI6pbaCQcd70zAOs2u+3XZ2xbgbsh15thN0OnU2wvm/6X1XycL3QcAa371O9nurmDA9ggHxpln/sqQNQzXwaINKCdx+sEYLvnAcaYPGPMRGPMAGwbREtgk3NumjHGKXvzKTZg7McY85oxJskYk9SyZcsj/BXUUae00A4sylpjuyj6wo7ltm1g9wb4YKztaeQ5khZstcz3D0PWOturZ/U0O6Dq58erHrfld9uHvteFzmsnYGSn2t49ngECYNQTtoHy02ts0MlLc0oTxgasjT/b6p9mzr/e8Nuh48k28wbb9fKGX+D8ydTo+Em2uiZni21vKHUK7u7qJ29a9YTLpsKf58CACTUf15iJ2OsQGl01cBzFfFnFtBDoKiIdgXRgPFDl1sLpqbTPaaO4DphjjMkD8kRkm4h0N8asBU4DajEBijrmpS20vWjATmgW3gL2brcZ5ZFgjO2+2ediO8rVPUBr+9KqGWPKNFv3X7KvMmPteqYdCNXpFNuzKGud7Zk06EqbobQdCHOedqrGnAJ49bv2kAg7Ovez6+1ArXbHw5A/w+rpdvK28hLbwOuWeKL98dSi44G/Y9OWMOIeG2RH/9eOLi7IbDR3xT41+Gp7Y3KobR4NjM8ChDGmTERuAb7DdnN9yxizSkQmOftfAXoC74pIOTYAXOvxFrcCH4hICLARmOirtKpGZPNv9u4+sq0dILVrva3iGXKDrb/1ZsNsWPgGjHvPVsNUtz3Z9uyJH2ynlSjOtVU0zTvYkbR7NlVWDYENIr87vY1Sf7ADoCLb2j72zw+0o32v+gqm3WQboEfcY48d/yF8fJUtHcT1td/DW318VFuY+E3Vbaf91X6Hpq3h+Bvqds28GfEXj/f+mw28no3AyrsB9Vy95mM+HQdhjJkBzKi27RWP5/MAry1SxphkIMmX6VON0Jbf7IjXDifamUDdts6Hzqd4P2fFJ7Z3z55Nth55z+bKPus52+B/59hqlsDQyrvzNv0rn898EBa9ZauVAoPsSNztS+xAr+1L7IC3bmfbu/+T74Vv7obnB0DuNhj7ZuXUC1Ft4epv4KPLYf13tgdTTUGtug4neO+2eiQM/JP9UcccnWpDNXx7thy4EditrNje6XYYDt3PttuG3mynJXA33oLTddNjOmX33X/GMpvRv3ScrVYxprJL6KXv2wx8wat2sJRnD6C2AyobmD8cD+9cABEt7ShjsCOO2w+zzwddZRuQY7vChS/v3z8/KMSWNDqd4nSjVMp/dKoN5T/uPvsdTvBefbFns13mceNsWw3jORrWfbfuadsfdsrqDsMh8SS4/DPbQJuRbN+DR233za9uh5P+YqtlSgpsXTvYxuesdfb59NtsBp36A5z9hJ2iOaIl/G+UnQPHM73uQUvTb7VjF068C5Im2j7/rXrZ6Rc6OAEiMBiunHbg6xLSBK788uDXTykf0xKE8p+NP8N7F9p5fLz58e+2ITa8hZ3uAOw0DU91h3+1tlU1nssvLpsKIZHQ+VTbSNjldJshdzrFNiz/+oydkjkgyI4fKCux240LEPt86zybqe/eAH+8bLt8Drnevn/7oTD6JTjlgarpjOliB2tlpdjxAKc/YoMDQO+LICrB+5gDpRo4DRDKf9yBYeGbNrP2lJ8FKV/D4KtsCWP3RltqmP8yRMfbEbSL34aZzvCY4nzb1bTPGHsH7qnzqYCBWY/ayd/GvmkbnVOmV1YvdT7V9kgq3A1Db4ILXrRrBpz7VNXxAgMus2MKPAUEOIPDAmyDrqeT7oZbF3sfc6BUA6dVTOrQGAPvj7WzXnp27zTGjtYtL7F17dUbWUsL7fiAqLa22qfTSFuS+H2ynQ76uGvtgLDk92131cFX20nd1n9vxwaUl9i7+gETbI+i7cn2fVd/aRuSB3hpTI0fBBe9Yev92/S3aWyeaINNs3a2h1HXM+wIY3Bm5qxjl86R99sG7erdUgMCIMA3c/Ur5WsaIBqz0kK7vGKnkZUjao+UHStshlqSXxkgCvfY/vmpP9jXoVFw07zKefHB9iZa+IZ9HhJpG2RfP82urwt2Woirv7bTX3cYbjPcFp1sYHAv3uLOhFv2gLXf2sbp5R/bAWLtqs/mgq1u6ndJ1dcn3W3bDNIX2UniWve1+yJa2snl6so9cZtSjYgGiMaqMAc+HGcbbjNXH7kAkbPVLtqy7jv7Om2hnTyuSQs7lUTqD3DWv227wZeT7H7PALFrvX28+C1bNx/eHM592pYmItvCzPvg5RPstBHnPWuPdWfYa50e054BwpTbOYvSFtoBZ7UdoDToStttdfqttvurO0C0H9poBjkpdbg0QDRWS96xwaFVL1sNY8z+GZ8xdkrouN7eM8WFb9gSSECQbZyNHwwvDoG+F9vpI8Kb21LDhp/stpSvIGGInZentNAOBMtMqbrQTfZ6W3LofVHlZ3Y+xf4YY6uKts6D85+vDGotOtnHLb/bxt+QCPu6lTMNxaovbFdS97KUtdX/Uts7KSjMVgWNfLDqegxKHeO0kbqxylhuB30Nngj7dkHe9v2P2fATvDLczhPkzerp9i7buOCPV2HNN7a//9L3bNXM8ZPsNNLrf7BjFXYsh57n2XODw23GvnNV1ffctd7W73sLSCJ2NPNVX9nGabfItjYTrz43UUwX2zDsXqj+YOsHeBPSpHL09Mj7fDfYTKmjkJYgGhOXy95JhzaFnSvtEolt+tt9Gcts7x9P7mqieS9B7wur7jPGvkf3c+w8Qb89bwNNdHs7TVDOVrtv90ZbrRTV1p7X47zK92jVy3uASBxe83do2rJyeUW3gAC73nBWStVG4OBw29i8e6NdCtJX03srdQSVuwypmfkUlpbTo3UkYcENt4ebliAak0VvwnN97II2u9bbKZBb97F32RnJdhzA8k8qj0/90d6Zpy2AtEVV3ys/E/Zl2+qnfpfau/ftS6HPRXDR63D8jbbefuDlULwX5j5jA4JnA2+rXjbzLtlnX5cU2NlHY+ow37+bu5qp+kLt7tcJx2nbgToqvDQ7lbOem8OFL/3Gw1/a8T3GVF8JAUrKXBX7VqbnsnDzbl7+eQOXvjqP1+ZsYF9JWcWx3s4/ErQE0ZikL7ZtAn+8bDP0uD62vj62mx1ElrPFBoR2x9kSwu4NdjGY3ybbLp8Xeywwv9MZmBbX285G2rqv7bnU+0I766h7NbKOI+DG320vJM/SAzgLtBvYtdaek73Bbq9rF1KAGHeAqDb9dcvusPYbSDiE6iXVKBWWlLMzr4jE2Igaj1m4eTdT/tjK1cMT6ZfQrFbv686E5SA3IuUuw2eL0zipWywlZS5ufH8J/dtFc/MpXYiLCuO9+VsY0rEFCc3C+WJpOlcM7cCDX6ygc8um/OeSfoQGBTJlwVYembaKO8/oxtbd+5iyYGvF+3eMjeDfM9bw1Pfr6Nkmir1FpQgw6+6RtfoedaEBoqEzxs5KuuQ9W9VTfcbRDbNtG8DZ/67MgP9w1vWNcxZRaTMAlk+FiFb2Ln7Gvc7gMew6BHnbbQApLapcXtFdNdTKWSXrpLttm4S3tXBju8K4d/bf7j5352pbRbTLmcbiUEoQiSNsG0iragGilUcJQjV6mXuL+HXdLsYMjCcgoGpGXVLm4s6Pk/l2RQYuA0+O7cdFg+L5ZV0WJ3SOJTwkkHkbspk8ax3zN9plW5PTcvj29pMIDQqseI/ZazMJChD6t2tGbFM7pUpZuYur/7eQ+RuzaRkZygX925LQPJwt2fu49dSuBATA5B/Xc8WwDszbkM39n68gtmkIoUGB5BWWkpqZz1fLMrjqhA5k7S3mybH96B0fxYyVGVzy6jxcLsOq7Xlk7S1mRLeWPPX9Wpo3CeaJmXYamBtGdOKkrrHENwunU8umLN6ym29X7GDl9lzaRkfS8QDB8HBogGjoNs2BaTfbLqHb5sOyD221jtvS92Hlp3Z65uxUu604F4KbVM7733aADRCn/dV2f/3hr3a20GbtbZVQj3Ns9dSmOdDNmSAuc7XtzhoRY1/3HlO1N1JttOhoSyyzHrU9mmK7AXJo4wy6nVmZNk+9RtvlRRN1HMLRaGdeEYUl5Qe82webQReWlnPlmwtYs2MvCzfv5t9j+lJuDPd/toLC0jJKyw0/rN7JxOGJrEjL5dGvVvHtygxmr81ieJcYju8YwzM/rKNVZCh/Pa8X8c3CmPT+El7+eQN3nN6Nn9bs5N5Pl7Mr347qDwkM4PkJAzi7TxvenLuJuam7uDSpHXv2lfDG3E2Uu2yJosxlaBISyBtzN/HT2kzyCkvpEx/FvmJbkvnw+qG0iAhh/GvzeWn2Btq1CGdEt5YEBgiXH9+BN+Zu4smx/QB4ZPoq5m3MpntcJJ/cOIxpydsJDw7k4sEJVa7H4A4tGNzByzKrR5gGiIZuzdcQFA63LID3xti5iLqfY8cdgM3IoXKaiLi+sHOFrf93T+/Qf4Jt0B3wJ9seEdPFjl529/lPPMl2PV37TWUmvHNl1TV2D0VAILTuZxvI258AW51uqrWdwro2gkIb3Rz8DdnstZn8sjaLv57Xi0DnDr603MWmXQUI0DUu8qDv8fZvm1i1PY8B7ZvxxLdrEBHm3HMK0U2CvR7/xMw1vDZnI82bBJOzr5Rz+7Vh6sJtZO4tJjwkkG+WZxAdHkxuYSn3nNWdm0/pQnpOIWc/O4fZa7MYMzCeL5PT+S01mwsHtOXxsf0qGoYv6N+W52etp9xleHPuJjrERPDUJf2JCA3isRkp3PTBEs7q3ZrZazM5o1ccj4/ti4iwK7+Y4jIX/52dynvztxAUIAxq34wV6bmUuQz/u3oIXeOasreojJaRthTy7rVDuOqtBdw8skvFtbtvVA8uHBhPn/hoAMYOTmDr7n3ENwsnJCiAK4Z2ONxf2WHRANGQGQNrZtgxAiERcM5T8OoIu1LZ6Y/Y+Yvc1Tarv7SPx/8Zvrqt6hq94c2qrjLW4xz74xYUasccrP3W9gbatc4OPnNXQx2Oce/abrKRbeCXx23JRjU4JWUuflqTSZOQQEZ08750747cIm6bspS9RWXERYVx48jObMku4LLX/yA9x07H/tylA7hwYGVvuZx9Jcxem8moPm0ICw5kZXou//f1agzwyeI0urRqyoasfP77cyoPnFPZAcEYw868Yr5btYOXf97AiG4tCQkM4KJB8Yzq05r+CdG88FMqe4vKuOP0rtw4sjMbswro0doGqPhm4bx9zXHkF5dzcreWnNkrjm179nHdiZ2qVE09PrYvuYWlvPBTKq0iQ3l74nHERdlq1vevO54HP1/B8rRcerSO4v9G965of3BXPd15RjemJW+npMzF5PEDWbdzL5l7i+mbYDN8zx5KnVs25dd7T6nShhEcGFARHAACA8Rn1UWHQnzV+u0PSUlJZtGiRQc/8GiRsRxePclOHDfoCrvt46sgdRbcuQJy0+04BrAZb+k+uHkB7N5kG4jdM4rWxrKP4AtnJbKoBNvbaMJU6D7qyH4n5XOzUnby1m+b+O+fBhMd7v2u3NP6nXv50xt/kLm3GIBz+7XhsYv6EhVmzzXGsG5nPo9+tYqlW3MY2L4Zizbv4eZTuvDxom3sKynjwXN68uniNJZuzWHSyZ0IDwmi3OXi7d+3sCu/mD7xUdx+Wjcmz1rHjtxipt8ynA1Z+SR1aMFDX67g6+UZnNkrjqAA4YQusUxZsJWlW3MAGN4lhrcnDiE4sGqny9zCUlam53JC55iDNhwfSGm5izfnbmJk95b0aB1V5/PnrMtiX0kZZ/dpc8hp8CcRWWyM8bo4mwaIhmjPZludFBRmRyL/ZR00bWX37VgBr5wIpzxk+/1/fr0NBDlbbfXRQzsObWnIkgKY9X+2Tr/DCVCUB6GR2nW0AdtTUMLW3fvolxBdkUEaYzj3+bmszsjjokHxPDNugNdzf0/dxYcLtnLLqV2479PlbNtTyNOX9Gd1Rh7P/rCOrnGRjD+uHW/9ton0PYWUOfXtj13Ul7N6t+aSV35nQ1YBzZsE8+41x9M3IZo9BSVc9sYfpGTkVXxO77ZRjEtqx1Pfr2VvURki8OKEQZzbrzIzTc8pZOx/fyckKID84jJ2F5TQMjKUG07qRGJsBCd1jW3QYwWOdhogGqrifNumsG6mnRX1jEft9iXvwfRb7BoD7YbAFV9UPe/D8bbBus/FdsrrYTfDb8/ZgHH7snr+EupwZe4t4uOF27hiWGLFHb8xho27Cli8eQ9NQm3vm6+WbeeZcQM4vVcc5S7D2Jd/J3lbDh1imnDRwATGDo5nV34JF770Gz1aR7Jmx17O7BVHeEggmXnFtIgIoWNsBJuyC/hmeQYAAQIuA89PGMgF/e1gx1/WZTHpvcUUlpYzsH0zhnWKoV2LJpzSvRWtoytnpi0qLSdAhJCgyjt7YwxlLkO5yz5GhARW1Nlvyd5HXFQoCc1rrmYsLXexMj2XrnGRNA3VGvD6oAGiofr9Rfj+IYiKt3MX/WW9XSXNvcbx/VtAAvdfOS1tEbxxmp0jKba7nSLi4yuh82lwxef++S7qkN0xdSlfJm+nY2wEL18+iHbNmzDp/cX8ur5yMaSQwACaNQnGZQzf3TGCTxen8di3a7j2xI6kZOTx+4ZsQgID6NQygq279/H7/afy9+mrWJ5mG01bRoaSubeItD2FxEWGcXaf1lx1QiIPfr6CNtFhPD2uf5VqmtXb88jILeTUHq0Oq/pGNXwHChAaov0pbaGduuKsf9oMfus8O1lc5irb37+mqqKEpMp1FOJ62Z5CYHsnqXozZ10We/aVcEH/togIZeUuvliazhm94mjWJGS/4zP3FjFvQzZn9W7N0q05zF6byYiuLZm2bDtn9Y5j8ZYcznt+Lu1aNGHr7n3cd3YPzuwdR2m5i5iIULILirnghd84/ZlfyC0s5azecTx8bk9EhG279/GPr1fz/eqdTBjSnmZNQnhu/MD90lDuMhU9aACm3DDU63fr1TaKXm3rXh+vGhcNEP6Uvthm9l1Ot+0NKV85ASLFbjuQEfc4AaKPrVoaeHndxykcw9L27GNFWi6j+tbcsLgyPZfnflzP42P7VvRacduavY8/O9Uw8zZk88j5vXlpdiovzk7l/P5teWHCQIwxPPPDOv7YtJs3rkrizo+S+S01mxYRIewusH3tX5uzkcjQIJ4Y249yl+HJmWuZvmw7z48fWKWeHqBlZCj/GtOHWSmZdGsdybXDO1bc3bdr0YRXrxjMH5t2V+kVU11ggJYGVO1pFZO/7N0JT3eDM/8FJ9wCUybYXkt/ngP/6QRn/hNOuLXm842xq6y1HwphNWcIan/G2Pr7JVtzuO/sHtw4sjN7i0q59p1FnNgllttOsyO9J7w2n3kbs6s09ubuK2XDrnye+HYNq7bncfHgBN7+fTNxUaFk7i2mTVQY23OLePbS/szbkM3Hi9IA6Nwygg1ZBVx9QiJpe/bRvXUk5/Zty3M/ruPUHq0YP6Syx1n1u3ylfEmrmBqidCeQJTi/l57n2wVxFr5uX7fq6f08NxHodpbv0teIzUrJZMnWHDrFRvDEzDXkFJaweVcBCzbtZsGm3QQFCkkdWjBvYzadYiP4fEk6A9s3p7i0nMmz1rO3yE6S9sTYvlx6XHtG9WnNv2ak0CoyjPeuHcL5L87lzo9sZ4EbR3amRZMQ/jUjhX4J0VUGmAG8duX+/5caHFRDoSUIX1szww5yazek6gjiHx+F35+HB9Ls9pJ9MLm/nWzPVQp3pVROoa0OyuUyFJSUER4cSFC1/vLbdtvqoOKyctpEh7MxK5+QoAC+vX0Ej0xfWXGXf/+oHqxIz+Wb5RkEBgjR4cH8cOcILn5lHpt2FQBwYpdYJg5PpG2zcHq2qVpHb4xBRFiZnsuCTbs5o1cc7Vo0wRjD1IXbOLFLLO1a6EBB1bBoCcJflr5v51ECO5VF0kToeoYd1LZxtp3Kwh00QprA8Nvg+4dtlVHk0TnoxhfKyl0VmX7m3iKahgYRHhzIF0vTiYsKIymxOX96/Q8WbdlDSFAA95zZnX4J0bw7fwtjBsTz359T2bZ7Hyd2jSUjt4igwAAePrcX4SGBPHlxf8YltWN1Rh5XDO1Auctwdu/WTF+2nXP6tiamaSjf3HYiG7NsgOjdNqrGXj3u7X3io6u0A4gIE4bUYdCiUg2EliB8JX0JvHUWtB8GQ2+C5R/Z6TCMq/KYE26DM/9R+bqkwJYiYrvDxG/qPcn+5HIZPlq0jZO6xlbpJ/9b6i5um7KUXm2jOLdvGx79ajUtIkI4vlMLPl+STnCgMLRTDL+u38WkkzuTmrmXH1MyAQgKkIoBXp79/JVSlXQchD+8c4Gdz+imeZUT6+Vl2DWZi/PtAjix3apO3Q12mu3AEDuFdiOyp6CE5hH7d/10e+b7tTz/UyrxzcKZesNQ2rVowieLtnHfZ8tp16IJO/OKKCp1MaBdM/IKS9m4q4DLh7ZneVouy9NymTg8kUfO740xhg/+2EpuYSmXD+3AlAVbKXcZbj5FuwAr5Y0GiPqWmQL/HQqn/c2uo3CM+3JpOnd8lMw/RvcmKbEF9366nN0FJYQGBRDTNISosGBmrcnktB6tWLh5N2HBgVw4MJ43ft3I8C6xvHz5YHbkFvLLul1cPrQ9LheszshlUPvm5BWWMXNVBhcOjK+Y018pVXt+CxAicjYwGQgE3jDGPF5tf3PgLaAzUARcY4xZ6bE/EFgEpBtjqi1Xtr8GEyC+vhOWfmAbmt3rKRxD1u3cS2RYEG2iw8naW8wZz/5CvtPzJzIsiODAAE7sGktxmYvs/GJ25ZfQuWUEk8cPZENWPg99sZLkbTkMaNeMD68/niYh2lSmlK/4pZHaydxfAs4A0oCFIjLdGLPa47AHgWRjzBgR6eEcf5rH/tuBFODoGdJZlGdXZ+t3SaMPDsvTcoiLCquYHtndW+evX66kSUggD5zTk08WbWNfcTkfTxrG3R8vY29RGVNvGEqnlk29vmfvttF8cdMJLNmaQ/fWkRoclPIjX/73DQFSjTEbAURkKjAa8AwQvYDHAIwxa0QkUUTijDE7RSQBOBf4F3CXD9N5ZK2baafdHniFv1NyyFZtz+W6dxZxcreW3H1m94oFT3bmFTF/YzaDOzQnbU8hl70+n7DgQMYltSNtzz6WpeWStbeYk7rGkplXzAOfr6BZk2CeuLgvg9o3Z/otwyl3Ga/TUHgSEQZ3aF4fX1UpdQC+DBDxwDaP12nA8dWOWQZcBMwVkSFAByAB2Ak8B9wLHHyJqoZk1RcQ2RYShvg7JQdVWu5i5sodjOrTmvziMu7/bAX92zXjvXmbKSwt59PFaXy/eif//dMgvlyaztSF9tfZNDSI0KAAEmMi6BgbwTvzNtMxNoKTusRyXMcWXDI4geIyFz+m7OTUHq2IdNYVcD8qpY4OvgwQ3jqLV2/weByYLCLJwApgKVAmIucBmcaYxSIy8oAfInIDcANA+/Z+6mvucsGKj6HtILuYT9I1+/dOaoDen7+FR79azWMX9SW/qIyZq3Ywc9UOwoMD+WTSMMKCA7j2nUWMf20+ANcM78gZveJ4+vu1rM7I44Prj6dH6yhKy137LeYSFBjA6AHx3j5WKXWU8FkjtYgMA/5ujDnLef0AgDHmsRqOF2AT0A94ALgCKAPCsG0QnxtjLj/QZ9ZbI/XcZ6G0CE55wL5e+gFMu8lOv+0qg2u+h/bVC0sNS1FpOSOenE3m3mJ6tI6kzGWIDLOTxhkD3Z2lG3flF/PYjDWM6tOa03vFAZWjlrVEoNTRz18jqRcCXUWkI5AOjAeqrC4vIs2AfcaYEuA6YI4xJg8bIB5wjhkJ/OVgwaHelJfBb5MBgZH323UcfvonxPW18yOVFUPCcf5OZRXFZeVs272PLq0qa+umLNhK5t5ixgyM54ul6QA8flFfulVbdD62aShPj+tfZVtAgGhwUOoY4LMAYYwpE5FbgO+w3VzfMsasEpFJzv5XgJ7AuyJSjm28vtZX6Tlitv1h50sC2L0RVk+Dvdvh4jftqOny0gZVvfT18u08NmMN6TmFvHFlEqf3imNlei5PfbeWYZ1i+PeYvsxK2UmZy3CejjRWSnnwaR9CY8wMYEa1ba94PJ8HHHDIsDHmZ+BnHyTv0Kz7tvJ5+mJI/hAST7LrOAMEHbiHji+4XIYALzOAfrE0jTs/Wkaf+CjCQwJ54IsVFJSU8Y+vU5wFZQYQHhLIP8f0paikXJd4VEpVoTlCXa2dCR1PtqvBLZtqp84YcoPfkvOvb1bzw+qdfHXriUSGBVNW7uLZH9exPC2XeRuyOaFzDP+beBypmfmMfvE3bp+aTELzcN6eeFzF+AWdo0gp5Y0GiLrIWlcZEFxlsGGW3d59lF+S8/2qHbz+6yYAXv55A385szv3fbaCz5ak0Tc+mgv6t+XR0b0JDQqkd9toXr8qiZIyF6f1aLXflNhKKVWdBoi6WPAaBARDrwsgdxts+c2uB92snc8/+rkf17E+M5//XNyPxVv28O68LfyWuos+8VEkxkTwxtxNzN+YzZKtOdx5ejduP33/mrtTurfyeTqVUo2HBojaKthl13fofylEtq5cCa77OT7/6O9W7eC5H9cDkJKRx6ZdBbSJCuPcvm24/fSuBIjw89ossvKL+feYvkwY4vuApZRq/DRA1NYfr0BZoV3DAaDTKdBnLAw88r1vd+UXk76nkD7x0aRm5nPvp8vpGx/NlcM6cP/nK7igf1sev6gf4SGVs5f+dv+pRITsv5qaUkodKg0QB2MM/Po0zPkP9BoNLbvb7WFRcPFbR/SjSstdTHpvMbPW2AVvereNIm1PIaFBAbx42UA6xERwdp/WXscgRIfruASl1JGlAeJActNg+q2w4SfoOw4ueN5nH2WM4ZHpq5i1JpObRnYmvnk4L/6USvMmwbx37fEVaxnrADWlVH3RAFETY+D9sZCzDc55Co67zo6U9oF9JWU8On01Hy3axo0jO3Pv2T0AGJfUDpcxuhCOUsovNEDUJCMZstbA+ZNh8NVH9K3d6yZ0adWUPm2jGffqPFZtz+OmkZ25+8zuFcdVnwBPKaXqkwaImqz6wk6+1/OCI/7Wz/ywjhd+SiUkKICB7Zqxanser14+mDN7tz7in6WUUodKb1G9McYGiE6nQJMWR/StX5i1nhd+SmXsoAS6tmrKH5t2c9fp3TQ4KKUaHC1BeJO+BHK2wsn3H9G3fX3ORp7+YR0XDYznPxf3Y29xGfM2ZHOmM422Uko1JFqC8CZjqX3sfMphv9Wq7bnsKyljQ1Y+j32bwqg+rXny4n4EBAjR4cGc3ae114n2lFLK37QE4U1+JiAQcXhTU3y2OI27P1nGCZ1jiGkaSmhQIP+4sI8OZlNKHRU0QHiTvxMiYiHw0C6PMYZPF6dx/+cr6BQbwe8bsgH484hOxDYNPZIpVUopn9FbWW/ys6DpobUL7C0q5Yb3FnPPp8tJ6tCc6beeyMThicQ2DeGGEZ2OcEKVUsp3tAThTf5OaFr36qWsvcVMfHsBazL28tA5PbnmxI4EBgiPnN+bB0b1JCRI47FS6uihAcKb/EyI6VLn0/42bSWpmfm8flXSflNra3BQSh1tNNeqzphDKkFszynku1U7uOqERF13QSnVKGiAqK4oF8qL69wGMWXBVgxw+fEdfJMupZSqZxogqivIso91CBC78ouZsmAbp/VoVTHrqlJKHe20DaK6/J32sZZVTL9v2MWtHy5lb3EZk07u7MOEKaVU/apVCUJEPhORc0Wk8Zc46hAgjDE8/OVKIsOC+PrWE0lKPLLzNimllD/VNsN/GbgMWC8ij4tIDx+myb/y7Wputalimr9xNxuzCrjl1K50i4v0ccKUUqp+1SpAGGN+NMb8CRgEbAZ+EJHfRWSiiDSuJc7yd0JAMIQ1O+ihHy7YSlRYEOf1a+P7dCmlVD2rdZWRiMQAVwPXAUuBydiA8YNPUuYv+Vm2eimg5kuTkVvI5B/XM3NlBmMHJxAWrCu+KaUan1o1UovI50AP4D3gfGNMhrPrIxFZ5KvE+UX+TohoecBDJr23mOXpuQxu35zrT9LpM5RSjVNtezG9aIz5ydsOY0zSEUyP/+XvhMiaq4w2ZOWzLC2Xh8/tyXUaHJRSjVhtq5h6ikgz9wsRaS4iN/kmSX62N+OAPZimJW9HBC7o37YeE6WUUvWvtgHiemNMjvuFMWYPcP3BThKRs0VkrYikish+y7M5geYLEVkuIgtEpI+zvZ2IzBaRFBFZJSK31zKdh6cwxw6Uq2EeJmMM05PTOaFzDK2iwuolSUop5S+1DRABIlKx7JmIBAIhBzrBOeYlYBTQC5ggIr2qHfYgkGyM6QdciW34BigD7jbG9ASGAjd7OffI27XePrbsvt+usnIXz89KZXP2Pkb3j/d5UpRSyt9qGyC+Az4WkdNE5FRgCjDzIOcMAVKNMRuNMSXAVGB0tWN6AbMAjDFrgEQRiTPGZBhjljjb9wIpgO9z5V3r7GNst/123fPpcp79cR3n9WvD6IFavaSUavxqGyDuA34CbgRuxmbq9x7knHhgm8frNPbP5JcBFwGIyBCgA5DgeYCIJAIDgT9qmdZDt2stBIZAs6oT7u0tKuXr5du5fGh7XrxsEKFB2q1VKdX41aoXkzHGhR1N/XId3lu8bDPVXj8OTBaRZGAFdnxFWcUbiDQFPgPuMMbkef0QkRuAGwDat29fh+R5kbUOWnTeb6nRX9fvorTccIFWLSmljiG1HQfRFXgMWyVU0TprjDlQP880oJ3H6wRgu+cBTqY/0fkMATY5PzgjtD8DPjDGfF7ThxhjXgNeA0hKSqoegOpm1zpo3We/zT+u3kmzJsEMat/ssN5eKaWOJrWtYvoftvRQBpwCvIsdNHcgC4GuItJRREKA8cB0zwNEpJmzD+wI7TnGmDwnWLwJpBhjnqllGg9PWTHs2QSxVRuoy8pd/LQ2k1O7tyIosPHPVaiUUm61zfHCjTGzADHGbDHG/B049UAnGGPKgFuwDdwpwMfGmFUiMklEJjmH9QRWicgabG8nd3fW4cAVwKkikuz8nFOnb1ZXuzeCce3XQL10Ww45+0o5vVfdFhBSSqmjXW1HUhc5U32vF5FbgHTgoPNhG2NmADOqbXvF4/k8oKuX8+bivQ3Dd7LW2seWVQPE3PW7CBAY3iW2XpOjlFL+VtsSxB1AE+A2YDBwOXCVj9LkH3lO80izqg3d8zdm07ttNNHhjWvSWqWUOpiDBghnwNs4Y0y+MSbNGDPRGDPWGDO/HtJXf0r32cfgiIpNRaXlLN2aw7DOMX5KlFJK+c9BA4QxphwY7DmSulEqLQQJhMDKksKSrXsoKXcxtJOuFKeUOvbUtg1iKTBNRD4BCtwbD9T99KhTWgjB4eARB+dvyCZA4DhdSlQpdQyqbYBoAWRTteeSARpPgChzAoSH+Rt30zc+msgwbX9QSh17ajuSeqKvE+J3pYUQVBkgyspdLE/P4bIhHQ5wklJKNV61HUn9P/afJgNjzDVHPEX+Ulq1BLE+M5+iUhf920X7MVFKKeU/ta1i+trjeRgwhmrTZhz1SgshuHKNhxVpuQD0jdcAoZQ6NtW2iukzz9ciMgX40Scp8peyQghuUvFyeXoOkWFBJMZEHOAkpZRqvA51cqGuwGFOndrAlBZCUGUJYnlaLn3jowkIaNy9e5VSqia1ChAisldE8tw/wFfYNSIaj9LKEkRxWTkpGXn0TdDqJaXUsau2VUyRvk6I33k0Uq/bkU9puaFffDP/pkkppfyotiWIMSIS7fG6mYhc6LNU+YNHI3XKDrs2Ue+2Uf5MkVJK+VVt2yAeMcbkul8YY3KAR3ySIn/xaKTOyCkCoG2z8AOdoZRSjVptA4S342rbRfbo4NFIvSOvkNimIYQE6QJBSqljV21zwEUi8oyIdBaRTiLyLLDYlwmrVy4XlBVVlCB25BbROjrsICcppVTjVtsAcStQAnwEfAwUAjf7KlH1rsxWKbnbIDJyi2gdpdVLSqljW217MRUA9/s4Lf5TWmgf3SWIvCKSEpv7MUFKKeV/te3F9IOINPN43VxEvvNZqupbmTtAhFNUWk7OvlLaRGsJQil1bKttFVOs03MJAGPMHmqxJvVRw12CCApnR66tbmodpW0QSqljW20DhEtEKqbWEJFEvMzuetQqrSxBZLgDhDZSK6WOcbXtqvoQMFdEfnFejwBu8E2S/KAiQISxM08DhFJKQe0bqWeKSBI2KCQD07A9mRqH0n32MbhJZQlCq5iUUse42i4YdB1wO5CADRBDgXlUXYL06OXu5hoUxo7cQiLDgogIbVzjAJVSqq5q2wZxO3AcsMUYcwowEMjyWarqm0cJYkdeEW20ekkppWodIIqMMUUAIhJqjFkDdPddsupZqXugXLgzilq7uCqlVG3rUdKccRBfAj+IyB4a05KjFSWIcHbkFdG9deOf3VwppQ6mto3UY5ynfxeR2UA0MNNnqapvThuECQpjd0EJMU1D/ZwgpZTyvzq3xBpjfjn4UUcZp5vrXlcwpeWGmIgQPydIKaX8z6fzWYvI2SKyVkRSRWS/uZycKTu+EJHlIrJARPrU9twjqnQfBASze58LgOZNNEAopZTPAoSIBAIvAaOAXsAEEelV7bAHgWRjTD/gSmByHc49ckqLIDic3ftKAGjRVAOEUkr5sgQxBEg1xmw0xpQAU4HR1Y7pBcwCcHpGJYpIXC3PPXJK99kAke8ECC1BKKWUTwNEPLDN43Was83TMuAiABEZAnTADsarzblHTlkRBIVVliC0DUIppXwaIMTLtuoT/D0ONBeRZOyiREuBslqeaz9E5AYRWSQii7KyDnHsXuk+CG7C7gINEEop5ebL+STSgHYerxOoNnbCGJMHTAQQEQE2OT9NDnaux3u8BrwGkJSUdGgzzDptEHsKSggNCqBJSOAhvY1SSjUmvixBLAS6ikhHEQkBxgPTPQ8QkWbOPoDrgDlO0DjouUdUaSEEh5NdUEJMRAg2Viml1LHNZyUIY0yZiNwCfAcEAm8ZY1aJyCRn/ytAT+BdESkHVgPXHuhcX6WV0n3QpAW7C0portVLSikF+LaKCWPMDGBGtW2veDyfB3St7bk+426kzi3R9gellHL4dKDcUcOjkVoDhFJKWRogwGmkDmOPBgillKqgAQKgtJCywDD2FpfpPExKKeXQAAEQ1ZbC0JYA2kitlFIODRAAN89nW69JAFqCUEophwYIh3sUtc7kqpRSlgYIh3sephidyVUppQANEBVynADRTEsQSikFaICoUFRaDkB4sM7DpJRSoAGiQkmZXU0uJEgviVJKgQaICiVlLkQgKEAn6lNKKdAAUaG43EVwYIDO5KqUUg4NEI6SMhehgXo5lFLKTXNER0mZS9sflFLKg+aIjtJyDRBKKeVJc0SHliCUUqoqzREdJeUuQrQNQimlKmiO6Cgps72YlFJKWZojOoq1ikkpparQHNGhbRBKKVWV5oiO0nIXoRoglFKqguaIDm2kVkqpqjRHdGgjtVJKVaU5okPbIJRSqirNER0aIJRSqirNER0lOtWGUkpVoTmio6RMG6mVUsqT5oiOEu3mqpRSVWiO6NBeTEopVZVPc0QROVtE1opIqojc72V/tIh8JSLLRGSViEz02Hens22liEwRkTBfpbOs3IXL6HrUSinlyWc5oogEAi8Bo4BewAQR6VXtsJuB1caY/sBI4GkRCRGReOA2IMkY0wcIBMb7Kq0l5S5AA4RSSnnyZY44BEg1xmw0xpQAU4HR1Y4xQKTYhaCbAruBMmdfEBAuIkFAE2C7rxJaUuYECK1iUkqpCr7MEeOBbR6v05xtnl4EemIz/xXA7cYYlzEmHXgK2ApkALnGmO99lVAtQSil1P58mSOKl22m2uuzgGSgLTAAeFFEokSkOba00dHZFyEil3v9EJEbRGSRiCzKyso6pIRWlCA0QCilVAVf5ohpQDuP1wnsX000EfjcWKnAJqAHcDqwyRiTZYwpBT4HTvD2IcaY14wxScaYpJYtWx5SQrWKSSml9ufLHHEh0FVEOopICLaReXq1Y7YCpwGISBzQHdjobB8qIk2c9onTgBRfJVSrmJRSan9BvnpjY0yZiNwCfIfthfSWMWaViExy9r8C/AN4W0RWYKuk7jPG7AJ2icinwBJso/VS4DVfpVVLEEoptT+fBQgAY8wMYEa1ba94PN8OnFnDuY8Aj/gyfW7aBqFU41daWkpaWhpFRUX+TopfhIWFkZCQQHBwcK3P8WmAOFpoFZNSjV9aWhqRkZEkJiZia66PHcYYsrOzSUtLo2PHjrU+T3NEKksQOtWGUo1XUVERMTExx1xwABARYmJi6lx60hyRygChk/Up1bgdi8HB7VC+u+aIaBWTUkp5ozki2otJKeV72dnZDBgwgAEDBtC6dWvi4+MrXosIAwYMoE+fPpx//vnk5ORUObd///5MmDChyrarr76aTz/9FICRI0eSlJRUsW/RokWMHDnysNOsOSLai0kp5XsxMTEkJyeTnJzMpEmTuPPOOyteR0REkJyczMqVK2nRogUvvfRSxXkpKSm4XC7mzJlDQUFBje+fmZnJt99+e0TTrL2YgFKtYlLqmPLoV6tYvT3viL5nr7ZRPHJ+78N+n2HDhrF8+fKK1x9++CFXXHEFKSkpTJ8+fb+ShNs999zDP//5T0aNGnXYaXDTHBEo1l5MSqkGoLy8nFmzZnHBBRdUbPvoo4+49NJLmTBhAlOmTKnx3GHDhhEaGsrs2bOPWHq0BEFlI7X2YlLq2HAk7vSPpMLCQgYMGMDmzZsZPHgwZ5xxBgALFy6kZcuWdOjQgYSEBK655hr27NlD8+bNvb7Pww8/zD//+U+eeOKJI5IuzRHRRmqllH+Fh4eTnJzMli1bKCkpqWiDmDJlCmvWrCExMZHOnTuTl5fHZ599VuP7nHrqqRQVFTF//vwjki7NEbEBIihACAg4dvtIK6X8Lzo6mueff56nnnqK4uJiPvnkE5YvX87mzZvZvHkz06ZNO2A1E8BDDz3Ek08+eUTSowECGyC0gVop1RAMHDiQ/v378/HHHxMfH098fOU6ayNGjGD16tVkZGTUeP4555zDoS59UJ0YU30Nn6NXUlKSWbRoUZ3Pe2TaSr5M3s6yR7zOG6iUagRSUlLo2bOnv5PhV96ugYgsNsYkeTteb5uxjdRaglBKqao0V8R2c9UGaqWUqkpzRWwbhHZxVUqpqjRXRBuplVLKG80V0TYIpZTyRnNF7FxMOs2GUkpVpbkiThWTBgillA+NHDmS7777rsq25557jptuuomsrCyCg4N59dVXq+xPTExk165d9ZnMKjRXRNsglFK+N2HCBKZOnVpl29SpU5kwYQKffPIJQ4cOPego6fqmk/XhdHPVAKHUsePb+2HHiiP7nq37wqjHa9x98cUX8/DDD1NcXExoaCibN29m+/btnHjiiTz44IM8/fTTXHbZZaSnp1cZPe1PmiuijdRKKd+LiYlhyJAhzJw5E7Clh0svvZS0tDR27NjBkCFDGDduHB999JGfU1pJSxA44yC0DUKpY8cB7vR9yV3NNHr0aKZOncpbb73F1KlTGTduHADjx4/n2muv5a677vJL+qrTAIH2YlJK1Y8LL7yQu+66iyVLllBYWMigQYO47rrr2LlzJx988AEA27dvZ/369XTt2tXPqdUqJkAbqZVS9aNp06aMHDmSa665hgkTJrB27VoKCgpIT0+vmNL7gQce2K8x2180V0QDhFKq/kyYMIFly5Yxfvx4pkyZwpgxY6rsHzt2bJXeTP369SMhIYGEhIR6r3rSKibgjF5x9G4b5e9kKKWOAWPGjMG9zMLf//73/fb369eP1atXA7B58+Z6TNn+NEAAz40f6O8kKKVUg+PTehUROVtE1opIqojc72V/tIh8JSLLRGSViEz02NdMRD4VkTUikiIiw3yZVqWUUlX5LECISCDwEjAK6AVMEJFe1Q67GVhtjOkPjASeFpEQZ99kYKYxpgfQH0jxVVqVUseGxrSCZl0dynf3ZQliCJBqjNlojCkBpgKjqx1jgEgREaApsBsoE5EoYATwJoAxpsQYk+PDtCqlGrmwsDCys7OPySBhjCE7O5uwsLA6nefLNoh4YJvH6zTg+GrHvAhMB7YDkcClxhiXiHQCsoD/iUh/YDFwuzGmwIfpVUo1YgkJCaSlpZGVleXvpPhFWFgYCQkJdTrHlwFCvGyrHrrPApKBU4HOwA8i8quTrkHArcaYP0RkMnA/8Nf9PkTkBuAGgPbt2x+xxCulGpfg4GA6duzo72QcVXxZxZQGtPN4nYAtKXiaCHxurFRgE9DDOTfNGPOHc9yn2ICxH2PMa8aYJGNMUsuWLY/oF1BKqWOZLwPEQqCriHR0Gp7HY6uTPG0FTgMQkTigO7DRGLMD2CYi3Z3jTgNW+zCtSimlqvFZFZMxpkxEbgG+AwKBt4wxq0RkkrP/FeAfwNsisgJbJXWfMca9OsatwAdOcNmILW0opZSqJ9KYWvRFJAvYcoinxwL+W7qpZpquumuoadN01Y2mq+4OJW0djDFe6+cbVYA4HCKyyBiT5O90VKfpqruGmjZNV91ouuruSKdNZ6hTSinllQYIpZRSXmmAqPSavxNQA01X3TXUtGm66kbTVXdHNG3aBqGUUsorLUEopZTySgOEUkopr475AHGwNSvqMR3tRGS2s/bFKhG53dn+dxFJF5Fk5+ccP6Vvs4iscNKwyNnWQkR+EJH1zmPzek5Td4/rkiwieSJyhz+umYi8JSKZIrLSY1uN10dEHnD+5taKyFl+SNt/nLVWlovIFyLSzNmeKCKFHtfulXpOV42/u/q6ZjWk6yOPNG0WkWRne31er5ryCN/9nRljjtkf7AjvDUAnIARYBvTyU1raAIOc55HAOuw6Gn8H/tIArtVmILbatieB+53n9wNP+Pl3uQPo4I9rhp2efhCw8mDXx/m9LgNCgY7O32BgPaftTCDIef6ER9oSPY/zwzXz+rurz2vmLV3V9j8N/M0P16umPMJnf2fHegmiNmtW1AtjTIYxZonzfC92gaR4f6SlDkYD7zjP3wEu9F9SOA3YYIw51JH0h8UYMwe7nomnmq7PaGCqMabYGLMJSMX+LdZb2owx3xtjypyX87GTadarGq5ZTertmh0oXc7aNeOAKb747AM5QB7hs7+zYz1AeFuzwu+ZsogkAgMB92y2tzhVAW/VdzWOBwN8LyKLnSnWAeKMMRlg/3iBVn5KG9jJID3/aRvCNavp+jS0v7trgG89XncUkaUi8ouInOSH9Hj73TWUa3YSsNMYs95jW71fr2p5hM/+zo71AFGbNSvqlYg0BT4D7jDG5AEvY9fKGABkYIu3/jDcGDMIu4TszSIywk/p2I/YCR0vAD5xNjWUa1aTBvN3JyIPAWXAB86mDKC9MWYgcBfwodgVHutLTb+7hnLNJlD1RqTer5eXPKLGQ71sq9M1O9YDRG3WrKg3IhKM/cV/YIz5HMAYs9MYU26McQGv48OqiAMxxmx3HjOBL5x07BSRNk7a2wCZ/kgbNmgtMcbsdNLYIK4ZNV+fBvF3JyJXAecBfzJOpbVTHZHtPF+MrbfuVl9pOsDvzu/XTESCgIuAj9zb6vt6ecsj8OHf2bEeIGqzZkW9cOo23wRSjDHPeGxv43HYGGBl9XPrIW0RIhLpfo5t4FyJvVZXOYddBUyr77Q5qtzVNYRr5qjp+kwHxotIqIh0BLoCC+ozYSJyNnAfcIExZp/H9pYiEug87+SkbWM9pqum353frxlwOrDGGJPm3lCf16umPAJf/p3VR+t7Q/4BzsH2BtgAPOTHdJyILf4txy7Dmuyk7T1ghbN9OtDGD2nrhO0NsQxY5b5OQAwwC1jvPLbwQ9qaANlAtMe2er9m2ACVAZRi79yuPdD1AR5y/ubWAqP8kLZUbP20+2/tFefYsc7veBmwBDi/ntNV4++uvq6Zt3Q5298GJlU7tj6vV015hM/+znSqDaWUUl4d61VMSimlaqABQimllFcaIJRSSnmlAUIppZRXGiCUUkp5pQFCqQZAREaKyNf+TodSnjRAKKWU8koDhFJ1ICKXi8gCZ+7/V0UkUETyReRpEVkiIrNEpKVz7AARmS+Vay40d7Z3EZEfRWSZc05n5+2bisinYtdp+MAZOauU32iAUKqWRKQncCl24sIBQDnwJyACOxfUIOAX4BHnlHeB+4wx/bCjg93bPwBeMsb0B07AjtoFOzvnHdh5/DsBw338lZQ6oCB/J0Cpo8hpwGBgoXNzH46dGM1F5QRu7wOfi0g00MwY84uz/R3gE2dOq3hjzBcAxpgiAOf9Fhhnnh9nxbJEYK7Pv5VSNdAAoVTtCfCOMeaBKhtF/lrtuAPNX3OgaqNij+fl6P+n8jOtYlKq9mYBF4tIK6hYC7gD9v/oYueYy4C5xphcYI/HAjJXAL8YO39/mohc6LxHqIg0qc8voVRt6R2KUrVkjFktIg9jV9YLwM72eTNQAPQWkcVALradAuzUy684AWAjMNHZfgXwqoj8n/Mel9Tj11Cq1nQ2V6UOk4jkG2Oa+jsdSh1pWsWklFLKKy1BKKWU8kpLEEoppbzSAKGUUsorDRBKKaW80gChlFLKKw0QSimlvPp/lY760WEGnacAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9108db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1cf93ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 2ms/step - loss: 0.0873 - tp: 2632.0000 - fp: 165.0000 - tn: 19835.0000 - fn: 1368.0000 - accuracy: 0.9361 - precision: 0.9410 - recall: 0.6580 - auc: 0.9788 - prc: 0.9161\n"
     ]
    }
   ],
   "source": [
    "loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b7826a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82       466\n",
      "           1       0.85      0.72      0.78       805\n",
      "           2       0.79      0.89      0.84       765\n",
      "           3       0.77      0.80      0.78       719\n",
      "           4       0.85      0.92      0.88       761\n",
      "           5       0.90      0.99      0.94       484\n",
      "\n",
      "    accuracy                           0.84      4000\n",
      "   macro avg       0.85      0.84      0.84      4000\n",
      "weighted avg       0.84      0.84      0.84      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "y_pred_label = [class_names[i] for i in np.argmax(y_pred, axis=1)]\n",
    "y_true_label = [class_names[i] for i in np.argmax(y_test, axis=1)]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names,normalize=True,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e8526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes 3, 4 Need to be weighted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30c05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
