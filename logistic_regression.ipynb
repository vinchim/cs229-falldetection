{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10255, 51) (10255,) (2564, 51) (2564,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntotal_len = len(x_features)\\ntrain_len = int(0.9*total_len)\\n\\nprint(total_len)\\nprint(train_len)\\n\\nx_train = x_features[:train_len]\\ny_train = y_labels[:train_len]\\n\\nx_test = x_features[train_len:]\\ny_test = y_labels[train_len:]\\n\\nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\\n\\nprint(df.columns)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read labels file\n",
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "\n",
    "labels_df = pd.read_csv(\"processedLabels.csv\")\n",
    "\n",
    "df[\"labels\"] = labels_df\n",
    "\n",
    "y_labels = np.array(labels_df).T.flatten()\n",
    "\n",
    "df = df.drop(columns=['file_name','class_name','class_no'])\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df = df.dropna()\n",
    "all_features = df.to_numpy()\n",
    "\n",
    "train, test = train_test_split(all_features, shuffle=True, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = train[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "\n",
    "x_test = test[:,:-1]\n",
    "y_test = test[:,-1]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "'''\n",
    "total_len = len(x_features)\n",
    "train_len = int(0.9*total_len)\n",
    "\n",
    "print(total_len)\n",
    "print(train_len)\n",
    "\n",
    "x_train = x_features[:train_len]\n",
    "y_train = y_labels[:train_len]\n",
    "\n",
    "x_test = x_features[train_len:]\n",
    "y_test = y_labels[train_len:]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "print(df.columns)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DISTRIBUTION\n",
      "1: 0.5165285226718673\n",
      "2: 0.24085811799122378\n",
      "3: 0.10716723549488055\n",
      "4: 0.04222330570453437\n",
      "5: 0.025646026328620185\n",
      "6: 0.008191126279863481\n",
      "7: 0.059385665529010236\n",
      "\n",
      "TEST DISTRIBUTION\n",
      "1: 0.4906396255850234\n",
      "2: 0.25585023400936036\n",
      "3: 0.11076443057722309\n",
      "4: 0.04758190327613104\n",
      "5: 0.0249609984399376\n",
      "6: 0.009750390015600624\n",
      "7: 0.06006240249609984\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DISTRIBUTION\")\n",
    "for i in range(1,8):\n",
    "    print(f\"{i}: {np.sum(y_train == i)/len(y_train)}\")\n",
    "\n",
    "\n",
    "print(\"\\nTEST DISTRIBUTION\")\n",
    "for i in range(1,8):\n",
    "    print(f\"{i}: {np.sum(y_test == i)/len(y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOSE_x</th>\n",
       "      <th>NOSE_y</th>\n",
       "      <th>NOSE_score</th>\n",
       "      <th>LEFT_EYE_x</th>\n",
       "      <th>LEFT_EYE_y</th>\n",
       "      <th>LEFT_EYE_score</th>\n",
       "      <th>RIGHT_EYE_x</th>\n",
       "      <th>RIGHT_EYE_y</th>\n",
       "      <th>RIGHT_EYE_score</th>\n",
       "      <th>LEFT_EAR_x</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_KNEE_x</th>\n",
       "      <th>RIGHT_KNEE_y</th>\n",
       "      <th>RIGHT_KNEE_score</th>\n",
       "      <th>LEFT_ANKLE_x</th>\n",
       "      <th>LEFT_ANKLE_y</th>\n",
       "      <th>LEFT_ANKLE_score</th>\n",
       "      <th>RIGHT_ANKLE_x</th>\n",
       "      <th>RIGHT_ANKLE_y</th>\n",
       "      <th>RIGHT_ANKLE_score</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>201.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.419481</td>\n",
       "      <td>203.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.658552</td>\n",
       "      <td>199.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.702547</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.338401</td>\n",
       "      <td>214.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>198.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.145871</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>93.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.752774</td>\n",
       "      <td>96.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.692105</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.708114</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.682770</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.303428</td>\n",
       "      <td>115.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.197985</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>250.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.577688</td>\n",
       "      <td>254.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.565331</td>\n",
       "      <td>249.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.403487</td>\n",
       "      <td>261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.499749</td>\n",
       "      <td>229.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.289280</td>\n",
       "      <td>222.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.394534</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>181.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.684886</td>\n",
       "      <td>187.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.688225</td>\n",
       "      <td>178.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.511854</td>\n",
       "      <td>196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>174.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.243457</td>\n",
       "      <td>186.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.263143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968</th>\n",
       "      <td>183.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.763576</td>\n",
       "      <td>187.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.453835</td>\n",
       "      <td>181.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.544314</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>176.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.502712</td>\n",
       "      <td>230.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.785312</td>\n",
       "      <td>186.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.233179</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NOSE_x  NOSE_y  NOSE_score  LEFT_EYE_x  LEFT_EYE_y  LEFT_EYE_score  \\\n",
       "2068    201.0   111.0    0.419481       203.0       109.0        0.658552   \n",
       "3968     93.0    73.0    0.752774        96.0        68.0        0.692105   \n",
       "2731    250.0    61.0    0.577688       254.0        59.0        0.565331   \n",
       "6593    181.0   106.0    0.684886       187.0       100.0        0.688225   \n",
       "11968   183.0   159.0    0.763576       187.0       155.0        0.453835   \n",
       "\n",
       "       RIGHT_EYE_x  RIGHT_EYE_y  RIGHT_EYE_score  LEFT_EAR_x  ...  \\\n",
       "2068         199.0        109.0         0.702547       206.0  ...   \n",
       "3968          91.0         69.0         0.708114       104.0  ...   \n",
       "2731         249.0         57.0         0.403487       261.0  ...   \n",
       "6593         178.0        100.0         0.511854       196.0  ...   \n",
       "11968        181.0        154.0         0.544314       199.0  ...   \n",
       "\n",
       "       RIGHT_KNEE_x  RIGHT_KNEE_y  RIGHT_KNEE_score  LEFT_ANKLE_x  \\\n",
       "2068          197.0         152.0          0.338401         214.0   \n",
       "3968          105.0         135.0          0.682770         121.0   \n",
       "2731          220.0         121.0          0.499749         229.0   \n",
       "6593          174.0         198.0          0.148360         170.0   \n",
       "11968         176.0         207.0          0.502712         230.0   \n",
       "\n",
       "       LEFT_ANKLE_y  LEFT_ANKLE_score  RIGHT_ANKLE_x  RIGHT_ANKLE_y  \\\n",
       "2068          170.0          0.109490          198.0          167.0   \n",
       "3968          121.0          0.303428          115.0          119.0   \n",
       "2731          145.0          0.289280          222.0          142.0   \n",
       "6593          225.0          0.243457          186.0          191.0   \n",
       "11968         221.0          0.785312          186.0          219.0   \n",
       "\n",
       "       RIGHT_ANKLE_score  labels  \n",
       "2068            0.145871     2.0  \n",
       "3968            0.197985     4.0  \n",
       "2731            0.394534     7.0  \n",
       "6593            0.263143     1.0  \n",
       "11968           0.233179     4.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shell\\anaconda3\\envs\\cs229\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='sag')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = x_train\n",
    "X_test = x_test\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter = 1000,solver = 'sag')\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         1\n",
      "         1.0       0.89      0.96      0.93      1258\n",
      "         2.0       0.75      0.84      0.79       656\n",
      "         3.0       0.71      0.61      0.66       284\n",
      "         4.0       0.61      0.16      0.25       122\n",
      "         5.0       0.54      0.61      0.57        64\n",
      "         6.0       0.64      0.36      0.46        25\n",
      "         7.0       0.57      0.35      0.43       154\n",
      "\n",
      "    accuracy                           0.80      2564\n",
      "   macro avg       0.59      0.49      0.51      2564\n",
      "weighted avg       0.79      0.80      0.79      2564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shell\\anaconda3\\envs\\cs229\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shell\\anaconda3\\envs\\cs229\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shell\\anaconda3\\envs\\cs229\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8042121684867395\n"
     ]
    }
   ],
   "source": [
    "score = logreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.02788\n",
      "Feature: 1, Score: -0.08650\n",
      "Feature: 2, Score: -0.03933\n",
      "Feature: 3, Score: -0.00069\n",
      "Feature: 4, Score: 0.12844\n",
      "Feature: 5, Score: -0.04565\n",
      "Feature: 6, Score: 0.01109\n",
      "Feature: 7, Score: 0.07286\n",
      "Feature: 8, Score: -0.05461\n",
      "Feature: 9, Score: -0.03651\n",
      "Feature: 10, Score: -0.08949\n",
      "Feature: 11, Score: -0.07954\n",
      "Feature: 12, Score: -0.00383\n",
      "Feature: 13, Score: -0.08458\n",
      "Feature: 14, Score: -0.07379\n",
      "Feature: 15, Score: 0.03330\n",
      "Feature: 16, Score: -0.03881\n",
      "Feature: 17, Score: -0.07999\n",
      "Feature: 18, Score: -0.06292\n",
      "Feature: 19, Score: -0.02640\n",
      "Feature: 20, Score: -0.07702\n",
      "Feature: 21, Score: -0.03880\n",
      "Feature: 22, Score: -0.07620\n",
      "Feature: 23, Score: -0.06640\n",
      "Feature: 24, Score: 0.12215\n",
      "Feature: 25, Score: -0.09413\n",
      "Feature: 26, Score: -0.07450\n",
      "Feature: 27, Score: 0.03628\n",
      "Feature: 28, Score: 0.03867\n",
      "Feature: 29, Score: -0.04575\n",
      "Feature: 30, Score: -0.06556\n",
      "Feature: 31, Score: 0.04840\n",
      "Feature: 32, Score: -0.05598\n",
      "Feature: 33, Score: -0.00793\n",
      "Feature: 34, Score: 0.10694\n",
      "Feature: 35, Score: -0.06340\n",
      "Feature: 36, Score: -0.02366\n",
      "Feature: 37, Score: 0.03893\n",
      "Feature: 38, Score: -0.05096\n",
      "Feature: 39, Score: -0.03426\n",
      "Feature: 40, Score: 0.04718\n",
      "Feature: 41, Score: -0.04909\n",
      "Feature: 42, Score: 0.03831\n",
      "Feature: 43, Score: 0.04113\n",
      "Feature: 44, Score: -0.03865\n",
      "Feature: 45, Score: 0.00887\n",
      "Feature: 46, Score: -0.03324\n",
      "Feature: 47, Score: 0.00312\n",
      "Feature: 48, Score: -0.01124\n",
      "Feature: 49, Score: -0.01163\n",
      "Feature: 50, Score: -0.00495\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "importance = logreg.coef_[0]\n",
    "\n",
    "for i,j in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,j))\n",
    "\n",
    "pyplot.bar([X for X in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38d722011ef30cc44693f62b5a1008120e58804130fbdca4508dc2db07294492"
  },
  "kernelspec": {
   "display_name": "Python 3.6.6 ('cs229')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
